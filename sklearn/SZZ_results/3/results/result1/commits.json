{"19ad136223b62a631f8f331859f297730005e899":{"changes":{"sklearn\/__init__.py":"MODIFY","sklearn\/tree\/_classes.py":"MODIFY","sklearn\/utils\/tests\/test_testing.py":"MODIFY","sklearn\/metrics\/_classification.py":"MODIFY","sklearn\/ensemble\/tests\/test_voting.py":"MODIFY","sklearn\/utils\/deprecation.py":"MODIFY","sklearn\/inspection\/_partial_dependence.py":"MODIFY","sklearn\/feature_extraction\/tests\/test_feature_hasher.py":"MODIFY","sklearn\/utils\/tests\/test_utils.py":"MODIFY","doc\/developers\/tips.rst":"MODIFY","sklearn\/inspection\/tests\/test_plot_partial_dependence.py":"MODIFY","sklearn\/tests\/test_common.py":"MODIFY","sklearn\/linear_model\/_least_angle.py":"MODIFY","sklearn\/model_selection\/_search.py":"MODIFY","sklearn\/ensemble\/tests\/test_forest.py":"MODIFY","sklearn\/externals\/six.py":"MODIFY","sklearn\/utils\/__init__.py":"MODIFY","sklearn\/ensemble\/tests\/test_iforest.py":"MODIFY","sklearn\/ensemble\/_iforest.py":"MODIFY","sklearn\/utils\/tests\/test_linear_assignment.py":"MODIFY","sklearn\/metrics\/tests\/test_score_objects.py":"MODIFY","sklearn\/model_selection\/_split.py":"MODIFY","sklearn\/tests\/test_pipeline.py":"MODIFY","sklearn\/feature_extraction\/tests\/test_image.py":"MODIFY","sklearn\/metrics\/cluster\/tests\/test_unsupervised.py":"MODIFY","sklearn\/utils\/linear_assignment_.py":"MODIFY","sklearn\/utils\/validation.py":"MODIFY","sklearn\/ensemble\/_gb.py":"MODIFY","sklearn\/ensemble\/_base.py":"MODIFY","sklearn\/tests\/test_dummy.py":"MODIFY","sklearn\/pipeline.py":"MODIFY","sklearn\/utils\/tests\/test_deprecated_utils.py":"MODIFY","sklearn\/decomposition\/_sparse_pca.py":"MODIFY","sklearn\/compose\/_column_transformer.py":"MODIFY","sklearn\/utils\/tests\/test_validation.py":"MODIFY","sklearn\/datasets\/tests\/test_base.py":"MODIFY","sklearn\/tests\/test_docstring_parameters.py":"MODIFY","sklearn\/feature_extraction\/text.py":"MODIFY","sklearn\/linear_model\/tests\/test_logistic.py":"MODIFY","sklearn\/model_selection\/tests\/test_search.py":"MODIFY","sklearn\/model_selection\/tests\/test_split.py":"MODIFY","sklearn\/datasets\/_base.py":"MODIFY","sklearn\/externals\/joblib\/__init__.py":"MODIFY","sklearn\/svm\/_classes.py":"MODIFY","sklearn\/linear_model\/tests\/test_ridge.py":"MODIFY","sklearn\/tests\/test_calibration.py":"MODIFY","doc\/developers\/contributing.rst":"MODIFY","sklearn\/feature_extraction\/tests\/test_text.py":"MODIFY","sklearn\/utils\/tests\/test_estimator_checks.py":"MODIFY","sklearn\/metrics\/_scorer.py":"MODIFY","sklearn\/tests\/test_import_deprecations.py":"MODIFY","sklearn\/ensemble\/tests\/test_partial_dependence.py":"MODIFY","sklearn\/svm\/tests\/test_svm.py":"MODIFY","sklearn\/ensemble\/tests\/test_gradient_boosting.py":"MODIFY","sklearn\/utils\/tests\/test_extmath.py":"MODIFY","sklearn\/utils\/_testing.py":"MODIFY","sklearn\/tree\/tests\/test_tree.py":"MODIFY","sklearn\/metrics\/tests\/test_classification.py":"MODIFY","sklearn\/utils\/tests\/test_deprecation.py":"MODIFY","sklearn\/utils\/estimator_checks.py":"MODIFY","sklearn\/decomposition\/tests\/test_sparse_pca.py":"MODIFY","sklearn\/compose\/tests\/test_column_transformer.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY","sklearn\/cluster\/tests\/test_hierarchical.py":"MODIFY"},"diff":{"sklearn\/__init__.py":[{"add":[],"delete":["16","import warnings","27","# Make sure that DeprecationWarning within this package always gets printed","28","warnings.filterwarnings('always', category=DeprecationWarning,","29","                        module=r'^{0}\\.'.format(re.escape(__name__)))","30",""]}],"sklearn\/tree\/_classes.py":[{"add":["300","                          FutureWarning)","317","                          \"to the 'presort' parameter.\",","318","                          FutureWarning)","1231","        warnings.warn(msg, FutureWarning)","1239","        warnings.warn(msg, FutureWarning)"],"delete":["300","                          DeprecationWarning)","317","                          \"to the 'presort' parameter.\", DeprecationWarning)","1230","        warnings.warn(msg, DeprecationWarning)","1238","        warnings.warn(msg, DeprecationWarning)"]}],"sklearn\/utils\/tests\/test_testing.py":[{"add":["41","@pytest.mark.filterwarnings(\"ignore\",","42","                            category=FutureWarning)  # 0.24","48","@pytest.mark.filterwarnings(\"ignore\",","49","                            category=FutureWarning)  # 0.24","55","@pytest.mark.filterwarnings(\"ignore\",","56","                            category=FutureWarning)  # 0.24","63","@pytest.mark.filterwarnings(\"ignore\",","64","                            category=FutureWarning)  # 0.24","152","                                 category=FutureWarning))","259","            warnings.warn(\"yo\", FutureWarning)","674","    with pytest.warns(FutureWarning, match=msg):"],"delete":["41","@pytest.mark.filterwarnings(\"ignore\", category=DeprecationWarning)  # 0.24","47","@pytest.mark.filterwarnings(\"ignore\", category=DeprecationWarning)  # 0.24","53","@pytest.mark.filterwarnings(\"ignore\", category=DeprecationWarning)  # 0.24","60","@pytest.mark.filterwarnings(\"ignore\", category=DeprecationWarning)  # 0.24","148","                                 category=DeprecationWarning))","255","            warnings.warn(\"yo\", DeprecationWarning)","670","    with pytest.warns(DeprecationWarning, match=msg):"]}],"sklearn\/metrics\/_classification.py":[{"add":["643","                  'and multiclass classification tasks.',","644","                  FutureWarning)","2136","                      FutureWarning)"],"delete":["643","                  'and multiclass classification tasks.', DeprecationWarning)","2135","                      DeprecationWarning)"]}],"sklearn\/ensemble\/tests\/test_voting.py":[{"add":["560","    with pytest.warns(FutureWarning, match=msg):"],"delete":["560","    with pytest.warns(DeprecationWarning, match=msg):"]}],"sklearn\/utils\/deprecation.py":[{"add":["4","","67","            warnings.warn(msg, category=FutureWarning)","86","            warnings.warn(msg, category=FutureWarning)","101","            warnings.warn(msg, category=FutureWarning)","143","    warnings.warn(message, FutureWarning)"],"delete":["66","            warnings.warn(msg, category=DeprecationWarning)","85","            warnings.warn(msg, category=DeprecationWarning)","100","            warnings.warn(msg, category=DeprecationWarning)","142","    warnings.warn(message, DeprecationWarning)"]}],"sklearn\/inspection\/_partial_dependence.py":[{"add":["646","                      FutureWarning)"],"delete":["646","                      DeprecationWarning)"]}],"sklearn\/feature_extraction\/tests\/test_feature_hasher.py":[{"add":["146","@ignore_warnings(category=FutureWarning)"],"delete":["146","@ignore_warnings(category=DeprecationWarning)"]}],"sklearn\/utils\/tests\/test_utils.py":[{"add":["69","        assert issubclass(w[0].category, FutureWarning)","85","        assert issubclass(w[0].category, FutureWarning)","641","            FutureWarning, \"deprecated in version 0.20.1\",","642","            *args, **kw)"],"delete":["69","        assert issubclass(w[0].category, DeprecationWarning)","85","        assert issubclass(w[0].category, DeprecationWarning)","641","            DeprecationWarning, \"deprecated in version 0.20.1\", *args, **kw)"]}],"doc\/developers\/tips.rst":[{"add":["104","Since our continuous integration tests will error if","105","``FutureWarning`` isn't properly caught,","106","it is also recommended to run ``pytest`` along with the","107","``-Werror::FutureWarning`` flag."],"delete":["104","Since our continuous integration tests will error if ``DeprecationWarning``","105","or ``FutureWarning`` aren't properly caught, it is also recommended to run","106","``pytest`` along with the ``-Werror::DeprecationWarning`` and","107","``-Werror::FutureWarning`` flags."]}],"sklearn\/inspection\/tests\/test_plot_partial_dependence.py":[{"add":["375","    with pytest.warns(FutureWarning, match=msg):"],"delete":["375","    with pytest.warns(DeprecationWarning, match=msg):"]}],"sklearn\/tests\/test_common.py":[{"add":["93","    with ignore_warnings(category=(FutureWarning,","94","                                   ConvergenceWarning,","122","@ignore_warnings(category=(DeprecationWarning, FutureWarning))"],"delete":["93","    with ignore_warnings(category=(DeprecationWarning, ConvergenceWarning,","121","@ignore_warnings(category=DeprecationWarning)"]}],"sklearn\/linear_model\/_least_angle.py":[{"add":["159","                      FutureWarning)"],"delete":["159","                      DeprecationWarning)"]}],"sklearn\/model_selection\/_search.py":[{"add":["817","                \"removed in 0.24.\", FutureWarning"],"delete":["817","                \"removed in 0.24.\", DeprecationWarning"]}],"sklearn\/ensemble\/tests\/test_forest.py":[{"add":["1240","        est = assert_warns_message(FutureWarning,","1241","                                   \"min_impurity_decrease\","],"delete":["1240","        est = assert_warns_message(DeprecationWarning, \"min_impurity_decrease\","]}],"sklearn\/externals\/six.py":[{"add":["30","              \"(https:\/\/pypi.org\/project\/six\/).\", FutureWarning)"],"delete":["30","              \"(https:\/\/pypi.org\/project\/six\/).\", DeprecationWarning)"]}],"sklearn\/utils\/__init__.py":[{"add":["1183","        with ignore_warnings(category=FutureWarning):"],"delete":["1183","        with ignore_warnings(category=DeprecationWarning):"]}],"sklearn\/ensemble\/tests\/test_iforest.py":[{"add":["322","    with pytest.warns(FutureWarning, match=warn_msg):"],"delete":["322","    with pytest.warns(DeprecationWarning, match=warn_msg):"]}],"sklearn\/ensemble\/_iforest.py":[{"add":["235","                    FutureWarning"],"delete":["235","                    DeprecationWarning"]}],"sklearn\/utils\/tests\/test_linear_assignment.py":[{"add":["10","@pytest.mark.filterwarnings(","11","  \"ignore::FutureWarning\")"],"delete":["10","@pytest.mark.filterwarnings(\"ignore::DeprecationWarning\")"]}],"sklearn\/metrics\/tests\/test_score_objects.py":[{"add":["561","    with pytest.warns(FutureWarning):"],"delete":["561","    with pytest.warns(DeprecationWarning):"]}],"sklearn\/model_selection\/_split.py":[{"add":["295","                FutureWarning","2170","        warnings.simplefilter(\"always\", FutureWarning)","2176","            if len(w) and w[0].category == FutureWarning:"],"delete":["295","                DeprecationWarning","2170","        warnings.simplefilter(\"always\", DeprecationWarning)","2176","            if len(w) and w[0].category == DeprecationWarning:"]}],"sklearn\/tests\/test_pipeline.py":[{"add":["1190","    with pytest.warns(FutureWarning, match=msg):","1195","    with pytest.warns(FutureWarning, match=msg):"],"delete":["1190","    with pytest.warns(DeprecationWarning, match=msg):","1195","    with pytest.warns(DeprecationWarning, match=msg):"]}],"sklearn\/feature_extraction\/tests\/test_image.py":[{"add":["342","    with pytest.warns(FutureWarning, match=msg):"],"delete":["342","    with pytest.warns(DeprecationWarning, match=msg):"]}],"sklearn\/metrics\/cluster\/tests\/test_unsupervised.py":[{"add":["227","    assert_warns_message(FutureWarning, depr_message,"],"delete":["227","    assert_warns_message(DeprecationWarning, depr_message,"]}],"sklearn\/utils\/linear_assignment_.py":[{"add":["15","","21","    FutureWarning)","127","        FutureWarning)"],"delete":["20","    DeprecationWarning)","126","        DeprecationWarning)"]}],"sklearn\/utils\/validation.py":[{"add":["437","            FutureWarning, stacklevel=2)","931","                      \"argument is ignored.\", FutureWarning)","935","                      \"argument is ignored.\", FutureWarning)","1145","                          FutureWarning)"],"delete":["437","            DeprecationWarning, stacklevel=2)","931","                      \"argument is ignored.\", DeprecationWarning)","935","                      \"argument is ignored.\", DeprecationWarning)","1145","                          DeprecationWarning)"]}],"sklearn\/ensemble\/_gb.py":[{"add":["1341","                          FutureWarning)"],"delete":["1341","                          DeprecationWarning)"]}],"sklearn\/ensemble\/_base.py":[{"add":["232","                \"Use the string 'drop' instead.\", FutureWarning"],"delete":["232","                \"Use the string 'drop' instead.\", DeprecationWarning"]}],"sklearn\/tests\/test_dummy.py":[{"add":["763","    with pytest.warns(FutureWarning,"],"delete":["763","    with pytest.warns(DeprecationWarning,"]}],"sklearn\/pipeline.py":[{"add":["851","                              FutureWarning)"],"delete":["851","                              DeprecationWarning)"]}],"sklearn\/utils\/tests\/test_deprecated_utils.py":[{"add":["20","    with pytest.warns(FutureWarning,","21","                      match=\"removed in version 0.24\"):","27","    with pytest.warns(FutureWarning,","28","                      match=\"removed in version 0.24\"):","34","    with pytest.warns(FutureWarning,","35","                      match=\"removed in version 0.24\"):","41","    with pytest.warns(FutureWarning,","42","                      match=\"removed in version 0.24\"):","48","    with pytest.warns(FutureWarning,","49","                      match=\"removed in version 0.24\"):","55","    with pytest.warns(FutureWarning,","56","                      match=\"removed in version 0.24\"):","79","    with pytest.warns(FutureWarning,","80","                      match=\"removed in version 0.24\"):","86","    with pytest.warns(FutureWarning,","87","                      match=\"removed in version 0.24\"):","93","    with pytest.warns(FutureWarning,","94","                      match=\"removed in version 0.24\"):"],"delete":["20","    with pytest.warns(DeprecationWarning, match=\"removed in version 0.24\"):","26","    with pytest.warns(DeprecationWarning, match=\"removed in version 0.24\"):","32","    with pytest.warns(DeprecationWarning, match=\"removed in version 0.24\"):","38","    with pytest.warns(DeprecationWarning, match=\"removed in version 0.24\"):","44","    with pytest.warns(DeprecationWarning, match=\"removed in version 0.24\"):","50","    with pytest.warns(DeprecationWarning, match=\"removed in version 0.24\"):","73","    with pytest.warns(DeprecationWarning, match=\"removed in version 0.24\"):","79","    with pytest.warns(DeprecationWarning, match=\"removed in version 0.24\"):","85","    with pytest.warns(DeprecationWarning, match=\"removed in version 0.24\"):"]}],"sklearn\/decomposition\/_sparse_pca.py":[{"add":["22","                \" constructor.\", FutureWarning"],"delete":["22","                \" constructor.\", DeprecationWarning"]}],"sklearn\/compose\/_column_transformer.py":[{"add":["424","                          FutureWarning)"],"delete":["424","                          DeprecationWarning)"]}],"sklearn\/utils\/tests\/test_validation.py":[{"add":["452","            warnings.simplefilter(\"ignore\", FutureWarning)  # 0.23","487","    with pytest.warns(FutureWarning,","490","    with pytest.warns(FutureWarning,","727","        FutureWarning,","731","        FutureWarning,","801","        warnings.simplefilter(\"ignore\", FutureWarning)  # 0.23","820","        warnings.simplefilter(\"ignore\", FutureWarning)  # 0.23","1009","    with pytest.warns(FutureWarning,","1013","    with pytest.warns(FutureWarning,","1021","    with pytest.warns(FutureWarning,","1033","    with pytest.warns(FutureWarning,","1037","    with pytest.warns(FutureWarning,","1046","    with pytest.warns(FutureWarning,","1050","    with pytest.warns(FutureWarning,"],"delete":["452","            warnings.simplefilter(\"ignore\", DeprecationWarning)  # 0.23","487","    with pytest.warns(DeprecationWarning,","490","    with pytest.warns(DeprecationWarning,","727","        DeprecationWarning,","731","        DeprecationWarning,","801","        warnings.simplefilter(\"ignore\", DeprecationWarning)  # 0.23","820","        warnings.simplefilter(\"ignore\", DeprecationWarning)  # 0.23","1009","    with pytest.warns(DeprecationWarning,","1013","    with pytest.warns(DeprecationWarning,","1021","    with pytest.warns(DeprecationWarning,","1033","    with pytest.warns(DeprecationWarning,","1037","    with pytest.warns(DeprecationWarning,","1046","    with pytest.warns(DeprecationWarning,","1050","    with pytest.warns(DeprecationWarning,"]}],"sklearn\/datasets\/tests\/test_base.py":[{"add":["294","        warnings.warn(msg, FutureWarning)","298","        warnings.warn(\"unrelated warning\", FutureWarning)","314","    with pytest.warns(FutureWarning, match=msg):","329","    with pytest.warns(FutureWarning, match=\"unrelated warning\"):"],"delete":["294","        warnings.warn(msg, DeprecationWarning)","298","        warnings.warn(\"unrelated warning\", DeprecationWarning)","314","    with pytest.warns(DeprecationWarning, match=msg):","329","    with pytest.warns(DeprecationWarning, match=\"unrelated warning\"):"]}],"sklearn\/tests\/test_docstring_parameters.py":[{"add":["21","","22","# walk_packages() ignores DeprecationWarnings, now we need to ignore","23","# FutureWarnings","24","with warnings.catch_warnings():","25","    warnings.simplefilter('ignore', FutureWarning)","26","    PUBLIC_MODULES = set([","27","        pckg[1] for pckg in walk_packages(prefix='sklearn.',","28","                                          path=sklearn.__path__)","29","        if not (\"._\" in pckg[1] or \".tests.\" in pckg[1])","30","    ])","54","@pytest.mark.filterwarnings('ignore::FutureWarning')","135","@ignore_warnings(category=FutureWarning)"],"delete":["21","PUBLIC_MODULES = set([pckg[1] for pckg in walk_packages(prefix='sklearn.',","22","                                                        path=sklearn.__path__)","23","                      if not (\"._\" in pckg[1] or \".tests.\" in pckg[1])])","127","@ignore_warnings(category=DeprecationWarning)"]}],"sklearn\/feature_extraction\/text.py":[{"add":["1839","            warnings.warn(msg, FutureWarning)"],"delete":["1839","            warnings.warn(msg, DeprecationWarning)"]}],"sklearn\/linear_model\/tests\/test_logistic.py":[{"add":["1731","    assert_warns_message(FutureWarning,"],"delete":["1731","    assert_warns_message(DeprecationWarning,"]}],"sklearn\/model_selection\/tests\/test_search.py":[{"add":["1696","    with pytest.warns(FutureWarning,","1736","    with pytest.warns(FutureWarning, match=depr_msg):"],"delete":["1696","    with pytest.warns(DeprecationWarning,","1736","    with pytest.warns(DeprecationWarning, match=depr_msg):"]}],"sklearn\/model_selection\/tests\/test_split.py":[{"add":["1425","        warnings.simplefilter(\"ignore\", FutureWarning)","1592","    with pytest.warns(FutureWarning,"],"delete":["1425","        warnings.simplefilter(\"ignore\", DeprecationWarning)","1592","    with pytest.warns(DeprecationWarning,"]}],"sklearn\/datasets\/_base.py":[{"add":["934","            warnings.warn(message=message, category=FutureWarning)"],"delete":["934","            warnings.warn(message=message, category=DeprecationWarning)"]}],"sklearn\/externals\/joblib\/__init__.py":[{"add":["14","    warnings.warn(msg, category=FutureWarning)"],"delete":["14","    warnings.warn(msg, category=DeprecationWarning)"]}],"sklearn\/svm\/_classes.py":[{"add":["225","                          FutureWarning)","414","                          FutureWarning)"],"delete":["225","                          DeprecationWarning)","414","                          DeprecationWarning)"]}],"sklearn\/linear_model\/tests\/test_ridge.py":[{"add":["524","    # ignore warning from GridSearchCV: FutureWarning: The default","525","    # of the `iid` parameter will change from True to False in version 0.22","526","    # and will be removed in 0.24","527","    with ignore_warnings(category=FutureWarning):"],"delete":["524","    # ignore warning from GridSearchCV: DeprecationWarning: The default of the","525","    # `iid` parameter will change from True to False in version 0.22 and will","526","    # be removed in 0.24","527","    with ignore_warnings(category=DeprecationWarning):"]}],"sklearn\/tests\/test_calibration.py":[{"add":["322","@ignore_warnings(category=FutureWarning)"],"delete":["322","@ignore_warnings(category=(DeprecationWarning, FutureWarning))"]}],"doc\/developers\/contributing.rst":[{"add":["828","If a parameter has to be deprecated, a ``FutureWarning`` warning","829","must be raised too.","837","                          \"will be removed in 0.15.\",","838","                          FutureWarning)","853","                            \"will be removed in 0.15.\",","854","                            FutureWarning)"],"delete":["828","If a parameter has to be deprecated, use ``DeprecationWarning`` appropriately.","836","                          \"will be removed in 0.15.\", DeprecationWarning)","851","                            \"will be removed in 0.15.\", DeprecationWarning)"]}],"sklearn\/feature_extraction\/tests\/test_text.py":[{"add":["545","    with pytest.warns(FutureWarning, match=msg):","1370","    with pytest.warns(FutureWarning, match=msg):"],"delete":["545","    with pytest.warns(DeprecationWarning, match=msg):","1370","    with pytest.warns(DeprecationWarning, match=msg):"]}],"sklearn\/utils\/tests\/test_estimator_checks.py":[{"add":["465","        with ignore_warnings(category=FutureWarning):","475","        with ignore_warnings(category=FutureWarning):"],"delete":["465","        with ignore_warnings(category=(FutureWarning, DeprecationWarning)):","475","        with ignore_warnings(category=(FutureWarning, DeprecationWarning)):"]}],"sklearn\/metrics\/_scorer.py":[{"add":["165","                          category=FutureWarning,"],"delete":["165","                          category=DeprecationWarning,"]}],"sklearn\/tests\/test_import_deprecations.py":[{"add":["38","    with pytest.warns(FutureWarning,"],"delete":["38","    with pytest.warns(DeprecationWarning,"]}],"sklearn\/ensemble\/tests\/test_partial_dependence.py":[{"add":["29","@ignore_warnings(category=FutureWarning)","68","@ignore_warnings(category=FutureWarning)","84","@ignore_warnings(category=FutureWarning)","98","@ignore_warnings(category=FutureWarning)","124","@ignore_warnings(category=FutureWarning)","153","@ignore_warnings(category=FutureWarning)","189","@ignore_warnings(category=FutureWarning)","226","@ignore_warnings(category=FutureWarning)","275","    with pytest.warns(FutureWarning, match=warn_msg):"],"delete":["29","@ignore_warnings(category=DeprecationWarning)","68","@ignore_warnings(category=DeprecationWarning)","84","@ignore_warnings(category=DeprecationWarning)","98","@ignore_warnings(category=DeprecationWarning)","124","@ignore_warnings(category=DeprecationWarning)","153","@ignore_warnings(category=DeprecationWarning)","189","@ignore_warnings(category=DeprecationWarning)","226","@ignore_warnings(category=DeprecationWarning)","275","    with pytest.warns(DeprecationWarning, match=warn_msg):"]}],"sklearn\/svm\/tests\/test_svm.py":[{"add":["748","    assert_warns_message(FutureWarning,","753","    assert_warns_message(FutureWarning,","759","    assert_warns_message(FutureWarning,","765","    assert_warns_message(FutureWarning,"],"delete":["748","    assert_warns_message(DeprecationWarning,","753","    assert_warns_message(DeprecationWarning,","759","    assert_warns_message(DeprecationWarning,","765","    assert_warns_message(DeprecationWarning,"]}],"sklearn\/ensemble\/tests\/test_gradient_boosting.py":[{"add":["1089","    est = assert_warns_message(FutureWarning,","1090","                               \"min_impurity_decrease\",","1403","    with pytest.warns(FutureWarning,"],"delete":["1089","    est = assert_warns_message(DeprecationWarning, \"min_impurity_decrease\",","1402","    with pytest.warns(DeprecationWarning,"]}],"sklearn\/utils\/tests\/test_extmath.py":[{"add":["650","    with pytest.warns(FutureWarning, match=msg):"],"delete":["650","    with pytest.warns(DeprecationWarning, match=msg):"]}],"sklearn\/utils\/_testing.py":[{"add":["53","","124","        if hasattr(np, 'FutureWarning'):","170","        if hasattr(np, 'FutureWarning'):","246","        if hasattr(np, 'FutureWarning'):","496","                      FutureWarning)","501","                      FutureWarning)","506","                      FutureWarning)","519","        with ignore_warnings(category=FutureWarning):"],"delete":["123","        if hasattr(np, 'VisibleDeprecationWarning'):","169","        if hasattr(np, 'VisibleDeprecationWarning'):","245","        if hasattr(np, 'VisibleDeprecationWarning'):","495","                      DeprecationWarning)","500","                      DeprecationWarning)","505","                      DeprecationWarning)","518","        with ignore_warnings(category=DeprecationWarning):"]}],"sklearn\/tree\/tests\/test_tree.py":[{"add":["528","        with ignore_warnings(category=FutureWarning):","809","            assert_warns(FutureWarning, est.fit, X, y)","825","        assert_warns_message(FutureWarning,","1625","    with pytest.warns(FutureWarning,","1959","    with pytest.warns(FutureWarning, match=match):","1963","    with pytest.warns(FutureWarning, match=match):"],"delete":["528","        with ignore_warnings(category=DeprecationWarning):","809","            assert_warns(DeprecationWarning, est.fit, X, y)","825","        assert_warns_message(DeprecationWarning,","1625","    with pytest.warns(DeprecationWarning,","1959","    with pytest.warns(DeprecationWarning, match=match):","1963","    with pytest.warns(DeprecationWarning, match=match):"]}],"sklearn\/metrics\/tests\/test_classification.py":[{"add":["1143","    assert_warns_message(FutureWarning,","2214","    jss = partial(assert_warns, FutureWarning,","2215","                  jaccard_similarity_score)"],"delete":["1143","    assert_warns_message(DeprecationWarning,","2214","    jss = partial(assert_warns, DeprecationWarning, jaccard_similarity_score)"]}],"sklearn\/utils\/tests\/test_deprecation.py":[{"add":["38","    assert_warns_message(FutureWarning, 'qwerty', MockClass1)","39","    assert_warns_message(FutureWarning, 'mockclass2_method',","41","    assert_warns_message(FutureWarning, 'deprecated', MockClass3)","42","    val = assert_warns_message(FutureWarning, 'deprecated',","43","                               mock_function)"],"delete":["38","    assert_warns_message(DeprecationWarning, 'qwerty', MockClass1)","39","    assert_warns_message(DeprecationWarning, 'mockclass2_method',","41","    assert_warns_message(DeprecationWarning, 'deprecated', MockClass3)","42","    val = assert_warns_message(DeprecationWarning, 'deprecated', mock_function)"]}],"sklearn\/utils\/estimator_checks.py":[{"add":["146","@ignore_warnings(category=FutureWarning)","655","    with ignore_warnings(category=FutureWarning):","660","        with ignore_warnings(category=FutureWarning):","666","            with ignore_warnings(category=FutureWarning):","701","@ignore_warnings(category=FutureWarning)","728","@ignore_warnings(category=(FutureWarning))","745","@ignore_warnings(category=(FutureWarning))","765","@ignore_warnings(category=FutureWarning)","803","@ignore_warnings(category=(FutureWarning, UserWarning))","902","@ignore_warnings(category=FutureWarning)","957","@ignore_warnings(category=FutureWarning)","1007","@ignore_warnings(category=FutureWarning)","1138","@ignore_warnings(category=FutureWarning)","1152","@ignore_warnings(category=FutureWarning)","1168","@ignore_warnings(category=FutureWarning)","1344","@ignore_warnings(category=FutureWarning)","1367","@ignore_warnings(category=FutureWarning)","1387","        with ignore_warnings(category=FutureWarning):","1500","@ignore_warnings(category=FutureWarning)","1526","@ignore_warnings(category=FutureWarning)","1584","@ignore_warnings(category=FutureWarning)","1607","@ignore_warnings(category=FutureWarning)","1666","@ignore_warnings(category=FutureWarning)","1681","@ignore_warnings(category=FutureWarning)","1691","    with ignore_warnings(category=FutureWarning):","1934","@ignore_warnings(category=(FutureWarning))","1968","@ignore_warnings(category=FutureWarning)","2007","@ignore_warnings(category=FutureWarning)","2139","@ignore_warnings(category=FutureWarning)","2167","@ignore_warnings(category=FutureWarning)","2235","        assert_warns_message(FutureWarning, msg, func, X)","2238","@ignore_warnings(category=FutureWarning)","2290","@ignore_warnings(category=FutureWarning)","2310","@ignore_warnings(category=FutureWarning)","2349","@ignore_warnings(category=FutureWarning)","2388","@ignore_warnings(category=FutureWarning)","2422","@ignore_warnings(category=FutureWarning)","2445","@ignore_warnings(category=FutureWarning)","2455","@ignore_warnings(category=FutureWarning)","2463","@ignore_warnings(category=FutureWarning)","2490","    with ignore_warnings(category=FutureWarning):","2574","@ignore_warnings(category=FutureWarning)","2608","@ignore_warnings(category=FutureWarning)","2634","@ignore_warnings(category=FutureWarning)","2646","@ignore_warnings(category=FutureWarning)","2700","@ignore_warnings(category=FutureWarning)","2711","@ignore_warnings(category=FutureWarning)"],"delete":["146","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","655","    with ignore_warnings(category=DeprecationWarning):","660","        with ignore_warnings(category=(DeprecationWarning, FutureWarning)):","666","            with ignore_warnings(category=(DeprecationWarning, FutureWarning)):","701","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","728","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","745","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","765","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","803","@ignore_warnings(category=(DeprecationWarning, FutureWarning, UserWarning))","902","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","957","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","1007","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","1138","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","1152","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","1168","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","1344","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","1367","@ignore_warnings(category=DeprecationWarning)","1387","        with ignore_warnings(category=(DeprecationWarning, FutureWarning)):","1500","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","1526","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","1584","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","1607","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","1666","@ignore_warnings(category=DeprecationWarning)","1681","@ignore_warnings(category=DeprecationWarning)","1691","    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):","1967","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2006","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2138","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2166","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2234","        assert_warns_message(DeprecationWarning, msg, func, X)","2237","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2289","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2309","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2348","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2387","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2421","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2444","@ignore_warnings(category=DeprecationWarning)","2454","@ignore_warnings(category=DeprecationWarning)","2462","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2489","    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):","2573","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2607","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2633","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2645","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2699","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","2710","@ignore_warnings(category=(DeprecationWarning, FutureWarning))"]}],"sklearn\/decomposition\/tests\/test_sparse_pca.py":[{"add":["197","    with pytest.warns(FutureWarning, match=warn_msg):"],"delete":["15","","198","    with pytest.warns(DeprecationWarning, match=warn_msg):"]}],"sklearn\/compose\/tests\/test_column_transformer.py":[{"add":["502","    with pytest.warns(FutureWarning, match=msg):","1110","    with pytest.warns(FutureWarning, match=warn_msg):","1135","    with pytest.warns(FutureWarning, match=msg):","1141","    with pytest.warns(FutureWarning, match=msg):","1151","    with pytest.warns(FutureWarning, match=msg):"],"delete":["502","    with pytest.warns(DeprecationWarning, match=msg):","1110","    with pytest.warns(DeprecationWarning, match=warn_msg):","1135","    with pytest.warns(DeprecationWarning, match=msg):","1141","    with pytest.warns(DeprecationWarning, match=msg):","1151","    with pytest.warns(DeprecationWarning, match=msg):"]}],"doc\/whats_new\/v0.22.rst":[{"add":["15","","16","Deprecations: using ``FutureWarning`` from now on","17","-------------------------------------------------","18","","19","When deprecating a feature, previous versions of scikit-learn used to raise","20","a ``DeprecationWarning``. Since the ``DeprecationWarnings`` aren't shown by","21","default by Python, scikit-learn needed to resort to a custom warning filter","22","that would always show the warnings.","23","","24","This filter is now removed, and starting from 0.22 scikit-learn will show","25","``FutureWarnings`` for deprecations. :pr:`15080` by `Nicolas Hug`_.","26","","27",""],"delete":[]}],"sklearn\/cluster\/tests\/test_hierarchical.py":[{"add":["736","    with pytest.warns(FutureWarning, match=match):"],"delete":["736","    with pytest.warns(DeprecationWarning, match=match):"]}]}},"ac72a4844ad7b9c170af546050eb9147ed8318bf":{"changes":{"doc\/whats_new\/v0.22.rst":"MODIFY","sklearn\/cluster\/mean_shift_.py":"MODIFY","sklearn\/cluster\/tests\/test_mean_shift.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.22.rst":[{"add":["91","- |Fix| :class:`~cluster.MeanShift` now accepts a :term:`max_iter` with a","92","  default value of 300 instead of always using the default 300. It also now","93","  exposes an ``n_iter_`` indicating the maximum number of iterations performed","94","  on each seed. :pr:`15120` by `Adrin Jalali`_.","95",""],"delete":[]}],"sklearn\/cluster\/mean_shift_.py":[{"add":["103","            break","105","    return tuple(my_mean), len(points_within), completed_iterations","181","    model = MeanShift(bandwidth=bandwidth, seeds=seeds,","182","                      min_bin_freq=min_bin_freq,","183","                      bin_seeding=bin_seeding,","184","                      cluster_all=cluster_all, n_jobs=n_jobs,","185","                      max_iter=max_iter).fit(X)","186","    return model.cluster_centers_, model.labels_","290","    max_iter : int, default=300","291","        Maximum number of iterations, per seed point before the clustering","292","        operation terminates (for that seed point), if has not converged yet.","293","","294","        .. versionadded:: 0.22","295","","304","    n_iter_ : int","305","        Maximum number of iterations performed on each seed.","306","","307","        .. versionadded:: 0.22","308","","349","                 min_bin_freq=1, cluster_all=True, n_jobs=None, max_iter=300):","356","        self.max_iter = max_iter","370","        bandwidth = self.bandwidth","371","        if bandwidth is None:","372","            bandwidth = estimate_bandwidth(X, n_jobs=self.n_jobs)","373","        elif bandwidth <= 0:","374","            raise ValueError(\"bandwidth needs to be greater than zero or None,\"","375","                             \" got %f\" % bandwidth)","376","","377","        seeds = self.seeds","378","        if seeds is None:","379","            if self.bin_seeding:","380","                seeds = get_bin_seeds(X, bandwidth, self.min_bin_freq)","381","            else:","382","                seeds = X","383","        n_samples, n_features = X.shape","384","        center_intensity_dict = {}","385","","386","        # We use n_jobs=1 because this will be used in nested calls under","387","        # parallel calls to _mean_shift_single_seed so there is no need for","388","        # for further parallelism.","389","        nbrs = NearestNeighbors(radius=bandwidth, n_jobs=1).fit(X)","390","","391","        # execute iterations on all seeds in parallel","392","        all_res = Parallel(n_jobs=self.n_jobs)(","393","            delayed(_mean_shift_single_seed)","394","            (seed, X, nbrs, self.max_iter) for seed in seeds)","395","        # copy results in a dictionary","396","        for i in range(len(seeds)):","397","            if all_res[i][1]:  # i.e. len(points_within) > 0","398","                center_intensity_dict[all_res[i][0]] = all_res[i][1]","399","","400","        self.n_iter_ = max([x[2] for x in all_res])","401","","402","        if not center_intensity_dict:","403","            # nothing near seeds","404","            raise ValueError(\"No point was within bandwidth=%f of any seed.\"","405","                             \" Try a different seeding strategy \\","406","                             or increase the bandwidth.\"","407","                             % bandwidth)","408","","409","        # POST PROCESSING: remove near duplicate points","410","        # If the distance between two kernels is less than the bandwidth,","411","        # then we have to remove one because it is a duplicate. Remove the","412","        # one with fewer points.","413","","414","        sorted_by_intensity = sorted(center_intensity_dict.items(),","415","                                     key=lambda tup: (tup[1], tup[0]),","416","                                     reverse=True)","417","        sorted_centers = np.array([tup[0] for tup in sorted_by_intensity])","418","        unique = np.ones(len(sorted_centers), dtype=np.bool)","419","        nbrs = NearestNeighbors(radius=bandwidth,","420","                                n_jobs=self.n_jobs).fit(sorted_centers)","421","        for i, center in enumerate(sorted_centers):","422","            if unique[i]:","423","                neighbor_idxs = nbrs.radius_neighbors([center],","424","                                                      return_distance=False)[0]","425","                unique[neighbor_idxs] = 0","426","                unique[i] = 1  # leave the current point as unique","427","        cluster_centers = sorted_centers[unique]","428","","429","        # ASSIGN LABELS: a point belongs to the cluster that it is closest to","430","        nbrs = NearestNeighbors(n_neighbors=1,","431","                                n_jobs=self.n_jobs).fit(cluster_centers)","432","        labels = np.zeros(n_samples, dtype=np.int)","433","        distances, idxs = nbrs.kneighbors(X)","434","        if self.cluster_all:","435","            labels = idxs.flatten()","436","        else:","437","            labels.fill(-1)","438","            bool_selector = distances.flatten() <= bandwidth","439","            labels[bool_selector] = idxs.flatten()[bool_selector]","440","","441","        self.cluster_centers_, self.labels_ = cluster_centers, labels"],"delete":["103","            return tuple(my_mean), len(points_within)","180","","181","    if bandwidth is None:","182","        bandwidth = estimate_bandwidth(X, n_jobs=n_jobs)","183","    elif bandwidth <= 0:","184","        raise ValueError(\"bandwidth needs to be greater than zero or None,\"","185","                         \" got %f\" % bandwidth)","186","    if seeds is None:","187","        if bin_seeding:","188","            seeds = get_bin_seeds(X, bandwidth, min_bin_freq)","189","        else:","190","            seeds = X","191","    n_samples, n_features = X.shape","192","    center_intensity_dict = {}","193","","194","    # We use n_jobs=1 because this will be used in nested calls under","195","    # parallel calls to _mean_shift_single_seed so there is no need for","196","    # for further parallelism.","197","    nbrs = NearestNeighbors(radius=bandwidth, n_jobs=1).fit(X)","198","","199","    # execute iterations on all seeds in parallel","200","    all_res = Parallel(n_jobs=n_jobs)(","201","        delayed(_mean_shift_single_seed)","202","        (seed, X, nbrs, max_iter) for seed in seeds)","203","    # copy results in a dictionary","204","    for i in range(len(seeds)):","205","        if all_res[i] is not None:","206","            center_intensity_dict[all_res[i][0]] = all_res[i][1]","207","","208","    if not center_intensity_dict:","209","        # nothing near seeds","210","        raise ValueError(\"No point was within bandwidth=%f of any seed.\"","211","                         \" Try a different seeding strategy \\","212","                         or increase the bandwidth.\"","213","                         % bandwidth)","214","","215","    # POST PROCESSING: remove near duplicate points","216","    # If the distance between two kernels is less than the bandwidth,","217","    # then we have to remove one because it is a duplicate. Remove the","218","    # one with fewer points.","219","","220","    sorted_by_intensity = sorted(center_intensity_dict.items(),","221","                                 key=lambda tup: (tup[1], tup[0]),","222","                                 reverse=True)","223","    sorted_centers = np.array([tup[0] for tup in sorted_by_intensity])","224","    unique = np.ones(len(sorted_centers), dtype=np.bool)","225","    nbrs = NearestNeighbors(radius=bandwidth,","226","                            n_jobs=n_jobs).fit(sorted_centers)","227","    for i, center in enumerate(sorted_centers):","228","        if unique[i]:","229","            neighbor_idxs = nbrs.radius_neighbors([center],","230","                                                  return_distance=False)[0]","231","            unique[neighbor_idxs] = 0","232","            unique[i] = 1  # leave the current point as unique","233","    cluster_centers = sorted_centers[unique]","234","","235","    # ASSIGN LABELS: a point belongs to the cluster that it is closest to","236","    nbrs = NearestNeighbors(n_neighbors=1, n_jobs=n_jobs).fit(cluster_centers)","237","    labels = np.zeros(n_samples, dtype=np.int)","238","    distances, idxs = nbrs.kneighbors(X)","239","    if cluster_all:","240","        labels = idxs.flatten()","241","    else:","242","        labels.fill(-1)","243","        bool_selector = distances.flatten() <= bandwidth","244","        labels[bool_selector] = idxs.flatten()[bool_selector]","245","    return cluster_centers, labels","397","                 min_bin_freq=1, cluster_all=True, n_jobs=None):","417","        self.cluster_centers_, self.labels_ = \\","418","            mean_shift(X, bandwidth=self.bandwidth, seeds=self.seeds,","419","                       min_bin_freq=self.min_bin_freq,","420","                       bin_seeding=self.bin_seeding,","421","                       cluster_all=self.cluster_all, n_jobs=self.n_jobs)"]}],"sklearn\/cluster\/tests\/test_mean_shift.py":[{"add":["157","","158","","159","@pytest.mark.parametrize('max_iter', [1, 100])","160","def test_max_iter(max_iter):","161","    clusters1, _ = mean_shift(X, max_iter=max_iter)","162","    ms = MeanShift(max_iter=max_iter).fit(X)","163","    clusters2 = ms.cluster_centers_","164","","165","    assert ms.n_iter_ <= ms.max_iter","166","    assert len(clusters1) == len(clusters2)","167","","168","    for c1, c2 in zip(clusters1, clusters2):","169","        assert np.allclose(c1, c2)"],"delete":[]}]}},"8fe89ea5241d0301fa0ee5f9f02b3f3db2ee89d4":{"changes":{"sklearn\/impute\/_base.py":"MODIFY","sklearn\/utils\/estimator_checks.py":"MODIFY"},"diff":{"sklearn\/impute\/_base.py":[{"add":["670","                'X_types': ['2darray', 'string']}"],"delete":["670","                'X_types': ['2darray', 'str']}"]}],"sklearn\/utils\/estimator_checks.py":[{"add":["665","    if 'string' not in tags['X_types']:"],"delete":["665","    if 'str' not in tags['X_types']:"]}]}},"af82929bfa2dbac2453c22641969d4d69dd324f1":{"changes":{"sklearn\/svm\/libsvm.pyx":"MODIFY","sklearn\/svm\/base.py":"MODIFY","sklearn\/svm\/tests\/test_svm.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY"},"diff":{"sklearn\/svm\/libsvm.pyx":[{"add":["220","    if svm_type == 0 or svm_type == 1:","221","        n_class_SV = np.empty(n_class, dtype=np.int32)","222","        copy_nSV(n_class_SV.data, model)","223","    else:","224","        # OneClass and SVR are considered to have 2 classes","225","        n_class_SV = np.array([SV_len, SV_len], dtype=np.int32)"],"delete":["219","    # TODO: do only in classification","221","    n_class_SV = np.empty(n_class, dtype=np.int32)","222","    copy_nSV(n_class_SV.data, model)"]}],"sklearn\/svm\/base.py":[{"add":["246","        self.support_, self.support_vectors_, self._n_support, \\","270","            self.intercept_, self._n_support, \\","330","            X, self.support_, self.support_vectors_, self._n_support,","356","            self.probability, self._n_support,","409","            X, self.support_, self.support_vectors_, self._n_support,","435","            self.probability, self._n_support,","486","    @property","487","    def n_support_(self):","488","        try:","489","            check_is_fitted(self)","490","        except NotFittedError:","491","            raise AttributeError","492","","493","        svm_type = LIBSVM_IMPL.index(self._impl)","494","        if svm_type in (0, 1):","495","            return self._n_support","496","        else:","497","            # SVR and OneClass","498","            # _n_support has size 2, we make it size 1","499","            return np.array([self._n_support[0]])","500","","685","            X, self.support_, self.support_vectors_, self._n_support,","712","            self.probability, self._n_support,","721","            coef = _one_vs_one_coef(self.dual_coef_, self._n_support,"],"delete":["246","        self.support_, self.support_vectors_, self.n_support_, \\","270","            self.intercept_, self.n_support_, \\","330","            X, self.support_, self.support_vectors_, self.n_support_,","356","            self.probability, self.n_support_,","409","            X, self.support_, self.support_vectors_, self.n_support_,","435","            self.probability, self.n_support_,","670","            X, self.support_, self.support_vectors_, self.n_support_,","697","            self.probability, self.n_support_,","706","            coef = _one_vs_one_coef(self.dual_coef_, self.n_support_,"]}],"sklearn\/svm\/tests\/test_svm.py":[{"add":["1190","","1191","","1192","def test_n_support_oneclass_svr():","1193","    # Make n_support is correct for oneclass and SVR (used to be","1194","    # non-initialized)","1195","    # this is a non regression test for issue #14774","1196","    X = np.array([[0], [0.44], [0.45], [0.46], [1]])","1197","    clf = svm.OneClassSVM()","1198","    assert not hasattr(clf, 'n_support_')","1199","    clf.fit(X)","1200","    assert clf.n_support_ == clf.support_vectors_.shape[0]","1201","    assert clf.n_support_.size == 1","1202","    assert clf.n_support_ == 3","1203","","1204","    y = np.arange(X.shape[0])","1205","    reg = svm.SVR().fit(X, y)","1206","    assert reg.n_support_ == reg.support_vectors_.shape[0]","1207","    assert reg.n_support_.size == 1","1208","    assert reg.n_support_ == 4"],"delete":[]}],"doc\/whats_new\/v0.22.rst":[{"add":["539","- |Fix| The `n_support_` attribute of :class:`svm.SVR` and","540","  :class:`svm.OneClassSVM` was previously non-initialized, and had size 2. It","541","  has now size 1 with the correct value. :pr:`15099` by `Nicolas Hug`_.","542",""],"delete":[]}]}},"ff3af8deef29ee61f94a5c3229f9cfe0e6118e7e":{"changes":{"doc\/whats_new\/v0.22.rst":"MODIFY","sklearn\/decomposition\/nmf.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.22.rst":[{"add":["165","- |Efficiency| :class:`decomposition.NMF(solver='mu')` fitted on sparse input","166","  matrices now uses batching to avoid briefly allocating an array with size","167","  (#non-zero elements, n_components). :pr:`15257` by `Mart Willocx <Maocx>`_.","168",""],"delete":[]}],"sklearn\/decomposition\/nmf.py":[{"add":["11","import time","12","import warnings","13","from math import sqrt","15","from .cdnmf_fast import _update_cdnmf_fast","17","from ..exceptions import ConvergenceWarning","171","        n_vals = ii.shape[0]","172","        dot_vals = np.empty(n_vals)","173","        n_components = W.shape[1]","174","","175","        batch_size = max(n_components, n_vals \/\/ n_components)","176","        for start in range(0, n_vals, batch_size):","177","            batch = slice(start, start + batch_size)","178","            dot_vals[batch] = np.multiply(W[ii[batch], :],","179","                                          H.T[jj[batch], :]).sum(axis=1)","180",""],"delete":["8","from math import sqrt","9","import warnings","11","import time","12","","20","from ..exceptions import ConvergenceWarning","21","from .cdnmf_fast import _update_cdnmf_fast","172","        dot_vals = np.multiply(W[ii, :], H.T[jj, :]).sum(axis=1)"]}]}},"bd2cc1064829d9531558ae4e9c211ea85a9e628e":{"changes":{"sklearn\/cluster\/tests\/test_optics.py":"MODIFY"},"diff":{"sklearn\/cluster\/tests\/test_optics.py":[{"add":["111","                   xi=0.3).fit(X)"],"delete":["111","                   xi=0.1).fit(X)"]}]}},"d624bb1771e97f861c71d70735437233f4b2516f":{"changes":{"build_tools\/azure\/posix.yml":"MODIFY"},"diff":{"build_tools\/azure\/posix.yml":[{"add":["25","    - bash: sudo chown -R $USER $CONDA","26","      displayName: Take ownership of conda installation","27","      condition: eq(variables['DISTRIB'], 'conda')"],"delete":[]}]}},"d92f12a137827b0e6357a133db3de6a3c3f34bf7":{"changes":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":"MODIFY","sklearn\/linear_model\/coordinate_descent.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":[{"add":["890","","891","","892","def test_multi_task_lasso_cv_dtype():","893","    n_samples, n_features = 10, 3","894","    rng = np.random.RandomState(42)","895","    X = rng.binomial(1, .5, size=(n_samples, n_features))","896","    X = X.astype(int)  # make it explicit that X is int","897","    y = X[:, [0, 0]].copy()","898","    est = MultiTaskLassoCV(n_alphas=5, fit_intercept=True).fit(X, y)","899","    assert_array_almost_equal(est.coef_, [[1, 0, 0]] * 2, decimal=3)"],"delete":[]}],"sklearn\/linear_model\/coordinate_descent.py":[{"add":["1114","            X = check_array(X, 'csc', dtype=[np.float64, np.float32],","1115","                            copy=False)"],"delete":["1114","            X = check_array(X, 'csc', copy=False)"]}],"doc\/whats_new\/v0.22.rst":[{"add":["341","- |FIX| :class:`linear_model.MultiTaskLassoCV` and","342","  :class:`linear_model.MultiTaskElasticNetCV` with X of dtype int","343","  and `fit_intercept=True`.","344","  :pr:`15086` by :user:`Alex Gramfort <agramfort>`.","345",""],"delete":[]}]}},"db23c4ece02b55c51987d78420c7616917f82031":{"changes":{"sklearn\/compose\/tests\/test_target.py":"MODIFY","sklearn\/compose\/tests\/test_column_transformer.py":"MODIFY"},"diff":{"sklearn\/compose\/tests\/test_target.py":[{"add":["31","    with pytest.raises(ValueError,","32","                       match=\"'transformer' and functions\"","33","                       \" 'func'\/'inverse_func' cannot both be set.\"):","34","        regr.fit(X, y)","39","    with pytest.raises(TypeError, match=r\"fit\\(\\) got an unexpected \"","40","                       \"keyword argument 'sample_weight'\"):","41","        regr.fit(X, y, sample_weight=sample_weight)","44","    with pytest.raises(ValueError, match=\"When 'func' is provided, \"","45","                       \"'inverse_func' must also be provided\"):","46","        regr.fit(X, y)","264","    with pytest.raises(AssertionError):","265","        tt.fit(X, y.tolist())","266","    with pytest.raises(AssertionError):","267","        tt.predict(X)"],"delete":["9","from sklearn.utils.testing import assert_raises","10","from sklearn.utils.testing import assert_raises_regex","33","    assert_raises_regex(ValueError, \"'transformer' and functions\"","34","                        \" 'func'\/'inverse_func' cannot both be set.\",","35","                        regr.fit, X, y)","40","    assert_raises_regex(TypeError, r\"fit\\(\\) got an unexpected keyword \"","41","                        \"argument 'sample_weight'\", regr.fit, X, y,","42","                        sample_weight=sample_weight)","45","    assert_raises_regex(ValueError, \"When 'func' is provided, 'inverse_func'\"","46","                        \" must also be provided\", regr.fit, X, y)","264","    assert_raises(AssertionError, tt.fit, X, y.tolist())","265","    assert_raises(AssertionError, tt.predict, X)"]}],"sklearn\/compose\/tests\/test_column_transformer.py":[{"add":["649","    with pytest.raises(NotFittedError):","650","        ct.get_feature_names()"],"delete":["10","from sklearn.utils.testing import assert_raises","650","    assert_raises(NotFittedError, ct.get_feature_names)"]}]}},"3d606cf8ba18949c3083e460e9ccda393c6c20b2":{"changes":{"sklearn\/model_selection\/_validation.py":"MODIFY","sklearn\/model_selection\/tests\/test_search.py":"MODIFY","sklearn\/model_selection\/_search.py":"MODIFY"},"diff":{"sklearn\/model_selection\/_validation.py":[{"add":["496","        # clone after setting parameters in case any parameters","497","        # are estimators (like pipeline steps)","498","        # because pipeline doesn't clone steps in fit","499","        cloned_parameters = {}","500","        for k, v in parameters.items():","501","            cloned_parameters[k] = clone(v, safe=False)","502","","503","        estimator = estimator.set_params(**cloned_parameters)"],"delete":["496","        estimator.set_params(**parameters)"]}],"sklearn\/model_selection\/tests\/test_search.py":[{"add":["65","from sklearn.linear_model import Ridge, SGDClassifier, LinearRegression","200","def test_grid_search_pipeline_steps():","201","    # check that parameters that are estimators are cloned before fitting","202","    pipe = Pipeline([('regressor', LinearRegression())])","203","    param_grid = {'regressor': [LinearRegression(), Ridge()]}","204","    grid_search = GridSearchCV(pipe, param_grid, cv=2)","205","    grid_search.fit(X, y)","206","    regressor_results = grid_search.cv_results_['param_regressor']","207","    assert isinstance(regressor_results[0], LinearRegression)","208","    assert isinstance(regressor_results[1], Ridge)","209","    assert not hasattr(regressor_results[0], 'coef_')","210","    assert not hasattr(regressor_results[1], 'coef_')","211","    assert regressor_results[0] is not grid_search.best_estimator_","212","    assert regressor_results[1] is not grid_search.best_estimator_","213","    # check that we didn't modify the parameter grid that was passed","214","    assert not hasattr(param_grid['regressor'][0], 'coef_')","215","    assert not hasattr(param_grid['regressor'][1], 'coef_')","216","","217",""],"delete":["65","from sklearn.linear_model import Ridge, SGDClassifier"]}],"sklearn\/model_selection\/_search.py":[{"add":["729","            # we clone again after setting params in case some","730","            # of the params are estimators as well.","731","            self.best_estimator_ = clone(clone(base_estimator).set_params(","732","                **self.best_params_))"],"delete":["729","            self.best_estimator_ = clone(base_estimator).set_params(","730","                **self.best_params_)"]}]}},"f6923a297130ce95a5fa1adf5c049d59800d7408":{"changes":{"sklearn\/feature_extraction\/image.py":"MODIFY"},"diff":{"sklearn\/feature_extraction\/image.py":[{"add":["324","        Determines the random number generator used for random sampling when","325","        `max_patches` is not None. Use an int to make the randomness","326","        deterministic.","327","        See :term:`Glossary <random_state>`.","456","        Determines the random number generator used for random sampling when","457","        `max_patches` is not None. Use an int to make the randomness","458","        deterministic.","459","        See :term:`Glossary <random_state>`.","460",""],"delete":["324","        Pseudo number generator state used for random sampling to use if","325","        `max_patches` is not None.  If int, random_state is the seed used by","326","        the random number generator; If RandomState instance, random_state is","327","        the random number generator; If None, the random number generator is","328","        the RandomState instance used by `np.random`.","457","        If int, random_state is the seed used by the random number generator;","458","        If RandomState instance, random_state is the random number generator;","459","        If None, the random number generator is the RandomState instance used","460","        by `np.random`."]}]}},"730d1e726b9fb59811639896c5f8c26bb2ee0628":{"changes":{"doc\/whats_new\/v0.23.rst":"MODIFY","sklearn\/linear_model\/tests\/test_ridge.py":"MODIFY","sklearn\/linear_model\/_ridge.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.23.rst":[{"add":["102","- |Fix| Fixed a bug in :class:`linear_model.RidgeClassifierCV` to pass a","103","  specific scoring strategy. Before the internal estimator outputs score","104","  instead of predictions.","105","  :pr:`14848` by :user:`Venkatachalam N <venkyyuvy>`.","106",""],"delete":[]}],"sklearn\/linear_model\/tests\/test_ridge.py":[{"add":["62","def _accuracy_callable(y_test, y_pred):","63","    return np.mean(y_test == y_pred)","64","","65","","66","def _mean_squared_error_callable(y_test, y_pred):","67","    return ((y_test - y_pred) ** 2).mean()","68","","69","","736","@pytest.mark.parametrize(\"scoring\", [None, \"accuracy\", _accuracy_callable])","737","@pytest.mark.parametrize(\"cv\", [None, KFold(5)])","738","@pytest.mark.parametrize(\"filter_\", [DENSE_FILTER, SPARSE_FILTER])","739","def test_ridge_classifier_with_scoring(filter_, scoring, cv):","740","    # non-regression test for #14672","741","    # check that RidgeClassifierCV works with all sort of scoring and","742","    # cross-validation","743","    scoring_ = make_scorer(scoring) if callable(scoring) else scoring","744","    clf = RidgeClassifierCV(scoring=scoring_, cv=cv)","745","    # Smoke test to check that fit\/predict does not raise error","746","    clf.fit(filter_(X_iris), y_iris).predict(filter_(X_iris))","747","","748","","749","@pytest.mark.parametrize(\"cv\", [None, KFold(5)])","750","@pytest.mark.parametrize(\"filter_\", [DENSE_FILTER, SPARSE_FILTER])","751","def test_ridge_regression_custom_scoring(filter_, cv):","752","    # check that custom scoring is working as expected","753","    # check the tie breaking strategy (keep the first alpha tried)","754","","755","    def _dummy_score(y_test, y_pred):","756","        return 0.42","757","","758","    alphas = np.logspace(-2, 2, num=5)","759","    clf = RidgeClassifierCV(","760","        alphas=alphas, scoring=make_scorer(_dummy_score), cv=cv","761","    )","762","    clf.fit(filter_(X_iris), y_iris)","763","    assert clf.best_score_ == pytest.approx(0.42)","764","    # In case of tie score, the first alphas will be kept","765","    assert clf.alpha_ == pytest.approx(alphas[0])","766","","767","","887","@pytest.mark.parametrize(","888","    \"scoring\", [None, 'neg_mean_squared_error', _mean_squared_error_callable]","889",")","899","    scoring_ = make_scorer(scoring) if callable(scoring) else scoring","900","","901","    r = RidgeCV(alphas=alphas, cv=None, store_cv_values=True, scoring=scoring_)","919","@pytest.mark.parametrize(\"scoring\", [None, 'accuracy', _accuracy_callable])","920","def test_ridge_classifier_cv_store_cv_values(scoring):","929","    scoring_ = make_scorer(scoring) if callable(scoring) else scoring","930","","931","    r = RidgeClassifierCV(","932","        alphas=alphas, cv=None, store_cv_values=True, scoring=scoring_","933","    )"],"delete":["847","@pytest.mark.parametrize(\"scoring\", [None, 'neg_mean_squared_error'])","857","    r = RidgeCV(alphas=alphas, cv=None, store_cv_values=True, scoring=scoring)","875","def test_ridge_classifier_cv_store_cv_values():","884","    r = RidgeClassifierCV(alphas=alphas, cv=None, store_cv_values=True)"]}],"sklearn\/linear_model\/_ridge.py":[{"add":["21","from ..base import RegressorMixin, MultiOutputMixin, is_classifier","1059","class _IdentityRegressor:","1060","    \"\"\"Fake regressor which will directly output the prediction.\"\"\"","1069","class _IdentityClassifier(LinearClassifierMixin):","1070","    \"\"\"Fake classifier which will directly output the prediction.","1071","","1072","    We inherit from LinearClassifierMixin to get the proper shape for the","1073","    output `y`.","1074","    \"\"\"","1075","    def __init__(self, classes):","1076","        self.classes_ = classes","1077","","1078","    def decision_function(self, y_predict):","1079","        return y_predict","1080","","1081","","1083","    \"\"\"Ridge regression with built-in Generalized Cross-Validation.","1128","                 gcv_mode=None, store_cv_values=False,","1129","                 is_clf=False):","1137","        self.is_clf = is_clf","1522","                if self.is_clf:","1523","                    identity_estimator = _IdentityClassifier(","1524","                        classes=np.arange(n_y)","1525","                    )","1526","                    predictions_, y_ = predictions, y.argmax(axis=1)","1527","                else:","1528","                    identity_estimator = _IdentityRegressor()","1529","                    predictions_, y_ = predictions.ravel(), y.ravel()","1530","","1531","                alpha_score = scorer(identity_estimator, predictions_, y_)","1532","","1602","                                  store_cv_values=self.store_cv_values,","1603","                                  is_clf=is_classifier(self))","1615","            model = RidgeClassifier if is_classifier(self) else Ridge","1616","            gs = GridSearchCV(model(fit_intercept=self.fit_intercept,","1903","        target = Y if self.cv is None else y","1904","        _BaseRidgeCV.fit(self, X, target, sample_weight=sample_weight)"],"delete":["21","from ..base import RegressorMixin, MultiOutputMixin","1059","class _IdentityEstimator:","1060","    \"\"\"Hack to call a scorer when we already have the predictions.\"\"\"","1070","    \"\"\"Ridge regression with built-in Generalized Cross-Validation","1115","                 gcv_mode=None, store_cv_values=False):","1504","                alpha_score = scorer(","1505","                    _IdentityEstimator(), predictions.ravel(), y.ravel())","1578","                                  store_cv_values=self.store_cv_values)","1590","            gs = GridSearchCV(Ridge(fit_intercept=self.fit_intercept,","1718","    pass","1878","        _BaseRidgeCV.fit(self, X, Y, sample_weight=sample_weight)"]}]}},"a3fad528f99755df44d787d505681d66af9eaa5c":{"changes":{"doc\/tutorial\/statistical_inference\/unsupervised_learning.rst":"MODIFY","doc\/conftest.py":"MODIFY"},"diff":{"doc\/tutorial\/statistical_inference\/unsupervised_learning.rst":[{"add":["23","algorithms. The simplest clustering algorithm is :ref:`k_means`.","26","   :target: ..\/..\/auto_examples\/cluster\/plot_cluster_iris.html","27","   :scale: 70","28","   :align: center","172","also referred to as connected components) when clustering an image.","175","   :target: ..\/..\/auto_examples\/cluster\/plot_coin_ward_segmentation.html","176","   :scale: 40","177","   :align: center","179","::","181","    >>> from skimage.data import coins","182","    >>> from scipy.ndimage.filters import gaussian_filter","183","    >>> from skimage.transform import rescale","184","    >>> rescaled_coins = rescale(","185","    ...     gaussian_filter(coins(), sigma=2),","186","    ...     0.2, mode='reflect', anti_aliasing=False, multichannel=False","187","    ... )","188","    >>> X = np.reshape(rescaled_coins, (-1, 1))","190","We need a vectorized version of the image. `'rescaled_coins'` is a down-scaled","191","version of the coins image to speed up the process::","192","","193","    >>> from sklearn.feature_extraction import grid_to_graph","194","    >>> connectivity = grid_to_graph(*rescaled_coins.shape)","195","","196","Define the graph structure of the data. Pixels connected to their neighbors::","197","","198","    >>> n_clusters = 27  # number of regions","199","","200","    >>> from sklearn.cluster import AgglomerativeClustering","201","    >>> ward = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward',","202","    ...                                connectivity=connectivity)","203","    >>> ward.fit(X)","204","    AgglomerativeClustering(connectivity=..., n_clusters=27)","205","    >>> label = np.reshape(ward.labels_, rescaled_coins.shape)","218","   :target: ..\/..\/auto_examples\/cluster\/plot_digits_agglomeration.html","219","   :align: center","220","   :scale: 57"],"delete":["23","algorithms. The simplest clustering algorithm is","24",":ref:`k_means`.","27","    :target: ..\/..\/auto_examples\/cluster\/plot_cluster_iris.html","28","    :scale: 70","29","    :align: right","30","","174","also referred to as connected components) when","175","clustering an image:","178","    :target: ..\/..\/auto_examples\/cluster\/plot_coin_ward_segmentation.html","179","    :scale: 40","180","    :align: right","182",".. literalinclude:: ..\/..\/auto_examples\/cluster\/plot_coin_ward_segmentation.py","183","    :lines: 21-45","185","..","186","    >>> from sklearn.feature_extraction.image import grid_to_graph","187","    >>> connectivity = grid_to_graph(*face.shape)","201","    :target: ..\/..\/auto_examples\/cluster\/plot_digits_agglomeration.html","202","    :align: right","203","    :scale: 57"]}],"doc\/conftest.py":[{"add":["60","    try:","61","        import skimage  # noqa","62","    except ImportError:","63","        raise SkipTest(\"Skipping unsupervised_learning.rst, scikit-image \"","64","                       \"not installed\")"],"delete":[]}]}},"73caac258c5df478779336e0f9336d4ad321fd1d":{"changes":{"lgtm.yml":"MODIFY"},"diff":{"lgtm.yml":[{"add":["3","      - pip3 install numpy==1.16.3","4","      - pip3 install --no-deps scipy Cython"],"delete":["3","      - pip3 install numpy scipy Cython"]}]}},"1c116807ce1e925f73c87c34e586520d455682d6":{"changes":{"sklearn\/preprocessing\/tests\/test_label.py":"MODIFY","sklearn\/preprocessing\/tests\/test_base.py":"MODIFY","sklearn\/preprocessing\/tests\/test_data.py":"MODIFY","sklearn\/preprocessing\/tests\/test_discretization.py":"MODIFY","sklearn\/preprocessing\/tests\/test_encoders.py":"MODIFY"},"diff":{"sklearn\/preprocessing\/tests\/test_label.py":[{"add":["133","    with pytest.raises(ValueError):","134","        lb.transform(multi_label)","137","    with pytest.raises(ValueError):","138","        lb.transform([])","139","    with pytest.raises(ValueError):","140","        lb.inverse_transform([])","142","    with pytest.raises(ValueError):","143","        LabelBinarizer(neg_label=2, pos_label=1)","144","    with pytest.raises(ValueError):","145","        LabelBinarizer(neg_label=2, pos_label=2)","147","    with pytest.raises(ValueError):","148","        LabelBinarizer(neg_label=1, pos_label=2, sparse_output=True)","151","    with pytest.raises(ValueError):","152","        _inverse_binarize_thresholding(y=csr_matrix([[1, 2], [2, 1]]),","153","                                       output_type=\"foo\", classes=[1, 2],","154","                                       threshold=0)","158","    with pytest.raises(ValueError):","159","        LabelBinarizer().fit_transform(y_seq_of_seqs)","162","    with pytest.raises(ValueError):","163","        _inverse_binarize_thresholding(y=csr_matrix([[1, 2], [2, 1]]),","164","                                       output_type=\"foo\",","165","                                       classes=[1, 2, 3],","166","                                       threshold=0)","169","    with pytest.raises(ValueError):","170","        _inverse_binarize_thresholding(y=np.array([[1, 2, 3], [2, 1, 3]]),","171","                                       output_type=\"binary\",","172","                                       classes=[1, 2, 3],","173","                                       threshold=0)","176","    with pytest.raises(ValueError):","177","        LabelBinarizer().fit(np.array([[1, 3], [2, 1]]))","178","    with pytest.raises(ValueError):","179","        label_binarize(np.array([[1, 3], [2, 1]]), [1, 2, 3])","216","    with pytest.raises(ValueError):","217","        le.transform([0, 6])","225","    with pytest.raises(ValueError, match=msg):","226","        le.transform(\"apple\")","232","    with pytest.raises(ValueError):","233","        le.transform([])","234","    with pytest.raises(ValueError):","235","        le.inverse_transform([])","241","    with pytest.raises(ValueError, match=msg):","242","        le.inverse_transform([-2])","243","    with pytest.raises(ValueError, match=msg):","244","        le.inverse_transform([-2, -3, -4])","248","    with pytest.raises(ValueError, match=msg):","249","        le.inverse_transform(\"\")","307","    with pytest.raises(ValueError):","308","        mlb.inverse_transform(csr_matrix(np.array([[0, 1, 1],","309","                                                   [2, 0, 0],","310","                                                   [1, 1, 0]])))","395","    with pytest.raises(ValueError, match=err_msg):","396","        mlb.fit(inp)","459","    with pytest.raises(TypeError):","460","        mlb.fit_transform([({}), ({}, {'a': 'b'})])","475","    with pytest.raises(ValueError):","476","        mlb.inverse_transform(np.array([[1, 3]]))","483","    with pytest.raises(ValueError):","484","        mlb.inverse_transform(np.array([[1]]))","485","    with pytest.raises(ValueError):","486","        mlb.inverse_transform(np.array([[1, 1, 1]]))","510","            with pytest.raises(ValueError):","511","                label_binarize(y, classes, neg_label=neg_label,","512","                               pos_label=pos_label,","513","                               sparse_output=sparse_output)","577","    with pytest.raises(ValueError):","578","        label_binarize(y, classes, neg_label=-1, pos_label=pos_label,","579","                       sparse_output=True)","596","    with pytest.raises(ValueError):","597","        label_binarize(y, classes, neg_label=-1, pos_label=pos_label,","598","                       sparse_output=True)","602","    with pytest.raises(ValueError):","603","        label_binarize([0, 2], classes=[0, 2], pos_label=0, neg_label=1)"],"delete":["14","from sklearn.utils.testing import assert_raises","15","from sklearn.utils.testing import assert_raise_message","135","    assert_raises(ValueError, lb.transform, multi_label)","138","    assert_raises(ValueError, lb.transform, [])","139","    assert_raises(ValueError, lb.inverse_transform, [])","141","    assert_raises(ValueError, LabelBinarizer, neg_label=2, pos_label=1)","142","    assert_raises(ValueError, LabelBinarizer, neg_label=2, pos_label=2)","144","    assert_raises(ValueError, LabelBinarizer, neg_label=1, pos_label=2,","145","                  sparse_output=True)","148","    assert_raises(ValueError, _inverse_binarize_thresholding,","149","                  y=csr_matrix([[1, 2], [2, 1]]), output_type=\"foo\",","150","                  classes=[1, 2], threshold=0)","154","    assert_raises(ValueError, LabelBinarizer().fit_transform, y_seq_of_seqs)","157","    assert_raises(ValueError, _inverse_binarize_thresholding,","158","                  y=csr_matrix([[1, 2], [2, 1]]), output_type=\"foo\",","159","                  classes=[1, 2, 3], threshold=0)","162","    assert_raises(ValueError, _inverse_binarize_thresholding,","163","                  y=np.array([[1, 2, 3], [2, 1, 3]]), output_type=\"binary\",","164","                  classes=[1, 2, 3], threshold=0)","167","    assert_raises(ValueError, LabelBinarizer().fit, np.array([[1, 3], [2, 1]]))","168","    assert_raises(ValueError, label_binarize, np.array([[1, 3], [2, 1]]),","169","                  [1, 2, 3])","206","    assert_raises(ValueError, le.transform, [0, 6])","214","    assert_raise_message(ValueError, msg, le.transform, \"apple\")","220","    assert_raises(ValueError, le.transform, [])","221","    assert_raises(ValueError, le.inverse_transform, [])","227","    assert_raise_message(ValueError, msg, le.inverse_transform, [-2])","228","    assert_raise_message(ValueError, msg, le.inverse_transform, [-2, -3, -4])","232","    assert_raise_message(ValueError, msg, le.inverse_transform, \"\")","290","    assert_raises(ValueError, mlb.inverse_transform,","291","                  csr_matrix(np.array([[0, 1, 1],","292","                                       [2, 0, 0],","293","                                       [1, 1, 0]])))","378","    assert_raise_message(ValueError, err_msg, mlb.fit, inp)","441","    assert_raises(TypeError, mlb.fit_transform, [({}), ({}, {'a': 'b'})])","456","    assert_raises(ValueError, mlb.inverse_transform, np.array([[1, 3]]))","463","    assert_raises(ValueError, mlb.inverse_transform, np.array([[1]]))","464","    assert_raises(ValueError, mlb.inverse_transform, np.array([[1, 1, 1]]))","488","            assert_raises(ValueError, label_binarize, y, classes,","489","                          neg_label=neg_label, pos_label=pos_label,","490","                          sparse_output=sparse_output)","554","    assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,","555","                  pos_label=pos_label, sparse_output=True)","572","    assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,","573","                  pos_label=pos_label, sparse_output=True)","577","    assert_raises(ValueError, label_binarize, [0, 2], classes=[0, 2],","578","                  pos_label=0, neg_label=1)"]}],"sklearn\/preprocessing\/tests\/test_base.py":[{"add":["62","    err_msg = (\"The retain_order option can only be set to True \"","63","               \"for dense matrices.\")","64","    with pytest.raises(ValueError, match=err_msg):","65","        _transform_selected(sparse.csr_matrix(X), Binarizer().transform,","66","                            dtype=np.int, selected=[0], retain_order=True)","71","    err_msg = (\"The retain_order option can only be set to True \"","72","               \"if the dimensions of the input array match the \"","73","               \"dimensions of the transformed array.\")","74","    with pytest.raises(ValueError, match=err_msg):","75","        _transform_selected(X, transform, dtype=np.int,","76","                            selected=[0], retain_order=True)"],"delete":["5","from sklearn.utils.testing import assert_raise_message","63","    assert_raise_message(ValueError,","64","                         \"The retain_order option can only be set to True \"","65","                         \"for dense matrices.\",","66","                         _transform_selected, sparse.csr_matrix(X),","67","                         Binarizer().transform, dtype=np.int, selected=[0],","68","                         retain_order=True)","73","    assert_raise_message(ValueError,","74","                         \"The retain_order option can only be set to True \"","75","                         \"if the dimensions of the input array match the \"","76","                         \"dimensions of the transformed array.\",","77","                         _transform_selected, X, transform, dtype=np.int,","78","                         selected=[0], retain_order=True)"]}],"sklearn\/preprocessing\/tests\/test_data.py":[{"add":["692","    with pytest.raises(ValueError):","693","        scaler.fit(X)","791","    with pytest.raises(ValueError):","792","        StandardScaler().fit(X_csr)","793","    with pytest.raises(ValueError):","794","        StandardScaler().fit(X_csc)","1026","    with pytest.raises(ValueError):","1027","        scale(X_csr, with_mean=True)","1028","    with pytest.raises(ValueError):","1029","        StandardScaler(with_mean=True).fit(X_csr)","1031","    with pytest.raises(ValueError):","1032","        scale(X_csc, with_mean=True)","1033","    with pytest.raises(ValueError):","1034","        StandardScaler(with_mean=True).fit(X_csc)","1038","    with pytest.raises(ValueError):","1039","        scaler.transform(X_csr)","1040","    with pytest.raises(ValueError):","1041","        scaler.transform(X_csc)","1044","    with pytest.raises(ValueError):","1045","        scaler.inverse_transform(X_transformed_csr)","1048","    with pytest.raises(ValueError):","1049","        scaler.inverse_transform(X_transformed_csc)","1055","    with pytest.raises(ValueError, match=\"Input contains infinity \"","1056","                       \"or a value too large\"):","1057","        scale(X)","1211","    err_msg = \"Invalid value for 'n_quantiles': 0.\"","1212","    with pytest.raises(ValueError, match=err_msg):","1213","        QuantileTransformer(n_quantiles=0).fit(X)","1214","    err_msg = \"Invalid value for 'subsample': 0.\"","1215","    with pytest.raises(ValueError, match=err_msg):","1216","        QuantileTransformer(subsample=0).fit(X)","1217","    err_msg = (\"The number of quantiles cannot be greater than \"","1218","               \"the number of samples used. Got 1000 quantiles \"","1219","               \"and 10 samples.\")","1220","    with pytest.raises(ValueError, match=err_msg):","1221","        QuantileTransformer(subsample=10).fit(X)","1224","    err_msg = \"QuantileTransformer only accepts non-negative sparse matrices.\"","1225","    with pytest.raises(ValueError, match=err_msg):","1226","        transformer.fit(X_neg)","1228","    err_msg = \"QuantileTransformer only accepts non-negative sparse matrices.\"","1229","    with pytest.raises(ValueError, match=err_msg):","1230","        transformer.transform(X_neg)","1234","    err_msg = (\"X does not have the same number of features as the previously\"","1235","               \" fitted \" \"data. Got 2 instead of 3.\")","1236","    with pytest.raises(ValueError, match=err_msg):","1237","        transformer.transform(X_bad_feat)","1238","    err_msg = (\"X does not have the same number of features \"","1239","               \"as the previously fitted data. Got 2 instead of 3.\")","1240","    with pytest.raises(ValueError, match=err_msg):","1241","        transformer.inverse_transform(X_bad_feat)","1246","    err_msg = (\"'output_distribution' has to be either 'normal' or \"","1247","               \"'uniform'. Got 'rnd' instead.\")","1248","    with pytest.raises(ValueError, match=err_msg):","1249","        transformer.fit(X)","1255","    err_msg = (\"'output_distribution' has to be either 'normal' or 'uniform'.\"","1256","               \" Got 'rnd' instead.\")","1257","    with pytest.raises(ValueError, match=err_msg):","1258","        transformer.transform(X)","1260","    err_msg = (\"'output_distribution' has to be either 'normal' or 'uniform'.\"","1261","               \" Got 'rnd' instead.\")","1262","    with pytest.raises(ValueError, match=err_msg):","1263","        transformer.inverse_transform(X_tran)","1265","    with pytest.raises(ValueError,","1266","                       match='Expected 2D array, got scalar array instead'):","1267","        transformer.transform(10)","1557","        with pytest.raises(ValueError, match=r'Invalid quantile range: \\('):","1558","            scaler.fit(iris.data)","1578","    with pytest.raises(ValueError):","1579","        scale(X_csr, with_mean=False, axis=1)","1968","    with pytest.raises(ValueError):","1969","        normalize([[0]], axis=2)","1970","    with pytest.raises(ValueError):","1971","        normalize([[0]], norm='l3')","2006","        with pytest.raises(NotImplementedError):","2007","            normalize(X_sparse, norm=norm, return_norm=True)","2064","    with pytest.raises(ValueError):","2065","        binarizer.transform(sparse.csc_matrix(X))","2171","    with pytest.raises(ValueError, match=\"axis should be either equal \"","2172","                                         \"to 0 or 1. Got axis=2\"):","2173","        quantile_transform(X.T, axis=2)","2180","    with pytest.raises(NotFittedError):","2181","        pt.transform(X)","2182","    with pytest.raises(NotFittedError):","2183","        pt.inverse_transform(X)","2264","    with pytest.raises(ValueError, match=not_positive_message):","2265","        pt.transform(X_with_negatives)","2267","    with pytest.raises(ValueError, match=not_positive_message):","2268","        pt.fit(X_with_negatives)","2270","    with pytest.raises(ValueError, match=not_positive_message):","2271","        power_transform(X_with_negatives, 'box-cox')","2273","    with pytest.raises(ValueError, match=not_positive_message):","2274","        pt.transform(np.zeros(X_2d.shape))","2276","    with pytest.raises(ValueError, match=not_positive_message):","2277","        pt.fit(np.zeros(X_2d.shape))","2279","    with pytest.raises(ValueError, match=not_positive_message):","2280","        power_transform(np.zeros(X_2d.shape), 'box-cox')","2300","    with pytest.raises(ValueError, match=wrong_shape_message):","2301","        pt.transform(X[:, 0:1])","2303","    with pytest.raises(ValueError, match=wrong_shape_message):","2304","        pt.inverse_transform(X[:, 0:1])","2313","    with pytest.raises(ValueError, match=bad_method_message):","2314","        pt.fit(X)"],"delete":["18","from sklearn.utils.testing import assert_raise_message","23","from sklearn.utils.testing import assert_raises","24","from sklearn.utils.testing import assert_raises_regex","695","    assert_raises(ValueError, scaler.fit, X)","793","    assert_raises(ValueError, StandardScaler().fit, X_csr)","794","    assert_raises(ValueError, StandardScaler().fit, X_csc)","1026","    assert_raises(ValueError, scale, X_csr, with_mean=True)","1027","    assert_raises(ValueError, StandardScaler(with_mean=True).fit, X_csr)","1029","    assert_raises(ValueError, scale, X_csc, with_mean=True)","1030","    assert_raises(ValueError, StandardScaler(with_mean=True).fit, X_csc)","1034","    assert_raises(ValueError, scaler.transform, X_csr)","1035","    assert_raises(ValueError, scaler.transform, X_csc)","1038","    assert_raises(ValueError, scaler.inverse_transform, X_transformed_csr)","1041","    assert_raises(ValueError, scaler.inverse_transform, X_transformed_csc)","1047","    assert_raises_regex(ValueError,","1048","                        \"Input contains infinity or a value too large\",","1049","                        scale, X)","1203","    assert_raises_regex(ValueError, \"Invalid value for 'n_quantiles': 0.\",","1204","                        QuantileTransformer(n_quantiles=0).fit, X)","1205","    assert_raises_regex(ValueError, \"Invalid value for 'subsample': 0.\",","1206","                        QuantileTransformer(subsample=0).fit, X)","1207","    assert_raises_regex(ValueError, \"The number of quantiles cannot be\"","1208","                        \" greater than the number of samples used. Got\"","1209","                        \" 1000 quantiles and 10 samples.\",","1210","                        QuantileTransformer(subsample=10).fit, X)","1213","    assert_raises_regex(ValueError, \"QuantileTransformer only accepts \"","1214","                        \"non-negative sparse matrices.\",","1215","                        transformer.fit, X_neg)","1217","    assert_raises_regex(ValueError, \"QuantileTransformer only accepts \"","1218","                        \"non-negative sparse matrices.\",","1219","                        transformer.transform, X_neg)","1223","    assert_raises_regex(ValueError, \"X does not have the same number of \"","1224","                        \"features as the previously fitted data. Got 2\"","1225","                        \" instead of 3.\",","1226","                        transformer.transform, X_bad_feat)","1227","    assert_raises_regex(ValueError, \"X does not have the same number of \"","1228","                        \"features as the previously fitted data. Got 2\"","1229","                        \" instead of 3.\",","1230","                        transformer.inverse_transform, X_bad_feat)","1235","    assert_raises_regex(ValueError, \"'output_distribution' has to be either\"","1236","                        \" 'normal' or 'uniform'. Got 'rnd' instead.\",","1237","                        transformer.fit, X)","1243","    assert_raises_regex(ValueError, \"'output_distribution' has to be either\"","1244","                        \" 'normal' or 'uniform'. Got 'rnd' instead.\",","1245","                        transformer.transform, X)","1247","    assert_raises_regex(ValueError, \"'output_distribution' has to be either\"","1248","                        \" 'normal' or 'uniform'. Got 'rnd' instead.\",","1249","                        transformer.inverse_transform, X_tran)","1251","    assert_raise_message(ValueError,","1252","                         'Expected 2D array, got scalar array instead',","1253","                         transformer.transform, 10)","1543","        assert_raises_regex(ValueError, r'Invalid quantile range: \\(',","1544","                            scaler.fit, iris.data)","1564","    assert_raises(ValueError, scale, X_csr, with_mean=False, axis=1)","1953","    assert_raises(ValueError, normalize, [[0]], axis=2)","1954","    assert_raises(ValueError, normalize, [[0]], norm='l3')","1989","        assert_raises(NotImplementedError, normalize, X_sparse,","1990","                      norm=norm, return_norm=True)","2047","    assert_raises(ValueError, binarizer.transform, sparse.csc_matrix(X))","2153","    assert_raises_regex(ValueError, \"axis should be either equal to 0 or 1\"","2154","                        \". Got axis=2\", quantile_transform, X.T, axis=2)","2161","    assert_raises(NotFittedError, pt.transform, X)","2162","    assert_raises(NotFittedError, pt.inverse_transform, X)","2243","    assert_raise_message(ValueError, not_positive_message,","2244","                         pt.transform, X_with_negatives)","2246","    assert_raise_message(ValueError, not_positive_message,","2247","                         pt.fit, X_with_negatives)","2249","    assert_raise_message(ValueError, not_positive_message,","2250","                         power_transform, X_with_negatives, 'box-cox')","2252","    assert_raise_message(ValueError, not_positive_message,","2253","                         pt.transform, np.zeros(X_2d.shape))","2255","    assert_raise_message(ValueError, not_positive_message,","2256","                         pt.fit, np.zeros(X_2d.shape))","2258","    assert_raise_message(ValueError, not_positive_message,","2259","                         power_transform, np.zeros(X_2d.shape), 'box-cox')","2279","    assert_raise_message(ValueError, wrong_shape_message,","2280","                         pt.transform, X[:, 0:1])","2282","    assert_raise_message(ValueError, wrong_shape_message,","2283","                         pt.inverse_transform, X[:, 0:1])","2292","    assert_raise_message(ValueError, bad_method_message,","2293","                         pt.fit, X)"]}],"sklearn\/preprocessing\/tests\/test_discretization.py":[{"add":["39","    err_msg = (\"KBinsDiscretizer received an invalid \"","40","               \"number of bins. Received 1, expected at least 2.\")","41","    with pytest.raises(ValueError, match=err_msg):","42","        est.fit_transform(X)","45","    err_msg = (\"KBinsDiscretizer received an invalid \"","46","               \"n_bins type. Received float, expected int.\")","47","    with pytest.raises(ValueError, match=err_msg):","48","        est.fit_transform(X)","55","    err_msg = r\"n_bins must be a scalar or array of shape \\(n_features,\\).\"","56","    with pytest.raises(ValueError, match=err_msg):","57","        est.fit_transform(X)","62","    err_msg = r\"n_bins must be a scalar or array of shape \\(n_features,\\).\"","63","    with pytest.raises(ValueError, match=err_msg):","64","        est.fit_transform(X)","69","    err_msg = (\"KBinsDiscretizer received an invalid number of bins \"","70","               \"at indices 0, 3. Number of bins must be at least 2, \"","71","               \"and must be an int.\")","72","    with pytest.raises(ValueError, match=err_msg):","73","        est.fit_transform(X)","78","    err_msg = (\"KBinsDiscretizer received an invalid number of bins \"","79","               \"at indices 0, 2. Number of bins must be at least 2, \"","80","               \"and must be an int.\")","81","    with pytest.raises(ValueError, match=err_msg):","82","        est.fit_transform(X)","105","    err_msg = \"Incorrect number of features. Expecting 4, received 5\"","106","    with pytest.raises(ValueError, match=err_msg):","107","        est.transform(bad_X)","130","    with pytest.raises(ValueError):","131","        est.fit(X)","135","    with pytest.raises(ValueError):","136","        est.transform(X)","152","    err_msg = (r\"Valid options for 'encode' are \"","153","               r\"\\('onehot', 'onehot-dense', 'ordinal'\\). \"","154","               r\"Got encode='invalid-encode' instead.\")","155","    with pytest.raises(ValueError, match=err_msg):","156","        est.fit(X)","184","    err_msg = (r\"Valid options for 'strategy' are \"","185","               r\"\\('uniform', 'quantile', 'kmeans'\\). \"","186","               r\"Got strategy='invalid-strategy' instead.\")","187","    with pytest.raises(ValueError, match=err_msg):","188","        est.fit(X)"],"delete":["11","    assert_raises,","12","    assert_raise_message,","41","    assert_raise_message(ValueError, \"KBinsDiscretizer received an invalid \"","42","                         \"number of bins. Received 1, expected at least 2.\",","43","                         est.fit_transform, X)","46","    assert_raise_message(ValueError, \"KBinsDiscretizer received an invalid \"","47","                         \"n_bins type. Received float, expected int.\",","48","                         est.fit_transform, X)","55","    assert_raise_message(ValueError,","56","                         \"n_bins must be a scalar or array of shape \"","57","                         \"(n_features,).\", est.fit_transform, X)","62","    assert_raise_message(ValueError,","63","                         \"n_bins must be a scalar or array of shape \"","64","                         \"(n_features,).\", est.fit_transform, X)","69","    assert_raise_message(ValueError,","70","                         \"KBinsDiscretizer received an invalid number of bins \"","71","                         \"at indices 0, 3. Number of bins must be at least 2, \"","72","                         \"and must be an int.\",","73","                         est.fit_transform, X)","78","    assert_raise_message(ValueError,","79","                         \"KBinsDiscretizer received an invalid number of bins \"","80","                         \"at indices 0, 2. Number of bins must be at least 2, \"","81","                         \"and must be an int.\",","82","                         est.fit_transform, X)","105","    assert_raise_message(ValueError,","106","                         \"Incorrect number of features. Expecting 4, \"","107","                         \"received 5\", est.transform, bad_X)","130","    assert_raises(ValueError, est.fit, X)","134","    assert_raises(ValueError, est.transform, X)","150","    assert_raise_message(ValueError, \"Valid options for 'encode' are \"","151","                         \"('onehot', 'onehot-dense', 'ordinal'). \"","152","                         \"Got encode='invalid-encode' instead.\",","153","                         est.fit, X)","181","    assert_raise_message(ValueError, \"Valid options for 'strategy' are \"","182","                         \"('uniform', 'quantile', 'kmeans'). \"","183","                         \"Got strategy='invalid-strategy' instead.\",","184","                         est.fit, X)"]}],"sklearn\/preprocessing\/tests\/test_encoders.py":[{"add":["262","    with pytest.raises(ValueError, match=msg):","263","        enc.inverse_transform(X_tr)","522","    with pytest.raises(ValueError, match=msg):","523","        enc.inverse_transform(X_tr)","554","","647","    err_msg = \"`drop` should have length equal to the number\"","648","    with pytest.raises(ValueError, match=err_msg):","649","        enc.fit([['abc', 2, 55], ['def', 1, 55], ['def', 3, 59]])"],"delete":["10","from sklearn.utils.testing import assert_raises_regex","263","    assert_raises_regex(ValueError, msg, enc.inverse_transform, X_tr)","522","    assert_raises_regex(ValueError, msg, enc.inverse_transform, X_tr)","645","    assert_raises_regex(","646","        ValueError,","647","        \"`drop` should have length equal to the number\",","648","        enc.fit, [['abc', 2, 55], ['def', 1, 55], ['def', 3, 59]])"]}]}},"947dffcc9c07bbb01739ad4d34a2f33b8e1120ed":{"changes":{"sklearn\/ensemble\/_hist_gradient_boosting\/gradient_boosting.py":"MODIFY","sklearn\/ensemble\/_hist_gradient_boosting\/tests\/test_gradient_boosting.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY"},"diff":{"sklearn\/ensemble\/_hist_gradient_boosting\/gradient_boosting.py":[{"add":["428","        if is_classifier(self):","429","            y_small_train = self.classes_[y_small_train.astype(int)]","435","            if is_classifier(self):","436","                y_val = self.classes_[y_val.astype(int)]"],"delete":[]}],"sklearn\/ensemble\/_hist_gradient_boosting\/tests\/test_gradient_boosting.py":[{"add":["417","","418","","419","@pytest.mark.parametrize(\"scoring\", [None, 'loss'])","420","def test_string_target_early_stopping(scoring):","421","    # Regression tests for #14709 where the targets need to be encoded before","422","    # to compute the score","423","    rng = np.random.RandomState(42)","424","    X = rng.randn(100, 10)","425","    y = np.array(['x'] * 50 + ['y'] * 50, dtype=object)","426","    gbrt = HistGradientBoostingClassifier(n_iter_no_change=10, scoring=scoring)","427","    gbrt.fit(X, y)"],"delete":[]}],"doc\/whats_new\/v0.22.rst":[{"add":["134","  - |Fix| Fixed a bug where early stopping would break with string targets.","135","    :pr:`14710` by :user:`Guillaume Lemaitre <glemaitre>`."],"delete":[]}]}},"dd3b80e8c736dd73005c42d832b4a919a052eae8":{"changes":{"examples\/plot_kernel_approximation.py":"MODIFY"},"diff":{"examples\/plot_kernel_approximation.py":[{"add":["30","","31","###########################################################################","32","# Python package and dataset imports, load dataset","33","# ---------------------------------------------------","34","","40","print(__doc__)","41","","56","","57","##################################################################","58","# Timing and accuracy plots","59","# --------------------------------------------------","125","plt.figure(figsize=(16, 4))","126","accuracy = plt.subplot(121)","127","# second y axis for timings","128","timescale = plt.subplot(122)","163","plt.tight_layout()","164","plt.show()","165","","166","","167","############################################################################","168","# Decision Surfaces of RBF Kernel SVM and Linear SVM","169","# --------------------------------------------------------","170","# The second plot visualized the decision surfaces of the RBF kernel SVM and","171","# the linear SVM with approximate kernel maps.","172","# The plot shows decision surfaces of the classifiers projected onto","173","# the first two principal components of the data. This visualization should","174","# be taken with a grain of salt since it is just an interesting slice through","175","# the decision surface in 64 dimensions. In particular note that","176","# a datapoint (represented as a dot) does not necessarily be classified","177","# into the region it is lying in, since it will not lie on the plane","178","# that the first two principal components span.","179","# The usage of :class:`RBFSampler` and :class:`Nystroem` is described in detail","180","# in :ref:`kernel_approximation`.","205","plt.figure(figsize=(18, 7.5))","206","plt.rcParams.update({'font.size': 14})"],"delete":["29","The second plot visualized the decision surfaces of the RBF kernel SVM and","30","the linear SVM with approximate kernel maps.","31","The plot shows decision surfaces of the classifiers projected onto","32","the first two principal components of the data. This visualization should","33","be taken with a grain of salt since it is just an interesting slice through","34","the decision surface in 64 dimensions. In particular note that","35","a datapoint (represented as a dot) does not necessarily be classified","36","into the region it is lying in, since it will not lie on the plane","37","that the first two principal components span.","38","","39","The usage of :class:`RBFSampler` and :class:`Nystroem` is described in detail","40","in :ref:`kernel_approximation`.","41","","43","print(__doc__)","128","plt.figure(figsize=(8, 8))","129","accuracy = plt.subplot(211)","130","# second y axis for timeings","131","timescale = plt.subplot(212)","190","plt.tight_layout()","191","plt.figure(figsize=(12, 5))","192",""]}]}},"3aafaa97f3fb6ea6d57f357ff94f777f8ff6289f":{"changes":{"sklearn\/semi_supervised\/tests\/test_label_propagation.py":"MODIFY"},"diff":{"sklearn\/semi_supervised\/tests\/test_label_propagation.py":[{"add":["3","import pytest","121","        with pytest.raises(ValueError):","122","            label_propagation.LabelSpreading(alpha=alpha).fit(X, y)"],"delete":["5","from sklearn.utils.testing import assert_raises","121","        assert_raises(ValueError,","122","                      lambda **kwargs:","123","                      label_propagation.LabelSpreading(**kwargs).fit(X, y),","124","                      alpha=alpha)"]}]}},"98ca716429d3f59dbf4d622bd3b60c2173377e9c":{"changes":{"sklearn\/_build_utils\/__init__.py":"MODIFY"},"diff":{"sklearn\/_build_utils\/__init__.py":[{"add":["10","import contextlib","89","        n_jobs = 1","90","        with contextlib.suppress(ImportError):","91","            import joblib","92","            if LooseVersion(joblib.__version__) > LooseVersion(\"0.13.0\"):","93","                # earlier joblib versions don't account for CPU affinity","94","                # constraints, and may over-estimate the number of available","95","                # CPU particularly in CI (cf loky#114)","96","                n_jobs = joblib.effective_n_jobs()","97","","100","            nthreads=n_jobs,"],"delete":[]}]}},"9d2595f2be4db6b4af29d21aa88292d2e179ce12":{"changes":{"doc\/themes\/scikit-learn-modern\/static\/css\/theme.css":"MODIFY"},"diff":{"doc\/themes\/scikit-learn-modern\/static\/css\/theme.css":[{"add":["590","div.sk-page-content h1 code,","591","div.sk-page-content h2 code,","592","div.sk-page-content h3 code,","593","div.sk-page-content h4 code {","594","  white-space: normal;","595","}","596",""],"delete":[]}]}},"8e8e60eaa33ceeb6e2e846c747813bcf57899148":{"changes":{"sklearn\/svm\/tests\/test_sparse.py":"MODIFY","sklearn\/svm\/tests\/test_bounds.py":"MODIFY","sklearn\/svm\/tests\/test_svm.py":"MODIFY"},"diff":{"sklearn\/svm\/tests\/test_sparse.py":[{"add":["11","from sklearn.utils.testing import (assert_warns,","191","    with pytest.raises(ValueError):","192","        svm.SVC(C=-1).fit(X, Y)","196","    with pytest.raises(ValueError):","197","        clf.fit(X_sp, Y)","200","    with pytest.raises(ValueError):","201","        clf.fit(X_sp, Y2)"],"delete":["11","from sklearn.utils.testing import (assert_raises, assert_warns,","191","    assert_raises(ValueError, svm.SVC(C=-1).fit, X, Y)","195","    assert_raises(ValueError, clf.fit, X_sp, Y)","198","    assert_raises(ValueError, clf.fit, X_sp, Y2)"]}],"sklearn\/svm\/tests\/test_bounds.py":[{"add":["68","    with pytest.raises(ValueError):","69","        l1_min_c(X, y)","73","    with pytest.raises(ValueError):","74","        l1_min_c(dense_X, Y1, 'l1')"],"delete":["9","from sklearn.utils.testing import assert_raises","69","    assert_raises(ValueError, l1_min_c, X, y)","73","    assert_raises(ValueError, l1_min_c, dense_X, Y1, 'l1')"]}],"sklearn\/svm\/tests\/test_svm.py":[{"add":["19","from sklearn.utils.testing import assert_warns","21","from sklearn.utils.testing import ignore_warnings","99","    with pytest.raises(ValueError):","100","        clf.predict(KT.T)","234","    with pytest.raises(ValueError):","235","        clf.predict(X)","250","    with pytest.raises(AttributeError):","251","        (lambda: clf.coef_)()","476","    with pytest.raises(ValueError):","477","        svm.SVC(C=-1).fit(X, Y)","481","    with pytest.raises(ValueError):","482","        clf.fit(X, Y)","485","    with pytest.raises(ValueError):","486","        clf.fit(X, Y2)","501","    with pytest.raises(ValueError):","502","        clf.fit(X, Y)","506","    with pytest.raises(ValueError):","507","        clf.fit(X, Y, sample_weight=range(len(X) - 1))","511","    with pytest.raises(ValueError):","512","        clf.predict(sparse.lil_matrix(X))","516","    with pytest.raises(ValueError):","517","        clf.predict(X)","521","    with pytest.raises(ValueError):","522","        clf.predict(Xt)","577","            with pytest.raises(ValueError, match=\"Unsupported set of \"","578","                               \"arguments.*penalty='%s.*loss='%s.*dual=%s\"","579","                               % (penalty, loss, dual)):","580","                clf.fit(X, y)","585","    with pytest.raises(ValueError, match=\".*loss='l3' is not supported.*\"):","586","        svm.LinearSVC(loss=\"l3\").fit(X, y)","808","        with pytest.raises(AttributeError):","809","            clf.__setattr__('coef_', np.arange(3))","810","        with pytest.raises((RuntimeError, ValueError)):","811","            clf.coef_.__setitem__((0, 0), 0)","858","    with pytest.raises(ValueError):","859","        svc.fit(X, Y)","872","    with pytest.raises(Exception, match=r\".*\\bSVC\\b.*\\bnot\\b.*\\bfitted\\b\"):","873","        clf.predict(X)","876","    with pytest.raises(Exception, match=r\".*\\bNuSVR\\b.*\\bnot\\b.*\\bfitted\\b\"):","877","        clf.predict(X)"],"delete":["19","from sklearn.utils.testing import assert_raises_regexp, assert_warns","21","from sklearn.utils.testing import ignore_warnings, assert_raises","99","    assert_raises(ValueError, clf.predict, KT.T)","233","    assert_raises(ValueError, clf.predict, X)","248","    assert_raises(AttributeError, lambda: clf.coef_)","473","    assert_raises(ValueError, svm.SVC(C=-1).fit, X, Y)","477","    assert_raises(ValueError, clf.fit, X, Y)","480","    assert_raises(ValueError, clf.fit, X, Y2)","495","    assert_raises(ValueError, clf.fit, X, Y)","499","    assert_raises(ValueError, clf.fit, X, Y, sample_weight=range(len(X) - 1))","503","    assert_raises(ValueError, clf.predict, sparse.lil_matrix(X))","507","    assert_raises(ValueError, clf.predict, X)","511","    assert_raises(ValueError, clf.predict, Xt)","566","            assert_raises_regexp(ValueError,","567","                                 \"Unsupported set of arguments.*penalty='%s.*\"","568","                                 \"loss='%s.*dual=%s\"","569","                                 % (penalty, loss, dual),","570","                                 clf.fit, X, y)","575","    assert_raises_regexp(ValueError, \".*loss='l3' is not supported.*\",","576","                         svm.LinearSVC(loss=\"l3\").fit, X, y)","798","        assert_raises(AttributeError, clf.__setattr__, 'coef_', np.arange(3))","799","        assert_raises((RuntimeError, ValueError),","800","                      clf.coef_.__setitem__, (0, 0), 0)","847","    assert_raises(ValueError, svc.fit, X, Y)","860","    assert_raises_regexp(Exception, r\".*\\bSVC\\b.*\\bnot\\b.*\\bfitted\\b\",","861","                         clf.predict, X)","864","    assert_raises_regexp(Exception, r\".*\\bNuSVR\\b.*\\bnot\\b.*\\bfitted\\b\",","865","                         clf.predict, X)"]}]}},"f82d966d7b6286aa34a11374304c0bca515f4331":{"changes":{"doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/inspection\/partial_dependence.py":"MODIFY","sklearn\/inspection\/tests\/test_partial_dependence.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.21.rst":[{"add":["28","","29",":mod:`sklearn.inspection`","30",".....................","31","","32","- |Fix| Fixed a bug in :func:`inspection.plot_partial_dependence` where ","33","  ``target`` parameter was not being taken into account for multiclass problems.","34","  :pr:`14393` by :user:`Guillem G. Subies <guillemgsubies>`.","35",""],"delete":[]}],"sklearn\/inspection\/partial_dependence.py":[{"add":[],"delete":["588","    else:","589","        target_idx = 0"]}],"sklearn\/inspection\/tests\/test_partial_dependence.py":[{"add":["482","    clf = GradientBoostingClassifier(n_estimators=10, random_state=1)","483","    iris = load_iris()","484","","485","    # Test partial dependence plot function on multi-class input.","486","    clf.fit(iris.data, iris.target)","501","    fig2 = pyplot.gcf()","502","    axs2 = fig2.get_axes()","503","    assert len(axs2) == 2","504","    assert all(ax.has_data for ax in axs2)","505","","506","    # check that the pd plots are the same for 0 and \"setosa\"","507","    assert all(axs[0].lines[0]._y == axs2[0].lines[0]._y)","508","    # check that the pd plots are different for another target","509","    clf.fit(iris.data, iris.target)","510","    plot_partial_dependence(clf, iris.data, [0, 1],","511","                            target=1,","512","                            grid_resolution=grid_resolution)","513","    fig3 = pyplot.gcf()","514","    axs3 = fig3.get_axes()","515","    assert any(axs[0].lines[0]._y != axs3[0].lines[0]._y)"],"delete":["481","    # Test partial dependence plot function on multi-class input.","482","    iris = load_iris()","483","    clf = GradientBoostingClassifier(n_estimators=10, random_state=1)","484","    clf.fit(iris.data, iris.target)","485","","497","    clf = GradientBoostingClassifier(n_estimators=10, random_state=1)","499","","500","    grid_resolution = 25","504","    fig = pyplot.gcf()","505","    axs = fig.get_axes()","506","    assert len(axs) == 2","507","    assert all(ax.has_data for ax in axs)"]}]}},"e49b9d3d754b189062d23bf213847a6370158282":{"changes":{"sklearn\/datasets\/tests\/data\/openml\/62\/api-v1-json-data-qualities-62.json.gz":"ADD","sklearn\/datasets\/tests\/data\/openml\/62\/data-v1-download-52352.arff.gz":"ADD","sklearn\/datasets\/tests\/test_openml.py":"MODIFY","sklearn\/datasets\/tests\/data\/openml\/62\/api-v1-json-data-62.json.gz":"ADD","sklearn\/datasets\/tests\/data\/openml\/62\/api-v1-json-data-features-62.json.gz":"ADD","doc\/whats_new\/v0.22.rst":"MODIFY","sklearn\/datasets\/openml.py":"MODIFY"},"diff":{"sklearn\/datasets\/tests\/data\/openml\/62\/api-v1-json-data-qualities-62.json.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/62\/data-v1-download-52352.arff.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/test_openml.py":[{"add":["1160","","1161","","1162","@pytest.mark.parametrize('gzip_response', [True, False])","1163","def test_fetch_openml_with_ignored_feature(monkeypatch, gzip_response):","1164","    # Regression test for #14340","1165","    # 62 is the ID of the ZOO dataset","1166","    data_id = 62","1167","    _monkey_patch_webbased_functions(monkeypatch, data_id, gzip_response)","1168","","1169","    dataset = sklearn.datasets.fetch_openml(data_id=data_id, cache=False)","1170","    assert dataset is not None","1171","    # The dataset has 17 features, including 1 ignored (animal),","1172","    # so we assert that we don't have the ignored feature in the final Bunch","1173","    assert dataset['data'].shape == (101, 16)","1174","    assert 'animal' not in dataset['feature_names']"],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/62\/api-v1-json-data-62.json.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/62\/api-v1-json-data-features-62.json.gz":[{"add":[],"delete":[]}],"doc\/whats_new\/v0.22.rst":[{"add":["82","- |Fix| Fixed a bug in :func:`datasets.fetch_openml`, which failed to load","83","  an OpenML dataset that contains an ignored feature.","84","  :pr:`14623` by :user:`Sarra Habchi <HabchiSarra>`.","85",""],"delete":[]}],"sklearn\/datasets\/openml.py":[{"add":["426","def _get_num_samples(data_qualities):","427","    \"\"\"Get the number of samples from data qualities.","428","","429","    Parameters","430","    ----------","431","    data_qualities : list of dict","432","        Used to retrieve the number of instances (samples) in the dataset.","433","","434","    Returns","435","    -------","436","    n_samples : int","437","        The number of samples in the dataset or -1 if data qualities are","438","        unavailable.","439","    \"\"\"","440","    # If the data qualities are unavailable, we return -1","441","    default_n_samples = -1","442","","444","        return default_n_samples","445","","447","    return int(float(qualities.get('NumberOfInstances', default_n_samples)))","721","        # The shape must include the ignored features to keep the right indexes","722","        # during the arff data conversion.","724","        shape = _get_num_samples(data_qualities), len(features_list)"],"delete":["426","def _get_data_shape(data_qualities):","427","    # Using the data_info dictionary from _get_data_info_by_name to extract","428","    # the number of samples \/ features","430","        return None","432","    try:","433","        return (int(float(qualities['NumberOfInstances'])),","434","                int(float(qualities['NumberOfFeatures'])))","435","    except AttributeError:","436","        return None","711","        shape = _get_data_shape(data_qualities)","712","        # if the data qualities were not available, we can still get the","713","        # n_features from the feature list, with the n_samples unknown","714","        if shape is None:","715","            shape = (-1, len(features_list))"]}]}},"0ea324406174f046877c98bfe758c16122ad8ba7":{"changes":{"sklearn\/metrics\/tests\/test_score_objects.py":"MODIFY","sklearn\/metrics\/_scorer.py":"MODIFY","sklearn\/metrics\/tests\/test_common.py":"MODIFY","doc\/modules\/classes.rst":"MODIFY","doc\/whats_new\/_contributors.rst":"MODIFY","doc\/modules\/model_evaluation.rst":"MODIFY","sklearn\/metrics\/__init__.py":"MODIFY","sklearn\/metrics\/tests\/test_regression.py":"MODIFY","doc\/whats_new\/v0.24.rst":"MODIFY","sklearn\/metrics\/_regression.py":"MODIFY"},"diff":{"sklearn\/metrics\/tests\/test_score_objects.py":[{"add":["45","                      'neg_mean_absolute_percentage_error',","50","                      'mean_absolute_percentage_error',"],"delete":[]}],"sklearn\/metrics\/_scorer.py":[{"add":["32","               brier_score_loss, jaccard_score, mean_absolute_percentage_error)","616","neg_mean_absolute_percentage_error_scorer = make_scorer(","617","    mean_absolute_percentage_error, greater_is_better=False","618",")","679","               neg_mean_absolute_percentage_error=neg_mean_absolute_percentage_error_scorer,  # noqa"],"delete":["32","               brier_score_loss, jaccard_score)"]}],"sklearn\/metrics\/tests\/test_common.py":[{"add":["43","from sklearn.metrics import mean_absolute_percentage_error","101","    \"mean_absolute_percentage_error\": mean_absolute_percentage_error,","429","    \"r2_score\", \"explained_variance_score\", \"mean_absolute_percentage_error\"","476","    \"mean_compound_poisson_deviance\", \"mean_absolute_percentage_error\"","1375","        if metric == mean_absolute_percentage_error:","1376","            assert np.isfinite(current_score)","1377","            assert current_score > 1e6","1378","            # Here we are not comparing the values in case of MAPE because","1379","            # whenever y_true value is exactly zero, the MAPE value doesn't","1380","            # signify anything. Thus, in this case we are just expecting","1381","            # very large finite value.","1382","        else:","1383","            assert_almost_equal(score, current_score)"],"delete":["427","    \"r2_score\", \"explained_variance_score\"","474","    \"mean_compound_poisson_deviance\"","1373","        assert_almost_equal(score, current_score)"]}],"doc\/modules\/classes.rst":[{"add":["902","","983","   metrics.mean_absolute_percentage_error"],"delete":["902","\t"]}],"doc\/whats_new\/_contributors.rst":[{"add":["178",".. _Guillaume Lemaitre: https:\/\/github.com\/glemaitre"],"delete":["178",".. _Guillaume Lemaitre: https:\/\/github.com\/glemaitre"]}],"doc\/modules\/model_evaluation.rst":[{"add":["56","====================================   ==============================================     ==================================","57","Scoring                                Function                                           Comment","58","====================================   ==============================================     ==================================","60","'accuracy'                             :func:`metrics.accuracy_score`","61","'balanced_accuracy'                    :func:`metrics.balanced_accuracy_score`","62","'average_precision'                    :func:`metrics.average_precision_score`","63","'neg_brier_score'                      :func:`metrics.brier_score_loss`","64","'f1'                                   :func:`metrics.f1_score`                           for binary targets","65","'f1_micro'                             :func:`metrics.f1_score`                           micro-averaged","66","'f1_macro'                             :func:`metrics.f1_score`                           macro-averaged","67","'f1_weighted'                          :func:`metrics.f1_score`                           weighted average","68","'f1_samples'                           :func:`metrics.f1_score`                           by multilabel sample","69","'neg_log_loss'                         :func:`metrics.log_loss`                           requires ``predict_proba`` support","70","'precision' etc.                       :func:`metrics.precision_score`                    suffixes apply as with 'f1'","71","'recall' etc.                          :func:`metrics.recall_score`                       suffixes apply as with 'f1'","72","'jaccard' etc.                         :func:`metrics.jaccard_score`                      suffixes apply as with 'f1'","73","'roc_auc'                              :func:`metrics.roc_auc_score`","74","'roc_auc_ovr'                          :func:`metrics.roc_auc_score`","75","'roc_auc_ovo'                          :func:`metrics.roc_auc_score`","76","'roc_auc_ovr_weighted'                 :func:`metrics.roc_auc_score`","77","'roc_auc_ovo_weighted'                 :func:`metrics.roc_auc_score`","80","'adjusted_mutual_info_score'           :func:`metrics.adjusted_mutual_info_score`","81","'adjusted_rand_score'                  :func:`metrics.adjusted_rand_score`","82","'completeness_score'                   :func:`metrics.completeness_score`","83","'fowlkes_mallows_score'                :func:`metrics.fowlkes_mallows_score`","84","'homogeneity_score'                    :func:`metrics.homogeneity_score`","85","'mutual_info_score'                    :func:`metrics.mutual_info_score`","86","'normalized_mutual_info_score'         :func:`metrics.normalized_mutual_info_score`","87","'v_measure_score'                      :func:`metrics.v_measure_score`","90","'explained_variance'                   :func:`metrics.explained_variance_score`","91","'max_error'                            :func:`metrics.max_error`","92","'neg_mean_absolute_error'              :func:`metrics.mean_absolute_error`","93","'neg_mean_squared_error'               :func:`metrics.mean_squared_error`","94","'neg_root_mean_squared_error'          :func:`metrics.mean_squared_error`","95","'neg_mean_squared_log_error'           :func:`metrics.mean_squared_log_error`","96","'neg_median_absolute_error'            :func:`metrics.median_absolute_error`","97","'r2'                                   :func:`metrics.r2_score`","98","'neg_mean_poisson_deviance'            :func:`metrics.mean_poisson_deviance`","99","'neg_mean_gamma_deviance'              :func:`metrics.mean_gamma_deviance`","100","'neg_mean_absolute_percentage_error'   :func:`metrics.mean_absolute_percentage_error`","101","====================================   ==============================================     ==================================","1966",".. _mean_absolute_percentage_error:","1967","","1968","Mean absolute percentage error","1969","------------------------------","1970","The :func:`mean_absolute_percentage_error` (MAPE), also known as mean absolute","1971","percentage deviation (MAPD), is an evaluation metric for regression problems.","1972","The idea of this metric is to be sensitive to relative errors. It is for example","1973","not changed by a global scaling of the target variable.","1974","","1975","If :math:`\\hat{y}_i` is the predicted value of the :math:`i`-th sample","1976","and :math:`y_i` is the corresponding true value, then the mean absolute percentage","1977","error (MAPE) estimated over :math:`n_{\\text{samples}}` is defined as","1978","","1979",".. math::","1980","","1981","  \\text{MAPE}(y, \\hat{y}) = \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}}-1} \\frac{{}\\left| y_i - \\hat{y}_i \\right|}{max(\\epsilon, \\left| y_i \\right|)}","1982","","1983","where :math:`\\epsilon` is an arbitrary small yet strictly positive number to","1984","avoid undefined results when y is zero.","1985","","1986","The :func:`mean_absolute_percentage_error` function supports multioutput.","1987","","1988","Here is a small example of usage of the :func:`mean_absolute_percentage_error`","1989","function::","1990","","1991","  >>> from sklearn.metrics import mean_absolute_percentage_error","1992","  >>> y_true = [1, 10, 1e6]","1993","  >>> y_pred = [0.9, 15, 1.2e6]","1994","  >>> mean_absolute_percentage_error(y_true, y_pred)","1995","  0.2666...","1996","","1997","In above example, if we had used `mean_absolute_error`, it would have ignored","1998","the small magnitude values and only reflected the error in prediction of highest","1999","magnitude value. But that problem is resolved in case of MAPE because it calculates","2000","relative percentage error with respect to actual output.","2001",""],"delete":["56","==============================    =============================================     ==================================","57","Scoring                           Function                                          Comment","58","==============================    =============================================     ==================================","60","'accuracy'                        :func:`metrics.accuracy_score`","61","'balanced_accuracy'               :func:`metrics.balanced_accuracy_score`","62","'average_precision'               :func:`metrics.average_precision_score`","63","'neg_brier_score'                 :func:`metrics.brier_score_loss`","64","'f1'                              :func:`metrics.f1_score`                          for binary targets","65","'f1_micro'                        :func:`metrics.f1_score`                          micro-averaged","66","'f1_macro'                        :func:`metrics.f1_score`                          macro-averaged","67","'f1_weighted'                     :func:`metrics.f1_score`                          weighted average","68","'f1_samples'                      :func:`metrics.f1_score`                          by multilabel sample","69","'neg_log_loss'                    :func:`metrics.log_loss`                          requires ``predict_proba`` support","70","'precision' etc.                  :func:`metrics.precision_score`                   suffixes apply as with 'f1'","71","'recall' etc.                     :func:`metrics.recall_score`                      suffixes apply as with 'f1'","72","'jaccard' etc.                    :func:`metrics.jaccard_score`                     suffixes apply as with 'f1'","73","'roc_auc'                         :func:`metrics.roc_auc_score`","74","'roc_auc_ovr'                     :func:`metrics.roc_auc_score`","75","'roc_auc_ovo'                     :func:`metrics.roc_auc_score`","76","'roc_auc_ovr_weighted'            :func:`metrics.roc_auc_score`","77","'roc_auc_ovo_weighted'            :func:`metrics.roc_auc_score`","80","'adjusted_mutual_info_score'      :func:`metrics.adjusted_mutual_info_score`","81","'adjusted_rand_score'             :func:`metrics.adjusted_rand_score`","82","'completeness_score'              :func:`metrics.completeness_score`","83","'fowlkes_mallows_score'           :func:`metrics.fowlkes_mallows_score`","84","'homogeneity_score'               :func:`metrics.homogeneity_score`","85","'mutual_info_score'               :func:`metrics.mutual_info_score`","86","'normalized_mutual_info_score'    :func:`metrics.normalized_mutual_info_score`","87","'v_measure_score'                 :func:`metrics.v_measure_score`","90","'explained_variance'              :func:`metrics.explained_variance_score`","91","'max_error'                       :func:`metrics.max_error`","92","'neg_mean_absolute_error'         :func:`metrics.mean_absolute_error`","93","'neg_mean_squared_error'          :func:`metrics.mean_squared_error`","94","'neg_root_mean_squared_error'     :func:`metrics.mean_squared_error`","95","'neg_mean_squared_log_error'      :func:`metrics.mean_squared_log_error`","96","'neg_median_absolute_error'       :func:`metrics.median_absolute_error`","97","'r2'                              :func:`metrics.r2_score`","98","'neg_mean_poisson_deviance'       :func:`metrics.mean_poisson_deviance`","99","'neg_mean_gamma_deviance'         :func:`metrics.mean_gamma_deviance`","100","==============================    =============================================     =================================="]}],"sklearn\/metrics\/__init__.py":[{"add":["66","from ._regression import mean_absolute_percentage_error","131","    'mean_absolute_percentage_error',"],"delete":[]}],"sklearn\/metrics\/tests\/test_regression.py":[{"add":["15","from sklearn.metrics import mean_absolute_percentage_error","35","    mape = mean_absolute_percentage_error(y_true, y_pred)","36","    assert np.isfinite(mape)","37","    assert mape > 1e6","92","    error = np.around(mean_absolute_percentage_error(y_true, y_pred),","93","                      decimals=2)","94","    assert np.isfinite(error)","95","    assert error > 1e6","110","    assert_almost_equal(mean_absolute_percentage_error([0.], [0.]), 0.00, 2)","209","    mape = mean_absolute_percentage_error(y_true, y_pred,","210","                                          multioutput='raw_values')","216","    assert_array_almost_equal(mape, [0.0778, 0.2262], decimal=2)","268","    mapew = mean_absolute_percentage_error(y_true, y_pred,","269","                                           multioutput=[0.4, 0.6])","276","    assert_almost_equal(mapew, 0.1668, decimal=2)","325","","326","","327","def test_mean_absolute_percentage_error():","328","    random_number_generator = np.random.RandomState(42)","329","    y_true = random_number_generator.exponential(size=100)","330","    y_pred = 1.2 * y_true","331","    assert mean_absolute_percentage_error(y_true, y_pred) == pytest.approx(0.2)"],"delete":[]}],"doc\/whats_new\/v0.24.rst":[{"add":["152","- |Feature| Added :func:`metrics.mean_absolute_percentage_error` metric and","153","  the associated scorer for regression problems. :issue:`10708` fixed with the","154","  PR :pr:`15007` by :user:`Ashutosh Hathidara <ashutosh1919>`. The scorer and","155","  some practical test cases were taken from PR :pr:`10711` by","156","  :user:`Mohamed Ali Jamaoui <mohamed-ali>`.","157",""],"delete":[]}],"sklearn\/metrics\/_regression.py":[{"add":["22","#          Ashutosh Hathidara <ashutoshhathidara98@gmail.com>","44","    \"mean_absolute_percentage_error\",","196","def mean_absolute_percentage_error(y_true, y_pred,","197","                                   sample_weight=None,","198","                                   multioutput='uniform_average'):","199","    \"\"\"Mean absolute percentage error regression loss","200","","201","    Note here that we do not represent the output as a percentage in range","202","    [0, 100]. Instead, we represent it in range [0, 1\/eps]. Read more in the","203","    :ref:`User Guide <mean_absolute_percentage_error>`.","204","","205","    Parameters","206","    ----------","207","    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)","208","        Ground truth (correct) target values.","209","","210","    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)","211","        Estimated target values.","212","","213","    sample_weight : array-like of shape (n_samples,), default=None","214","        Sample weights.","215","","216","    multioutput : {'raw_values', 'uniform_average'} or array-like","217","        Defines aggregating of multiple output values.","218","        Array-like value defines weights used to average errors.","219","        If input is list then the shape must be (n_outputs,).","220","","221","        'raw_values' :","222","            Returns a full set of errors in case of multioutput input.","223","","224","        'uniform_average' :","225","            Errors of all outputs are averaged with uniform weight.","226","","227","    Returns","228","    -------","229","    loss : float or ndarray of floats in the range [0, 1\/eps]","230","        If multioutput is 'raw_values', then mean absolute percentage error","231","        is returned for each output separately.","232","        If multioutput is 'uniform_average' or an ndarray of weights, then the","233","        weighted average of all output errors is returned.","234","","235","        MAPE output is non-negative floating point. The best value is 0.0.","236","        But note the fact that bad predictions can lead to arbitarily large","237","        MAPE values, especially if some y_true values are very close to zero.","238","        Note that we return a large value instead of `inf` when y_true is zero.","239","","240","    Examples","241","    --------","242","    >>> from sklearn.metrics import mean_absolute_percentage_error","243","    >>> y_true = [3, -0.5, 2, 7]","244","    >>> y_pred = [2.5, 0.0, 2, 8]","245","    >>> mean_absolute_percentage_error(y_true, y_pred)","246","    0.3273...","247","    >>> y_true = [[0.5, 1], [-1, 1], [7, -6]]","248","    >>> y_pred = [[0, 2], [-1, 2], [8, -5]]","249","    >>> mean_absolute_percentage_error(y_true, y_pred)","250","    0.5515...","251","    >>> mean_absolute_percentage_error(y_true, y_pred, multioutput=[0.3, 0.7])","252","    0.6198...","253","    \"\"\"","254","    y_type, y_true, y_pred, multioutput = _check_reg_targets(","255","        y_true, y_pred, multioutput)","256","    check_consistent_length(y_true, y_pred, sample_weight)","257","    epsilon = np.finfo(np.float64).eps","258","    mape = np.abs(y_pred - y_true) \/ np.maximum(np.abs(y_true), epsilon)","259","    output_errors = np.average(mape,","260","                               weights=sample_weight, axis=0)","261","    if isinstance(multioutput, str):","262","        if multioutput == 'raw_values':","263","            return output_errors","264","        elif multioutput == 'uniform_average':","265","            # pass None as weights to np.average: uniform mean","266","            multioutput = None","267","","268","    return np.average(output_errors, weights=multioutput)","269","","270",""],"delete":[]}]}},"53f76d1a24ef42eb8c620fc1116c53db11dd07d9":{"changes":{"sklearn\/feature_extraction\/text.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY","sklearn\/feature_extraction\/tests\/test_text.py":"MODIFY"},"diff":{"sklearn\/feature_extraction\/text.py":[{"add":["17","from functools import partial","47","def _preprocess(doc, accent_function=None, lower=False):","48","    \"\"\"Chain together an optional series of text preprocessing steps to","49","    apply to a document.","50","","51","    Parameters","52","    ----------","53","    doc: str","54","        The string to preprocess","55","    accent_function: callable","56","        Function for handling accented characters. Common strategies include","57","        normalizing and removing.","58","    lower: bool","59","        Whether to use str.lower to lowercase all fo the text","60","","61","    Returns","62","    -------","63","    doc: str","64","        preprocessed string","65","    \"\"\"","66","    if lower:","67","        doc = doc.lower()","68","    if accent_function is not None:","69","        doc = accent_function(doc)","70","    return doc","71","","72","","73","def _analyze(doc, analyzer=None, tokenizer=None, ngrams=None,","74","             preprocessor=None, decoder=None, stop_words=None):","75","    \"\"\"Chain together an optional series of text processing steps to go from","76","    a single document to ngrams, with or without tokenizing or preprocessing.","77","","78","    If analyzer is used, only the decoder argument is used, as the analyzer is","79","    intended to replace the preprocessor, tokenizer, and ngrams steps.","80","","81","    Parameters","82","    ----------","83","    analyzer: callable","84","    tokenizer: callable","85","    ngrams: callable","86","    preprocessor: callable","87","    decoder: callable","88","    stop_words: list","89","","90","    Returns","91","    -------","92","    ngrams: list","93","        A sequence of tokens, possibly with pairs, triples, etc.","94","    \"\"\"","95","","96","    if decoder is not None:","97","        doc = decoder(doc)","98","    if analyzer is not None:","99","        doc = analyzer(doc)","100","    else:","101","        if preprocessor is not None:","102","            doc = preprocessor(doc)","103","        if tokenizer is not None:","104","            doc = tokenizer(doc)","105","        if ngrams is not None:","106","            if stop_words is not None:","107","                doc = ngrams(doc, stop_words)","108","            else:","109","                doc = ngrams(doc)","110","    return doc","111","","112","","303","            strip_accents = None","314","        return partial(","315","            _preprocess, accent_function=strip_accents, lower=self.lowercase","316","        )","323","        return token_pattern.findall","396","            return partial(","397","                _analyze, analyzer=self.analyzer, decoder=self.decode","398","            )","403","            return partial(_analyze, ngrams=self._char_ngrams,","404","                           preprocessor=preprocess, decoder=self.decode)","407","            return partial(_analyze, ngrams=self._char_wb_ngrams,","408","                           preprocessor=preprocess, decoder=self.decode)","415","            return partial(_analyze, ngrams=self._word_ngrams,","416","                           tokenizer=tokenize, preprocessor=preprocess,","417","                           decoder=self.decode, stop_words=stop_words)"],"delete":["234","        # unfortunately python functools package does not have an efficient","235","        # `compose` function that would have allowed us to chain a dynamic","236","        # number of functions. However the cost of a lambda call is a few","237","        # hundreds of nanoseconds which is negligible when compared to the","238","        # cost of tokenizing a string of 1000 chars for instance.","239","        noop = lambda x: x","240","","243","            strip_accents = noop","254","        if self.lowercase:","255","            return lambda x: strip_accents(x.lower())","256","        else:","257","            return strip_accents","264","        return lambda doc: token_pattern.findall(doc)","337","            return lambda doc: self.analyzer(self.decode(doc))","342","            return lambda doc: self._char_ngrams(preprocess(self.decode(doc)))","345","            return lambda doc: self._char_wb_ngrams(","346","                preprocess(self.decode(doc)))","353","            return lambda doc: self._word_ngrams(","354","                tokenize(preprocess(self.decode(doc))), stop_words)"]}],"doc\/whats_new\/v0.22.rst":[{"add":["136",":mod:`sklearn.feature_extraction`","137",".......................","138","","139","- |Fix| Functions created by build_preprocessor and build_analyzer of","140","  :class:`feature_extraction.text.VectorizerMixin` can now be pickled.","141","  :pr:`14430` by :user:`Dillon Niederhut <deniederhut>`.","142","","231","","240","","241","- |Fix| KernelCenterer now throws error when fit on non-square","273","  :pr:`14336` by :user:`Gregory Dexter <gdex1>`.","284",""],"delete":["224","  ","233"," ","234","- |Fix| KernelCenterer now throws error when fit on non-square ","266","  :pr:`14336` by :user:`Gregory Dexter <gdex1>`.  ","277","  "]}],"sklearn\/feature_extraction\/tests\/test_text.py":[{"add":["482","    processor = v3.build_preprocessor()","483","    text = (\"J'ai mang du kangourou  ce midi, \"","484","            \"c'tait pas trs bon.\")","485","    expected = strip_accents_ascii(text)","486","    result = processor(text)","487","    assert expected == result","891","@pytest.mark.parametrize('factory', [","892","    CountVectorizer.build_analyzer,","893","    CountVectorizer.build_preprocessor,","894","    CountVectorizer.build_tokenizer,","895","])","896","def test_pickling_built_processors(factory):","897","    \"\"\"Tokenizers cannot be pickled","898","    https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/12833","899","    \"\"\"","900","    vec = CountVectorizer()","901","    function = factory(vec)","902","    text = (\"J'ai mang du kangourou  ce midi, \"","903","            \"c'tait pas trs bon.\")","904","    roundtripped_function = pickle.loads(pickle.dumps(function))","905","    expected = function(text)","906","    result = roundtripped_function(text)","907","    assert result == expected","908","","909",""],"delete":["482","    assert v3.build_preprocessor() == strip_accents_ascii"]}]}}}
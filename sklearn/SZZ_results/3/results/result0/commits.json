{"bb208d3bf6e77a4408c00b5fb6a6b7ce674b8912":{"changes":{"doc\/whats_new\/v0.22.rst":"MODIFY","sklearn\/cross_decomposition\/pls_.py":"MODIFY","sklearn\/cross_decomposition\/tests\/test_pls.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.22.rst":[{"add":["389",":mod:`sklearn.cross_decomposition`","390","..................................","391","","392","- |Fix| Fixed a bug where :class:`cross_decomposition.PLSCanonical` and","393","  :class:`cross_decomposition.PLSRegression` were raising an error when fitted","394","  with a target matrix `Y` in which the first column was constant.","395","  :issue:`13609` by :user:`Camila Williamson <camilaagw>`.","406","  :pr:`13609` by :user:`Guillaume Lemaitre <glemaitre>`."],"delete":["399","  :pr:`14195` by :user:`Guillaume Lemaitre <glemaitre>`."]}],"sklearn\/cross_decomposition\/pls_.py":[{"add":["33","    for col in Y.T:","34","        if np.any(np.abs(col) > np.finfo(np.double).eps):","35","            y_score = col.reshape(len(col), 1)","36","            break","37",""],"delete":["33","    y_score = Y[:, [0]]"]}],"sklearn\/cross_decomposition\/tests\/test_pls.py":[{"add":["263","    # 4) Another \"Non regression test\" of PLS Regression (PLS2):","264","    #    Checking behavior when the first column of Y is constant","265","    # ===============================================","266","    # The results were compared against a modified version of plsreg2","267","    # from the R-package plsdepot","268","    X = d.data","269","    Y = d.target","270","    Y[:, 0] = 1","271","    pls_2 = pls_.PLSRegression(n_components=X.shape[1])","272","    pls_2.fit(X, Y)","273","","274","    x_weights = np.array(","275","        [[-0.6273573, 0.007081799, 0.7786994],","276","         [-0.7493417, -0.277612681, -0.6011807],","277","         [-0.2119194, 0.960666981, -0.1794690]])","278","    x_weights_sign_flip = pls_2.x_weights_ \/ x_weights","279","","280","    x_loadings = np.array(","281","        [[-0.6273512, -0.22464538, 0.7786994],","282","         [-0.6643156, -0.09871193, -0.6011807],","283","         [-0.5125877, 1.01407380, -0.1794690]])","284","    x_loadings_sign_flip = pls_2.x_loadings_ \/ x_loadings","285","","286","    y_loadings = np.array(","287","        [[0.0000000, 0.0000000, 0.0000000],","288","         [0.4357300, 0.5828479, 0.2174802],","289","         [-0.1353739, -0.2486423, -0.1810386]])","290","","291","    # R\/python sign flip should be the same in x_weight and x_rotation","292","    assert_array_almost_equal(x_loadings_sign_flip, x_weights_sign_flip, 4)","293","","294","    # This test that R \/ python give the same result up to column","295","    # sign indeterminacy","296","    assert_array_almost_equal(np.abs(x_loadings_sign_flip), 1, 4)","297","    assert_array_almost_equal(np.abs(x_weights_sign_flip), 1, 4)","298","","299","    # For the PLSRegression with default parameters, it holds that","300","    # y_loadings==y_weights. In this case we only test that R\/python","301","    # give the same result for the y_loadings irrespective of the sign","302","    assert_array_almost_equal(np.abs(pls_2.y_loadings_), np.abs(y_loadings), 4)","303",""],"delete":[]}]}},"e912fe7984127a5ca9dd35ffe316b69aa33d8cc9":{"changes":{"sklearn\/manifold\/tests\/test_mds.py":"MODIFY","sklearn\/manifold\/tests\/test_locally_linear.py":"MODIFY","sklearn\/manifold\/tests\/test_spectral_embedding.py":"MODIFY","sklearn\/manifold\/tests\/test_t_sne.py":"MODIFY"},"diff":{"sklearn\/manifold\/tests\/test_mds.py":[{"add":["2","import pytest","33","    with pytest.raises(ValueError):","34","        mds.smacof(sim)","41","    with pytest.raises(ValueError):","42","        mds.smacof(sim)","53","    with pytest.raises(ValueError):","54","        mds.smacof(sim, init=Z, n_init=1)"],"delete":["4","from sklearn.utils.testing import assert_raises","33","    assert_raises(ValueError, mds.smacof, sim)","40","    assert_raises(ValueError, mds.smacof, sim)","51","    assert_raises(ValueError, mds.smacof, sim, init=Z, n_init=1)"]}],"sklearn\/manifold\/tests\/test_locally_linear.py":[{"add":["5","import pytest","132","    with pytest.raises(ValueError):","133","        f(manifold.locally_linear_embedding(M, 2, 1,","134","                                            method='standard',","135","                                            eigen_solver='arpack'))"],"delete":["10","from sklearn.utils.testing import assert_raises","132","    assert_raises(ValueError, f(manifold.locally_linear_embedding),","133","                  M, 2, 1, method='standard', eigen_solver='arpack')"]}],"sklearn\/manifold\/tests\/test_spectral_embedding.py":[{"add":["204","    with pytest.raises(ValueError):","205","        se.fit(S)","212","    with pytest.raises(ValueError):","213","        se.fit(S)"],"delete":["19","from sklearn.utils.testing import assert_raises","205","    assert_raises(ValueError, se.fit, S)","212","    assert_raises(ValueError, se.fit, S)"]}],"sklearn\/manifold\/tests\/test_t_sne.py":[{"add":["304","    with pytest.raises(ValueError, match=\"early_exaggeration .*\"):","305","        tsne.fit_transform(np.array([[0.0], [0.0]]))","311","    with pytest.raises(ValueError, match=\"n_iter .*\"):","312","        tsne.fit_transform(np.array([[0.0], [0.0]]))","318","    with pytest.raises(ValueError, match=\".* square distance matrix\"):","319","        tsne.fit_transform(np.array([[0.0], [1.0]]))","327","        with pytest.raises(ValueError, match=\"All distances .*precomputed.*\"):","328","            tsne.fit_transform(bad_dist)","338","    with pytest.raises(ValueError, match=\"All distances .*metric given.*\"):","339","        tsne.fit_transform(X)","346","    with pytest.raises(ValueError, match=m):","347","        tsne.fit_transform(np.array([[0.0], [1.0]]))","367","    with pytest.raises(ValueError, match=\"Unknown metric not available.*\"):","368","        tsne.fit_transform(np.array([[0.0], [1.0]]))","371","    with pytest.raises(ValueError, match=\"Metric 'not available' not valid.*\"):","372","        tsne.fit_transform(np.array([[0.0], [1.0]]))","378","    with pytest.raises(ValueError, match=\"'method' must be 'barnes_hut' or \"):","379","        tsne.fit_transform(np.array([[0.0], [1.0]]))","386","        with pytest.raises(ValueError, match=\"'angle' must be between \"","387","                                             \"0.0 - 1.0\"):","388","            tsne.fit_transform(np.array([[0.0], [1.0]]))","394","    with pytest.raises(ValueError, match=\"The parameter init=\\\"pca\\\" cannot\"","395","                                         \" be used with\"","396","                                         \" metric=\\\"precomputed\\\".\"):","397","        tsne.fit_transform(np.array([[0.0], [1.0]]))","403","    with pytest.raises(ValueError, match=\"'n_components' should be .*\"):","404","        tsne.fit_transform(np.array([[0.0], [1.0]]))","572","    with pytest.raises(TypeError, match=\"A sparse matrix was.*\"):","573","        tsne.fit_transform(X_csr)"],"delete":["13","from sklearn.utils.testing import assert_raises_regexp","305","    assert_raises_regexp(ValueError, \"early_exaggeration .*\",","306","                         tsne.fit_transform, np.array([[0.0], [0.0]]))","312","    assert_raises_regexp(ValueError, \"n_iter .*\", tsne.fit_transform,","313","                         np.array([[0.0], [0.0]]))","319","    assert_raises_regexp(ValueError, \".* square distance matrix\",","320","                         tsne.fit_transform, np.array([[0.0], [1.0]]))","328","        assert_raises_regexp(ValueError, \"All distances .*precomputed.*\",","329","                             tsne.fit_transform, bad_dist)","339","    assert_raises_regexp(ValueError, \"All distances .*metric given.*\",","340","                         tsne.fit_transform, X)","347","    assert_raises_regexp(ValueError, m, tsne.fit_transform,","348","                         np.array([[0.0], [1.0]]))","368","    assert_raises_regexp(ValueError, \"Unknown metric not available.*\",","369","                         tsne.fit_transform, np.array([[0.0], [1.0]]))","372","    assert_raises_regexp(ValueError, \"Metric 'not available' not valid.*\",","373","                         tsne.fit_transform, np.array([[0.0], [1.0]]))","379","    assert_raises_regexp(ValueError, \"'method' must be 'barnes_hut' or \",","380","                         tsne.fit_transform, np.array([[0.0], [1.0]]))","387","        assert_raises_regexp(ValueError, \"'angle' must be between 0.0 - 1.0\",","388","                             tsne.fit_transform, np.array([[0.0], [1.0]]))","394","    assert_raises_regexp(ValueError, \"The parameter init=\\\"pca\\\" cannot be \"","395","                         \"used with metric=\\\"precomputed\\\".\",","396","                         tsne.fit_transform, np.array([[0.0], [1.0]]))","402","    assert_raises_regexp(ValueError, \"'n_components' should be .*\",","403","                         tsne.fit_transform, np.array([[0.0], [1.0]]))","571","    assert_raises_regexp(TypeError, \"A sparse matrix was.*\",","572","                         tsne.fit_transform, X_csr)"]}]}},"93c628eedea495d0fe3e284c066e5cebff5b758c":{"changes":{"sklearn\/isotonic.py":"MODIFY","sklearn\/tests\/test_isotonic.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY"},"diff":{"sklearn\/isotonic.py":[{"add":["326","        check_params = dict(accept_sparse=False, ensure_2d=False)","327","        X = check_array(X, dtype=[np.float64, np.float32], **check_params)","328","        y = check_array(y, dtype=X.dtype, **check_params)"],"delete":["326","        check_params = dict(accept_sparse=False, ensure_2d=False,","327","                            dtype=[np.float64, np.float32])","328","        X = check_array(X, **check_params)","329","        y = check_array(y, **check_params)"]}],"sklearn\/tests\/test_isotonic.py":[{"add":["5","import pytest","6","","389","    assert np.all(y >= 0)","390","    assert np.all(y <= 0.1)","395","    assert np.all(y >= 0)","396","    assert np.all(y <= 0.1)","401","    assert np.all(y >= 0)","489","@pytest.mark.parametrize(","490","    \"y_dtype\", [np.int32, np.int64, np.float32, np.float64]","491",")","492","def test_isotonic_mismatched_dtype(y_dtype):","493","    # regression test for #15004","494","    # check that data are converted when X and y dtype differ","495","    reg = IsotonicRegression()","496","    y = np.array([2, 1, 4, 3, 5], dtype=y_dtype)","497","    X = np.arange(len(y), dtype=np.float32)","498","    reg.fit(X, y)","499","    assert reg.predict(X).dtype == X.dtype","500","","501",""],"delete":["387","    assert(np.all(y >= 0))","388","    assert(np.all(y <= 0.1))","393","    assert(np.all(y >= 0))","394","    assert(np.all(y <= 0.1))","399","    assert(np.all(y >= 0))"]}],"doc\/whats_new\/v0.22.rst":[{"add":["574",":mod:`sklearn.isotonic`","575","..................................","576","","577","- |Fix| Fixed a bug where :class:`isotonic.IsotonicRegression.fit` raised error","578","  when `X.dtype == 'float32'` and `X.dtype != y.dtype`.","579","  :pr:`14902` by :user:`Lucas <lostcoaster>`.","580","","581",""],"delete":[]}]}},"a2968c2e4f0cbd5e957b0ba1d63ce2cb16d8008f":{"changes":{"sklearn\/feature_selection\/tests\/test_base.py":"MODIFY","sklearn\/feature_selection\/tests\/test_chi2.py":"MODIFY","sklearn\/feature_selection\/tests\/test_mutual_info.py":"MODIFY","sklearn\/feature_selection\/tests\/test_variance_threshold.py":"MODIFY","sklearn\/feature_selection\/tests\/test_from_model.py":"MODIFY","sklearn\/feature_selection\/tests\/test_feature_select.py":"MODIFY"},"diff":{"sklearn\/feature_selection\/tests\/test_base.py":[{"add":["1","import pytest","56","    with pytest.raises(ValueError):","57","        sel.transform(np.array([[1], [2]]))","73","    with pytest.raises(ValueError):","74","        sel.transform(np.array([[1], [2]]))","93","    with pytest.raises(ValueError):","94","        sel.inverse_transform(np.array([[1], [2]]))","110","    with pytest.raises(ValueError):","111","        sel.inverse_transform(np.array([[1], [2]]))"],"delete":["8","from sklearn.utils.testing import assert_raises","56","    assert_raises(ValueError, sel.transform, np.array([[1], [2]]))","72","    assert_raises(ValueError, sel.transform, np.array([[1], [2]]))","91","    assert_raises(ValueError, sel.inverse_transform, np.array([[1], [2]]))","107","    assert_raises(ValueError, sel.inverse_transform, np.array([[1], [2]]))"]}],"sklearn\/feature_selection\/tests\/test_chi2.py":[{"add":["8","import pytest","67","        with pytest.raises(ValueError):","68","            chi2(X, y)"],"delete":["13","from sklearn.utils.testing import assert_raises","67","        assert_raises(ValueError, chi2, X, y)"]}],"sklearn\/feature_selection\/tests\/test_mutual_info.py":[{"add":["2","import pytest","6","from sklearn.utils.testing import assert_array_equal, assert_almost_equal","184","        with pytest.raises(ValueError):","185","            mutual_info(X_csr, y, discrete_features=False)","186","        with pytest.raises(ValueError):","187","            mutual_info(X, y, discrete_features='manual')","188","        with pytest.raises(ValueError):","189","            mutual_info(X_csr, y, discrete_features=[True, False, True])","190","        with pytest.raises(IndexError):","191","            mutual_info(X, y, discrete_features=[True, False, True, False])","192","        with pytest.raises(IndexError):","193","            mutual_info(X, y, discrete_features=[1, 4])"],"delete":["5","from sklearn.utils.testing import (assert_array_equal, assert_almost_equal,","6","                                   assert_raises)","184","        assert_raises(ValueError, mutual_info, X_csr, y,","185","                      discrete_features=False)","186","        assert_raises(ValueError, mutual_info, X, y,","187","                      discrete_features='manual')","188","        assert_raises(ValueError, mutual_info, X_csr, y,","189","                      discrete_features=[True, False, True])","190","        assert_raises(IndexError, mutual_info, X, y,","191","                      discrete_features=[True, False, True, False])","192","        assert_raises(IndexError, mutual_info, X, y, discrete_features=[1, 4])"]}],"sklearn\/feature_selection\/tests\/test_variance_threshold.py":[{"add":["3","from sklearn.utils.testing import assert_array_equal","21","    with pytest.raises(ValueError):","22","        VarianceThreshold().fit([[0, 1, 2, 3]])","23","    with pytest.raises(ValueError):","24","        VarianceThreshold().fit([[0, 1], [0, 1]])"],"delete":["3","from sklearn.utils.testing import assert_array_equal, assert_raises","21","    assert_raises(ValueError, VarianceThreshold().fit, [[0, 1, 2, 3]])","22","    assert_raises(ValueError, VarianceThreshold().fit, [[0, 1], [0, 1]])"]}],"sklearn\/feature_selection\/tests\/test_from_model.py":[{"add":["29","        with pytest.raises(ValueError):","30","            model.transform(data)","292","    with pytest.raises(ValueError):","293","        model.fit(data, y)"],"delete":["6","from sklearn.utils.testing import assert_raises","30","        assert_raises(ValueError, model.transform, data)","292","    assert_raises(ValueError, model.fit, data, y)"]}],"sklearn\/feature_selection\/tests\/test_feature_select.py":[{"add":["325","    with pytest.raises(ValueError):","326","        SelectPercentile(percentile=-1).fit(X, y)","327","    with pytest.raises(ValueError):","328","        SelectPercentile(percentile=101).fit(X, y)","329","    with pytest.raises(ValueError):","330","        GenericUnivariateSelect(mode='percentile', param=-1).fit(X, y)","331","    with pytest.raises(ValueError):","332","        GenericUnivariateSelect(mode='percentile', param=101).fit(X, y)","567","        with pytest.raises(TypeError):","568","            SelectFeatures(score_func=10).fit(X, y)","575","    with pytest.raises(ValueError):","576","        SelectKBest(k=-1).fit(X, y)","577","    with pytest.raises(ValueError):","578","        SelectKBest(k=4).fit(X, y)","579","    with pytest.raises(ValueError):","580","        GenericUnivariateSelect(mode='k_best', param=-1).fit(X, y)","581","    with pytest.raises(ValueError):","582","        GenericUnivariateSelect(mode='k_best', param=4).fit(X, y)"],"delete":["11","from sklearn.utils.testing import assert_raises","326","    assert_raises(ValueError, SelectPercentile(percentile=-1).fit, X, y)","327","    assert_raises(ValueError, SelectPercentile(percentile=101).fit, X, y)","328","    assert_raises(ValueError, GenericUnivariateSelect(mode='percentile',","329","                                                      param=-1).fit, X, y)","330","    assert_raises(ValueError, GenericUnivariateSelect(mode='percentile',","331","                                                      param=101).fit, X, y)","566","        assert_raises(TypeError, SelectFeatures(score_func=10).fit, X, y)","573","    assert_raises(ValueError, SelectKBest(k=-1).fit, X, y)","574","    assert_raises(ValueError, SelectKBest(k=4).fit, X, y)","575","    assert_raises(ValueError,","576","                  GenericUnivariateSelect(mode='k_best', param=-1).fit, X, y)","577","    assert_raises(ValueError,","578","                  GenericUnivariateSelect(mode='k_best', param=4).fit, X, y)"]}]}},"e74e03294af942a6c82a7b482f517567e330dee5":{"changes":{"sklearn\/tree\/tests\/test_export.py":"MODIFY","sklearn\/tree\/tests\/test_tree.py":"MODIFY"},"diff":{"sklearn\/tree\/tests\/test_export.py":[{"add":["7","import pytest","217","    with pytest.raises(NotFittedError):","218","        export_graphviz(clf, out)","226","    with pytest.raises(ValueError, match=message):","227","        export_graphviz(clf, None, feature_names=[\"a\"])","231","    with pytest.raises(ValueError, match=message):","232","        export_graphviz(clf, None, feature_names=[\"a\", \"b\", \"c\"])","236","    with pytest.raises(TypeError, match=message):","237","        export_graphviz(clf.fit(X, y).tree_)","241","    with pytest.raises(IndexError):","242","        export_graphviz(clf, out, class_names=[])","246","    with pytest.raises(ValueError, match=\"should be greater or equal\"):","247","        export_graphviz(clf, out, precision=-1)","248","    with pytest.raises(ValueError, match=\"should be an integer\"):","249","        export_graphviz(clf, out, precision=\"1\")","316","    err_msg = \"max_depth bust be >= 0, given -1\"","317","    with pytest.raises(ValueError, match=err_msg):","318","        export_text(clf, max_depth=-1)","319","    err_msg = \"feature_names must contain 2 elements, got 1\"","320","    with pytest.raises(ValueError, match=err_msg):","321","        export_text(clf, feature_names=['a'])","322","    err_msg = \"decimals must be >= 0, given -1\"","323","    with pytest.raises(ValueError, match=err_msg):","324","        export_text(clf, decimals=-1)","325","    err_msg = \"spacing must be > 0, given 0\"","326","    with pytest.raises(ValueError, match=err_msg):","327","        export_text(clf, spacing=0)"],"delete":["13","from sklearn.utils.testing import (assert_raises,","14","                                   assert_raises_regex,","15","                                   assert_raise_message)","219","    assert_raises(NotFittedError, export_graphviz, clf, out)","227","    assert_raise_message(ValueError, message, export_graphviz, clf, None,","228","                         feature_names=[\"a\"])","232","    assert_raise_message(ValueError, message, export_graphviz, clf, None,","233","                         feature_names=[\"a\", \"b\", \"c\"])","237","    assert_raise_message(TypeError, message,","238","                         export_graphviz, clf.fit(X, y).tree_)","242","    assert_raises(IndexError, export_graphviz, clf, out, class_names=[])","246","    assert_raises_regex(ValueError, \"should be greater or equal\",","247","                        export_graphviz, clf, out, precision=-1)","248","    assert_raises_regex(ValueError, \"should be an integer\",","249","                        export_graphviz, clf, out, precision=\"1\")","316","    assert_raise_message(ValueError,","317","                         \"max_depth bust be >= 0, given -1\",","318","                         export_text, clf, max_depth=-1)","319","    assert_raise_message(ValueError,","320","                         \"feature_names must contain 2 elements, got 1\",","321","                         export_text, clf, feature_names=['a'])","322","    assert_raise_message(ValueError,","323","                         \"decimals must be >= 0, given -1\",","324","                         export_text, clf, decimals=-1)","325","    assert_raise_message(ValueError,","326","                         \"spacing must be > 0, given 0\",","327","                         export_text, clf, spacing=0)"]}],"sklearn\/tree\/tests\/test_tree.py":[{"add":["393","    with pytest.raises(ValueError):","394","        getattr(clf, 'feature_importances_')","473","        with pytest.raises(ValueError):","474","            est.fit(X, y)","477","        with pytest.raises(ValueError):","478","            est.fit(X, y)","481","        with pytest.raises(ValueError):","482","            est.fit(X, y)","485","        with pytest.raises(ValueError):","486","            est.fit(X, y)","489","        with pytest.raises(ValueError):","490","            est.fit(X, y)","498","        with pytest.raises(NotFittedError):","499","            est.predict_proba(X)","503","        with pytest.raises(ValueError):","504","            est.predict_proba(X2)","507","        with pytest.raises(ValueError):","508","            TreeEstimator(min_samples_leaf=-1).fit(X, y)","509","        with pytest.raises(ValueError):","510","            TreeEstimator(min_samples_leaf=.6).fit(X, y)","511","        with pytest.raises(ValueError):","512","            TreeEstimator(min_samples_leaf=0.).fit(X, y)","513","        with pytest.raises(ValueError):","514","            TreeEstimator(min_samples_leaf=3.).fit(X, y)","515","        with pytest.raises(ValueError):","516","            TreeEstimator(min_weight_fraction_leaf=-1).fit(X, y)","517","        with pytest.raises(ValueError):","518","            TreeEstimator(min_weight_fraction_leaf=0.51).fit(X, y)","519","        with pytest.raises(ValueError):","520","            TreeEstimator(min_samples_split=-1).fit(X, y)","521","        with pytest.raises(ValueError):","522","            TreeEstimator(min_samples_split=0.0).fit(X, y)","523","        with pytest.raises(ValueError):","524","            TreeEstimator(min_samples_split=1.1).fit(X, y)","525","        with pytest.raises(ValueError):","526","            TreeEstimator(min_samples_split=2.5).fit(X, y)","527","        with pytest.raises(ValueError):","528","            TreeEstimator(max_depth=-1).fit(X, y)","529","        with pytest.raises(ValueError):","530","            TreeEstimator(max_features=42).fit(X, y)","533","            with pytest.raises(ValueError):","534","                TreeEstimator(min_impurity_split=-1.0).fit(X, y)","535","        with pytest.raises(ValueError):","536","            TreeEstimator(min_impurity_decrease=-1.0).fit(X, y)","541","        with pytest.raises(ValueError):","542","            est.fit(X, y2)","552","        with pytest.raises(NotFittedError):","553","            est.predict(T)","558","        with pytest.raises(ValueError):","559","            est.predict(t[:, 1:])","566","        with pytest.raises(ValueError):","567","            est.predict(X)","568","        with pytest.raises(ValueError):","569","            est.apply(X)","573","        with pytest.raises(ValueError):","574","            clf.predict(Xt)","575","        with pytest.raises(ValueError):","576","            clf.apply(Xt)","580","        with pytest.raises(NotFittedError):","581","            est.apply(T)","1124","    with pytest.raises(ValueError):","1125","        clf.fit(X, y, sample_weight=sample_weight)","1128","    with pytest.raises(ValueError):","1129","        clf.fit(X, y, sample_weight=sample_weight)","1132","    with pytest.raises(ValueError):","1133","        clf.fit(X, y, sample_weight=sample_weight)","1136","    with pytest.raises(ValueError):","1137","        clf.fit(X, y, sample_weight=sample_weight)","1195","    with pytest.raises(ValueError):","1196","        clf.fit(X, y)","1197","    with pytest.raises(ValueError):","1198","        clf.fit(X, _y)","1202","    with pytest.raises(ValueError):","1203","        clf.fit(X, _y)","1207","    with pytest.raises(ValueError):","1208","        clf.fit(X, _y)","1226","        with pytest.raises(ValueError):","1227","            est.fit(X, y)","1229","        with pytest.raises(ValueError):","1230","            est.fit(X, y)","1232","        with pytest.raises(ValueError):","1233","            est.fit(X, y)","1310","    with pytest.raises(MemoryError):","1311","        _realloc_test()","1324","    with pytest.raises(Exception):","1325","        clf.fit(X, y)","1331","    with pytest.raises(MemoryError):","1332","        clf.fit(X, y)","1552","    with pytest.raises(ValueError):","1553","        TreeEstimator(random_state=0).fit(X, y)","1557","    with pytest.raises(ValueError):","1558","        est.predict([X])","1624","    with pytest.raises(ValueError):","1625","        est.fit(X, y)","1651","    with pytest.raises(ValueError,","1652","                       match=msg.replace('(', r'\\(').replace(')', r'\\)')):","1653","        est.fit(X, y)","1700","    with pytest.raises(TypeError):","1701","        TreeEstimator(random_state=0).fit(X, y)"],"delete":["24","from sklearn.utils.testing import assert_raises","28","from sklearn.utils.testing import assert_raise_message","395","    assert_raises(ValueError, getattr, clf, 'feature_importances_')","474","        assert_raises(ValueError, est.fit, X, y)","477","        assert_raises(ValueError, est.fit, X, y)","480","        assert_raises(ValueError, est.fit, X, y)","483","        assert_raises(ValueError, est.fit, X, y)","486","        assert_raises(ValueError, est.fit, X, y)","494","        assert_raises(NotFittedError, est.predict_proba, X)","498","        assert_raises(ValueError, est.predict_proba, X2)","501","        assert_raises(ValueError, TreeEstimator(min_samples_leaf=-1).fit, X, y)","502","        assert_raises(ValueError, TreeEstimator(min_samples_leaf=.6).fit, X, y)","503","        assert_raises(ValueError, TreeEstimator(min_samples_leaf=0.).fit, X, y)","504","        assert_raises(ValueError, TreeEstimator(min_samples_leaf=3.).fit, X, y)","505","        assert_raises(ValueError,","506","                      TreeEstimator(min_weight_fraction_leaf=-1).fit,","507","                      X, y)","508","        assert_raises(ValueError,","509","                      TreeEstimator(min_weight_fraction_leaf=0.51).fit,","510","                      X, y)","511","        assert_raises(ValueError, TreeEstimator(min_samples_split=-1).fit,","512","                      X, y)","513","        assert_raises(ValueError, TreeEstimator(min_samples_split=0.0).fit,","514","                      X, y)","515","        assert_raises(ValueError, TreeEstimator(min_samples_split=1.1).fit,","516","                      X, y)","517","        assert_raises(ValueError, TreeEstimator(min_samples_split=2.5).fit,","518","                      X, y)","519","        assert_raises(ValueError, TreeEstimator(max_depth=-1).fit, X, y)","520","        assert_raises(ValueError, TreeEstimator(max_features=42).fit, X, y)","523","            assert_raises(ValueError,","524","                          TreeEstimator(min_impurity_split=-1.0).fit, X, y)","525","        assert_raises(ValueError,","526","                      TreeEstimator(min_impurity_decrease=-1.0).fit, X, y)","531","        assert_raises(ValueError, est.fit, X, y2)","541","        assert_raises(NotFittedError, est.predict, T)","546","        assert_raises(ValueError, est.predict, t[:, 1:])","553","        assert_raises(ValueError, est.predict, X)","554","        assert_raises(ValueError, est.apply, X)","558","        assert_raises(ValueError, clf.predict, Xt)","559","        assert_raises(ValueError, clf.apply, Xt)","563","        assert_raises(NotFittedError, est.apply, T)","1106","    assert_raises(ValueError, clf.fit, X, y, sample_weight=sample_weight)","1109","    assert_raises(ValueError, clf.fit, X, y, sample_weight=sample_weight)","1112","    assert_raises(ValueError, clf.fit, X, y, sample_weight=sample_weight)","1115","    assert_raises(ValueError, clf.fit, X, y, sample_weight=sample_weight)","1173","    assert_raises(ValueError, clf.fit, X, y)","1174","    assert_raises(ValueError, clf.fit, X, _y)","1178","    assert_raises(ValueError, clf.fit, X, _y)","1182","    assert_raises(ValueError, clf.fit, X, _y)","1200","        assert_raises(ValueError, est.fit, X, y)","1202","        assert_raises(ValueError, est.fit, X, y)","1204","        assert_raises(ValueError, est.fit, X, y)","1281","    assert_raises(MemoryError, _realloc_test)","1294","    assert_raises(Exception, clf.fit, X, y)","1300","    assert_raises(MemoryError, clf.fit, X, y)","1520","    assert_raises(ValueError, TreeEstimator(random_state=0).fit, X, y)","1524","    assert_raises(ValueError, est.predict, [X])","1590","    assert_raises(ValueError, est.fit, X, y)","1616","    assert_raise_message(ValueError, msg, est.fit, X, y)","1663","    assert_raises(TypeError, TreeEstimator(random_state=0).fit, X, y)"]}]}},"e2b6bff0aca06f1276e2486c67169e3ca264d1f1":{"changes":{"doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/tree\/tests\/test_export.py":"MODIFY","sklearn\/tree\/export.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.21.rst":[{"add":["21",":mod:`sklearn.tree`","22","...................","23","","24","- |Fix| Fixed bug in :func:`tree.export_text` when the tree has one feature and ","25","  a single feature name is passed in. :pr:`14053` by `Thomas Fan`","26",""],"delete":[]}],"sklearn\/tree\/tests\/test_export.py":[{"add":["398","    X_single = [[-2], [-1], [-1], [1], [1], [2]]","399","    reg = DecisionTreeRegressor(max_depth=2, random_state=0)","400","    reg.fit(X_single, y_mo)","401","","402","    expected_report = dedent(\"\"\"","403","    |--- first <= 0.0","404","    |   |--- value: [-1.0, -1.0]","405","    |--- first >  0.0","406","    |   |--- value: [1.0, 1.0]","407","    \"\"\").lstrip()","408","    assert export_text(reg, decimals=1,","409","                       feature_names=['first']) == expected_report","410","    assert export_text(reg, decimals=1, show_weights=True,","411","                       feature_names=['first']) == expected_report","412",""],"delete":[]}],"sklearn\/tree\/export.py":[{"add":["892","        feature_names_ = [feature_names[i] if i != _tree.TREE_UNDEFINED","893","                          else None for i in tree_.feature]"],"delete":["892","        feature_names_ = [feature_names[i] for i in tree_.feature]"]}]}},"a0cfcef679ee9bb7fd05e146767b510663f870a2":{"changes":{"sklearn\/linear_model\/tests\/test_omp.py":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_omp.py":[{"add":["19","n_samples, n_features, n_nonzero_coefs, n_targets = 25, 35, 5, 3"],"delete":["19","n_samples, n_features, n_nonzero_coefs, n_targets = 20, 30, 5, 3"]}]}},"df1e3fbe86a24dd01d0455ef434f7ea22d0ddba0":{"changes":{"sklearn\/linear_model\/tests\/test_ridge.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY","sklearn\/linear_model\/base.py":"MODIFY","sklearn\/linear_model\/ridge.py":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_ridge.py":[{"add":["1212","","1213","","1214","def test_ridge_sag_with_X_fortran():","1215","    # check that Fortran array are converted when using SAG solver","1216","    X, y = make_regression(random_state=42)","1217","    # for the order of X and y to not be C-ordered arrays","1218","    X = np.asfortranarray(X)","1219","    X = X[::2, :]","1220","    y = y[::2]","1221","    Ridge(solver='sag').fit(X, y)"],"delete":[]}],"doc\/whats_new\/v0.22.rst":[{"add":["117","- |Enhancement| :class:`linear_model.BayesianRidge` now accepts hyperparameters","129","  :pr:`14108`, :pr:`14170` by :user:`Alex Henrie <alexhenrie>`.","130","","131","- |Fix| :class:`linear_model.Ridge` with `solver='sag'` now accepts F-ordered","132","  and non-contiguous arrays and makes a conversion instead of failing.","133","  :pr:`14458` by :user:`Guillaume Lemaitre <glemaitre>`."],"delete":["117","- |Enhancement| :class:`linearmodel.BayesianRidge` now accepts hyperparameters","129","  :pr:`14108`, pr:`14170` by :user:`Alex Henrie <alexhenrie>`."]}],"sklearn\/linear_model\/base.py":[{"add":["93","        X = np.ascontiguousarray(X)"],"delete":[]}],"sklearn\/linear_model\/ridge.py":[{"add":["411","        y = check_array(y, dtype=X.dtype, ensure_2d=False, order=None)"],"delete":["411","        y = check_array(y, dtype=X.dtype, ensure_2d=False, order=\"C\")"]}]}},"96c1a5b973936175ce6bd1ef4e0758a77da027c1":{"changes":{"sklearn\/metrics\/tests\/test_score_objects.py":"MODIFY","sklearn\/metrics\/_scorer.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY"},"diff":{"sklearn\/metrics\/tests\/test_score_objects.py":[{"add":["6","from functools import partial","32","from sklearn.linear_model import Ridge, LogisticRegression, Perceptron","673","","674","","675","@pytest.mark.parametrize('scorer_name, metric', [","676","    ('roc_auc_ovr', partial(roc_auc_score, multi_class='ovr')),","677","    ('roc_auc_ovo', partial(roc_auc_score, multi_class='ovo')),","678","    ('roc_auc_ovr_weighted', partial(roc_auc_score, multi_class='ovr',","679","                                     average='weighted')),","680","    ('roc_auc_ovo_weighted', partial(roc_auc_score, multi_class='ovo',","681","                                     average='weighted'))])","682","def test_multiclass_roc_proba_scorer(scorer_name, metric):","683","    scorer = get_scorer(scorer_name)","684","    X, y = make_classification(n_classes=3, n_informative=3, n_samples=20,","685","                               random_state=0)","686","    lr = LogisticRegression(multi_class=\"multinomial\").fit(X, y)","687","    y_proba = lr.predict_proba(X)","688","    expected_score = metric(y, y_proba)","689","","690","    assert scorer(lr, X, y) == pytest.approx(expected_score)","691","","692","","693","def test_multiclass_roc_proba_scorer_label():","694","    scorer = make_scorer(roc_auc_score, multi_class='ovo',","695","                         labels=[0, 1, 2], needs_proba=True)","696","    X, y = make_classification(n_classes=3, n_informative=3, n_samples=20,","697","                               random_state=0)","698","    lr = LogisticRegression(multi_class=\"multinomial\").fit(X, y)","699","    y_proba = lr.predict_proba(X)","700","","701","    y_binary = y == 0","702","    expected_score = roc_auc_score(y_binary, y_proba,","703","                                   multi_class='ovo',","704","                                   labels=[0, 1, 2])","705","","706","    assert scorer(lr, X, y_binary) == pytest.approx(expected_score)","707","","708","","709","@pytest.mark.parametrize('scorer_name', [","710","    'roc_auc_ovr', 'roc_auc_ovo',","711","    'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted'])","712","def test_multiclass_roc_no_proba_scorer_errors(scorer_name):","713","    # Perceptron has no predict_proba","714","    scorer = get_scorer(scorer_name)","715","    X, y = make_classification(n_classes=3, n_informative=3, n_samples=20,","716","                               random_state=0)","717","    lr = Perceptron().fit(X, y)","718","    msg = \"'Perceptron' object has no attribute 'predict_proba'\"","719","    with pytest.raises(AttributeError, match=msg):","720","        scorer(lr, X, y)"],"delete":["31","from sklearn.linear_model import Ridge, LogisticRegression"]}],"sklearn\/metrics\/_scorer.py":[{"add":["249","            elif y_pred.shape[1] == 1:  # not multiclass","647","roc_auc_ovo_scorer = make_scorer(roc_auc_score, needs_proba=True,","649","roc_auc_ovo_weighted_scorer = make_scorer(roc_auc_score, needs_proba=True,","652","roc_auc_ovr_scorer = make_scorer(roc_auc_score, needs_proba=True,","654","roc_auc_ovr_weighted_scorer = make_scorer(roc_auc_score, needs_proba=True,"],"delete":["249","            else:","647","roc_auc_ovo_scorer = make_scorer(roc_auc_score, needs_threshold=True,","649","roc_auc_ovo_weighted_scorer = make_scorer(roc_auc_score, needs_threshold=True,","652","roc_auc_ovr_scorer = make_scorer(roc_auc_score, needs_threshold=True,","654","roc_auc_ovr_weighted_scorer = make_scorer(roc_auc_score, needs_threshold=True,"]}],"doc\/whats_new\/v0.22.rst":[{"add":["472","- |Feature| Added multiclass support to :func:`metrics.roc_auc_score` with","473","  corresponding scorers 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', ","474","  and 'roc_auc_ovo_weighted'. :pr:`12789` and :pr:`15274` by ","475","  :user:`Kathy Chen <kathyxchen>`, :user:`Mohamed Maskani <maskani-moh>`, and","476","  `Thomas Fan`_."],"delete":["472","- |Feature| Added multiclass support to :func:`metrics.roc_auc_score`.","473","  :issue:`12789` by :user:`Kathy Chen <kathyxchen>`,","474","  :user:`Mohamed Maskani <maskani-moh>`, and :user:`Thomas Fan <thomasjpfan>`."]}]}},"2e7b554293d430ef6ce7dfca194b78a6c039f7b5":{"changes":{"sklearn\/linear_model\/tests\/test_ridge.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY","sklearn\/linear_model\/ridge.py":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_ridge.py":[{"add":["468","def test_ridge_loo_cv_asym_scoring():","469","    # checking on asymmetric scoring","470","    scoring = 'explained_variance'","471","    n_samples, n_features = 10, 5","472","    n_targets = 1","473","    X, y = _make_sparse_offset_regression(","474","        n_samples=n_samples, n_features=n_features, n_targets=n_targets,","475","        random_state=0, shuffle=False, noise=1, n_informative=5","476","    )","477","","478","    alphas = [1e-3, .1, 1., 10., 1e3]","479","    loo_ridge = RidgeCV(cv=n_samples, fit_intercept=True,","480","                        alphas=alphas, scoring=scoring,","481","                        normalize=True)","482","","483","    gcv_ridge = RidgeCV(fit_intercept=True,","484","                        alphas=alphas, scoring=scoring,","485","                        normalize=True)","486","","487","    loo_ridge.fit(X, y)","488","    gcv_ridge.fit(X, y)","489","","490","    assert gcv_ridge.alpha_ == pytest.approx(loo_ridge.alpha_)","491","    assert_allclose(gcv_ridge.coef_, loo_ridge.coef_, rtol=1e-3)","492","    assert_allclose(gcv_ridge.intercept_, loo_ridge.intercept_, rtol=1e-3)","493","","494","","1073",""],"delete":[]}],"doc\/whats_new\/v0.22.rst":[{"add":["251","- |FIX| :class:`linear_model.RidgeCV` and :class:`linear_model.RidgeClassifierCV`  ","252","  now correctly scores when `cv=None`.","253","  :pr:`14864` by :user:`Venkatachalam N <venkyyuvy>`.","254",""],"delete":[]}],"sklearn\/linear_model\/ridge.py":[{"add":["1486","            # signature of scorer is (estimator, X, y)","1487","            out = [scorer(identity_estimator, cv_values[:, i], y.ravel())"],"delete":["1486","            out = [scorer(identity_estimator, y.ravel(), cv_values[:, i])"]}]}},"c997e9b3eaf00339bda796dbb34f4f64ca0fba85":{"changes":{"sklearn\/datasets\/lfw.py":"MODIFY"},"diff":{"sklearn\/datasets\/lfw.py":[{"add":["153","        if img.ndim == 0:"],"delete":["153","        if img.ndim is 0:"]}]}},"38af35db9c654d2b2ff60f69861910413636b9f9":{"changes":{"sklearn\/ensemble\/_hist_gradient_boosting\/gradient_boosting.py":"MODIFY","sklearn\/ensemble\/_hist_gradient_boosting\/tests\/test_gradient_boosting.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY"},"diff":{"sklearn\/ensemble\/_hist_gradient_boosting\/gradient_boosting.py":[{"add":["1044","        if (self.loss == 'categorical_crossentropy' and","1045","                self.n_trees_per_iteration_ == 1):","1046","            raise ValueError(\"'categorical_crossentropy' is not suitable for \"","1047","                             \"a binary classification problem. Please use \"","1048","                             \"'auto' or 'binary_crossentropy' instead.\")","1049",""],"delete":[]}],"sklearn\/ensemble\/_hist_gradient_boosting\/tests\/test_gradient_boosting.py":[{"add":["428","def test_crossentropy_binary_problem():","429","    # categorical_crossentropy should only be used if there are more than two","430","    # classes present. PR #14869","431","    X = [[1], [0]]","432","    y = [0, 1]","433","    gbrt = HistGradientBoostingClassifier(loss='categorical_crossentropy')","434","    with pytest.raises(ValueError,","435","                       match=\"'categorical_crossentropy' is not suitable for\"):","436","        gbrt.fit(X, y)","437","","438",""],"delete":[]}],"doc\/whats_new\/v0.22.rst":[{"add":["194","  - |Fix| :class:`ensemble.HistGradientBoostingClassifier` now raises an error","195","    if ``categorical_crossentropy`` loss is given for a binary classification","196","    problem. :pr:`14869` by `Adrin Jalali`_."],"delete":[]}]}},"7eded0f6470a500172e44656f7ee6110965a3c56":{"changes":{"doc\/modules\/ensemble.rst":"MODIFY"},"diff":{"doc\/modules\/ensemble.rst":[{"add":["927","of :math:`\\mathcal{O}(n_\\text{features} \\times n \\log(n))` where :math:`n`","928","is the number of samples at the node.","935",":math:`\\mathcal{O}(n_\\text{features} \\times n)` complexity, much smaller","936","than the previous one. In addition, instead of considering :math:`n` split","937","points, we here consider only ``max_bins`` split points, which is much","938","smaller."],"delete":["927","of :math:`\\mathcal{O}(\\text{n_features} * n \\log(n))` where :math:`n` is the","928","number of samples at the node.","935",":math:`\\mathcal{O}(\\text{n_features} * n)` complexity, much smaller than the","936","previous one. In addition, instead of considering :math:`n` split points, we","937","here consider only ``max_bins`` split points, which is much smaller."]}]}},"c3fb4bc8fce495f91343964cffecd504a28a2187":{"changes":{"sklearn\/cluster\/tests\/test_mean_shift.py":"MODIFY"},"diff":{"sklearn\/cluster\/tests\/test_mean_shift.py":[{"add":["38","    assert bandwidth == pytest.approx(0., abs=1e-5)"],"delete":["38","    assert bandwidth == 0."]}]}},"01ba635cfcd523d01604ae9eb37a13844df6d92e":{"changes":{"build_tools\/azure\/test_pytest_soft_dependency.sh":"MODIFY",".circleci\/config.yml":"MODIFY","build_tools\/azure\/install.sh":"MODIFY"},"diff":{"build_tools\/azure\/test_pytest_soft_dependency.sh":[{"add":["9","    # conda may remove coverage when uninstall pytest and py","10","    pip install coverage"],"delete":[]}],".circleci\/config.yml":[{"add":["51","      # TODO: Revert to 3 when wheel issue with conda installation of python 3.7.4","52","      - PYTHON_VERSION: 3.7.3"],"delete":["51","      - PYTHON_VERSION: 3"]}],"build_tools\/azure\/install.sh":[{"add":["26","version_ge() {","27","    # The two version numbers are seperated with a new line is piped to sort","28","    # -rV. The -V activates for version number sorting and -r sorts in","29","    # decending order. If the first argument is the top element of the sort, it","30","    # is greater than or equal to the second argument.","31","    test \"$(printf \"${1}\\n${2}\" | sort -rV | head -n 1)\" == \"$1\"","32","}","33","","35","","36","    # TODO","37","    # Remove when wheel issue is fixed with conda installations of python 3.7.4","38","    if [[ \"$PYTHON_VERSION\" == \"*\" ]]; then","39","        PINNED_PYTHON_VERSION=\"3.7.3\"","40","    else","41","        PINNED_PYTHON_VERSION=$PYTHON_VERSION","42","    fi","43","","44","    TO_INSTALL=\"python=$PINNED_PYTHON_VERSION pip pytest=$PYTEST_VERSION \\","45","                pytest-cov numpy=$NUMPY_VERSION scipy=$SCIPY_VERSION \\","70","    # Old packages coming from the 'free' conda channel have been removed but","71","    # we are using them for testing Python 3.5. See","72","    # https:\/\/www.anaconda.com\/why-we-removed-the-free-channel-in-conda-4-7\/","73","    # for more details. restore_free_channel is defined starting from conda 4.7","74","    conda_version=$(conda -V | awk '{print $2}')","75","    if version_ge \"$conda_version\" \"4.7.0\" && [[ \"$PYTHON_VERSION\" == \"3.5\" ]]; then","76","        conda config --set restore_free_channel true","77","    fi","78",""],"delete":["27","    TO_INSTALL=\"python=$PYTHON_VERSION pip pytest=$PYTEST_VERSION pytest-cov \\","28","                numpy=$NUMPY_VERSION scipy=$SCIPY_VERSION \\"]}]}},"8b002f2714e9787ad7101ca276daeb4dc4eed2a8":{"changes":{"sklearn\/manifold\/tests\/test_t_sne.py":"MODIFY"},"diff":{"sklearn\/manifold\/tests\/test_t_sne.py":[{"add":["3","from numpy.testing import assert_allclose","277","                random_state=0, method='exact', n_iter=750)","279","    assert_allclose(trustworthiness(X_csr, X_embedded, n_neighbors=1),","280","                    1.0, rtol=1.1e-1)"],"delete":["276","                random_state=0, method='exact', n_iter=500)","278","    assert_almost_equal(trustworthiness(X_csr, X_embedded, n_neighbors=1), 1.0,","279","                        decimal=1)"]}]}},"b7c41636907defd0ca210ed2e8e17fd4735567a0":{"changes":{"sklearn\/svm\/src\/liblinear\/liblinear_helper.c":"MODIFY"},"diff":{"sklearn\/svm\/src\/liblinear\/liblinear_helper.c":[{"add":["34","            for (j=0; j<i; j++)"],"delete":["34","            for (j=0; j<i-1; j++)"]}]}},"70351e6efca51de0ec2a2834831d67f024a9525b":{"changes":{"doc\/themes\/scikit-learn-modern\/static\/css\/theme.css":"MODIFY"},"diff":{"doc\/themes\/scikit-learn-modern\/static\/css\/theme.css":[{"add":["493","dl.citation > dd > ol > li {","494","  display: inline;","495","}","496","","497","dl.citation > dd > ol {","498","  margin-bottom: 0;","499","}"],"delete":[]}]}},"ca9ceba5589d881e26b0f9bea06418083ba433b0":{"changes":{"sklearn\/model_selection\/_split.py":"MODIFY","sklearn\/model_selection\/tests\/test_split.py":"MODIFY"},"diff":{"sklearn\/model_selection\/_split.py":[{"add":["1165","    def __repr__(self):","1166","        return _build_repr(self)","1167","","2163","                if value is None and hasattr(self, 'cvargs'):","2164","                    value = self.cvargs.get(key, None)"],"delete":[]}],"sklearn\/model_selection\/tests\/test_split.py":[{"add":["982","@pytest.mark.parametrize(","983","    \"RepeatedCV\", [RepeatedKFold, RepeatedStratifiedKFold]","984",")","985","def test_repeated_cv_repr(RepeatedCV):","986","    n_splits, n_repeats = 2, 6","987","    repeated_cv = RepeatedCV(n_splits=n_splits, n_repeats=n_repeats)","988","    repeated_cv_repr = ('{}(n_repeats=6, n_splits=2, random_state=None)'","989","                        .format(repeated_cv.__class__.__name__))","990","    assert repeated_cv_repr == repr(repeated_cv)","991","","992",""],"delete":[]}]}},"7aff4c3513cffce53a4f17737ba19e4f44c36a93":{"changes":{"sklearn\/metrics\/classification.py":"MODIFY","doc\/modules\/partial_dependence.rst":"MODIFY","doc\/about.rst":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY","doc\/modules\/computing.rst":"MODIFY"},"diff":{"sklearn\/metrics\/classification.py":[{"add":["1398",""],"delete":[]}],"doc\/modules\/partial_dependence.rst":[{"add":["123","    T. Hastie, R. Tibshirani and J. Friedman, `The Elements of"],"delete":["123"," .. [HTF2009] T. Hastie, R. Tibshirani and J. Friedman, `The Elements of"]}],"doc\/about.rst":[{"add":["171","   |                    |","177","   |                    |"],"delete":["171","   |      .......       |","177","   |      ........      |"]}],"doc\/whats_new\/v0.22.rst":[{"add":["664","  unnecessarily. :pr:`15094` by `Andreas M¨¹ller`_."],"delete":["664","  unnecessarily. :pre:`15094` by `Andreas M¨¹ller`_."]}],"doc\/modules\/computing.rst":[{"add":["636","- Manually setting one of the environment variables (``OMP_NUM_THREADS``,","637","  ``MKL_NUM_THREADS``, ``OPENBLAS_NUM_THREADS``, or ``BLIS_NUM_THREADS``)","638","  will take precedence over what joblib tries to do. The total number of","639","  threads will be ``n_jobs * <LIB>_NUM_THREADS``. Note that setting this","640","  limit will also impact your computations in the main process, which will","641","  only use ``<LIB>_NUM_THREADS``. Joblib exposes a context manager for","642","  finer control over the number of threads in its workers (see joblib docs","643","  linked below)."],"delete":["636"," - Manually setting one of the environment variables (``OMP_NUM_THREADS``,","637","   ``MKL_NUM_THREADS``, ``OPENBLAS_NUM_THREADS``, or ``BLIS_NUM_THREADS``)","638","   will take precedence over what joblib tries to do. The total number of","639","   threads will be ``n_jobs * <LIB>_NUM_THREADS``. Note that setting this","640","   limit will also impact your computations in the main process, which will","641","   only use ``<LIB>_NUM_THREADS``. Joblib exposes a context manager for","642","   finer control over the number of threads in its workers (see joblib docs","643","   linked below)."]}]}},"3ab22f973fb1ff1643fb980075559316478f7bd4":{"changes":{"examples\/decomposition\/plot_ica_blind_source_separation.py":"MODIFY"},"diff":{"examples\/decomposition\/plot_ica_blind_source_separation.py":[{"add":["71","plt.tight_layout()"],"delete":["71","plt.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.46)"]}]}},"42659232bd42cd38846ffbf3e579f72604772b96":{"changes":{"sklearn\/utils\/fixes.py":"MODIFY","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/linear_model\/tests\/test_bayes.py":"MODIFY","sklearn\/externals\/_scipy_linalg.py":"ADD","sklearn\/linear_model\/bayes.py":"MODIFY"},"diff":{"sklearn\/utils\/fixes.py":[{"add":["47","if sp_version >= (1, 3):","48","    # Preserves earlier default choice of pinvh cutoff `cond` value.","49","    # Can be removed once issue #14055 is fully addressed.","50","    from ..externals._scipy_linalg import pinvh","51","else:","52","    from scipy.linalg import pinvh # noqa","53",""],"delete":[]}],"doc\/whats_new\/v0.21.rst":[{"add":["57","- |Fix| Fixed a bug in :class:`impute.SimpleImputer` and","58","  :class:`impute.IterativeImputer` so that no errors are thrown when there are","59","  missing values in training data. :pr:`13974` by `Frank Hoang <fhoang7>`.","67","- |Fix| Compatibility fix for :class:`linear_model.ARDRegression` and","68","  Scipy>=1.3.0. Adapts to upstream changes to the default `pinvh` cutoff","69","  threshold which otherwise results in poor accuracy in some cases.","70","  :pr:`14067` by :user:`Tim Staley <timstaley>`."],"delete":["57","- |Fix| Fixed a bug in :class:`SimpleImputer` and :class:`IterativeImputer`","58","  so that no errors are thrown when there are missing values in training data.","59","  :pr:`13974` by `Frank Hoang <fhoang7>`."]}],"sklearn\/linear_model\/tests\/test_bayes.py":[{"add":["202","def test_ard_accuracy_on_easy_problem():","203","    # Check that ARD converges with reasonable accuracy on an easy problem","204","    # (Github issue #14055)","205","    # This particular seed seems to converge poorly in the failure-case","206","    # (scipy==1.3.0, sklearn==0.21.2)","207","    seed = 45","208","    X = np.random.RandomState(seed=seed).normal(size=(250, 3))","209","    y = X[:, 1]","210","","211","    regressor = ARDRegression()","212","    regressor.fit(X, y)","213","","214","    abs_coef_error = np.abs(1 - regressor.coef_[1])","215","    # Expect an accuracy of better than 1E-4 in most cases -","216","    # Failure-case produces 0.16!","217","    assert abs_coef_error < 0.01","218","","219",""],"delete":[]}],"sklearn\/externals\/_scipy_linalg.py":[{"add":[],"delete":[]}],"sklearn\/linear_model\/bayes.py":[{"add":["15","from ..utils.fixes import pinvh"],"delete":["10","from scipy.linalg import pinvh"]}]}},"125a54d9440567afe77ed45f57be0fa7edaa74c3":{"changes":{"azure-pipelines.yml":"MODIFY","sklearn\/__init__.py":"MODIFY"},"diff":{"azure-pipelines.yml":[{"add":["40","      pylatest_conda_mkl:","41","        DISTRIB: 'conda'","42","        PYTHON_VERSION: '*'","43","        INSTALL_MKL: 'true'","44","        NUMPY_VERSION: '*'","45","        SCIPY_VERSION: '*'","46","        CYTHON_VERSION: '*'","47","        PILLOW_VERSION: '*'","48","        PYTEST_VERSION: '*'","49","        JOBLIB_VERSION: '*'","50","        COVERAGE: 'true'"],"delete":[]}],"sklearn\/__init__.py":[{"add":["60","# Workaround issue discovered in intel-openmp 2019.5:","61","# https:\/\/github.com\/ContinuumIO\/anaconda-issues\/issues\/11294","62","os.environ.setdefault(\"KMP_INIT_AT_FORK\", \"FALSE\")"],"delete":[]}]}},"11d2539444744f1aad91f9f07202be09e5cc52d9":{"changes":{"build_tools\/circle\/build_doc.sh":"MODIFY",".circleci\/config.yml":"MODIFY"},"diff":{"build_tools\/circle\/build_doc.sh":[{"add":["103","    latexmk gsfonts ccache","114","export PATH=\"\/usr\/lib\/ccache:$MINICONDA_PATH\/bin:$PATH\"","115","","116","ccache -M 512M","117","export CCACHE_COMPRESS=1","134","export OMP_NUM_THREADS=1","135",""],"delete":["103","    latexmk gsfonts","114","export PATH=\"$MINICONDA_PATH\/bin:$PATH\""]}],".circleci\/config.yml":[{"add":["20","      - restore_cache:","21","          keys:","22","            - doc-min-deps-ccache-{{ .Branch }}","23","            - doc-min-deps-ccache","26","          key: doc-min-deps-ccache-{{ .Branch }}-{{ .BuildNum }}","27","          paths:","28","            - ~\/.ccache","29","            - ~\/.cache\/pip","30","      - save_cache:","53","      - restore_cache:","54","          keys:","55","            - doc-ccache-{{ .Branch }}","56","            - doc-ccache","59","          key: doc-ccache-{{ .Branch }}-{{ .BuildNum }}","60","          paths:","61","            - ~\/.ccache","62","            - ~\/.cache\/pip","63","      - save_cache:"],"delete":[]}]}},"a05c8d89d977a7b4df768a83657eeded561160ad":{"changes":{"sklearn\/feature_extraction\/tests\/test_feature_hasher.py":"MODIFY","sklearn\/feature_extraction\/tests\/test_image.py":"MODIFY","sklearn\/feature_extraction\/tests\/test_text.py":"MODIFY"},"diff":{"sklearn\/feature_extraction\/tests\/test_feature_hasher.py":[{"add":["3","import pytest","6","from sklearn.utils.testing import (ignore_warnings,","89","    with pytest.raises(ValueError):","90","        FeatureHasher(input_type=\"gobbledygook\")","91","    with pytest.raises(ValueError):","92","        FeatureHasher(n_features=-1)","93","    with pytest.raises(ValueError):","94","        FeatureHasher(n_features=0)","95","    with pytest.raises(TypeError):","96","        FeatureHasher(n_features='ham')","99","    with pytest.raises(ValueError):","100","        h.transform([])","101","    with pytest.raises(Exception):","102","        h.transform([[5.5]])","103","    with pytest.raises(Exception):","104","        h.transform([[None]])","111","    with pytest.raises(TypeError):","112","        hasher.fit()"],"delete":["5","from sklearn.utils.testing import (assert_raises, ignore_warnings,","88","    assert_raises(ValueError, FeatureHasher, input_type=\"gobbledygook\")","89","    assert_raises(ValueError, FeatureHasher, n_features=-1)","90","    assert_raises(ValueError, FeatureHasher, n_features=0)","91","    assert_raises(TypeError, FeatureHasher, n_features='ham')","94","    assert_raises(ValueError, h.transform, [])","95","    assert_raises(Exception, h.transform, [[5.5]])","96","    assert_raises(Exception, h.transform, [[None]])","103","    assert_raises(TypeError, hasher.fit)"]}],"sklearn\/feature_extraction\/tests\/test_image.py":[{"add":["8","import pytest","13","from sklearn.utils.testing import ignore_warnings","175","    with pytest.raises(ValueError):","176","        extract_patches_2d(face, (p_h, p_w), max_patches=2.0)","177","    with pytest.raises(ValueError):","178","        extract_patches_2d(face, (p_h, p_w), max_patches=-1.0)","331","    with pytest.raises(ValueError):","332","        extract_patches_2d(x, (4, 1))","333","    with pytest.raises(ValueError):","334","        extract_patches_2d(x, (1, 4))"],"delete":["12","from sklearn.utils.testing import assert_raises, ignore_warnings","174","    assert_raises(ValueError, extract_patches_2d, face, (p_h, p_w),","175","                  max_patches=2.0)","176","    assert_raises(ValueError, extract_patches_2d, face, (p_h, p_w),","177","                  max_patches=-1.0)","330","    assert_raises(ValueError, extract_patches_2d, x, (4, 1))","331","    assert_raises(ValueError, extract_patches_2d, x, (1, 4))"]}],"sklearn\/feature_extraction\/tests\/test_text.py":[{"add":["35","                                   SkipTest, assert_no_warnings,","180","    with pytest.raises(UnicodeDecodeError):","181","        wa(text_bytes)","185","    with pytest.raises(UnicodeDecodeError):","186","        ca(text_bytes)","303","    with pytest.raises(ValueError):","304","        cv.get_stop_words()","306","    with pytest.raises(ValueError):","307","        cv.get_stop_words()","457","    with pytest.raises(ValueError):","458","        t3.transform(counts_train)","466","    with pytest.raises(ValueError):","467","        t3.transform(X_incompt)","488","    with pytest.raises(ValueError):","489","        v3.transform(train_data)","502","    with pytest.raises(ValueError):","503","        v3.build_preprocessor()","507","    with pytest.raises(ValueError):","508","        v3.build_analyzer()","579","    with pytest.raises(ValueError):","580","        cv.get_feature_names()","1026","    with pytest.raises(ValueError):","1027","        setattr(copy, 'idf_', invalid_idf)","1033","    with pytest.raises(ValueError):","1034","        vect.fit([])"],"delete":["35","                                   SkipTest, assert_raises, assert_no_warnings,","180","    assert_raises(UnicodeDecodeError, wa, text_bytes)","184","    assert_raises(UnicodeDecodeError, ca, text_bytes)","301","    assert_raises(ValueError, cv.get_stop_words)","303","    assert_raises(ValueError, cv.get_stop_words)","453","    assert_raises(ValueError, t3.transform, counts_train)","461","    assert_raises(ValueError, t3.transform, X_incompt)","482","    assert_raises(ValueError, v3.transform, train_data)","495","    assert_raises(ValueError, v3.build_preprocessor)","499","    assert_raises(ValueError, v3.build_analyzer)","570","    assert_raises(ValueError, cv.get_feature_names)","1016","    assert_raises(ValueError, setattr, copy, 'idf_', invalid_idf)","1022","    assert_raises(ValueError, vect.fit, [])"]}]}}}
{"5cef1df11bc7ba337dc9cfc431e21659f4524457":{"changes":{"sklearn\/ensemble\/bagging.py":"MODIFY","sklearn\/ensemble\/tests\/test_bagging.py":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY"},"diff":{"sklearn\/ensemble\/bagging.py":[{"add":["312","        elif isinstance(self.max_features, np.float):","313","            max_features = self.max_features * self.n_features_","314","        else:","315","            raise ValueError(\"max_features must be int or float\")","320","        max_features = max(1, int(max_features))","321",""],"delete":["312","        else:  # float","313","            max_features = int(self.max_features * self.n_features_)"]}],"sklearn\/ensemble\/tests\/test_bagging.py":[{"add":["886","","887","","888","@pytest.mark.filterwarnings('ignore: Default solver will be changed')  # 0.22","889","@pytest.mark.filterwarnings('ignore: Default multi_class will')  # 0.22","890","def test_bagging_small_max_features():","891","    # Check that Bagging estimator can accept low fractional max_features","892","","893","    X = np.array([[1, 2], [3, 4]])","894","    y = np.array([1, 0])","895","","896","    bagging = BaggingClassifier(LogisticRegression(),","897","                                max_features=0.3, random_state=1)","898","    bagging.fit(X, y)"],"delete":[]}],"doc\/whats_new\/v0.20.rst":[{"add":["64","- |Fix| Fixed a bug affecting :class:`ensemble.BaggingClassifier`,","65","  :class:`ensemble.BaggingRegressor` and :class:`ensemble.IsolationForest`,","66","  where ``max_features`` was sometimes rounded down to zero.","67","  :issue:`12388` by :user:`Connor Tann <Connossor>`.","68",""],"delete":[]}]}},"cd6e4d52d9bcd8d2152b97c9cf8902eeec4642ca":{"changes":{"sklearn\/decomposition\/_dict_learning.py":"MODIFY","sklearn\/decomposition\/_factor_analysis.py":"MODIFY","sklearn\/decomposition\/_lda.py":"MODIFY","sklearn\/decomposition\/_kernel_pca.py":"MODIFY","sklearn\/decomposition\/_pca.py":"MODIFY","sklearn\/decomposition\/_sparse_pca.py":"MODIFY","sklearn\/decomposition\/_fastica.py":"MODIFY","sklearn\/decomposition\/_truncated_svd.py":"MODIFY","sklearn\/decomposition\/_nmf.py":"MODIFY"},"diff":{"sklearn\/decomposition\/_dict_learning.py":[{"add":["363","    random_state : int, RandomState instance, default=None","364","        Used for randomly initializing the dictionary. Pass an int for","365","        reproducible results across multiple function calls.","366","        See :term:`Glossary <random_state>`.","484","        Used for randomly initializing the dictionary. Pass an int for","485","        reproducible results across multiple function calls.","486","        See :term:`Glossary <random_state>`.","690","        Used for initializing the dictionary when ``dict_init`` is not","691","        specified, randomly shuffling the data when ``shuffle`` is set to","692","        ``True``, and updating the dictionary. Pass an int for reproducible","693","        results across multiple function calls.","694","        See :term:`Glossary <random_state>`.","1133","    random_state : int, RandomState instance or None, optional (default=None)","1134","        Used for initializing the dictionary when ``dict_init`` is not","1135","        specified, randomly shuffling the data when ``shuffle`` is set to","1136","        ``True``, and updating the dictionary. Pass an int for reproducible","1137","        results across multiple function calls.","1138","        See :term:`Glossary <random_state>`.","1325","        Used for initializing the dictionary when ``dict_init`` is not","1326","        specified, randomly shuffling the data when ``shuffle`` is set to","1327","        ``True``, and updating the dictionary. Pass an int for reproducible","1328","        results across multiple function calls.","1329","        See :term:`Glossary <random_state>`."],"delete":["363","    random_state : int, RandomState instance or None, optional (default=None)","364","        If int, random_state is the seed used by the random number generator;","365","        If RandomState instance, random_state is the random number generator;","366","        If None, the random number generator is the RandomState instance used","367","        by `np.random`.","485","        If int, random_state is the seed used by the random number generator;","486","        If RandomState instance, random_state is the random number generator;","487","        If None, the random number generator is the RandomState instance used","488","        by `np.random`.","692","        If int, random_state is the seed used by the random number generator;","693","        If RandomState instance, random_state is the random number generator;","694","        If None, the random number generator is the RandomState instance used","695","        by `np.random`.","1134","    random_state : int, RandomState instance or None, default=None","1135","        If int, random_state is the seed used by the random number generator;","1136","        If RandomState instance, random_state is the random number generator;","1137","        If None, the random number generator is the RandomState instance used","1138","        by `np.random`.","1325","        If int, random_state is the seed used by the random number generator;","1326","        If RandomState instance, random_state is the random number generator;","1327","        If None, the random number generator is the RandomState instance used","1328","        by `np.random`."]}],"sklearn\/decomposition\/_factor_analysis.py":[{"add":["91","    random_state : int, RandomState instance, default=None","92","        Only used when ``svd_method`` equals 'randomized'. Pass an int for","93","        reproducible results across multiple function calls.","94","        See :term:`Glossary <random_state>`."],"delete":["91","    random_state : int, RandomState instance or None, optional (default=0)","92","        If int, random_state is the seed used by the random number generator;","93","        If RandomState instance, random_state is the random number generator;","94","        If None, the random number generator is the RandomState instance used","95","        by `np.random`. Only used when ``svd_method`` equals 'randomized'."]}],"sklearn\/decomposition\/_lda.py":[{"add":["224","    random_state : int, RandomState instance, default=None","225","        Pass an int for reproducible results across multiple function calls.","226","        See :term:`Glossary <random_state>`."],"delete":["224","    random_state : int, RandomState instance or None, optional (default=None)","225","        If int, random_state is the seed used by the random number generator;","226","        If RandomState instance, random_state is the random number generator;","227","        If None, the random number generator is the RandomState instance used","228","        by `np.random`."]}],"sklearn\/decomposition\/_kernel_pca.py":[{"add":["78","    random_state : int, RandomState instance, default=None","79","        Used when ``eigen_solver`` == 'arpack'. Pass an int for reproducible","80","        results across multiple function calls.","81","        See :term:`Glossary <random_state>`."],"delete":["78","    random_state : int, RandomState instance or None, optional (default=None)","79","        If int, random_state is the seed used by the random number generator;","80","        If RandomState instance, random_state is the random number generator;","81","        If None, the random number generator is the RandomState instance used","82","        by `np.random`. Used when ``eigen_solver`` == 'arpack'."]}],"sklearn\/decomposition\/_pca.py":[{"add":["191","    random_state : int, RandomState instance, default=None","192","        Used when ``svd_solver`` == 'arpack' or 'randomized'. Pass an int","193","        for reproducible results across multiple function calls.","194","        See :term:`Glossary <random_state>`."],"delete":["191","    random_state : int, RandomState instance or None, optional (default None)","192","        If int, random_state is the seed used by the random number generator;","193","        If RandomState instance, random_state is the random number generator;","194","        If None, the random number generator is the RandomState instance used","195","        by `np.random`. Used when ``svd_solver`` == 'arpack' or 'randomized'."]}],"sklearn\/decomposition\/_sparse_pca.py":[{"add":["81","    random_state : int, RandomState instance, default=None","82","        Used during dictionary learning. Pass an int for reproducible results","83","        across multiple function calls.","84","        See :term:`Glossary <random_state>`.","283","    random_state : int, RandomState instance, default=None","284","        Used for random shuffling when ``shuffle`` is set to ``True``,","285","        during online dictionary learning. Pass an int for reproducible results","286","        across multiple function calls.","287","        See :term:`Glossary <random_state>`."],"delete":["81","    random_state : int, RandomState instance or None, optional (default=None)","82","        If int, random_state is the seed used by the random number generator;","83","        If RandomState instance, random_state is the random number generator;","84","        If None, the random number generator is the RandomState instance used","85","        by `np.random`.","284","    random_state : int, RandomState instance or None, optional (default=None)","285","        If int, random_state is the seed used by the random number generator;","286","        If RandomState instance, random_state is the random number generator;","287","        If None, the random number generator is the RandomState instance used","288","        by `np.random`."]}],"sklearn\/decomposition\/_fastica.py":[{"add":["204","    random_state : int, RandomState instance, default=None","205","        Used to initialize ``w_init`` when not specified, with a","206","        normal distribution. Pass an int, for reproducible results","207","        across multiple function calls.","208","        See :term:`Glossary <random_state>`.","343","    random_state : int, RandomState instance, default=None","344","        Used to initialize ``w_init`` when not specified, with a","345","        normal distribution. Pass an int, for reproducible results","346","        across multiple function calls.","347","        See :term:`Glossary <random_state>`."],"delete":["204","    random_state : int, RandomState instance or None, optional (default=None)","205","        If int, random_state is the seed used by the random number generator;","206","        If RandomState instance, random_state is the random number generator;","207","        If None, the random number generator is the RandomState instance used","208","        by `np.random`.","343","    random_state : int, RandomState instance or None, optional (default=None)","344","        If int, random_state is the seed used by the random number generator;","345","        If RandomState instance, random_state is the random number generator;","346","        If None, the random number generator is the RandomState instance used","347","        by `np.random`."]}],"sklearn\/decomposition\/_truncated_svd.py":[{"add":["58","    random_state : int, RandomState instance, default=None","59","        Used during randomized svd. Pass an int for reproducible results across","60","        multiple function calls.","61","        See :term:`Glossary <random_state>`."],"delete":["58","    random_state : int, RandomState instance or None, optional, default = None","59","        If int, random_state is the seed used by the random number generator;","60","        If RandomState instance, random_state is the random number generator;","61","        If None, the random number generator is the RandomState instance used","62","        by `np.random`."]}],"sklearn\/decomposition\/_nmf.py":[{"add":["289","    random_state : int, RandomState instance, default=None","290","        Used when ``init`` == 'nndsvdar' or 'random'. Pass an int for","291","        reproducible results across multiple function calls.","292","        See :term:`Glossary <random_state>`.","473","    random_state : int, RandomState instance, default=None","474","        Used to randomize the coordinates in the CD solver, when","475","        ``shuffle`` is set to ``True``. Pass an int for reproducible","476","        results across multiple function calls.","477","        See :term:`Glossary <random_state>`.","964","    random_state : int, RandomState instance, default=None","965","        Used for NMF initialisation (when ``init`` == 'nndsvdar' or","966","        'random'), and in Coordinate Descent. Pass an int for reproducible","967","        results across multiple function calls.","968","        See :term:`Glossary <random_state>`.","1157","    random_state : int, RandomState instance, default=None","1158","        Used for initialisation (when ``init`` == 'nndsvdar' or","1159","        'random'), and in Coordinate Descent. Pass an int for reproducible","1160","        results across multiple function calls.","1161","        See :term:`Glossary <random_state>`."],"delete":["289","    random_state : int, RandomState instance or None, optional, default: None","290","        If int, random_state is the seed used by the random number generator;","291","        If RandomState instance, random_state is the random number generator;","292","        If None, the random number generator is the RandomState instance used","293","        by `np.random`. Used when ``random`` == 'nndsvdar' or 'random'.","474","    random_state : int, RandomState instance or None, optional, default: None","475","        If int, random_state is the seed used by the random number generator;","476","        If RandomState instance, random_state is the random number generator;","477","        If None, the random number generator is the RandomState instance used","478","        by `np.random`.","965","    random_state : int, RandomState instance or None, optional, default: None","966","        If int, random_state is the seed used by the random number generator;","967","        If RandomState instance, random_state is the random number generator;","968","        If None, the random number generator is the RandomState instance used","969","        by `np.random`.","1158","    random_state : int, RandomState instance or None, optional, default: None","1159","        If int, random_state is the seed used by the random number generator;","1160","        If RandomState instance, random_state is the random number generator;","1161","        If None, the random number generator is the RandomState instance used","1162","        by `np.random`."]}]}},"55a98ab7e3b10966f6d00c3562f3a99896797964":{"changes":{"doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/linear_model\/tests\/test_logistic.py":"MODIFY","doc\/modules\/classes.rst":"MODIFY","sklearn\/linear_model\/logistic.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.21.rst":[{"add":["95","- |API| :func:`linear_model.logistic_regression_path` is deprecated","96","  in version 0.21 and will be removed in version 0.23.","97","  :issue:`12821` by :user:`Nicolas Hug <NicolasHug>`.","98",""],"delete":[]}],"sklearn\/linear_model\/tests\/test_logistic.py":[{"add":["37","    logistic_regression_path,","38","    _logistic_regression_path, LogisticRegressionCV,","398","        coefs, Cs, _ = f(_logistic_regression_path)(","413","        coefs, Cs, _ = f(_logistic_regression_path)(","430","    assert_warns(ConvergenceWarning, _logistic_regression_path,","1692","    coefs, _, _ = _logistic_regression_path(X, y, penalty='l1', Cs=Cs,","1693","                                            solver='saga', random_state=0,","1694","                                            multi_class='multinomial')","1749","","1750","","1751","def test_logistic_regression_path_deprecation():","1752","","1753","    assert_warns_message(DeprecationWarning,","1754","                         \"logistic_regression_path was deprecated\",","1755","                         logistic_regression_path, X, Y1)"],"delete":["37","    logistic_regression_path, LogisticRegressionCV,","397","        coefs, Cs, _ = f(logistic_regression_path)(","412","        coefs, Cs, _ = f(logistic_regression_path)(","429","    assert_warns(ConvergenceWarning, logistic_regression_path,","1691","    coefs, _, _ = logistic_regression_path(X, y, penalty='l1', Cs=Cs,","1692","                                           solver='saga', random_state=0,","1693","                                           multi_class='multinomial')"]}],"doc\/modules\/classes.rst":[{"add":["1508","   linear_model.logistic_regression_path"],"delete":["758","   linear_model.logistic_regression_path"]}],"sklearn\/linear_model\/logistic.py":[{"add":["31","from ..utils import deprecated","481","@deprecated('logistic_regression_path was deprecated in version 0.21 and '","482","            'will be removed in version 0.23.0')","500","    .. deprecated:: 0.21","501","        ``logistic_regression_path`` was deprecated in version 0.21 and will","502","        be removed in 0.23.","503","","504","    Read more in the :ref:`User Guide <logistic_regression>`.","505","","506","    Parameters","507","    ----------","508","    X : array-like or sparse matrix, shape (n_samples, n_features)","509","        Input data.","510","","511","    y : array-like, shape (n_samples,) or (n_samples, n_targets)","512","        Input data, target values.","513","","514","    pos_class : int, None","515","        The class with respect to which we perform a one-vs-all fit.","516","        If None, then it is assumed that the given problem is binary.","517","","518","    Cs : int | array-like, shape (n_cs,)","519","        List of values for the regularization parameter or integer specifying","520","        the number of regularization parameters that should be used. In this","521","        case, the parameters will be chosen in a logarithmic scale between","522","        1e-4 and 1e4.","523","","524","    fit_intercept : bool","525","        Whether to fit an intercept for the model. In this case the shape of","526","        the returned array is (n_cs, n_features + 1).","527","","528","    max_iter : int","529","        Maximum number of iterations for the solver.","530","","531","    tol : float","532","        Stopping criterion. For the newton-cg and lbfgs solvers, the iteration","533","        will stop when ``max{|g_i | i = 1, ..., n} <= tol``","534","        where ``g_i`` is the i-th component of the gradient.","535","","536","    verbose : int","537","        For the liblinear and lbfgs solvers set verbose to any positive","538","        number for verbosity.","539","","540","    solver : {'lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'}","541","        Numerical solver to use.","542","","543","    coef : array-like, shape (n_features,), default None","544","        Initialization value for coefficients of logistic regression.","545","        Useless for liblinear solver.","546","","547","    class_weight : dict or 'balanced', optional","548","        Weights associated with classes in the form ``{class_label: weight}``.","549","        If not given, all classes are supposed to have weight one.","550","","551","        The \"balanced\" mode uses the values of y to automatically adjust","552","        weights inversely proportional to class frequencies in the input data","553","        as ``n_samples \/ (n_classes * np.bincount(y))``.","554","","555","        Note that these weights will be multiplied with sample_weight (passed","556","        through the fit method) if sample_weight is specified.","557","","558","    dual : bool","559","        Dual or primal formulation. Dual formulation is only implemented for","560","        l2 penalty with liblinear solver. Prefer dual=False when","561","        n_samples > n_features.","562","","563","    penalty : str, 'l1', 'l2', or 'elasticnet'","564","        Used to specify the norm used in the penalization. The 'newton-cg',","565","        'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is","566","        only supported by the 'saga' solver.","567","","568","    intercept_scaling : float, default 1.","569","        Useful only when the solver 'liblinear' is used","570","        and self.fit_intercept is set to True. In this case, x becomes","571","        [x, self.intercept_scaling],","572","        i.e. a \"synthetic\" feature with constant value equal to","573","        intercept_scaling is appended to the instance vector.","574","        The intercept becomes ``intercept_scaling * synthetic_feature_weight``.","575","","576","        Note! the synthetic feature weight is subject to l1\/l2 regularization","577","        as all other features.","578","        To lessen the effect of regularization on synthetic feature weight","579","        (and therefore on the intercept) intercept_scaling has to be increased.","580","","581","    multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'","582","        If the option chosen is 'ovr', then a binary problem is fit for each","583","        label. For 'multinomial' the loss minimised is the multinomial loss fit","584","        across the entire probability distribution, *even when the data is","585","        binary*. 'multinomial' is unavailable when solver='liblinear'.","586","        'auto' selects 'ovr' if the data is binary, or if solver='liblinear',","587","        and otherwise selects 'multinomial'.","588","","589","        .. versionadded:: 0.18","590","           Stochastic Average Gradient descent solver for 'multinomial' case.","591","        .. versionchanged:: 0.20","592","            Default will change from 'ovr' to 'auto' in 0.22.","593","","594","    random_state : int, RandomState instance or None, optional, default None","595","        The seed of the pseudo random number generator to use when shuffling","596","        the data.  If int, random_state is the seed used by the random number","597","        generator; If RandomState instance, random_state is the random number","598","        generator; If None, the random number generator is the RandomState","599","        instance used by `np.random`. Used when ``solver`` == 'sag' or","600","        'liblinear'.","601","","602","    check_input : bool, default True","603","        If False, the input arrays X and y will not be checked.","604","","605","    max_squared_sum : float, default None","606","        Maximum squared sum of X over samples. Used only in SAG solver.","607","        If None, it will be computed, going through all the samples.","608","        The value should be precomputed to speed up cross validation.","609","","610","    sample_weight : array-like, shape(n_samples,) optional","611","        Array of weights that are assigned to individual samples.","612","        If not provided, then each sample is given unit weight.","613","","614","    l1_ratio : float or None, optional (default=None)","615","        The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only","616","        used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent","617","        to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent","618","        to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a","619","        combination of L1 and L2.","620","","621","    Returns","622","    -------","623","    coefs : ndarray, shape (n_cs, n_features) or (n_cs, n_features + 1)","624","        List of coefficients for the Logistic Regression model. If","625","        fit_intercept is set to True then the second dimension will be","626","        n_features + 1, where the last item represents the intercept. For","627","        ``multiclass='multinomial'``, the shape is (n_classes, n_cs,","628","        n_features) or (n_classes, n_cs, n_features + 1).","629","","630","    Cs : ndarray","631","        Grid of Cs used for cross-validation.","632","","633","    n_iter : array, shape (n_cs,)","634","        Actual number of iteration for each Cs.","635","","636","    Notes","637","    -----","638","    You might get slightly different results with the solver liblinear than","639","    with the others since this uses LIBLINEAR which penalizes the intercept.","640","","641","    .. versionchanged:: 0.19","642","        The \"copy\" parameter was removed.","643","    \"\"\"","644","","645","    return _logistic_regression_path(","646","        X, y, pos_class=None, Cs=10, fit_intercept=True, max_iter=100,","647","        tol=1e-4, verbose=0, solver='lbfgs', coef=None, class_weight=None,","648","        dual=False, penalty='l2', intercept_scaling=1., multi_class='warn',","649","        random_state=None, check_input=True, max_squared_sum=None,","650","        sample_weight=None, l1_ratio=None)","651","","652","","653","def _logistic_regression_path(X, y, pos_class=None, Cs=10, fit_intercept=True,","654","                              max_iter=100, tol=1e-4, verbose=0,","655","                              solver='lbfgs', coef=None,","656","                              class_weight=None, dual=False, penalty='l2',","657","                              intercept_scaling=1., multi_class='warn',","658","                              random_state=None, check_input=True,","659","                              max_squared_sum=None, sample_weight=None,","660","                              l1_ratio=None):","661","    \"\"\"Compute a Logistic Regression model for a list of regularization","662","    parameters.","663","","664","    This is an implementation that uses the result of the previous model","665","    to speed up computations along the set of solutions, making it faster","666","    than sequentially calling LogisticRegression for the different parameters.","667","    Note that there will be no speedup with liblinear solver, since it does","668","    not handle warm-starting.","669","","1150","    coefs, Cs, n_iter = _logistic_regression_path(","1563","        path_func = delayed(_logistic_regression_path)","2140","                w, _, _ = _logistic_regression_path("],"delete":["977","    coefs, Cs, n_iter = logistic_regression_path(","1390","        path_func = delayed(logistic_regression_path)","1967","                w, _, _ = logistic_regression_path("]}]}},"104f6847919a0a95daff711dcdc5e0722e4a3fce":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/utils\/validation.py":"MODIFY","doc\/whats_new\/_contributors.rst":"MODIFY","sklearn\/utils\/tests\/test_validation.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["182","","183","- |Fix| Calling :func:`utils.check_array` on `pandas.Series`, which","184","  raised an error in 0.20.0, now returns the expected output again.","185","  :issue:`12625` by `Andreas M¨¹ller`_"],"delete":[]}],"sklearn\/utils\/validation.py":[{"add":["479","    if hasattr(array, \"dtypes\") and len(array.dtypes):"],"delete":["479","    if hasattr(array, \"dtypes\") and hasattr(array, \"__array__\"):"]}],"doc\/whats_new\/_contributors.rst":[{"add":["50",".. _Andreas M¨¹ller: https:\/\/amueller.github.io\/"],"delete":["50",".. _Andreas M¨¹ller: https:\/\/peekaboo-vision.blogspot.com\/"]}],"sklearn\/utils\/tests\/test_validation.py":[{"add":["696","def test_check_array_series():","697","    # regression test that check_array works on pandas Series","698","    pd = importorskip(\"pandas\")","699","    res = check_array(pd.Series([1, 2, 3]), ensure_2d=False,","700","                      warn_on_dtype=True)","701","    assert_array_equal(res, np.array([1, 2, 3]))","702","","703",""],"delete":[]}]}},"90570ab0319c39ad89ea94ce1884ffefb6c79090":{"changes":{"sklearn\/tree\/_splitter.pxd":"MODIFY","sklearn\/tree\/_criterion.pyx":"MODIFY","sklearn\/tree\/_criterion.pxd":"MODIFY","sklearn\/tree\/_tree.pyx":"MODIFY","sklearn\/tree\/_utils.pxd":"MODIFY","sklearn\/tree\/_splitter.pyx":"MODIFY"},"diff":{"sklearn\/tree\/_splitter.pxd":[{"add":["0","# cython: language_level=3","1","","18","from ._tree cimport DTYPE_t          # Type of X","19","from ._tree cimport DOUBLE_t         # Type of y, sample_weight","20","from ._tree cimport SIZE_t           # Type for indices and counters","21","from ._tree cimport INT32_t          # Signed 32 bit integer","22","from ._tree cimport UINT32_t         # Unsigned 32 bit integer","64","    cdef const DOUBLE_t[:, ::1] y","84","    cdef int init(self, object X, const DOUBLE_t[:, ::1] y,"],"delete":["16","ctypedef np.npy_float32 DTYPE_t          # Type of X","17","ctypedef np.npy_float64 DOUBLE_t         # Type of y, sample_weight","18","ctypedef np.npy_intp SIZE_t              # Type for indices and counters","19","ctypedef np.npy_int32 INT32_t            # Signed 32 bit integer","20","ctypedef np.npy_uint32 UINT32_t          # Unsigned 32 bit integer","62","    cdef DOUBLE_t* y","63","    cdef SIZE_t y_stride","83","    cdef int init(self, object X, np.ndarray y,"]}],"sklearn\/tree\/_criterion.pyx":[{"add":["53","    cdef int init(self, const DOUBLE_t[:, ::1] y, DOUBLE_t* sample_weight,","278","    cdef int init(self, const DOUBLE_t[:, ::1] y,","336","                c = <SIZE_t> self.y[i, k]","445","                    label_index = k * self.sum_stride + <SIZE_t> self.y[i, k]","460","                    label_index = k * self.sum_stride + <SIZE_t> self.y[i, k]","739","    cdef int init(self, const DOUBLE_t[:, ::1] y, DOUBLE_t* sample_weight,","771","                y_ik = self.y[i, k]","837","                    sum_left[k] += w * self.y[i, k]","850","                    sum_left[k] -= w * self.y[i, k]","937","        cdef DOUBLE_t y_ik","954","                y_ik = self.y[i, k]","1023","    cdef int init(self, const DOUBLE_t[:, ::1] y, DOUBLE_t* sample_weight,","1062","                (<WeightedMedianCalculator> right_child[k]).push(self.y[i, k], w)","1167","                    (<WeightedMedianCalculator> right_child[k]).remove(self.y[i, k], w)","1169","                    (<WeightedMedianCalculator> left_child[k]).push(self.y[i, k], w)","1183","                    (<WeightedMedianCalculator> left_child[k]).remove(self.y[i, k], w)","1184","                    (<WeightedMedianCalculator> right_child[k]).push(self.y[i, k], w)","1217","                impurity += fabs(self.y[i, k] - self.node_medians[k]) * w","1252","                impurity_left += fabs(self.y[i, k] - median) * w","1264","                impurity_right += fabs(self.y[i, k] - median) * w"],"delete":["53","    cdef int init(self, DOUBLE_t* y, SIZE_t y_stride, DOUBLE_t* sample_weight,","65","        y_stride : SIZE_t","66","            y_stride is used to index the kth output value as follows:","67","            y[i, k] = y[i * y_stride + k]","226","        self.y = NULL","227","        self.y_stride = 0","283","    cdef int init(self, DOUBLE_t* y, SIZE_t y_stride,","296","        y_stride : SIZE_t","297","            The stride between elements in the buffer, important if there","298","            are multiple targets (multi-output)","312","        self.y_stride = y_stride","345","                c = <SIZE_t> y[i * y_stride + k]","420","        cdef DOUBLE_t* y = self.y","455","                    label_index = (k * self.sum_stride +","456","                                   <SIZE_t> y[i * self.y_stride + k])","471","                    label_index = (k * self.sum_stride +","472","                                   <SIZE_t> y[i * self.y_stride + k])","716","        self.y = NULL","717","        self.y_stride = 0","753","    cdef int init(self, DOUBLE_t* y, SIZE_t y_stride, DOUBLE_t* sample_weight,","760","        self.y_stride = y_stride","786","                y_ik = y[i * y_stride + k]","829","        cdef DOUBLE_t* y = self.y","836","        cdef DOUBLE_t y_ik","854","                    y_ik = y[i * self.y_stride + k]","855","                    sum_left[k] += w * y_ik","868","                    y_ik = y[i * self.y_stride + k]","869","                    sum_left[k] -= w * y_ik","949","","950","        cdef DOUBLE_t* y = self.y","966","        cdef DOUBLE_t y_ik","975","                y_ik = y[i * self.y_stride + k]","1016","        self.y = NULL","1017","        self.y_stride = 0","1046","    cdef int init(self, DOUBLE_t* y, SIZE_t y_stride, DOUBLE_t* sample_weight,","1053","        cdef DOUBLE_t y_ik","1058","        self.y_stride = y_stride","1084","                y_ik = y[i * y_stride + k]","1085","","1089","                (<WeightedMedianCalculator> right_child[k]).push(y_ik, w)","1174","        cdef DOUBLE_t* y = self.y","1179","        cdef DOUBLE_t y_ik","1195","                    y_ik = y[i * self.y_stride + k]","1197","                    (<WeightedMedianCalculator> right_child[k]).remove(y_ik, w)","1199","                    (<WeightedMedianCalculator> left_child[k]).push(y_ik, w)","1212","                    y_ik = y[i * self.y_stride + k]","1214","                    (<WeightedMedianCalculator> left_child[k]).remove(y_ik, w)","1215","                    (<WeightedMedianCalculator> right_child[k]).push(y_ik, w)","1235","        cdef DOUBLE_t* y = self.y","1239","        cdef DOUBLE_t y_ik","1247","                y_ik = y[i * self.y_stride + k]","1248","","1252","                impurity += fabs(y_ik - self.node_medians[k]) * w","1263","        cdef DOUBLE_t* y = self.y","1272","        cdef DOUBLE_t y_ik","1286","                y_ik = y[i * self.y_stride + k]","1287","","1291","                impurity_left += fabs(y_ik - median) * w","1300","                y_ik = y[i * self.y_stride + k]","1301","","1305","                impurity_right += fabs(y_ik - median) * w"]}],"sklearn\/tree\/_criterion.pxd":[{"add":["0","# cython: language_level=3","15","from ._tree cimport DTYPE_t          # Type of X","16","from ._tree cimport DOUBLE_t         # Type of y, sample_weight","17","from ._tree cimport SIZE_t           # Type for indices and counters","18","from ._tree cimport INT32_t          # Signed 32 bit integer","19","from ._tree cimport UINT32_t         # Unsigned 32 bit integer","27","    cdef const DOUBLE_t[:, ::1] y        # Values of y","55","    cdef int init(self, const DOUBLE_t[:, ::1] y, DOUBLE_t* sample_weight,"],"delete":["14","ctypedef np.npy_float32 DTYPE_t          # Type of X","15","ctypedef np.npy_float64 DOUBLE_t         # Type of y, sample_weight","16","ctypedef np.npy_intp SIZE_t              # Type for indices and counters","17","ctypedef np.npy_int32 INT32_t            # Signed 32 bit integer","18","ctypedef np.npy_uint32 UINT32_t          # Unsigned 32 bit integer","26","    cdef DOUBLE_t* y                     # Values of y","27","    cdef SIZE_t y_stride                 # Stride in y (since n_outputs >= 1)","55","    cdef int init(self, DOUBLE_t* y, SIZE_t y_stride, DOUBLE_t* sample_weight,"]}],"sklearn\/tree\/_tree.pyx":[{"add":["795","        cdef DTYPE_t[:, :] X_ndarray = X","812","                    if X_ndarray[i, node.feature] <= node.threshold:","915","        cdef DTYPE_t[:, :] X_ndarray = X","942","                    if X_ndarray[i, node.feature] <= node.threshold:"],"delete":["795","        cdef np.ndarray X_ndarray = X","796","        cdef DTYPE_t* X_ptr = <DTYPE_t*> X_ndarray.data","797","        cdef SIZE_t X_sample_stride = <SIZE_t> X.strides[0] \/ <SIZE_t> X.itemsize","798","        cdef SIZE_t X_fx_stride = <SIZE_t> X.strides[1] \/ <SIZE_t> X.itemsize","815","                    if X_ptr[X_sample_stride * i +","816","                             X_fx_stride * node.feature] <= node.threshold:","919","        cdef np.ndarray X_ndarray = X","920","        cdef DTYPE_t* X_ptr = <DTYPE_t*> X_ndarray.data","921","        cdef SIZE_t X_sample_stride = <SIZE_t> X.strides[0] \/ <SIZE_t> X.itemsize","922","        cdef SIZE_t X_fx_stride = <SIZE_t> X.strides[1] \/ <SIZE_t> X.itemsize","949","                    if X_ptr[X_sample_stride * i +","950","                             X_fx_stride * node.feature] <= node.threshold:"]}],"sklearn\/tree\/_utils.pxd":[{"add":["0","# cython: language_level=3","1","","14","from ._tree cimport Node"],"delete":["12","from _tree cimport Node"]}],"sklearn\/tree\/_splitter.pyx":[{"add":["118","                   DOUBLE_t[:, ::1] y,","179","        self.y = y","238","    cdef DTYPE_t[:, :] X","262","                  DOUBLE_t[:, ::1] y,","274","        self.X = X","412","                            Xf[p] = self.X[j, current.feature]","416","                        Xf[i] = self.X[samples[i], current.feature]","481","                if self.X[samples[p], best.feature] <= best.threshold:","735","                min_feature_value = self.X[samples[start], current.feature]","740","                    current_feature_value = self.X[samples[p], current.feature]","813","                    if self.X[samples[p], best.feature] <= best.threshold:","878","                  DOUBLE_t[:, ::1] y,"],"delete":["94","        self.y = NULL","95","        self.y_stride = 0","120","                   np.ndarray[DOUBLE_t, ndim=2, mode=\"c\"] y,","181","        self.y = <DOUBLE_t*> y.data","182","        self.y_stride = <SIZE_t> y.strides[0] \/ <SIZE_t> y.itemsize","208","                            self.y_stride,","242","    cdef DTYPE_t* X","243","    cdef SIZE_t X_sample_stride","244","    cdef SIZE_t X_feature_stride","256","        self.X = NULL","257","        self.X_sample_stride = 0","258","        self.X_feature_stride = 0","271","                  np.ndarray[DOUBLE_t, ndim=2, mode=\"c\"] y,","283","        # Initialize X","284","        cdef np.ndarray X_ndarray = X","285","","286","        self.X = <DTYPE_t*> X_ndarray.data","287","        self.X_sample_stride = <SIZE_t> X.strides[0] \/ <SIZE_t> X.itemsize","288","        self.X_feature_stride = <SIZE_t> X.strides[1] \/ <SIZE_t> X.itemsize","329","        cdef DTYPE_t* X = self.X","331","        cdef SIZE_t X_sample_stride = self.X_sample_stride","332","        cdef SIZE_t X_feature_stride = self.X_feature_stride","416","                feature_offset = self.X_feature_stride * current.feature","430","                            Xf[p] = X[self.X_sample_stride * j + feature_offset]","434","                        Xf[i] = X[self.X_sample_stride * samples[i] + feature_offset]","495","            feature_offset = X_feature_stride * best.feature","500","                if X[X_sample_stride * samples[p] + feature_offset] <= best.threshold:","677","        cdef DTYPE_t* X = self.X","679","        cdef SIZE_t X_sample_stride = self.X_sample_stride","680","        cdef SIZE_t X_feature_stride = self.X_feature_stride","755","                feature_stride = X_feature_stride * current.feature","758","                min_feature_value = X[X_sample_stride * samples[start] + feature_stride]","763","                    current_feature_value = X[X_sample_stride * samples[p] + feature_stride]","830","        feature_stride = X_feature_stride * best.feature","837","                    if X[X_sample_stride * samples[p] + feature_stride] <= best.threshold:","902","                  np.ndarray[DOUBLE_t, ndim=2, mode=\"c\"] y,"]}]}},"42073c2cc8d14a9b87c348685c35d171904a1df0":{"changes":{"sklearn\/decomposition\/tests\/test_nmf.py":"MODIFY","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/decomposition\/nmf.py":"MODIFY"},"diff":{"sklearn\/decomposition\/tests\/test_nmf.py":[{"add":["55","    for init in ['nndsvd', 'nndsvda', 'nndsvdar']:","56","        msg = (\"init = '{}' can only be used when \"","57","               \"n_components <= min(n_samples, n_features)\"","58","               .format(init))","59","        assert_raise_message(ValueError, msg, NMF(3, init).fit, A)","60","        assert_raise_message(ValueError, msg, nmf._initialize_nmf, A,","61","                             3, init)","62","","207","    for init in ['random', 'nndsvd']:","208","        for solver in ('cd', 'mu'):","209","            W_nmf, H, _ = non_negative_factorization(","210","                A, init=init, solver=solver, random_state=1, tol=1e-2)","211","            W_nmf_2, _, _ = non_negative_factorization(","212","                A, H=H, update_H=False, init=init, solver=solver,","213","                random_state=1, tol=1e-2)","215","            model_class = NMF(init=init, solver=solver, random_state=1,","216","                              tol=1e-2)","217","            W_cls = model_class.fit_transform(A)","218","            W_cls_2 = model_class.transform(A)","219","","220","            assert_array_almost_equal(W_nmf, W_cls, decimal=10)","221","            assert_array_almost_equal(W_nmf_2, W_cls_2, decimal=10)"],"delete":["199","    for solver in ('cd', 'mu'):","200","        W_nmf, H, _ = non_negative_factorization(","201","            A, solver=solver, random_state=1, tol=1e-2)","202","        W_nmf_2, _, _ = non_negative_factorization(","203","            A, H=H, update_H=False, solver=solver, random_state=1, tol=1e-2)","205","        model_class = NMF(solver=solver, random_state=1, tol=1e-2)","206","        W_cls = model_class.fit_transform(A)","207","        W_cls_2 = model_class.transform(A)","208","        assert_array_almost_equal(W_nmf, W_cls, decimal=10)","209","        assert_array_almost_equal(W_nmf_2, W_cls_2, decimal=10)"]}],"doc\/whats_new\/v0.21.rst":[{"add":["78",":mod:`sklearn.decomposition`","79","............................","80","","81","- |Fix| Fixed a bug in :class:`decomposition.NMF` where `init = 'nndsvd'`,","82","  `init = 'nndsvda'`, and `init = 'nndsvdar'` are allowed when","83","  `n_components < n_features` instead of","84","  `n_components <= min(n_samples, n_features)`. ","85","  :issue:`11650` by :user:`Hossein Pourbozorg <hossein-pourbozorg>` and","86","  :user:`Zijie (ZJ) Poh <zjpoh>`.","87",""],"delete":[]}],"sklearn\/decomposition\/nmf.py":[{"add":["263","        - None: 'nndsvd' if n_components <= min(n_samples, n_features),","264","            otherwise 'random'.","307","    if (init is not None and init != 'random'","308","            and n_components > min(n_samples, n_features)):","309","        raise ValueError(\"init = '{}' can only be used when \"","310","                         \"n_components <= min(n_samples, n_features)\"","311","                         .format(init))","312","","314","        if n_components <= min(n_samples, n_features):","1113","        - None: 'nndsvd' if n_components <= min(n_samples, n_features),","1114","            otherwise random."],"delete":["263","        - None: 'nndsvd' if n_components < n_features, otherwise 'random'.","307","        if n_components < n_features:","1106","        - None: 'nndsvd' if n_components < n_features, otherwise random."]}]}},"4c2eb3a0d67cbdacdb9314f585b2f73590ff0ac8":{"changes":{"sklearn\/metrics\/regression.py":"MODIFY","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/metrics\/tests\/test_regression.py":"MODIFY"},"diff":{"sklearn\/metrics\/regression.py":[{"add":["26","import warnings","28","from ..utils.validation import (check_array, check_consistent_length,","29","                                _num_samples)","31","from ..exceptions import UndefinedMetricWarning","505","    This metric is not well-defined for single samples and will return a NaN","506","    value if n_samples is less than two.","507","","542","    if _num_samples(y_pred) < 2:","543","        msg = \"R^2 score is not well-defined with less than two samples.\"","544","        warnings.warn(msg, UndefinedMetricWarning)","545","        return float('nan')","546",""],"delete":["27","from ..utils.validation import check_array, check_consistent_length"]}],"doc\/whats_new\/v0.21.rst":[{"add":["143","- |Fix| The metric :func:`metrics.r2_score` is degenerate with a single sample","144","  and now it returns NaN and raises :class:`exceptions.UndefinedMetricWarning`.","145","  :issue:`12855` by :user:`Pawel Sendyk <psendyk>.`","146",""],"delete":[]}],"sklearn\/metrics\/tests\/test_regression.py":[{"add":["4","import pytest","22","from ...exceptions import UndefinedMetricWarning","23","","194","","195","","196","@pytest.mark.parametrize('metric', [r2_score])","197","def test_regression_single_sample(metric):","198","    y_true = [0]","199","    y_pred = [1]","200","    warning_msg = 'not well-defined with less than two samples.'","201","","202","    # Trigger the warning","203","    with pytest.warns(UndefinedMetricWarning, match=warning_msg):","204","        score = metric(y_true, y_pred)","205","        assert np.isnan(score)"],"delete":["77",""]}]}},"d903436afed4725b0bb366517215bff5124c10af":{"changes":{"doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/multioutput.py":"MODIFY","sklearn\/tests\/test_multioutput.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.21.rst":[{"add":["508",":mod:`sklearn.multioutput`","509","........................","510","","511","- |Fix| Fixed a bug in :class:`multiout.MultiOutputClassifier` where the","512","  `predict_proba` method incorrectly checked for `predict_proba` attribute in","513","  the estimator object.","514","  :issue:`12222` by :user:`Rebekah Kim <rebekahkim>`","515","  "],"delete":[]}],"sklearn\/multioutput.py":[{"add":["147","                             \" a fit method\")","188","            raise ValueError(\"The base estimator should implement\"","189","                             \" a predict method\")","330","        This method will raise a ``ValueError`` if any of the","331","        estimators do not have ``predict_proba``.","332","","346","        if not all([hasattr(estimator, \"predict_proba\")","347","                    for estimator in self.estimators_]):","348","            raise ValueError(\"The base estimator should implement \"","356","        \"\"\"Returns the mean accuracy on the given test data and labels."],"delete":["147","                             \"  a fit method\")","188","            raise ValueError(\"The base estimator should implement a predict method\")","342","        if not hasattr(self.estimator, \"predict_proba\"):","343","            raise ValueError(\"The base estimator should implement\"","351","        \"\"\"\"Returns the mean accuracy on the given test data and labels."]}],"sklearn\/tests\/test_multioutput.py":[{"add":["33","from sklearn.model_selection import GridSearchCV","179","# check predict_proba passes","180","def test_multi_output_predict_proba():","181","    sgd_linear_clf = SGDClassifier(random_state=1, max_iter=5, tol=1e-3)","182","    param = {'loss': ('hinge', 'log', 'modified_huber')}","183","","184","    # inner function for custom scoring","185","    def custom_scorer(estimator, X, y):","186","        if hasattr(estimator, \"predict_proba\"):","187","            return 1.0","188","        else:","189","            return 0.0","190","    grid_clf = GridSearchCV(sgd_linear_clf, param_grid=param,","191","                            scoring=custom_scorer, cv=3, error_score=np.nan)","192","    multi_target_linear = MultiOutputClassifier(grid_clf)","193","    multi_target_linear.fit(X, y)","194","","195","    multi_target_linear.predict_proba(X)","196","","197","    # SGDClassifier defaults to loss='hinge' which is not a probabilistic","198","    # loss function; therefore it does not expose a predict_proba method","199","    sgd_linear_clf = SGDClassifier(random_state=1, max_iter=5, tol=1e-3)","200","    multi_target_linear = MultiOutputClassifier(sgd_linear_clf)","201","    multi_target_linear.fit(X, y)","202","    err_msg = \"The base estimator should implement predict_proba method\"","203","    with pytest.raises(ValueError, match=err_msg):","204","        multi_target_linear.predict_proba(X)","205","","206",""],"delete":[]}]}},"bea1eb51b34d5d61a3df217f5b7ed25f6b98eec3":{"changes":{"doc\/developers\/contributing.rst":"MODIFY"},"diff":{"doc\/developers\/contributing.rst":[{"add":["1145","When ``fit`` is called, any previous call to ``fit`` should be ignored. In","1146","general, calling ``estimator.fit(X1)`` and then ``estimator.fit(X2)`` should","1147","be the same as only calling ``estimator.fit(X2)``. However, this may not be","1148","true in practice when ``fit`` depends on some random process, see","1149",":term:`random_state`. Another exception to this rule is when the","1150","hyper-parameter ``warm_start`` is set to ``True`` for estimators that","1151","support it. ``warm_start=True`` means that the previous state of the","1152","trainable parameters of the estimator are reused instead of using the","1153","default initialization strategy.","1154","","1163","The estimated attributes are expected to be overridden when you call ``fit``","1164","a second time."],"delete":["1153","The last-mentioned attributes are expected to be overridden when","1154","you call ``fit`` a second time without taking any previous value into","1155","account: **fit should be idempotent**."]}]}},"b42a5152af2cf51d9d7c30c40abc56bf0fe327f5":{"changes":{"sklearn\/linear_model\/tests\/test_logistic.py":"MODIFY","sklearn\/utils\/testing.py":"MODIFY","sklearn\/utils\/estimator_checks.py":"MODIFY","sklearn\/utils\/__init__.py":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_logistic.py":[{"add":["0","import os","12","from sklearn.utils import compute_class_weight, _IS_32BIT","1258","@pytest.mark.parametrize('multi_class', ['ovr', 'multinomial'])","1259","def test_dtype_match(multi_class):","1268","    solver = 'newton-cg'","1270","    # Check type consistency","1271","    lr_32 = LogisticRegression(solver=solver, multi_class=multi_class,","1272","                               random_state=42)","1273","    lr_32.fit(X_32, y_32)","1274","    assert_equal(lr_32.coef_.dtype, X_32.dtype)","1276","    # check consistency with sparsity","1277","    lr_32_sparse = LogisticRegression(solver=solver,","1278","                                      multi_class=multi_class,","1279","                                      random_state=42)","1280","    lr_32_sparse.fit(X_sparse_32, y_32)","1281","    assert_equal(lr_32_sparse.coef_.dtype, X_sparse_32.dtype)","1283","    # Check accuracy consistency","1284","    lr_64 = LogisticRegression(solver=solver, multi_class=multi_class,","1285","                               random_state=42)","1286","    lr_64.fit(X_64, y_64)","1287","    assert_equal(lr_64.coef_.dtype, X_64.dtype)","1288","","1289","    rtol = 1e-6","1290","    if os.name == 'nt' and _IS_32BIT:","1291","        # FIXME","1292","        rtol = 1e-2","1293","","1294","    assert_allclose(lr_32.coef_, lr_64.coef_.astype(np.float32), rtol=rtol)"],"delete":["11","from sklearn.utils import compute_class_weight","1257","def test_dtype_match():","1266","    for solver in ['newton-cg']:","1267","        for multi_class in ['ovr', 'multinomial']:","1269","            # Check type consistency","1270","            lr_32 = LogisticRegression(solver=solver, multi_class=multi_class,","1271","                                       random_state=42)","1272","            lr_32.fit(X_32, y_32)","1273","            assert_equal(lr_32.coef_.dtype, X_32.dtype)","1275","            # check consistency with sparsity","1276","            lr_32_sparse = LogisticRegression(solver=solver,","1277","                                              multi_class=multi_class,","1278","                                              random_state=42)","1279","            lr_32_sparse.fit(X_sparse_32, y_32)","1280","            assert_equal(lr_32_sparse.coef_.dtype, X_sparse_32.dtype)","1282","            # Check accuracy consistency","1283","            lr_64 = LogisticRegression(solver=solver, multi_class=multi_class,","1284","                                       random_state=42)","1285","            lr_64.fit(X_64, y_64)","1286","            assert_equal(lr_64.coef_.dtype, X_64.dtype)","1287","            assert_almost_equal(lr_32.coef_, lr_64.coef_.astype(np.float32))"]}],"sklearn\/utils\/testing.py":[{"add":["48","from sklearn.utils import deprecated, IS_PYPY, _IS_32BIT","759","    skip_if_32bit = pytest.mark.skipif(_IS_32BIT,"],"delete":["17","import struct","49","from sklearn.utils import deprecated, IS_PYPY","760","    skip_if_32bit = pytest.mark.skipif(8 * struct.calcsize(\"P\") == 32,"]}],"sklearn\/utils\/estimator_checks.py":[{"add":["15","from sklearn.utils import IS_PYPY, _IS_32BIT","939","    if name in ('CCA', 'LocallyLinearEmbedding', 'KernelPCA') and _IS_32BIT:","1017","    if name in ('CCA', 'LocallyLinearEmbedding', 'KernelPCA') and _IS_32BIT:"],"delete":["8","import struct","16","from sklearn.utils import IS_PYPY","406","def _is_32bit():","407","    \"\"\"Detect if process is 32bit Python.\"\"\"","408","    return struct.calcsize('P') * 8 == 32","409","","410","","945","    if name in ('CCA', 'LocallyLinearEmbedding', 'KernelPCA') and _is_32bit():","1023","    if name in ('CCA', 'LocallyLinearEmbedding', 'KernelPCA') and _is_32bit():"]}],"sklearn\/utils\/__init__.py":[{"add":["5","import struct","37","_IS_32BIT = 8 * struct.calcsize(\"P\") == 32"],"delete":[]}]}},"71525c1482f0aacecd14ba9f19668d426557dc74":{"changes":{"\/dev\/null":"DELETE","sklearn\/utils\/tests\/test_show_versions.py":"ADD"},"diff":{"\/dev\/null":[{"add":[],"delete":[]}],"sklearn\/utils\/tests\/test_show_versions.py":[{"add":[],"delete":[]}]}},"0d13745d854ae5479425b6845b175b1ab402bd59":{"changes":{"sklearn\/metrics\/classification.py":"MODIFY"},"diff":{"sklearn\/metrics\/classification.py":[{"add":["677","            Calculate metrics for each label, and find their average weighted","780","            Calculate metrics for each label, and find their average weighted","952","            Calculate metrics for each label, and find their average weighted","1226","            Calculate metrics for each label, and find their average weighted","1325","            Calculate metrics for each label, and find their average weighted"],"delete":["677","            Calculate metrics for each label, and find their average, weighted","780","            Calculate metrics for each label, and find their average, weighted","952","            Calculate metrics for each label, and find their average, weighted","1226","            Calculate metrics for each label, and find their average, weighted","1325","            Calculate metrics for each label, and find their average, weighted"]}]}},"da138c5f78e5a4bab0f5a8eea2591e0f25474db0":{"changes":{"doc\/conftest.py":"MODIFY"},"diff":{"doc\/conftest.py":[{"add":["2","import warnings","78","def setup_unsupervised_learning():","79","    # ignore deprecation warnings from scipy.misc.face","80","    warnings.filterwarnings('ignore', 'The binary mode of fromstring',","81","                            DeprecationWarning)","82","","83","","102","    elif fname.endswith('statistical_inference\/unsupervised_learning.rst'):","103","        setup_unsupervised_learning()"],"delete":[]}]}},"a85eeb28eea46164d17111aaad1eb8728835534d":{"changes":{"sklearn\/svm\/tests\/test_sparse.py":"MODIFY","sklearn\/utils\/estimator_checks.py":"MODIFY"},"diff":{"sklearn\/svm\/tests\/test_sparse.py":[{"add":["12","                                   ignore_warnings, skip_if_32bit)","73","@skip_if_32bit","268","@skip_if_32bit"],"delete":["12","                                   ignore_warnings)"]}],"sklearn\/utils\/estimator_checks.py":[{"add":["1547","    assert_allclose(y_dec, decision)"],"delete":["1547","    assert_array_equal(y_dec, decision)"]}]}},"3df0c1971ad7f27e3ccd75ef63d6b5543313bb52":{"changes":{"sklearn\/feature_extraction\/image.py":"MODIFY"},"diff":{"sklearn\/feature_extraction\/image.py":[{"add":["53","    _, n_y, n_z = img.shape","333","        (n_patches, patch_height, patch_width, n_channels)","334","        The collection of patches extracted from the image, where `n_patches`","335","        is either `max_patches` or the total number of patches that can be","336","        extracted.","340","    >>> from sklearn.datasets import load_sample_images","342","    >>> # Use the array data from the first image in this dataset:","343","    >>> one_image = load_sample_images().images[0]","344","    >>> print('Image shape: {}'.format(one_image.shape))","345","    Image shape: (427, 640, 3)","347","    >>> print('Patches shape: {}'.format(patches.shape))","348","    Patches shape: (272214, 2, 2, 3)","349","    >>> # Here are just two of these patches:","350","    >>> print(patches[1]) # doctest: +NORMALIZE_WHITESPACE","351","    [[[174 201 231]","352","      [174 201 231]]","353","     [[173 200 230]","354","      [173 200 230]]]","355","    >>> print(patches[800])# doctest: +NORMALIZE_WHITESPACE","356","    [[[187 214 243]","357","      [188 215 244]]","358","     [[187 214 243]","359","      [188 215 244]]]","462","    Examples","463","    --------","464","    >>> from sklearn.datasets import load_sample_images","465","    >>> from sklearn.feature_extraction import image","466","    >>> # Use the array data from the second image in this dataset:","467","    >>> X = load_sample_images().images[1]","468","    >>> print('Image shape: {}'.format(X.shape))","469","    Image shape: (427, 640, 3)","470","    >>> pe = image.PatchExtractor(patch_size=(2, 2))","471","    >>> pe_fit = pe.fit(X)","472","    >>> pe_trans = pe.transform(X)","473","    >>> print('Patches shape: {}'.format(pe_trans.shape))","474","    Patches shape: (545706, 2, 2)","476",""],"delete":["53","    n_x, n_y, n_z = img.shape","333","         (n_patches, patch_height, patch_width, n_channels)","334","         The collection of patches extracted from the image, where `n_patches`","335","         is either `max_patches` or the total number of patches that can be","336","         extracted.","340","    >>> import numpy as np","342","    >>> one_image = np.arange(16).reshape((4, 4))","343","    >>> one_image","344","    array([[ 0,  1,  2,  3],","345","           [ 4,  5,  6,  7],","346","           [ 8,  9, 10, 11],","347","           [12, 13, 14, 15]])","349","    >>> patches.shape","350","    (9, 2, 2)","351","    >>> patches[0]","352","    array([[0, 1],","353","           [4, 5]])","354","    >>> patches[1]","355","    array([[1, 2],","356","           [5, 6]])","357","    >>> patches[8]","358","    array([[10, 11],","359","           [14, 15]])","422","","500",""]}]}},"419c6cc456f0353d22d701ba6e1110a2bdef219a":{"changes":{".circleci\/config.yml":"MODIFY"},"diff":{".circleci\/config.yml":[{"add":["126","            - doc"],"delete":["126","            - python3"]}]}},"e67e30cec29ba9a8c505d1c722cc1461a0e31fee":{"changes":{"sklearn\/cluster\/bicluster.py":"MODIFY","sklearn\/metrics\/scorer.py":"MODIFY","sklearn\/metrics\/tests\/test_score_objects.py":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/neighbors\/base.py":"MODIFY","sklearn\/dummy.py":"MODIFY","sklearn\/datasets\/samples_generator.py":"MODIFY","sklearn\/linear_model\/base.py":"MODIFY","sklearn\/preprocessing\/data.py":"MODIFY"},"diff":{"sklearn\/cluster\/bicluster.py":[{"add":["307","        self.rows_ = np.vstack([self.row_labels_ == c","308","                                for c in range(self.n_clusters)])","309","        self.columns_ = np.vstack([self.column_labels_ == c","310","                                   for c in range(self.n_clusters)])","506","        self.rows_ = np.vstack([self.row_labels_ == label","507","                                for label in range(n_row_clusters)","508","                                for _ in range(n_col_clusters)])","509","        self.columns_ = np.vstack([self.column_labels_ == label","510","                                   for _ in range(n_row_clusters)","511","                                   for label in range(n_col_clusters)])"],"delete":["307","        self.rows_ = np.vstack(self.row_labels_ == c","308","                               for c in range(self.n_clusters))","309","        self.columns_ = np.vstack(self.column_labels_ == c","310","                                  for c in range(self.n_clusters))","506","        self.rows_ = np.vstack(self.row_labels_ == label","507","                               for label in range(n_row_clusters)","508","                               for _ in range(n_col_clusters))","509","        self.columns_ = np.vstack(self.column_labels_ == label","510","                                  for _ in range(n_row_clusters)","511","                                  for label in range(n_col_clusters))"]}],"sklearn\/metrics\/scorer.py":[{"add":["179","                    y_pred = np.vstack([p for p in y_pred]).T"],"delete":["179","                    y_pred = np.vstack(p for p in y_pred).T"]}],"sklearn\/metrics\/tests\/test_score_objects.py":[{"add":["387","    score2 = roc_auc_score(y_test, np.vstack([p[:, -1] for p in y_proba]).T)","400","    score2 = roc_auc_score(y_test, np.vstack([p for p in y_proba]).T)"],"delete":["387","    score2 = roc_auc_score(y_test, np.vstack(p[:, -1] for p in y_proba).T)","400","    score2 = roc_auc_score(y_test, np.vstack(p for p in y_proba).T)"]}],"doc\/whats_new\/v0.20.rst":[{"add":["105","Miscellaneous","106",".............","107","","108","- |Fix| Make sure to avoid raising ``FutureWarning`` when calling","109","  ``np.vstack`` with numpy 1.16 and later (use list comprehensions","110","  instead of generator expressions in many locations of the scikit-learn","111","  code base). :issue:`12467` by :user:`Olivier Grisel`.","112",""],"delete":[]}],"sklearn\/neighbors\/base.py":[{"add":["422","            result = list(pairwise_distances_chunked(","425","                **kwds))"],"delete":["422","            result = pairwise_distances_chunked(","425","                **kwds)"]}],"sklearn\/dummy.py":[{"add":["222","                y = np.vstack([classes_[k][proba[k].argmax(axis=1)] for","223","                               k in range(self.n_outputs_)]).T"],"delete":["222","                y = np.vstack(classes_[k][proba[k].argmax(axis=1)] for","223","                              k in range(self.n_outputs_)).T"]}],"sklearn\/datasets\/samples_generator.py":[{"add":["631","    X = np.vstack([np.append(outer_circ_x, inner_circ_x),","632","                   np.append(outer_circ_y, inner_circ_y)]).T","685","    X = np.vstack([np.append(outer_circ_x, inner_circ_x),","686","                   np.append(outer_circ_y, inner_circ_y)]).T","1595","    rows = np.vstack([row_labels == c for c in range(n_clusters)])","1596","    cols = np.vstack([col_labels == c for c in range(n_clusters)])","1691","    rows = np.vstack([row_labels == label","1692","                      for label in range(n_row_clusters)","1693","                      for _ in range(n_col_clusters)])","1694","    cols = np.vstack([col_labels == label","1695","                      for _ in range(n_row_clusters)","1696","                      for label in range(n_col_clusters)])"],"delete":["631","    X = np.vstack((np.append(outer_circ_x, inner_circ_x),","632","                   np.append(outer_circ_y, inner_circ_y))).T","685","    X = np.vstack((np.append(outer_circ_x, inner_circ_x),","686","                   np.append(outer_circ_y, inner_circ_y))).T","1595","    rows = np.vstack(row_labels == c for c in range(n_clusters))","1596","    cols = np.vstack(col_labels == c for c in range(n_clusters))","1691","    rows = np.vstack(row_labels == label","1692","                     for label in range(n_row_clusters)","1693","                     for _ in range(n_col_clusters))","1694","    cols = np.vstack(col_labels == label","1695","                     for _ in range(n_row_clusters)","1696","                     for label in range(n_col_clusters))"]}],"sklearn\/linear_model\/base.py":[{"add":["480","                self.coef_ = np.vstack([out[0] for out in outs])","481","                self._residues = np.vstack([out[3] for out in outs])"],"delete":["480","                self.coef_ = np.vstack(out[0] for out in outs)","481","                self._residues = np.vstack(out[3] for out in outs)"]}],"sklearn\/preprocessing\/data.py":[{"add":["1384","        return np.vstack([np.bincount(c, minlength=self.n_input_features_)","1385","                          for c in combinations])"],"delete":["1384","        return np.vstack(np.bincount(c, minlength=self.n_input_features_)","1385","                         for c in combinations)"]}]}},"2ab2927b2ee4f821fd75050da19a7f1f81aaeca8":{"changes":{"examples\/neural_networks\/plot_mnist_filters.py":"MODIFY"},"diff":{"examples\/neural_networks\/plot_mnist_filters.py":[{"add":["30","X = X \/ 255."],"delete":[]}]}},"c3915c099528638323f38db89bac31db4296709e":{"changes":{"sklearn\/linear_model\/logistic.py":"MODIFY"},"diff":{"sklearn\/linear_model\/logistic.py":[{"add":["34","from ..utils import Parallel, delayed, effective_n_jobs","1251","            if effective_n_jobs(self.n_jobs) != 1:","1254","                              \" = {}.\".format(effective_n_jobs(self.n_jobs)))"],"delete":["34","from ..utils import Parallel, delayed","1251","            if self.n_jobs != 1:","1254","                              \" = {}.\".format(self.n_jobs))"]}]}},"013d295a13721ffade7ac321437c6d4458a64c7d":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/datasets\/olivetti_faces.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["53","- |Fix| Fixed olivetti faces dataset ``DESCR`` attribute to point to the right","54","  location in :func:`datasets.fetch_olivetti_faces`. :issue:`12441` by","55","  :user:`J¨¦r¨¦mie du Boisberranger <jeremiedbb>`","56",""],"delete":[]}],"sklearn\/datasets\/olivetti_faces.py":[{"add":["126","    with open(join(module_path, 'descr', 'olivetti_faces.rst')) as rst_file:"],"delete":["126","    with open(join(module_path, 'descr', 'covtype.rst')) as rst_file:"]}]}},"2d50b5e60093f4893d83418709ace19b91d3695b":{"changes":{"doc\/whats_new\/v0.19.rst":"MODIFY"},"diff":{"doc\/whats_new\/v0.19.rst":[{"add":["9","**July, 2018**"],"delete":["9","**October, 2018**"]}]}},"8f63e9144f51693c811eb435f8b6b2b5d3b3a63c":{"changes":{"sklearn\/gaussian_process\/_gpc.py":"MODIFY","sklearn\/gaussian_process\/kernels.py":"MODIFY","sklearn\/gaussian_process\/tests\/test_gpc.py":"MODIFY","doc\/whats_new\/v0.23.rst":"MODIFY","sklearn\/gaussian_process\/tests\/test_gpr.py":"MODIFY","sklearn\/gaussian_process\/_gpr.py":"MODIFY","doc\/whats_new\/v0.24.rst":"MODIFY"},"diff":{"sklearn\/gaussian_process\/_gpc.py":[{"add":["233","            self.kernel_._check_bounds_params()","234",""],"delete":[]}],"sklearn\/gaussian_process\/kernels.py":[{"add":["34","import warnings","35","from sklearn.exceptions import ConvergenceWarning","36","","391","    def _check_bounds_params(self):","392","        \"\"\"Called after fitting to warn if bounds may have been too tight.\"\"\"","393","        list_close = np.isclose(self.bounds,","394","                                np.atleast_2d(self.theta).T)","395","        idx = 0","396","        for hyp in self.hyperparameters:","397","            for dim in range(hyp.n_elements):","398","                if list_close[idx, 0]:","399","                    warnings.warn(\"The optimal value found for \"","400","                                  \"dimension %s of parameter %s is \"","401","                                  \"close to the specified lower \"","402","                                  \"bound %s. Decreasing the bound and\"","403","                                  \" calling fit again may find a \"","404","                                  \"better value.\" %","405","                                  (dim, hyp.name, hyp.bounds[dim][0]),","406","                                  ConvergenceWarning)","407","                elif list_close[idx, 1]:","408","                    warnings.warn(\"The optimal value found for \"","409","                                  \"dimension %s of parameter %s is \"","410","                                  \"close to the specified upper \"","411","                                  \"bound %s. Increasing the bound and\"","412","                                  \" calling fit again may find a \"","413","                                  \"better value.\" %","414","                                  (dim, hyp.name, hyp.bounds[dim][1]),","415","                                  ConvergenceWarning)","416","                idx += 1","417",""],"delete":[]}],"sklearn\/gaussian_process\/tests\/test_gpc.py":[{"add":["12","from sklearn.gaussian_process.kernels \\","13","    import RBF, ConstantKernel as C, WhiteKernel","15","from sklearn.exceptions import ConvergenceWarning","17","from sklearn.utils._testing \\","18","    import assert_almost_equal, assert_array_equal, assert_warns_message","185","","186","","187","def test_warning_bounds():","188","    kernel = RBF(length_scale_bounds=[1e-5, 1e-3])","189","    gpc = GaussianProcessClassifier(kernel=kernel)","190","    assert_warns_message(ConvergenceWarning, \"The optimal value found for \"","191","                                             \"dimension 0 of parameter \"","192","                                             \"length_scale is close to \"","193","                                             \"the specified upper bound \"","194","                                             \"0.001. Increasing the bound \"","195","                                             \"and calling fit again may \"","196","                                             \"find a better value.\",","197","                         gpc.fit, X, y)","198","","199","    kernel_sum = (WhiteKernel(noise_level_bounds=[1e-5, 1e-3]) +","200","                  RBF(length_scale_bounds=[1e3, 1e5]))","201","    gpc_sum = GaussianProcessClassifier(kernel=kernel_sum)","202","    with pytest.warns(None) as record:","203","        gpc_sum.fit(X, y)","204","","205","    assert len(record) == 2","206","    assert record[0].message.args[0] == (\"The optimal value found for \"","207","                                         \"dimension 0 of parameter \"","208","                                         \"k1__noise_level is close to the \"","209","                                         \"specified upper bound 0.001. \"","210","                                         \"Increasing the bound and calling \"","211","                                         \"fit again may find a better value.\")","212","","213","    assert record[1].message.args[0] == (\"The optimal value found for \"","214","                                         \"dimension 0 of parameter \"","215","                                         \"k2__length_scale is close to the \"","216","                                         \"specified lower bound 1000.0. \"","217","                                         \"Decreasing the bound and calling \"","218","                                         \"fit again may find a better value.\")","219","","220","    X_tile = np.tile(X, 2)","221","    kernel_dims = RBF(length_scale=[1., 2.],","222","                      length_scale_bounds=[1e1, 1e2])","223","    gpc_dims = GaussianProcessClassifier(kernel=kernel_dims)","224","","225","    with pytest.warns(None) as record:","226","        gpc_dims.fit(X_tile, y)","227","","228","    assert len(record) == 2","229","    assert record[0].message.args[0] == (\"The optimal value found for \"","230","                                         \"dimension 0 of parameter \"","231","                                         \"length_scale is close to the \"","232","                                         \"specified upper bound 100.0. \"","233","                                         \"Increasing the bound and calling \"","234","                                         \"fit again may find a better value.\")","235","","236","    assert record[1].message.args[0] == (\"The optimal value found for \"","237","                                         \"dimension 1 of parameter \"","238","                                         \"length_scale is close to the \"","239","                                         \"specified upper bound 100.0. \"","240","                                         \"Increasing the bound and calling \"","241","                                         \"fit again may find a better value.\")"],"delete":["12","from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C","15","from sklearn.utils._testing import assert_almost_equal, assert_array_equal"]}],"doc\/whats_new\/v0.23.rst":[{"add":["46",""],"delete":[]}],"sklearn\/gaussian_process\/tests\/test_gpr.py":[{"add":["18","from sklearn.exceptions import ConvergenceWarning","24","            assert_allclose, assert_warns_message)","470","","471","","472","def test_warning_bounds():","473","    kernel = RBF(length_scale_bounds=[1e-5, 1e-3])","474","    gpr = GaussianProcessRegressor(kernel=kernel)","475","    assert_warns_message(ConvergenceWarning, \"The optimal value found for \"","476","                                             \"dimension 0 of parameter \"","477","                                             \"length_scale is close to \"","478","                                             \"the specified upper bound \"","479","                                             \"0.001. Increasing the bound \"","480","                                             \"and calling fit again may \"","481","                                             \"find a better value.\",","482","                         gpr.fit, X, y)","483","","484","    kernel_sum = (WhiteKernel(noise_level_bounds=[1e-5, 1e-3]) +","485","                  RBF(length_scale_bounds=[1e3, 1e5]))","486","    gpr_sum = GaussianProcessRegressor(kernel=kernel_sum)","487","    with pytest.warns(None) as record:","488","        gpr_sum.fit(X, y)","489","","490","    assert len(record) == 2","491","    assert record[0].message.args[0] == (\"The optimal value found for \"","492","                                         \"dimension 0 of parameter \"","493","                                         \"k1__noise_level is close to the \"","494","                                         \"specified upper bound 0.001. \"","495","                                         \"Increasing the bound and calling \"","496","                                         \"fit again may find a better value.\")","497","","498","    assert record[1].message.args[0] == (\"The optimal value found for \"","499","                                         \"dimension 0 of parameter \"","500","                                         \"k2__length_scale is close to the \"","501","                                         \"specified lower bound 1000.0. \"","502","                                         \"Decreasing the bound and calling \"","503","                                         \"fit again may find a better value.\")","504","","505","    X_tile = np.tile(X, 2)","506","    kernel_dims = RBF(length_scale=[1., 2.],","507","                      length_scale_bounds=[1e1, 1e2])","508","    gpr_dims = GaussianProcessRegressor(kernel=kernel_dims)","509","","510","    with pytest.warns(None) as record:","511","        gpr_dims.fit(X_tile, y)","512","","513","    assert len(record) == 2","514","    assert record[0].message.args[0] == (\"The optimal value found for \"","515","                                         \"dimension 0 of parameter \"","516","                                         \"length_scale is close to the \"","517","                                         \"specified lower bound 10.0. \"","518","                                         \"Decreasing the bound and calling \"","519","                                         \"fit again may find a better value.\")","520","","521","    assert record[1].message.args[0] == (\"The optimal value found for \"","522","                                         \"dimension 1 of parameter \"","523","                                         \"length_scale is close to the \"","524","                                         \"specified lower bound 10.0. \"","525","                                         \"Decreasing the bound and calling \"","526","                                         \"fit again may find a better value.\")"],"delete":["23","            assert_allclose)"]}],"sklearn\/gaussian_process\/_gpr.py":[{"add":["253","            self.kernel_._check_bounds_params()","254",""],"delete":[]}],"doc\/whats_new\/v0.24.rst":[{"add":["149",":mod:`sklearn.gaussian_process`","150","...............................","151","","152","- |Enhancement| A new method","153","  :class:`gaussian_process.Kernel._check_bounds_params` is called after","154","  fitting a Gaussian Process and raises a ``ConvergenceWarning`` if the bounds","155","  of the hyperparameters are too tight.","156","  :issue:`12638` by :user:`Sylvain Lannuzel <SylvainLan>`","157",""],"delete":[]}]}},"042843a2ddf72441ac60234016b0e2b362ecc92c":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/preprocessing\/tests\/test_data.py":"MODIFY","sklearn\/preprocessing\/data.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["151","- |Fix| Fixed a bug in :class:`preprocessing.PowerTransformer` where the","152","  Yeo-Johnson transform was incorrect for lambda parameters outside of `[0, 2]`","153","  :issue:`12522` by :user:`Nicolas Hug<NicolasHug>`.","154",""],"delete":[]}],"sklearn\/preprocessing\/tests\/test_data.py":[{"add":["2347","def test_yeo_johnson_darwin_example():","2348","    # test from original paper \"A new family of power transformations to","2349","    # improve normality or symmetry\" by Yeo and Johnson.","2350","    X = [6.1, -8.4, 1.0, 2.0, 0.7, 2.9, 3.5, 5.1, 1.8, 3.6, 7.0, 3.0, 9.3,","2351","         7.5, -6.0]","2352","    X = np.array(X).reshape(-1, 1)","2353","    lmbda = PowerTransformer(method='yeo-johnson').fit(X).lambdas_","2354","    assert np.allclose(lmbda, 1.305, atol=1e-3)","2355","","2356",""],"delete":[]}],"sklearn\/preprocessing\/data.py":[{"add":["2539","    [ 1.38668178 -3.10053309]","2721","        x_inv = np.zeros_like(x)","2725","        if abs(lmbda) < np.spacing(1.):","2731","        if abs(lmbda - 2) > np.spacing(1.):","2744","        out = np.zeros_like(x)","2748","        if abs(lmbda) < np.spacing(1.):","2749","            out[pos] = np.log1p(x[pos])","2754","        if abs(lmbda - 2) > np.spacing(1.):","2757","            out[~pos] = -np.log1p(-x[~pos])","2786","            loglike = -n_samples \/ 2 * np.log(x_trans.var())","2787","            loglike += (lmbda - 1) * (np.sign(x) * np.log1p(np.abs(x))).sum()"],"delete":["2539","    [1.38668178e+00 5.93926346e-09]","2720","","2721","        Notes","2722","        -----","2723","        We're comparing lmbda to 1e-19 instead of strict equality to 0. See","2724","        scipy\/special\/_boxcox.pxd for a rationale behind this","2726","        x_inv = np.zeros(x.shape, dtype=x.dtype)","2730","        if lmbda < 1e-19:","2736","        if lmbda < 2 - 1e-19:","2747","","2748","        Notes","2749","        -----","2750","        We're comparing lmbda to 1e-19 instead of strict equality to 0. See","2751","        scipy\/special\/_boxcox.pxd for a rationale behind this","2754","        out = np.zeros(shape=x.shape, dtype=x.dtype)","2758","        if lmbda < 1e-19:","2759","            out[pos] = np.log(x[pos] + 1)","2764","        if lmbda < 2 - 1e-19:","2767","            out[~pos] = -np.log(-x[~pos] + 1)","2796","            # Estimated mean and variance of the normal distribution","2797","            est_mean = x_trans.sum() \/ n_samples","2798","            est_var = np.power(x_trans - est_mean, 2).sum() \/ n_samples","2799","","2800","            loglike = -n_samples \/ 2 * np.log(est_var)","2801","            loglike += (lmbda - 1) * (np.sign(x) * np.log(np.abs(x) + 1)).sum()"]}]}},"f6f7e3cfd365b39d4bc5a98cc8914c3a528477d6":{"changes":{"sklearn\/model_selection\/_validation.py":"MODIFY","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/model_selection\/tests\/test_validation.py":"MODIFY"},"diff":{"sklearn\/model_selection\/_validation.py":[{"add":["557","            for scorer_name in sorted(test_scores):","558","                msg += \", %s=\" % scorer_name","559","                if return_train_score:","560","                    msg += \"(train=%.3f,\" % train_scores[scorer_name]","561","                    msg += \" test=%.3f)\" % test_scores[scorer_name]","562","                else:","563","                    msg += \"%.3f\" % test_scores[scorer_name]","565","            msg += \", score=\"","566","            msg += (\"%.3f\" % test_scores if not return_train_score else","567","                    \"(train=%.3f, test=%.3f)\" % (train_scores, test_scores))","568",""],"delete":["506","","556","","559","            for scorer_name, score in test_scores.items():","560","                msg += \", %s=%s\" % (scorer_name, score)","562","            msg += \", score=%s\" % test_scores"]}],"doc\/whats_new\/v0.21.rst":[{"add":["83",":mod:`sklearn.model_selection`","84","......................","85","","86","- |Enhancement| Method :func:`_fit_and_score` now prints train_scores when","87","  `return_train_scores` is True and `verbose` > 2.","88","  :issue:`12613` by :user:`Marc Torrellas <marctorrellas>`.","89",""],"delete":[]}],"sklearn\/model_selection\/tests\/test_validation.py":[{"add":["31","from sklearn.model_selection import cross_val_score, ShuffleSplit","46","from sklearn.model_selection._validation import _score","1480","def test_fit_and_score_failing():","1540","","1541","","1542","def test_fit_and_score_working():","1543","    X, y = make_classification(n_samples=30, random_state=0)","1544","    clf = SVC(kernel=\"linear\", random_state=0)","1545","    train, test = next(ShuffleSplit().split(X))","1546","    # Test return_parameters option","1547","    fit_and_score_args = [clf, X, y, dict(), train, test, 0]","1548","    fit_and_score_kwargs = {'parameters': {'max_iter': 100, 'tol': 0.1},","1549","                            'fit_params': None,","1550","                            'return_parameters': True}","1551","    result = _fit_and_score(*fit_and_score_args,","1552","                            **fit_and_score_kwargs)","1553","    assert result[-1] == fit_and_score_kwargs['parameters']","1554","","1555","","1556","def three_params_scorer(i, j, k):","1557","    return 3.4213","1558","","1559","","1560","@pytest.mark.parametrize(\"return_train_score, scorer, expected\", [","1561","    (False, three_params_scorer,","1562","     \"[CV] .................................... , score=3.421, total=   0.0s\"),","1563","    (True, three_params_scorer,","1564","     \"[CV] ................ , score=(train=3.421, test=3.421), total=   0.0s\"),","1565","    (True, {'sc1': three_params_scorer, 'sc2': three_params_scorer},","1566","     \"[CV]  , sc1=(train=3.421, test=3.421)\"","1567","     \", sc2=(train=3.421, test=3.421), total=   0.0s\")","1568","])","1569","def test_fit_and_score_verbosity(capsys, return_train_score, scorer, expected):","1570","    X, y = make_classification(n_samples=30, random_state=0)","1571","    clf = SVC(kernel=\"linear\", random_state=0)","1572","    train, test = next(ShuffleSplit().split(X))","1573","","1574","    # test print without train score","1575","    fit_and_score_args = [clf, X, y, scorer, train, test, 10, None, None]","1576","    fit_and_score_kwargs = {'return_train_score': return_train_score}","1577","    _fit_and_score(*fit_and_score_args, **fit_and_score_kwargs)","1578","    out, _ = capsys.readouterr()","1579","    assert out.split('\\n')[1] == expected","1580","","1581","","1582","def test_score():","1583","    error_message = \"scoring must return a number, got None\"","1584","","1585","    def two_params_scorer(estimator, X_test):","1586","        return None","1587","    fit_and_score_args = [None, None, None, two_params_scorer]","1588","    assert_raise_message(ValueError, error_message,","1589","                         _score, *fit_and_score_args)"],"delete":["31","from sklearn.model_selection import cross_val_score","1479","def test_fit_and_score():"]}]}},"7f5aa85db6ce8a0204c9efc996a3c03378a94b15":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/neighbors\/dist_metrics.pyx":"MODIFY","sklearn\/neighbors\/tests\/test_dist_metrics.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["14","Changed models","15","--------------","16","","17","The following estimators and functions, when fit with the same data and","18","parameters, may produce different models from the previous version. This often","19","occurs due to changes in the modelling logic (bug fixes or enhancements), or in","20","random sampling procedures.","21","","22","- :mod:`sklearn.neighbors` when ``metric=='jaccard'`` (bug fix)","23","","34",":mod:`sklearn.neighbors`","35","........................","36","","37","- |Fix| Fixed :class:`sklearn.neighbors.DistanceMetric` jaccard distance","38","  function to return 0 when two all-zero vectors are compared.","39","  :issue:`12685` by :user:`Thomas Fan <thomasjpfan>`."],"delete":[]}],"sklearn\/neighbors\/dist_metrics.pyx":[{"add":["790","        # Based on https:\/\/github.com\/scipy\/scipy\/pull\/7373","791","        # When comparing two all-zero vectors, scipy>=1.2.0 jaccard metric","792","        # was changed to return 0, instead of nan.","793","        if nnz == 0:","794","            return 0"],"delete":[]}],"sklearn\/neighbors\/tests\/test_dist_metrics.py":[{"add":["8","from distutils.version import LooseVersion","9","from scipy import __version__ as scipy_version","105","    # Based on https:\/\/github.com\/scipy\/scipy\/pull\/7373","106","    # When comparing two all-zero vectors, scipy>=1.2.0 jaccard metric","107","    # was changed to return 0, instead of nan.","108","    if metric == 'jaccard' and LooseVersion(scipy_version) < '1.2.0':","109","        D_true[np.isnan(D_true)] = 0"],"delete":[]}]}},"2e98a9ca8d3549c7bf2a654590f2b9e76807253e":{"changes":{"sklearn\/decomposition\/tests\/test_pca.py":"MODIFY"},"diff":{"sklearn\/decomposition\/tests\/test_pca.py":[{"add":["723","    # decimal=5 fails on mac with scipy = 1.1.0","725","                              decimal=4)"],"delete":["724","                              decimal=5)"]}]}},"774ae893065d6c166d1eb32b8c8ca28b69520742":{"changes":{"sklearn\/feature_extraction\/tests\/test_image.py":"MODIFY","sklearn\/semi_supervised\/tests\/test_label_propagation.py":"MODIFY","sklearn\/cluster\/birch.py":"MODIFY"},"diff":{"sklearn\/feature_extraction\/tests\/test_image.py":[{"add":["306","        last_patch_slices = tuple(slice(i, i + j, None) for i, j in","307","                                  zip(last_patch, patch_size))","308","        assert_true((patches[(-1, None, None) * ndim] =="],"delete":["306","        last_patch_slices = [slice(i, i + j, None) for i, j in","307","                             zip(last_patch, patch_size)]","308","        assert_true((patches[[slice(-1, None, None)] * ndim] =="]}],"sklearn\/semi_supervised\/tests\/test_label_propagation.py":[{"add":["115","    Tuu = T_bar[tuple(np.meshgrid(unlabelled_idx, unlabelled_idx,","116","                      indexing='ij'))]","117","    Tul = T_bar[tuple(np.meshgrid(unlabelled_idx, labelled_idx,","118","                                  indexing='ij'))]"],"delete":["115","    Tuu = T_bar[np.meshgrid(unlabelled_idx, unlabelled_idx, indexing='ij')]","116","    Tul = T_bar[np.meshgrid(unlabelled_idx, labelled_idx, indexing='ij')]"]}],"sklearn\/cluster\/birch.py":[{"add":["76","    node1_dist, node2_dist = dist[(farthest_idx,)]"],"delete":["76","    node1_dist, node2_dist = dist[[farthest_idx]]"]}]}},"afa0694d129e6f04d61073131ac75c84ef038f7b":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/datasets\/tests\/test_openml.py":"MODIFY","sklearn\/datasets\/openml.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["39","- |Fix| :func:`dataset.fetch_openml` to correctly use the local cache.","40","  :issue:`12246` by :user:`Jan N. van Rijn <janvanrijn>`.","41",""],"delete":[]}],"sklearn\/datasets\/tests\/test_openml.py":[{"add":["14","                                     _download_data_arff,","15","                                     _get_local_path)","80","    # Please note that cache=False is crucial, as the monkey patched files are","81","    # not consistent with reality","143","    # monkey patches the urlopen function. Important note: Do NOT use this","144","    # in combination with a regular cache directory, as the files that are","145","    # stored as cache should not be mixed up with real openml datasets","461","def test_open_openml_url_cache(monkeypatch, gzip_response, tmpdir):","467","    cache_directory = str(tmpdir.mkdir('scikit_learn_data'))","469","    response1 = _open_openml_url(openml_path, cache_directory)","471","    location = _get_local_path(openml_path, cache_directory)","474","    response2 = _open_openml_url(openml_path, cache_directory)","479","def test_fetch_openml_cache(monkeypatch, gzip_response, tmpdir):","480","    def _mock_urlopen_raise(request):","481","        raise ValueError('This mechanism intends to test correct cache'","482","                         'handling. As such, urlopen should never be '","483","                         'accessed. URL: %s' % request.get_full_url())","484","    data_id = 2","485","    cache_directory = str(tmpdir.mkdir('scikit_learn_data'))","486","    _monkey_patch_webbased_functions(","487","        monkeypatch, data_id, gzip_response)","488","    X_fetched, y_fetched = fetch_openml(data_id=data_id, cache=True,","489","                                        data_home=cache_directory,","490","                                        return_X_y=True)","491","","492","    monkeypatch.setattr(sklearn.datasets.openml, 'urlopen',","493","                        _mock_urlopen_raise)","494","","495","    X_cached, y_cached = fetch_openml(data_id=data_id, cache=True,","496","                                      data_home=cache_directory,","497","                                      return_X_y=True)","498","    np.testing.assert_array_equal(X_fetched, X_cached)","499","    np.testing.assert_array_equal(y_fetched, y_cached)","500","","501","","502","@pytest.mark.parametrize('gzip_response', [True, False])"],"delete":["14","                                     _download_data_arff)","455","def test_open_openml_url_cache(monkeypatch, gzip_response):","461","    test_directory = os.path.join(os.path.expanduser('~'), 'scikit_learn_data')","463","    response1 = _open_openml_url(openml_path, test_directory)","465","    location = os.path.join(test_directory, 'openml.org', openml_path + '.gz')","468","    response2 = _open_openml_url(openml_path, test_directory)"]}],"sklearn\/datasets\/openml.py":[{"add":["33","def _get_local_path(openml_path, data_home):","34","    return os.path.join(data_home, 'openml.org', openml_path + \".gz\")","35","","36","","56","    def is_gzip(_fsrc):","57","        return _fsrc.info().get('Content-Encoding', '') == 'gzip'","58","","63","        fsrc = urlopen(req)","64","        if is_gzip(fsrc):","70","    local_path = _get_local_path(openml_path, data_home)","72","        fsrc = urlopen(req)","80","            if is_gzip(fsrc):","81","                with open(local_path, 'wb') as fdst:","82","                    shutil.copyfileobj(fsrc, fdst)","83","                    fsrc.close()","84","            else:","85","                with gzip.GzipFile(local_path, 'wb') as fdst:","86","                    shutil.copyfileobj(fsrc, fdst)","87","                    fsrc.close()","91","","92","    # XXX: First time, decompression will not be necessary (by using fsrc), but","93","    # it will happen nonetheless","94","    return gzip.GzipFile(local_path, 'rb')"],"delete":["54","    fsrc = urlopen(req)","55","    is_gzip = fsrc.info().get('Content-Encoding', '') == 'gzip'","58","        if is_gzip:","64","    local_path = os.path.join(data_home, 'openml.org', openml_path + \".gz\")","73","            with open(local_path, 'wb') as fdst:","74","                shutil.copyfileobj(fsrc, fdst)","75","                fsrc.close()","79","    # XXX: unnecessary decompression on first access","80","    if is_gzip:","81","        return gzip.GzipFile(local_path, 'rb')","82","    return fsrc"]}]}},"eb36c28fd9a5735f597502bae7e1a029408c6cf1":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/feature_extraction\/text.py":"MODIFY","sklearn\/feature_extraction\/tests\/test_text.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["87",":mod:`sklearn.feature_extraction`","88","...........................","89","","90","- |Fix| Fixed a regression in v0.20.0 where","91","  :func:`feature_extraction.text.CountVectorizer` and other text vectorizers","92","  could error during stop words validation with custom preprocessors","93","  or tokenizers. :issue:`12393` by `Roman Yurchak`_.","94",""],"delete":[]}],"sklearn\/feature_extraction\/text.py":[{"add":["272","        \"\"\"Check if stop words are consistent","273","","274","        Returns","275","        -------","276","        is_consistent : True if stop words are consistent with the preprocessor","277","                        and tokenizer, False if they are not, None if the check","278","                        was previously performed, \"error\" if it could not be","279","                        performed (e.g. because of the use of a custom","280","                        preprocessor \/ tokenizer)","281","        \"\"\"","282","        if id(self.stop_words) == getattr(self, '_stop_words_id', None):","283","            # Stop words are were previously validated","284","            return None","285","","287","        try:","297","                warnings.warn('Your stop_words may be inconsistent with '","298","                              'your preprocessing. Tokenizing the stop '","299","                              'words generated tokens %r not in '","300","                              'stop_words.' % sorted(inconsistent))","301","            return not inconsistent","302","        except Exception:","303","            # Failed to check stop words consistency (e.g. because a custom","304","            # preprocessor or tokenizer was used)","305","            self._stop_words_id = id(self.stop_words)","306","            return 'error'"],"delete":["273","        if id(self.stop_words) != getattr(self, '_stop_words_id', None):","283","                warnings.warn('Your stop_words may be inconsistent with your '","284","                              'preprocessing. Tokenizing the stop words '","285","                              'generated tokens %r not in stop_words.' %","286","                              sorted(inconsistent))"]}],"sklearn\/feature_extraction\/tests\/test_text.py":[{"add":["1","import re","1124","def _check_stop_words_consistency(estimator):","1125","    stop_words = estimator.get_stop_words()","1126","    tokenize = estimator.build_tokenizer()","1127","    preprocess = estimator.build_preprocessor()","1128","    return estimator._check_stop_words_consistency(stop_words, preprocess,","1129","                                                   tokenize)","1130","","1131","","1146","        # reset stop word validation","1147","        del vec._stop_words_id","1148","        assert _check_stop_words_consistency(vec) is False","1152","    assert _check_stop_words_consistency(vec) is None","1158","","1159","","1160","@fails_if_pypy","1161","@pytest.mark.parametrize('Estimator',","1162","                         [CountVectorizer, TfidfVectorizer, HashingVectorizer])","1163","def test_stop_word_validation_custom_preprocessor(Estimator):","1164","    data = [{'text': 'some text'}]","1165","","1166","    vec = Estimator()","1167","    assert _check_stop_words_consistency(vec) is True","1168","","1169","    vec = Estimator(preprocessor=lambda x: x['text'],","1170","                    stop_words=['and'])","1171","    assert _check_stop_words_consistency(vec) == 'error'","1172","    # checks are cached","1173","    assert _check_stop_words_consistency(vec) is None","1174","    vec.fit_transform(data)","1175","","1176","    class CustomEstimator(Estimator):","1177","        def build_preprocessor(self):","1178","            return lambda x: x['text']","1179","","1180","    vec = CustomEstimator(stop_words=['and'])","1181","    assert _check_stop_words_consistency(vec) == 'error'","1182","","1183","    vec = Estimator(tokenizer=lambda doc: re.compile(r'\\w{1,}')","1184","                                            .findall(doc),","1185","                    stop_words=['and'])","1186","    assert _check_stop_words_consistency(vec) is True"],"delete":[]}]}},"3c76b9c425048552a1850582bdc064baa1438185":{"changes":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":"MODIFY","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/linear_model\/coordinate_descent.py":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":[{"add":["820","","821","","822","def test_warm_start_multitask_lasso():","823","    X, y, X_test, y_test = build_dataset()","824","    Y = np.c_[y, y]","825","    clf = MultiTaskLasso(alpha=0.1, max_iter=5, warm_start=True)","826","    ignore_warnings(clf.fit)(X, Y)","827","    ignore_warnings(clf.fit)(X, Y)  # do a second round with 5 iterations","828","","829","    clf2 = MultiTaskLasso(alpha=0.1, max_iter=10)","830","    ignore_warnings(clf2.fit)(X, Y)","831","    assert_array_almost_equal(clf2.coef_, clf.coef_)"],"delete":[]}],"doc\/whats_new\/v0.21.rst":[{"add":["42",":mod:`sklearn.linear_model`","43","...........................","44","- |Fix| Fixed a bug in :class:`linear_model.MultiTaskElasticNet` which was breaking","45","  ``MultiTaskElasticNet`` and ``MultiTaskLasso`` when ``warm_start = True``. :issue:`12360`","46","  by :user:`Aakanksha Joshi <joaak>`.","47",""],"delete":[]}],"sklearn\/linear_model\/coordinate_descent.py":[{"add":["1797","        if not self.warm_start or not hasattr(self, \"coef_\"):"],"delete":["1797","        if not self.warm_start or self.coef_ is None:"]}]}},"dfdf605f67605cc2638d49b51c0dcb177813b3b5":{"changes":{"sklearn\/preprocessing\/_encoders.py":"MODIFY","sklearn\/preprocessing\/tests\/test_encoders.py":"MODIFY"},"diff":{"sklearn\/preprocessing\/_encoders.py":[{"add":["12","from .. import get_config as _get_config","17","from ..utils.fixes import _argmax, _object_dtype_isnan","40","    def _check_X(self, X):","41","        \"\"\"","42","        Perform custom check_array:","43","        - convert list of strings to object dtype","44","        - check for missing values for object dtype data (check_array does","45","          not do that)","47","        \"\"\"","54","        if X.dtype == np.dtype('object'):","55","            if not _get_config()['assume_finite']:","56","                if _object_dtype_isnan(X).any():","57","                    raise ValueError(\"Input contains NaN\")","58","","59","        return X","60","","61","    def _fit(self, X, handle_unknown='error'):","62","        X = self._check_X(X)","63","","93","        X = self._check_X(X)"],"delete":["16","from ..utils.fixes import _argmax","39","    def _fit(self, X, handle_unknown='error'):","76","","77","        X_temp = check_array(X, dtype=None)","78","        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):","79","            X = check_array(X, dtype=np.object)","80","        else:","81","            X = X_temp"]}],"sklearn\/preprocessing\/tests\/test_encoders.py":[{"add":["499","@pytest.mark.parametrize(\"X\", [np.array([[1, np.nan]]).T,","500","                               np.array([['a', np.nan]], dtype=object).T],","501","                         ids=['numeric', 'object'])","502","@pytest.mark.parametrize(\"handle_unknown\", ['error', 'ignore'])","503","def test_one_hot_encoder_raise_missing(X, handle_unknown):","504","    ohe = OneHotEncoder(categories='auto', handle_unknown=handle_unknown)","505","","506","    with pytest.raises(ValueError, match=\"Input contains NaN\"):","507","        ohe.fit(X)","508","","509","    with pytest.raises(ValueError, match=\"Input contains NaN\"):","510","        ohe.fit_transform(X)","511","","512","    ohe.fit(X[:1, :])","513","","514","    with pytest.raises(ValueError, match=\"Input contains NaN\"):","515","        ohe.transform(X)","516","","517","","545","@pytest.mark.parametrize(\"X\", [np.array([[1, np.nan]]).T,","546","                               np.array([['a', np.nan]], dtype=object).T],","547","                         ids=['numeric', 'object'])","548","def test_ordinal_encoder_raise_missing(X):","549","    ohe = OrdinalEncoder()","550","","551","    with pytest.raises(ValueError, match=\"Input contains NaN\"):","552","        ohe.fit(X)","553","","554","    with pytest.raises(ValueError, match=\"Input contains NaN\"):","555","        ohe.fit_transform(X)","556","","557","    ohe.fit(X[:1, :])","558","","559","    with pytest.raises(ValueError, match=\"Input contains NaN\"):","560","        ohe.transform(X)","561","","562",""],"delete":[]}]}},"6e9776329805868462955e8e2d832750ab513ec4":{"changes":{"sklearn\/linear_model\/stochastic_gradient.py":"MODIFY"},"diff":{"sklearn\/linear_model\/stochastic_gradient.py":[{"add":["320","    Returns y, coef, intercept, average_coef, average_intercept."],"delete":["320","    Returns y, coef, intercept."]}]}},"4223633b0d64c75fef1230f66cfb1d50fb5a8d04":{"changes":{"sklearn\/calibration.py":"MODIFY"},"diff":{"sklearn\/calibration.py":[{"add":["16","from scipy.special import expit","445","        P = expit(-(AB[0] * F + AB[1]))","519","        return expit(-(self.a_ * T + self.b_))"],"delete":["444","        E = np.exp(AB[0] * F + AB[1])","445","        P = 1. \/ (1. + E)","519","        return 1. \/ (1. + np.exp(self.a_ * T + self.b_))"]}]}},"3282d43ccc90b887c7567e28606b516e60221281":{"changes":{"sklearn\/datasets\/tests\/data\/openml\/1\/data-v1-download-1.arff.gz":"ADD","sklearn\/datasets\/tests\/test_openml.py":"MODIFY","sklearn\/datasets\/tests\/data\/openml\/1\/api-v1-json-data-1.json.gz":"ADD","sklearn\/datasets\/tests\/data\/openml\/1\/api-v1-json-data-features-1.json.gz":"ADD","sklearn\/datasets\/openml.py":"MODIFY","sklearn\/datasets\/tests\/data\/openml\/3\/api-v1-json-data-3.json.gz":"ADD","sklearn\/datasets\/tests\/data\/openml\/3\/api-v1-json-data-features-3.json.gz":"ADD","sklearn\/datasets\/tests\/data\/openml\/3\/data-v1-download-3.arff.gz":"ADD"},"diff":{"sklearn\/datasets\/tests\/data\/openml\/1\/data-v1-download-1.arff.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/test_openml.py":[{"add":["610","def test_dataset_with_openml_error(monkeypatch, gzip_response):","611","    data_id = 1","612","    _monkey_patch_webbased_functions(monkeypatch, data_id, gzip_response)","613","    assert_warns_message(","614","        UserWarning,","615","        \"OpenML registered a problem with the dataset. It might be unusable. \"","616","        \"Error:\",","617","        fetch_openml, data_id=data_id, cache=False","618","    )","619","","620","","621","@pytest.mark.parametrize('gzip_response', [True, False])","622","def test_dataset_with_openml_warning(monkeypatch, gzip_response):","623","    data_id = 3","624","    _monkey_patch_webbased_functions(monkeypatch, data_id, gzip_response)","625","    assert_warns_message(","626","        UserWarning,","627","        \"OpenML raised a warning on the dataset. It might be unusable. \"","628","        \"Warning:\",","629","        fetch_openml, data_id=data_id, cache=False","630","    )","631","","632","","633","@pytest.mark.parametrize('gzip_response', [True, False])"],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/1\/api-v1-json-data-1.json.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/1\/api-v1-json-data-features-1.json.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/openml.py":[{"add":["513","    if 'error' in data_description:","514","        warn(\"OpenML registered a problem with the dataset. It might be \"","515","             \"unusable. Error: {}\".format(data_description['error']))","516","    if 'warning' in data_description:","517","        warn(\"OpenML raised a warning on the dataset. It might be \"","518","             \"unusable. Warning: {}\".format(data_description['warning']))"],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/3\/api-v1-json-data-3.json.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/3\/api-v1-json-data-features-3.json.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/3\/data-v1-download-3.arff.gz":[{"add":[],"delete":[]}]}},"02dc9ed680e7f53f1b0d410dcdd37341c7958eb1":{"changes":{"doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/ensemble\/tests\/test_forest.py":"MODIFY","sklearn\/tree\/_tree.pyx":"MODIFY","sklearn\/ensemble\/tests\/test_gradient_boosting.py":"MODIFY","sklearn\/tree\/tests\/test_tree.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.21.rst":[{"add":["20","- Decision trees and derived ensembles when both `max_depth` and","21","  `max_leaf_nodes` are set. (bug fix)","129","- |Fix| Fixed an issue with :class:`tree.BaseDecisionTree`","130","  and consequently all estimators based","131","  on it, including :class:`tree.DecisionTreeClassifier`,","132","  :class:`tree.DecisionTreeRegressor`, :class:`tree.ExtraTreeClassifier`,","133","  and :class:`tree.ExtraTreeRegressor`, where they used to exceed the given","134","  ``max_depth`` by 1 while expanding the tree if ``max_leaf_nodes`` and","135","  ``max_depth`` were both specified by the user. Please note that this also","136","  affects all ensemble methods using decision trees.","137","  :pr:`12344` by :user:`Adrin Jalali <adrinjalali>`.","138","","139",""],"delete":[]}],"sklearn\/ensemble\/tests\/test_forest.py":[{"add":["713","    assert_equal(est.estimators_[0].get_depth(), 1)","717","    assert_equal(est.estimators_[0].get_depth(), 1)"],"delete":["713","    assert_greater(est.estimators_[0].tree_.max_depth, 1)","717","    assert_equal(est.estimators_[0].tree_.max_depth, 1)"]}],"sklearn\/tree\/_tree.pyx":[{"add":["452","        is_leaf = (depth >= self.max_depth or"],"delete":["452","        is_leaf = (depth > self.max_depth or"]}],"sklearn\/ensemble\/tests\/test_gradient_boosting.py":[{"add":["1105","    assert_equal(tree.max_depth, 1)"],"delete":["1105","    assert_greater(tree.max_depth, 1)"]}],"sklearn\/tree\/tests\/test_tree.py":[{"add":["1233","        assert_equal(est.get_depth(), 1)"],"delete":["1212","    from sklearn.tree._tree import TREE_LEAF","1234","        assert_greater(est.get_depth(), 1)"]}]}},"fe35e253aeb37057af9ae242700fd5c2e6f20c25":{"changes":{"sklearn\/linear_model\/tests\/test_logistic.py":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_logistic.py":[{"add":["1167","@pytest.mark.parametrize(\"random_seed\", [42])","1168","@pytest.mark.parametrize(\"penalty\", [\"l1\", \"l2\"])","1169","def test_logistic_regression_cv_refit(random_seed, penalty):","1170","    # Test that when refit=True, logistic regression cv with the saga solver","1171","    # converges to the same solution as logistic regression with a fixed","1172","    # regularization parameter.","1173","    # Internally the LogisticRegressionCV model uses a warm start to refit on","1174","    # the full data model with the optimal C found by CV. As the penalized","1175","    # logistic regression loss is convex, we should still recover exactly","1176","    # the same solution as long as the stopping criterion is strict enough (and","1177","    # that there are no exactly duplicated features when penalty='l1').","1178","    X, y = make_classification(n_samples=50, n_features=20,","1179","                               random_state=random_seed)","1180","    common_params = dict(","1181","        solver='saga',","1182","        penalty=penalty,","1183","        random_state=random_seed,","1184","        max_iter=10000,","1185","        tol=1e-12,","1186","    )","1187","    lr_cv = LogisticRegressionCV(Cs=[1.0], refit=True, **common_params)","1189","    lr = LogisticRegression(C=1.0, **common_params)","1191","    assert_array_almost_equal(lr_cv.coef_, lr.coef_)"],"delete":["1167","def test_logreg_cv_penalty():","1168","    # Test that the correct penalty is passed to the final fit.","1169","    X, y = make_classification(n_samples=50, n_features=20, random_state=0)","1170","    lr_cv = LogisticRegressionCV(penalty=\"l1\", Cs=[1.0], solver='saga')","1172","    lr = LogisticRegression(penalty=\"l1\", C=1.0, solver='saga')","1174","    assert_equal(np.count_nonzero(lr_cv.coef_), np.count_nonzero(lr.coef_))"]}]}},"2afee939df90e92e7dcde7d738c5be5f5611dae0":{"changes":{"sklearn\/preprocessing\/_encoders.py":"MODIFY","sklearn\/preprocessing\/tests\/test_encoders.py":"MODIFY"},"diff":{"sklearn\/preprocessing\/_encoders.py":[{"add":["383","                # Set categories_ to empty list if no categorical columns exist","384","                n_features = X.shape[1]","385","                sel = np.zeros(n_features, dtype=bool)","386","                sel[np.asarray(self.categorical_features)] = True","387","                if sum(sel) == 0:","388","                    self.categories_ = []","597","        check_is_fitted(self, 'categories_')","690","        elif len(input_features) != len(self.categories_):"],"delete":["23","","26","","685","        elif(len(input_features) != len(self.categories_)):"]}],"sklearn\/preprocessing\/tests\/test_encoders.py":[{"add":["9","from sklearn.exceptions import NotFittedError","253","def test_one_hot_encoder_not_fitted():","254","    X = np.array([['a'], ['b']])","255","    enc = OneHotEncoder(categories=['a', 'b'])","256","    msg = (\"This OneHotEncoder instance is not fitted yet. \"","257","           \"Call 'fit' with appropriate arguments before using this method.\")","258","    with pytest.raises(NotFittedError, match=msg):","259","        enc.transform(X)","260","","261","","262","def test_one_hot_encoder_no_categorical_features():","263","    X = np.array([[3, 2, 1], [0, 1, 1]], dtype='float64')","264","","265","    cat = [False, False, False]","266","    enc = OneHotEncoder(categorical_features=cat)","267","    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):","268","        X_tr = enc.fit_transform(X)","269","    expected_features = np.array(list(), dtype='object')","270","    assert_array_equal(X, X_tr)","271","    assert_array_equal(enc.get_feature_names(), expected_features)","272","    assert enc.categories_ == []","273","","274",""],"delete":[]}]}},"fc2503f80f74e788df8f6a2df8cf1abe643c0d59":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","doc\/themes\/scikit-learn\/static\/css\/bootstrap.css":"MODIFY","doc\/whats_new\/_contributors.rst":"MODIFY","doc\/themes\/scikit-learn\/static\/css\/bootstrap.min.css":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["52","Sorry if your contribution didn't make it into the highlights. There's a lot","53","here...","54","","64","- :class:`decomposition.SparsePCA` (bug fix)","65","- :class:`ensemble.gradient_boosting.GradientBoostingClassifier` (bug fix affecting feature importances)","68","- :class:`linear_model.LogisticRegressionCV` (bug fix)","73","- :class:`linear_model.SGDClassifier` (bug fix)","74","- :class:`linear_model.SGDRegressor` (bug fix)","75","- :class:`metrics.roc_auc_score` (bug fix)","76","- :class:`metrics.roc_curve` (bug fix)","77","- :class:`neural_network.BaseMultilayerPerceptron` (bug fix)","78","- :class:`neural_network.MLPClassifier` (bug fix)","79","- :class:`neural_network.MLPRegressor` (bug fix)","94",".. rubric:: :mod:`sklearn.cluster`:","96","- |MajorFeature| A new clustering algorithm: :class:`cluster.OPTICS`: an","97","  algoritm related to :class:`cluster.DBSCAN`, that has hyperparameters easier","98","  to set and tat scales better, by :user:`Shane <espg>`.","100","- |MajorFeature| :class:`cluster.AgglomerativeClustering` now supports Single","101","  Linkage clustering via ``linkage='single'``. :issue:`9372` by :user:`Leland","102","  McInnes <lmcinnes>` and :user:`Steve Astels <sastels>`.","103","","104","- |Feature| :class:`cluster.KMeans` and :class:`cluster.MiniBatchKMeans` now support","105","  sample weights via new parameter ``sample_weight`` in ``fit`` function.","106","  :issue:`10933` by :user:`Johannes Hansen <jnhansen>`.","107","","108","- |Efficiency| :class:`cluster.KMeans`, :class:`cluster.MiniBatchKMeans` and","109","  :func:`cluster.k_means` passed with ``algorithm='full'`` now enforces","110","  row-major ordering, improving runtime.","111","  :issue:`10471` by :user:`Gaurav Dhingra <gxyd>`.","112","","113","- |Efficiency| :class:`cluster.DBSCAN` now is parallelized according to ``n_jobs``","114","  regardless of ``algorithm``.","115","  :issue:`8003` by :user:`Jo?l Billaud <recamshak>`.","116","","117","- |Enhancement| :class:`cluster.KMeans` now gives a warning, if the number of","118","  distinct clusters found is smaller than ``n_clusters``. This may occur when","119","  the number of distinct points in the data set is actually smaller than the","120","  number of cluster one is looking for.","121","  :issue:`10059` by :user:`Christian Braune <christianbraune79>`.","122","","123","- |Fix| Fixed a bug where the ``fit`` method of","124","  :class:`cluster.AffinityPropagation` stored cluster","125","  centers as 3d array instead of 2d array in case of non-convergence. For the","126","  same class, fixed undefined and arbitrary behavior in case of training data","127","  where all samples had equal similarity.","128","  :issue:`9612`. By :user:`Jonatan Samoocha <jsamoocha>`.","129","","130","- |Fix| Fixed a bug in :func:`cluster.spectral_clustering` where the normalization of","131","  the spectrum was using a division instead of a multiplication. :issue:`8129`","132","  by :user:`Jan Margeta <jmargeta>`, :user:`Guillaume Lemaitre <glemaitre>`,","133","  and :user:`Devansh D. <devanshdalal>`.","134","","135","- |Fix| Fixed a bug in :func:`cluster.k_means_elkan` where the returned","136","  `iteration` was 1 less than the correct value. Also added the missing","137","  `n_iter_` attribute in the docstring of :class:`cluster.KMeans`.","138","  :issue:`11353` by :user:`Jeremie du Boisberranger <jeremiedbb>`.","139","","140","- |API| Deprecate ``pooling_func`` unused parameter in","141","  :class:`cluster.AgglomerativeClustering`.","142","  :issue:`9875` by :user:`Kumar Ashutosh <thechargedneutron>`.","143","","144",".. rubric:: :mod:`sklearn.compose`:","145","","146","- New module.","147","","148","- |MajorFeature| Added :class:`compose.ColumnTransformer`, which allows to","149","  apply different transformers to different columns of arrays or pandas","150","  DataFrames. :issue:`9012` by `Andreas M¨¹ller`_ and `Joris Van den Bossche`_,","151","  and :issue:`11315` by :user:`Thomas Fan <thomasjpfan>`.","152","","153","- |MajorFeature| Added the :class:`compose.TransformedTargetRegressor` which","154","  transforms the target y before fitting a regression model. The predictions","155","  are mapped back to the original space via an inverse transform. :issue:`9041`","156","  by `Andreas M¨¹ller`_ and :user:`Guillaume Lemaitre <glemaitre>`.","157","","158",".. rubric:: :mod:`sklearn.covariance`:","159","","160","- |API| The :func:`covariance.graph_lasso`,","161","  :class:`covariance.GraphLasso` and :class:`covariance.GraphLassoCV` have been","162","  renamed to :func:`covariance.graphical_lasso`,","163","  :class:`covariance.GraphicalLasso` and :class:`covariance.GraphicalLassoCV`","164","  respectively and will be removed in version 0.22.","165","  :issue:`9993` by :user:`Artiem Krinitsyn <artiemq>`","166","","167",".. rubric:: :mod:`sklearn.datasets`:","168","","169","- |Feature| In :func:`datasets.make_blobs`, one can now pass a list to the","170","  `n_samples` parameter to indicate the number of samples to generate per","171","  cluster.  :issue:`8617` by :user:`Maskani Filali Mohamed <maskani-moh>` and","172","  :user:`Konstantinos Katrioplas <kkatrio>`.","173","","174","- |Feature| Add ``filename`` attribute to :mod:`datasets` that have a CSV file.","175","  :issue:`9101` by :user:`alex-33 <alex-33>`","176","  and :user:`Maskani Filali Mohamed <maskani-moh>`.","177","","178","- |Fix| Fixed a bug in :func:`datasets.load_boston` which had a wrong data","179","  point.  :issue:`10801` by :user:`Takeshi Yoshizawa <tarcusx>`.","180","","181","- |Fix| Fixed a bug in :func:`datasets.load_iris` which had two wrong data points.","182","  :issue:`11082` by :user:`Sadhana Srinivasan <rotuna>`","183","  and :user:`Hanmin Qin <qinhanmin2014>`.","184","","185","- |Fix| Fixed a bug in :func:`datasets.fetch_kddcup99`, where data were not","186","  properly shuffled. :issue:`9731` by `Nicolas Goix`_.","187","","188","- |Fix| Fixed a bug in :func:`datasets.make_circles`, where no odd number of","189","  data points could be generated. :issue:`10037` by :user:`Christian Braune","190","  <christianbraune79>`.","191","","192",".. rubric:: :mod:`sklearn.decomposition`:","193","","194","- |Feature| :func:`decomposition.dict_learning` functions and models now","195","  support positivity constraints.  This applies to the dictionary and sparse","196","  code.  :issue:`6374` by :user:`John Kirkham <jakirkham>`.","197","","198","- |Feature| |Fix| :class:`decomposition.SparsePCA` now exposes","199","  ``normalize_components``. When set to True, the train and test data are","200","  centered with the train mean repsectively during the fit phase and the","201","  transform phase. This fixes the behavior of SparsePCA. When set to False,","202","  which is the default, the previous abnormal behaviour still holds. The False","203","  value is for backward compatibility and should not be used.  :issue:`11585`","204","  by :user:`Ivan Panico <FollowKenny>`.","205","","206","- |Fix| Fix for uninformative error in :class:`decomposition.IncrementalPCA`:","207","  now an error is raised if the number of components is larger than the","208","  chosen batch size. The ``n_components=None`` case was adapted accordingly.","209","  :issue:`6452`. By :user:`Wally Gauze <wallygauze>`.","210","","211","- |Fix| Fixed a bug where the ``partial_fit`` method of","212","  :class:`decomposition.IncrementalPCA` used integer division instead of float","213","  division on Python 2.","214","  :issue:`9492` by :user:`James Bourbeau <jrbourbeau>`.","215","","216","- |Fix| In :class:`decomposition.PCA` selecting a n_components parameter greater","217","  than the number of samples now raises an error.  Similarly, the","218","  ``n_components=None`` case now selects the minimum of n_samples and","219","  n_features.","220","  :issue:`8484` by :user:`Wally Gauze <wallygauze>`.","221","","222","- |Fix| Fixed a bug in :class:`decomposition.PCA` where users will get","223","  unexpected error with large datasets when ``n_components='mle'`` on Python 3","224","  versions.","225","  :issue:`9886` by :user:`Hanmin Qin <qinhanmin2014>`.","226","","227","- |Fix| Fixed a bug in :class:`decomposition.SparseCoder` when running OMP","228","  sparse coding in parallel using readonly memory mapped datastructures.","229","  :issue:`5956` by :user:`Vighnesh Birodkar <vighneshbirodkar>` and","230","  :user:`Olivier Grisel <ogrisel>`.","231","","232",".. rubric:: :mod:`sklearn.discriminant_analysis`:","233","","234","- |Efficiency| Memory usage improvement for :func:`_class_means` and","235","  :func:`_class_cov` in :mod:`discriminant_analysis`.  :issue:`10898` by","236","  :user:`Nanxin Chen <bobchennan>`.`","237","","238",".. rubric:: :mod:`sklearn.dummy`:","239","","240","- |Feature| :class:`dummy.DummyRegressor` now has a ``return_std`` option in its","241","  ``predict`` method. The returned standard deviations will be zeros.","242","","243","- |Feature| :class:`dummy.DummyClassifier` and :class:`dummy.DummyRegressor` now","244","  only require X to be an object with finite length or shape.  :issue:`9832` by","245","  :user:`Vrishank Bhardwaj <vrishank97>`.","246","","247",".. rubric:: :mod:`sklearn.ensemble`:","248","","249","- |Feature| :class:`ensemble.BaggingRegressor` and","250","  :class:`ensemble.BaggingClassifier` can now be fit with missing\/non-finite","251","  values in X and\/or multi-output Y to support wrapping pipelines that perform","252","  their own imputation.  :issue:`9707` by :user:`Jimmy Wan <jimmywan>`.","253","","254","- |Feature| :class:`ensemble.GradientBoostingClassifier` and","259","- |Feature| Add `named_estimators_` parameter in","260","  :class:`ensemble.VotingClassifier` to access fitted estimators.","261","  :issue:`9157` by :user:`Herilalaina Rakotoarison <herilalaina>`.","263","- |Fix| Fixed a bug when fitting :class:`ensemble.GradientBoostingClassifier` or","264","  :class:`ensemble.GradientBoostingRegressor` with ``warm_start=True`` which","265","  previously raised a segmentation fault due to a non-conversion of CSC matrix","266","  into CSR format expected by ``decision_function``. Similarly, Fortran-ordered","267","  arrays are converted to C-ordered arrays in the dense case. :issue:`9991` by","270","- |Fix| Fixed a bug in :class:`ensemble.gradient_boosting.GradientBoostingRegressor`","271","  and :class:`ensemble.gradient_boosting.GradientBoostingClassifier` to have","272","  feature importances summed and then normalized, rather than normalizing on a","273","  per-tree basis. The previous behavior over-weighted the Gini importance of","274","  features that appear in later stages. This issue only affected feature","275","  importances. :issue:`11176` by :user:`Gil Forsyth <gforsyth>`.","276","","277","- |API| The default value of the ``n_estimators`` parameter of","278","  :class:`ensemble.RandomForestClassifier`, :class:`ensemble.RandomForestRegressor`,","279","  :class:`ensemble.ExtraTreesClassifier`, :class:`ensemble.ExtraTreesRegressor`,","280","  and :class:`ensemble.RandomTreesEmbedding` will change from 10 in version 0.20","281","  to 100 in 0.22. A FutureWarning is raised when the default value is used.","282","  :issue:`11542` by :user:`Anna Ayzenshtat <annaayzenshtat>`.","283","","284","- |API| Classes derived from :class:`ensemble.BaseBagging`. The attribute","285","  ``estimators_samples_`` will return a list of arrays containing the indices","286","  selected for each bootstrap instead of a list of arrays containing the mask","287","  of the samples selected for each bootstrap. Indices allows to repeat samples","288","  while mask does not allow this functionality.","289","  :issue:`9524` by :user:`Guillaume Lemaitre <glemaitre>`.","290","","291","- |Fix| :class:`ensemble.BaseBagging` where one could not deterministically","292","  reproduce ``fit`` result usinbg the object attributes when ``random_state``","293","  is set.  :issue:`9723` by :user:`Guillaume Lemaitre <glemaitre>`.","294","","295",".. rubric:: :mod:`sklearn.feature_extraction`:","296","","297","- |Feature| Enable the call to :term:`get_feature_names` in unfitted","298","  :class:`feature_extraction.text.CountVectorizer` initialized with a","299","  vocabulary. :issue:`10908` by :user:`Mohamed Maskani <maskani-moh>`.","300","","301","- |Fix| Fixed a bug in :func:`feature_extraction.image.extract_patches_2d` which","302","  would throw an exception if ``max_patches`` was greater than or equal to the","303","  number of all possible patches rather than simply returning the number of","304","  possible patches. :issue:`10100` by :user:`Varun Agrawal <varunagrawal>`","305","","306","- |Fix| Fixed a bug in :class:`feature_extraction.text.CountVectorizer`,","307","  :class:`feature_extraction.text.TfidfVectorizer`,","308","  :class:`feature_extraction.text.HashingVectorizer` to support 64 bit sparse","309","  array indexing necessary to process large datasets with more than 2¡¤10\u2079 tokens","310","  (words or n-grams). :issue:`9147` by :user:`Claes-Fredrik Mannby <mannby>`","311","  and `Roman Yurchak`_.","312","","313","- |Fix| Fixed bug in :class:`feature_extraction.text.TFIDFVectorizer` which","314","  was ignoring the parameter ``dtype``. In addition,","315","  :class:`feature_extraction.text.TFIDFTransformer` will preserve ``dtype``","316","  for floating and raise a warning if ``dtype`` requested is integer.","317","  :issue:`10441` by :user:`Mayur Kulkarni <maykulkarni>` and","318","  :user:`Guillaume Lemaitre <glemaitre>`.","319","","320",".. rubric:: :mod:`sklearn.feature_selection`:","321","","322","- |Feature| Added select K best features functionality to","323","  :class:`feature_selection.SelectFromModel`.","324","  :issue:`6689` by :user:`Nihar Sheth <nsheth12>` and","325","  :user:`Quazi Rahman <qmaruf>`.","326","","327","- |Fix| Fixed computation of ``n_features_to_compute`` for edge case with tied","328","  CV scores in :class:`feature_selection.RFECV`.","329","  :issue:`9222` by :user:`Nick Hoh <nickypie>`.","330","","331",".. rubric:: :mod:`sklearn.gaussian_process`:","332","","333","- |Efficiency| In :class:`gaussian_process.GaussianProcessRegressor`, method","334","  ``predict`` is faster when using ``return_std=True`` in particular more when","335","  called several times in a row. :issue:`9234` by :user:`andrewww <andrewww>`","336","  and :user:`Minghui Liu <minghui-liu>`.","337","","338",".. rubric:: :mod:`sklearn.impute`:","339","","340","- New module, adopting ``preprocessing.Imputer`` as","341","  :class:`impute.SimpleImputer` with minor changes (see under preprocessing","342","  below).","343","","344","- |MajorFeature| Added :class:`impute.MissingIndicator` which generates a","345","  binary indicator for missing values. :issue:`8075` by :user:`Maniteja Nandana","346","  <maniteja123>` and :user:`Guillaume Lemaitre <glemaitre>`.","347","","348","- |Feature| The :class:`impute.SimpleImputer` has a new strategy,","349","  ``'constant'``, to complete missing values with a fixed one, given by the","350","  ``fill_value`` parameter. This strategy supports numeric and non-numeric","351","  data, and so does the ``'most_frequent'`` strategy now. :issue:`11211` by","352","  :user:`Jeremie du Boisberranger <jeremiedbb>`.","353","","354",".. rubric:: :mod:`sklearn.isotonic`:","355","","356","- |Fix| Fixed a bug in :class:`isotonic.IsotonicRegression` which incorrectly","357","  combined weights when fitting a model to data involving points with","358","  identical X values.","359","  :issue:`9432` by :user:`Dallas Card <dallascard>`","360","","361",".. rubric:: :mod:`sklearn.linear_model`:","362","","363","- |Feature| :class:`linear_model.SGDClassifier`,","364","  :class:`linear_model.SGDRegressor`,","374","- |Feature| Add `sample_weight` parameter to the fit method of","375","  :class:`linear_model.BayesianRidge` for weighted linear regression.","376","  :issue:`10111` by :user:`Peter St. John <pstjohn>`.","378","- |Fix| Fixed a bug in :func:`logistic.logistic_regression_path` to ensure","379","  that the returned coefficients are correct when ``multiclass='multinomial'``.","380","  Previously, some of the coefficients would override each other, leading to","381","  incorrect results in :class:`logistic.LogisticRegressionCV`.","382","  :issue:`11724` by :user:`Nicolas Hug <NicolasHug>`.","384","- |Fix| Fixed a bug in :class:`linear_model.LogisticRegression` where when using","385","  the parameter ``multi_class='multinomial'``, the ``predict_proba`` method was","386","  returning incorrect probabilities in the case of binary outcomes.","387","  :issue:`9939` by :user:`Roger Westover <rwolst>`.","389","- |Fix| Fixed a bug in :class:`linear_model.LogisticRegressionCV` where the","390","  ``score`` method always computes accuracy, not the metric given by","391","  the ``scoring`` parameter.","392","  :issue:`10998` by :user:`Thomas Fan <thomasjpfan>`.","394","- |Fix| Fixed a bug in :class:`linear_model.LogisticRegressionCV` where the","395","  'ovr' strategy was always used to compute cross-validation scores in the","396","  multiclass setting, even if 'multinomial' was set.","397","  :issue:`8720` by :user:`William de Vazelhes <wdevazelhes>`.","399","- |Fix| Fixed a bug in :class:`linear_model.OrthogonalMatchingPursuit` that was","400","  broken when setting ``normalize=False``.","401","  :issue:`10071` by `Alexandre Gramfort`_.","403","- |Fix| Fixed a bug in :class:`linear_model.ARDRegression` which caused","404","  incorrectly updated estimates for the standard deviation and the","405","  coefficients.  :issue:`10153` by :user:`J?rg D?pfert <jdoepfert>`.","407","- |Fix| Fixed a bug in :class:`linear_model.RidgeClassifierCV` where","408","  the parameter ``store_cv_values`` was not implemented though","409","  it was documented in ``cv_values`` as a way to set up the storage","410","  of cross-validation values for different alphas. :issue:`10297` by","411","  :user:`Mabel Villalba-Jim¨¦nez <mabelvj>`.","413","- |Fix| Fixed a bug in :class:`linear_model.ElasticNet` which caused the input","414","  to be overridden when using parameter ``copy_X=True`` and","415","  ``check_input=False``.  :issue:`10581` by :user:`Yacine Mazari <ymazari>`.","417","- |Fix| Fixed a bug in :class:`sklearn.linear_model.Lasso`","418","  where the coefficient had wrong shape when ``fit_intercept=False``.","419","  :issue:`10687` by :user:`Martin Hahn <martin-hahn>`.","421","- |Fix| Fixed a bug in :func:`sklearn.linear_model.LogisticRegression` where the","422","  multi_class='multinomial' with binary output with warm_start = True","423","  :issue:`10836` by :user:`Aishwarya Srinivasan <aishgrt1>`.","424","","425","- |Fix| Fixed a bug in :class:`linear_model.RidgeCV` where using integer","426","  ``alphas`` raised an error.","427","  :issue:`10393` by :user:`Mabel Villalba-Jim¨¦nez <mabelvj>`.","428","","429","- |Fix| Fixed condition triggering gap computation in","430","  :class:`linear_model.Lasso` and :class:`linear_model.ElasticNet` when working","431","  with sparse matrices.  :issue:`10992` by `Alexandre Gramfort`_.","432","","433","- |Fix| Fixed a bug in :class:`linear_model.SGDClassifier`,","434","  :class:`linear_model.SGDRegressor`,","435","  :class:`linear_model.PassiveAggressiveClassifier`,","436","  :class:`linear_model.PassiveAggressiveRegressor` and","437","  :class:`linear_model.Perceptron`, where the stopping criterion was stopping","438","  the algorithm before convergence. A parameter `n_iter_no_change` was added","439","  and set by default to 5. Previous behavior is equivalent to setting the","440","  parameter to 1. :issue:`9043` by `Tom Dupre la Tour`_.","441","","442","- |Fix| Fixed a bug where liblinear and libsvm-based estimators would segfault","443","  if passed a scipy.sparse matrix with 64-bit indices. They now raise a","444","  ValueError.","445","  :issue:`11327` by :user:`Karan Dhingra <kdhingra307>` and `Joel Nothman`_.","446","","447","- |API| Deprecate ``positive=True`` option in :class:`linear_model.Lars` as","448","  the underlying implementation is broken. Use :class:`linear_model.Lasso`","449","  instead.  :issue:`9837` by `Alexandre Gramfort`_.","450","","451","- |API| ``n_iter_`` may vary from previous releases in","452","  :class:`linear_model.LogisticRegression` with ``solver='lbfgs'`` and","453","  :class:`linear_model.HuberRegressor`.  For Scipy <= 1.0.0, the optimizer could","454","  perform more than the requested maximum number of iterations. Now both","455","  estimators will report at most ``max_iter`` iterations even if more were","456","  performed. :issue:`10723` by `Joel Nothman`_.","457","","458",".. rubric:: :mod:`sklearn.manifold`:","459","","460","- |Efficiency| Speed improvements for both 'exact' and 'barnes_hut' methods in","461","  :class:`manifold.TSNE`. :issue:`10593` and :issue:`10610` by","462","  `Tom Dupre la Tour`_.","463","","464","- |Feature| Support sparse input in :meth:`manifold.Isomap.fit`.","465","  :issue:`8554` by :user:`Leland McInnes <lmcinnes>`.","466","","467","- |Feature| :func:`manifold.t_sne.trustworthiness` accepts metrics other than","468","  Euclidean. :issue:`9775` by :user:`William de Vazelhes <wdevazelhes>`.","469","","470","- |API| |Feature| Deprecate ``precomputed`` parameter in function","471","  :func:`manifold.t_sne.trustworthiness`. Instead, the new parameter ``metric``","472","  should be used with any compatible metric including 'precomputed', in which","473","  case the input matrix ``X`` should be a matrix of pairwise distances or","474","  squared distances.  :issue:`9775` by :user:`William de Vazelhes","475","  <wdevazelhes>`.","476","","477","- |API| Deprecate ``precomputed`` parameter in function","478","  :func:`manifold.t_sne.trustworthiness`. Instead, the new parameter","479","  ``metric`` should be used with any compatible metric including","480","  'precomputed', in which case the input matrix ``X`` should be a matrix of","481","  pairwise distances or squared distances. :issue:`9775` by","482","  :user:`William de Vazelhes <wdevazelhes>`.","483","","484",".. rubric:: :mod:`sklearn.metrics`:","485","","486","- |MajorFeature| Added the :func:`metrics.davies_bouldin_score` metric for","487","  evaluation of clustering models without a ground truth.  :issue:`10827` by","488","  :user:`Luis Osa <logc>`.","489","","490","- |MajorFeature| Added the :func:`metrics.balanced_accuracy_score` metric and","491","  a corresponding ``'balanced_accuracy'`` scorer for binary and multiclass","492","  classification.  :issue:`8066` by :user:`xyguo` and :user:`Aman Dalmia","493","  <dalmia>`, and :issue:`10587` by `Joel Nothman`_.","494","","495","- |Feature| Partial AUC is available via ``max_fpr`` parameter in","499","- |Feature| A scorer based on :func:`metrics.brier_score_loss` is also","500","  available.  :issue:`9521` by :user:`Hanmin Qin <qinhanmin2014>`.","501","","502","- |Feature| Added control over the normalization in","508","","509","- |Feature| Added ``output_dict`` parameter in :func:`metrics.classification_report`","513","- |Feature| :func:`metrics.average_precision_score` now supports binary","514","  ``y_true`` other than ``{0, 1}`` or ``{-1, 1}`` through ``pos_label``","515","  parameter.  :issue:`9980` by :user:`Hanmin Qin <qinhanmin2014>`.","517","- |Feature| :func:`metrics.label_ranking_average_precision_score` now supports","518","  ``sample_weight``.","519","  :issue:`10845` by :user:`Jose Perez-Parras Toledano <jopepato>`.","521","- |Feature| Add ``dense_output`` parameter to :func:`metrics.pairwise.linear_kernel`.","522","  When False and both inputs are sparse, will return a sparse matrix.","523","  :issue:`10999` by :user:`Taylor G Smith <tgsmith61591>`.","525","- |Efficiency| :func:`metrics.cluster.silhouette_score` and","526","  :func:`metrics.cluster.silhouette_samples` are more memory efficient and run","527","  faster. This avoids some reported freezes and MemoryErrors.","528","  :issue:`11135` by `Joel Nothman`_.","530","- |Fix| Fixed a bug in :func:`metrics.precision_recall_fscore_support`","531","  when truncated `range(n_labels)` is passed as value for `labels`.","532","  :issue:`10377` by :user:`Gaurav Dhingra <gxyd>`.","534","- |Fix| Fixed a bug due to floating point error in","535","  :func:`metrics.roc_auc_score` with non-integer sample weights. :issue:`9786`","536","  by :user:`Hanmin Qin <qinhanmin2014>`.","538","- |Fix| Fixed a bug where :func:`metrics.roc_curve` sometimes starts on y-axis","539","  instead of (0, 0), which is inconsistent with the document and other","540","  implementations.  Note that this will not influence the result from","541","  :func:`metrics.roc_auc_score` :issue:`10093` by :user:`alexryndin","542","  <alexryndin>` and :user:`Hanmin Qin <qinhanmin2014>`.","544","- |Fix| Fixed a bug to avoid integer overflow. Casted product to 64 bits integer in","545","  :func:`metrics.mutual_info_score`.","546","  :issue:`9772` by :user:`Kumar Ashutosh <thechargedneutron>`.","548","- |Fix| Fixed a bug where :func:`metrics.average_precision_score` will sometimes return","549","  ``nan`` when ``sample_weight`` contains 0.","550","  :issue:`9980` by :user:`Hanmin Qin <qinhanmin2014>`.","552","- |Fix| Fixed a bug in :func:`metrics.fowlkes_mallows_score` to avoid integer","553","  overflow. Casted return value of `contingency_matrix` to `int64` and computed","554","  product of square roots rather than square root of product.","555","  :issue:`9515` by :user:`Alan Liddell <aliddell>` and","556","  :user:`Manh Dao <manhdao>`.","557","","558","- |API| Deprecate ``reorder`` parameter in :func:`metrics.auc` as it's no","559","  longer required for :func:`metrics.roc_auc_score`. Moreover using","560","  ``reorder=True`` can hide bugs due to floating point error in the input.","561","  :issue:`9851` by :user:`Hanmin Qin <qinhanmin2014>`.","562","","563","- |API| In :func:`metrics.normalized_mutual_information_score` and","564","  :func:`metrics.adjusted_mutual_information_score`, warn that","565","  ``average_method`` will have a new default value. In version 0.22, the","566","  default normalizer for each will become the *arithmetic* mean of the","567","  entropies of each clustering. Currently,","568","  :func:`metrics.normalized_mutual_information_score` uses the default of","569","  ``average_method='geometric'``, and","570","  :func:`metrics.adjusted_mutual_information_score` uses the default of","571","  ``average_method='max'`` to match their behaviors in version 0.19.","572","  :issue:`11124` by :user:`Arya McCarthy <aryamccarthy>`.","573","","574","- |API| The ``batch_size`` parameter to :func:`metrics.pairwise_distances_argmin_min`","575","  and :func:`metrics.pairwise_distances_argmin` is deprecated to be removed in","576","  v0.22.  It no longer has any effect, as batch size is determined by global","577","  ``working_memory`` config. See :ref:`working_memory`. :issue:`10280` by `Joel","578","  Nothman`_ and :user:`Aman Dalmia <dalmia>`.","579","","580",".. rubric:: :mod:`sklearn.mixture`:","581","","582","- |Feature| Added function :term:`fit_predict` to :class:`mixture.GaussianMixture`","583","  and :class:`mixture.GaussianMixture`, which is essentially equivalent to","584","  calling :term:`fit` and :term:`predict`. :issue:`10336` by :user:`Shu Haoran","585","  <haoranShu>` and :user:`Andrew Peng <Andrew-peng>`.","586","","587","- |Fix| Fixed a bug in :class:`mixture.BaseMixture` where the reported `n_iter_` was","588","  missing an iteration. It affected :class:`mixture.GaussianMixture` and","589","  :class:`mixture.BayesianGaussianMixture`. :issue:`10740` by :user:`Erich","590","  Schubert <kno10>` and :user:`Guillaume Lemaitre <glemaitre>`.","591","","592","- |Fix| Fixed a bug in :class:`mixture.BaseMixture` and its subclasses","593","  :class:`mixture.GaussianMixture` and :class:`mixture.BayesianGaussianMixture`","594","  where the ``lower_bound_`` was not the max lower bound across all","595","  initializations (when ``n_init > 1``), but just the lower bound of the last","596","  initialization. :issue:`10869` by :user:`Aur¨¦lien G¨¦ron <ageron>`.","597","","598",".. rubric:: :mod:`sklearn.model_selection`:","599","","600","- |Feature| Add `return_estimator` parameter in","601","  :func:`model_selection.cross_validate` to return estimators fitted on each","602","  split.  :issue:`9686` by :user:`Aur¨¦lien Bellet <bellet>`.","603","","604","- |Feature| New ``refit_time_`` attribute will be stored in","605","  :class:`model_selection.GridSearchCV` and","606","  :class:`model_selection.RandomizedSearchCV` if ``refit`` is set to ``True``.","607","  This will allow measuring the complete time it takes to perform","608","  hyperparameter optimization and refitting the best model on the whole","609","  dataset. :issue:`11310` by :user:`Matthias Feurer <mfeurer>`.","610","","611","- |Feature| Expose `error_score` parameter in","612","  :func:`model_selection.cross_validate`,","613","  :func:`model_selection.cross_val_score`,","614","  :func:`model_selection.learning_curve` and","615","  :func:`model_selection.validation_curve` to control the behavior triggered","616","  when an error occurs in :func:`model_selection._fit_and_score`.","617","  :issue:`11576` by :user:`Samuel O. Ronsin <samronsin>`.","618","","619","- |Feature| `BaseSearchCV` now has an experimental, private interface to","620","  support customized parameter search strategies, through its ``_run_search``","621","  method.  See the implementations in :class:`model_selection.GridSearchCV` and","622","  :class:`model_selection.RandomizedSearchCV` and please provide feedback if","623","  you use this. Note that we do not assure the stability of this API beyond","624","  version 0.20. :issue:`9599` by `Joel Nothman`_","625","","626","- |Enhancement| Add improved error message in","627","  :func:`model_selection.cross_val_score` when multiple metrics are passed in","628","  ``scoring`` keyword.  :issue:`11006` by :user:`Ming Li <minggli>`.","629","","630","- |API| The default number of cross-validation folds ``cv`` and the default","631","  number of splits ``n_splits`` in the :class:`model_selection.KFold`-like","632","  splitters will change from 3 to 5 in 0.22 as 3-fold has a lot of variance.","633","  :issue:`11557` by :user:`Alexandre Boucaud <aboucaud>`.","634","","635","- |API| The default of ``iid`` parameter of :class:`model_selection.GridSearchCV`","636","  and :class:`model_selection.RandomizedSearchCV` will change from ``True`` to","637","  ``False`` in version 0.22 to correspond to the standard definition of","638","  cross-validation, and the parameter will be removed in version 0.24","639","  altogether. This parameter is of greatest practical significance where the","640","  sizes of different test sets in cross-validation were very unequal, i.e. in","641","  group-based CV strategies. :issue:`9085` by :user:`Laurent Direr <ldirer>`","642","  and `Andreas M¨¹ller`_.","643","","644","- |API| Changed ValueError exception raised in","645","  :class:`model_selection.ParameterSampler` to a UserWarning for case where the","646","  class is instantiated with a greater value of ``n_iter`` than the total space","647","  of parameters in the parameter grid. ``n_iter`` now acts as an upper bound on","648","  iterations.  :issue:`#10982` by :user:`Juliet Lawton <julietcl>`","649","","650","- |API| Invalid input for :class:`model_selection.ParameterGrid` now","651","  raises TypeError.","652","  :issue:`10928` by :user:`Solutus Immensus <solutusimmensus>`","653","","654",".. rubric:: :mod:`sklearn.multioutput`:","655","","656","- |MajorFeature| Added :class:`multioutput.RegressorChain` for multi-target","657","  regression. :issue:`9257` by :user:`Kumar Ashutosh <thechargedneutron>`.","658","","659",".. rubric:: :mod:`sklearn.naive_bayes`:","660","","661","- |MajorFeature| Added :class:`naive_bayes.ComplementNB`, which implements the","662","  Complement Naive Bayes classifier described in Rennie et al. (2003).","663","  :issue:`8190` by :user:`Michael A. Alcorn <airalcorn2>`.","664","","665","- |Feature| Add `var_smoothing` parameter in :class:`naive_bayes.GaussianNB`","666","  to give a precise control over variances calculation.","667","  :issue:`9681` by :user:`Dmitry Mottl <Mottl>`.","668","","669","- |Fix| Fixed a bug in :class:`naive_bayes.GaussianNB` which incorrectly","670","  raised error for prior list which summed to 1.","671","  :issue:`10005` by :user:`Gaurav Dhingra <gxyd>`.","672","","673","- |Fix| Fixed a bug in :class:`naive_bayes.MultinomialNB` which did not accept","674","  vector valued pseudocounts (alpha).","675","  :issue:`10346` by :user:`Tobias Madsen <TobiasMadsen>`","676","","677",".. rubric:: :mod:`sklearn.neighbors`:","678","","679","- |Efficiency| :class:`neighbors.RadiusNeighborsRegressor` and","680","  :class:`neighbors.RadiusNeighborsClassifier` are now","681","  parallelized according to ``n_jobs`` regardless of ``algorithm``.","682","  :issue:`8003` by :user:`Jo?l Billaud <recamshak>`.","683","","684","- |Efficiency| :mod:`Nearest neighbors <neighbors>` query methods are now more","685","  memory efficient when ``algorithm='brute'``.","686","  :issue:`11136` by `Joel Nothman`_ and :user:`Aman Dalmia <dalmia>`.","687","","688","- |Feature| Add `sample_weight` parameter to the fit method of","689","  :class:`neighbors.KernelDensity` to enable weighting in kernel density","690","  estimation.","691","  :issue:`4394` by :user:`Samuel O. Ronsin <samronsin>`.","692","","693","- |Feature| Novelty detection with :class:`neighbors.LocalOutlierFactor`:","694","  Add a ``novelty`` parameter to :class:`neighbors.LocalOutlierFactor`. When","695","  ``novelty`` is set to True, :class:`neighbors.LocalOutlierFactor` can then ","696","  be used for novelty detection, i.e. predict on new unseen data. Available","697","  prediction methods are ``predict``, ``decision_function`` and","698","  ``score_samples``. By default, ``novelty`` is set to ``False``, and only","699","  the ``fit_predict`` method is avaiable.","700","  By :user:`Albert Thomas <albertcthomas>`.","701","","702","- |Fix| Fixed a bug in :class:`neighbors.NearestNeighbors` where fitting a","703","  NearestNeighbors model fails when a) the distance metric used is a","704","  callable and b) the input to the NearestNeighbors model is sparse.","705","  :issue:`9579` by :user:`Thomas Kober <tttthomasssss>`.","706","","707","- |Fix| Fixed a bug so ``predict`` in","708","  :class:`neighbors.RadiusNeighborsRegressor` can handle empty neighbor set","709","  when using non uniform weights. Also raises a new warning when no neighbors","710","  are found for samples.  :issue:`9655` by :user:`Andreas Bjerre-Nielsen","711","  <abjer>`.","712","","713","- |Fix| |Efficiency| Fixed a bug in ``KDTree`` construction that results in","714","  faster construction and querying times.","715","  :issue:`11556` by :user:`Jake VanderPlas <jakevdp>`","716","","717",".. rubric:: :mod:`sklearn.neural_network`:","718","","719","- |Feature| Add `n_iter_no_change` parameter in","726","- |Fix| Fixed a bug in :class:`neural_network.BaseMultilayerPerceptron`,","727","  :class:`neural_network.MLPRegressor`, and","728","  :class:`neural_network.MLPClassifier` with new ``n_iter_no_change``","729","  parameter now at 10 from previously hardcoded 2.","730","  :issue:`9456` by :user:`Nicholas Nadeau <nnadeau>`.","732","- |Fix| Fixed a bug in :class:`neural_network.MLPRegressor` where fitting","733","  quit unexpectedly early due to local minima or fluctuations.","734","  :issue:`9456` by :user:`Nicholas Nadeau <nnadeau>`","736",".. rubric:: :mod:`sklearn.pipeline`:","738","- |Feature| The ``predict`` method of :class:`pipeline.Pipeline` now passes","739","  keyword arguments on to the pipeline's last estimator, enabling the use of","740","  parameters such as ``return_std`` in a pipeline with caution.","741","  :issue:`9304` by :user:`Breno Freitas <brenolf>`.","743",".. rubric:: :mod:`sklearn.preprocessing`:","745","- |MajorFeature| Expanded :class:`preprocessing.OneHotEncoder` to allow to","746","  encode categorical string features as a numeric array using a one-hot (or","747","  dummy) encoding scheme, and added :class:`preprocessing.OrdinalEncoder` to","748","  convert to ordinal integers.  Those two classes now handle encoding of all","749","  feature types (also handles string-valued features) and derives the","750","  categories based on the unique values in the features instead of the maximum","751","  value in the features. :issue:`9151` and :issue:`10521` by :user:`Vighnesh","752","  Birodkar <vighneshbirodkar>` and `Joris Van den Bossche`_.","754","- |MajorFeature| Added :class:`preprocessing.KBinsDiscretizer` for turning","755","  continuous features into categorical or one-hot encoded","756","  features. :issue:`7668`, :issue:`9647`, :issue:`10195`,","757","  :issue:`10192`, :issue:`11272`, :issue:`11467` and :issue:`11505`.","758","  by :user:`Henry Lin <hlin117>`, `Hanmin Qin`_,","759","  `Tom Dupre la Tour`_ and :user:`Giovanni Giuseppe Costa <ggc87>`.","761","- |MajorFeature| Added :class:`preprocessing.PowerTransformer`, which","762","  implements the Yeo-Johnson and Box-Cox power transformations. Power","763","  transformations try to find a set of feature-wise parametric transformations","764","  to approximately map data to a Gaussian distribution centered at zero and","765","  with unit variance.  This is useful as a variance-stabilizing transformation","766","  in situations where normality and homoscedasticity are desirable.","767","  :issue:`10210` by :user:`Eric Chang <ericchang00>` and :user:`Maniteja","768","  Nandana <maniteja123>`, and :issue:`11520` by :user:`Nicolas Hug","769","  <nicolashug>`.","771","- |MajorFeature| NaN values are ignored and handled in the following","772","  preprocessing methods:","790","- |Feature| :class:`preprocessing.PolynomialFeatures` now supports sparse","791","  input.  :issue:`10452` by :user:`Aman Dalmia <dalmia>` and `Joel Nothman`_.","792","","793","- |Feature| :class:`preprocessing.RobustScaler` and","794","  :func:`preprocessing.robust_scale` can be fitted using sparse matrices.","797","- |Feature| :class:`preprocessing.OneHotEncoder` now supports the","798","  :term:`get_feature_names` method to obtain the transformed feature names.","799","  :issue:`10181` by  :user:`Nirvan Anjirbag <Nirvan101>` and","800","  `Joris Van den Bossche`_.","802","- |Feature| A parameter ``check_inverse`` was added to","803","  :class:`preprocessing.FunctionTransformer` to ensure that ``func`` and","804","  ``inverse_func`` are the inverse of each other.","805","  :issue:`9399` by :user:`Guillaume Lemaitre <glemaitre>`.","807","- |Feature| The ``transform`` method of :class:`sklearn.preprocessing.MultiLabelBinarizer`","808","  now ignores any unknown classes. A warning is raised stating the unknown classes","809","  classes found which are ignored.","810","  :issue:`10913` by :user:`Rodrigo Agundez <rragundez>`.","812","- |Fix| Fixed bugs in :class:`preprocessing.LabelEncoder` which would","813","  sometimes throw errors when ``transform`` or ``inverse_transform`` was called","814","  with empty arrays.  :issue:`10458` by :user:`Mayur Kulkarni <maykulkarni>`.","816","- |Fix| Fix ValueError in :class:`preprocessing.LabelEncoder` when using","820","- |Fix| Fix bug in :class:`preprocessing.OneHotEncoder` which discarded the","821","  ``dtype`` when returning a sparse matrix output.","822","  :issue:`11042` by :user:`Daniel Morales <DanielMorales9>`.","824","- |Fix| Fix ``fit`` and ``partial_fit`` in","825","  :class:`preprocessing.StandardScaler` in the rare case when `with_mean=False`","826","  and `with_std=False` which was crashing by calling ``fit`` more than once and","827","  giving inconsistent results for ``mean_`` whether the input was a sparse or a","828","  dense matrix. ``mean_`` will be set to ``None`` with both sparse and dense","829","  inputs. ``n_samples_seen_`` will be also reported for both input types.","832","- |API| Deprecate ``n_values`` and ``categorical_features`` parameters and","841","- |API| Deprecate :class:`preprocessing.Imputer` and move","842","  the corresponding module to :class:`impute.SimpleImputer`.","843","  :issue:`9726` by :user:`Kumar Ashutosh","846"," - The ``axis`` parameter that was in","847","   :class:`preprocessing.Imputer` is no longer present in","848","   :class:`impute.SimpleImputer`. The behavior is equivalent","849","   to ``axis=0`` (impute along columns).  Row-wise","850","   imputation can be performed with FunctionTransformer","851","   (e.g., ``FunctionTransformer(lambda X:","852","   SimpleImputer().fit_transform(X.T).T)``).  :issue:`10829`","853","   by :user:`Guillaume Lemaitre <glemaitre>` and","854","   :user:`Gilberto Olimpio <gilbertoolimpio>`.","856"," - The NaN marker for the missing values has been changed","857","   between the :class:`preprocessing.Imputer` and the","858","   :class:`impute.SimpleImputer`.","859","   ``missing_values='NaN'``?should now be","860","   ``missing_values=np.nan``.  :issue:`11211` by","861","   :user:`Jeremie du Boisberranger <jeremiedbb>`.","863","- |API| In :class:`preprocessing.FunctionTransformer`, the default of","864","  ``validate`` will be from ``True`` to ``False`` in 0.22.","865","  :issue:`10655` by :user:`Guillaume Lemaitre <glemaitre>`.","867",".. rubric:: :mod:`sklearn.svm`:","869","- |Fix| Fixed a bug in :class:`svm.SVC` where when the argument ``kernel`` is","870","  unicode in Python2, the ``predict_proba`` method was raising an","871","  unexpected TypeError given dense inputs.","872","  :issue:`10412` by :user:`Jiongyan Zhang <qmick>`.","874","- |API| Deprecate ``random_state`` parameter in :class:`svm.OneClassSVM` as","875","  the underlying implementation is not random.","876","  :issue:`9497` by :user:`Albert Thomas <albertcthomas>`.","878","- |API| The default value of ``gamma`` parameter of :class:`svm.SVC`,","879","  :class:`~svm.NuSVC`, :class:`~svm.SVR`, :class:`~svm.NuSVR`,","880","  :class:`~svm.OneClassSVM` will change from ``'auto'`` to ``'scale'`` in","881","  version 0.22 to account better for unscaled features. :issue:`8361` by","882","  :user:`Gaurav Dhingra <gxyd>` and :user:`Ting Neo <neokt>`.","884",".. rubric:: :mod:`sklearn.tree`:","886","- |Fix| Fixed a bug in :class:`tree.BaseDecisionTree` with `splitter=\"best\"`","887","  where split threshold could become infinite when values in X were","888","  near infinite. :issue:`10536` by :user:`Jonathan Ohayon <Johayon>`.","889","","890","- |Fix| Fixed a bug in :class:`tree.MAE` to ensure sample weights are being","891","  used during the calculation of tree MAE impurity. Previous behaviour could","892","  cause suboptimal splits to be chosen since the impurity calculation","893","  considered all samples to be of equal weight importance.","894","  :issue:`11464` by :user:`John Stott <JohnStott>`.","895","","896",".. rubric:: :mod:`sklearn.utils`:","897","","898","- |Feature| :func:`utils.check_array` and :func:`utils.check_X_y` now have","899","  ``accept_large_sparse`` to control whether scipy.sparse matrices with 64-bit","900","  indices should be rejected.","901","  :issue:`11327` by :user:`Karan Dhingra <kdhingra307>` and `Joel Nothman`_.","902","","903","- |Efficiency| |Fix| Avoid copying the data in :func:`utils.check_array` when","904","  the input data is a memmap (and ``copy=False``).  :issue:`10663` by","905","  :user:`Arthur Mensch <arthurmensch>` and :user:`Lo?c Est¨¨ve <lesteve>`.","906","","907","- |API| :func:`utils.check_array` yield a ``FutureWarning`` indicating","908","  that arrays of bytes\/strings will be interpreted as decimal numbers","909","  beginning in version 0.22. :issue:`10229` by :user:`Ryan Lee <rtlee9>`","910","","911",".. rubric:: Multiple modules","912","","913","- |Feature| |API| More consistent outlier detection API:","940","- |API| Added convergence warning to :class:`svm.LinearSVC` and","941","  :class:`linear_model.LogisticRegression` when ``verbose`` is set to 0.","942","  :issue:`10881` by :user:`Alexandre Sevin <AlexandreSev>`.","944","- |API| Changed warning type from :class:`UserWarning` to","954",".. rubric:: Miscellaneous","956","- |MajorFeature| A new configuration parameter, ``working_memory`` was added","957","  to control memory consumption limits in chunked operations, such as the new","958","  :func:`metrics.pairwise_distances_chunked`.  See :ref:`working_memory`.","959","  :issue:`10280` by `Joel Nothman`_ and :user:`Aman Dalmia <dalmia>`.","961","- |Feature| Add almost complete PyPy 3 support. Known unsupported","962","  functionalities are :func:`datasets.load_svmlight_file`,","963","  :class:`feature_extraction.FeatureHasher` and","964","  :class:`feature_extraction.text.HashingVectorizer`.  For running on PyPy,","965","  PyPy3-v5.10+, Numpy 1.14.0+, and scipy 1.1.0+ are required.","966","  :issue:`11010` by :user:`Ronan Lamy <rlamy>` and `Roman Yurchak`_.","968","- |Feature| An environment variable to use the site joblib instead of the","969","  vendored one was added (:ref:`environment_variable`). The main API of joblib","970","  is now exposed in :mod:`sklearn.utils`.","971","  :issue:`11166`by `Gael Varoquaux`_.","973","- |Feature| A utility method :func:`sklearn.show_versions()` was added to","974","  print out information relevant for debugging. It includes the user system,","975","  the Python executable, the version of the main libraries and BLAS binding","976","  information.  :issue:`11596` by :user:`Alexandre Boucaud <aboucaud>`","978","- |Fix| Fixed a bug when setting parameters on meta-estimator, involving both","979","  a wrapped estimator and its parameter. :issue:`9999` by :user:`Marcus Voss","980","  <marcus-voss>` and `Joel Nothman`_."],"delete":["64","- :class:`metrics.roc_auc_score` (bug fix)","65","- :class:`metrics.roc_curve` (bug fix)","66","- :class:`neural_network.BaseMultilayerPerceptron` (bug fix)","67","- :class:`neural_network.MLPRegressor` (bug fix)","68","- :class:`neural_network.MLPClassifier` (bug fix)","69","- :class:`linear_model.SGDClassifier` (bug fix)","70","- :class:`linear_model.SGDRegressor` (bug fix)","74","- :class:`ensemble.gradient_boosting.GradientBoostingClassifier` (bug fix affecting feature importances)","75","- :class:`linear_model.LogisticRegressionCV` (bug fix)","79","- :class:`decomposition.SparsePCA` (bug fix)","91","New features","92","............","94","Classifiers and regressors","96","- :class:`ensemble.GradientBoostingClassifier` and","101","- :class:`dummy.DummyRegressor` now has a ``return_std`` option in its","102","  ``predict`` method. The returned standard deviations will be zeros.","104","- Added :class:`multioutput.RegressorChain` for multi-target","105","  regression. :issue:`9257` by :user:`Kumar Ashutosh <thechargedneutron>`.","106","","107","- Added :class:`naive_bayes.ComplementNB`, which implements the Complement","108","  Naive Bayes classifier described in Rennie et al. (2003).","109","  :issue:`8190` by :user:`Michael A. Alcorn <airalcorn2>`.","110","","111","- :class:`ensemble.BaggingRegressor` and :class:`ensemble.BaggingClassifier` can now","112","  be fit with missing\/non-finite values in X and\/or multi-output Y to support","113","  wrapping pipelines that perform their own imputation.","114","  :issue:`9707` by :user:`Jimmy Wan <jimmywan>`.","115","","116","Preprocessing","117","","118","- Expanded :class:`preprocessing.OneHotEncoder` to allow to encode","119","  categorical string features as a numeric array using a one-hot (or dummy)","120","  encoding scheme, and added :class:`preprocessing.OrdinalEncoder` to","121","  convert to ordinal integers.  Those two classes now handle","122","  encoding of all feature types (also handles string-valued features) and","123","  derives the categories based on the unique values in the features instead of","124","  the maximum value in the features. :issue:`9151` and :issue:`10521` by","125","  :user:`Vighnesh Birodkar <vighneshbirodkar>` and `Joris Van den Bossche`_.","126","","127","- Added :class:`preprocessing.KBinsDiscretizer` for turning","128","  continuous features into categorical or one-hot encoded","129","  features. :issue:`7668`, :issue:`9647`, :issue:`10195`,","130","  :issue:`10192`, :issue:`11272`, :issue:`11467` and :issue:`11505`.","131","  by :user:`Henry Lin <hlin117>`, `Hanmin Qin`_,","132","  `Tom Dupre la Tour`_ and :user:`Giovanni Giuseppe Costa <ggc87>`.","133","","134","- Added :class:`compose.ColumnTransformer`, which allows to apply","135","  different transformers to different columns of arrays or pandas","136","  DataFrames. :issue:`9012` by `Andreas M¨¹ller`_ and `Joris Van den Bossche`_,","137","  and :issue:`11315` by :user:`Thomas Fan <thomasjpfan>`.","138","","139","- Added :class:`preprocessing.PowerTransformer`, which implements the","140","  Yeo-Johnson and Box-Cox power transformations. Power transformations try to","141","  find a set of feature-wise parametric transformations to approximately map","142","  data to a Gaussian distribution centered at zero and with unit variance.","143","  This is useful as a variance-stabilizing transformation in situations where","144","  normality and homoscedasticity are desirable.","145","  :issue:`10210` by :user:`Eric Chang <ericchang00>` and","146","  :user:`Maniteja Nandana <maniteja123>`, and :issue:`11520` by :user:`Nicolas","147","  Hug <nicolashug>`.","148","","149","- Added the :class:`compose.TransformedTargetRegressor` which transforms","150","  the target y before fitting a regression model. The predictions are mapped","151","  back to the original space via an inverse transform. :issue:`9041` by","152","  `Andreas M¨¹ller`_ and :user:`Guillaume Lemaitre <glemaitre>`.","153","","154","- Added :class:`MissingIndicator` which generates a binary indicator for","155","  missing values. :issue:`8075` by :user:`Maniteja Nandana <maniteja123>` and","158","- :class:`linear_model.SGDClassifier`, :class:`linear_model.SGDRegressor`,","168","Model evaluation","170","- Added the :func:`metrics.davies_bouldin_score` metric for unsupervised","171","  evaluation of clustering models. :issue:`10827` by :user:`Luis Osa <logc>`.","173","- Added the :func:`metrics.balanced_accuracy_score` metric and a corresponding","174","  ``'balanced_accuracy'`` scorer for binary and multiclass classification.","175","  :issue:`8066` by :user:`xyguo` and :user:`Aman Dalmia <dalmia>`, and","176","  :issue:`10587` by `Joel Nothman`_.","178","Decomposition, manifold learning and clustering","180","- A new clustering algorithm: :class:`cluster.OPTICS`: an algoritm","181","  related to :class:`cluster.DBSCAN`, that has hyperparameters easier to","182","  set and tat scales better, by :user:`Shane <espg>`.","184","- :class:`cluster.AgglomerativeClustering` now supports Single Linkage","185","  clustering via ``linkage='single'``. :issue:`9372` by","186","  :user:`Leland McInnes <lmcinnes>` and :user:`Steve Astels <sastels>`.","188","- :class:`cluster.KMeans` and :class:`cluster.MiniBatchKMeans` now support","189","  sample weights via new parameter ``sample_weight`` in ``fit`` function.","190","  :issue:`10933` by :user:`Johannes Hansen <jnhansen>`.","192","- :mod:`dict_learning` functions and models now support positivity constraints.","193","  This applies to the dictionary and sparse code.","194","  :issue:`6374` by :user:`John Kirkham <jakirkham>`.","196","- :class:`decomposition.SparsePCA` now exposes ``normalize_components``. When","197","  set to True, the train and test data are centered with the train mean ","198","  repsectively during the fit phase and the transform phase. This fixes the","199","  behavior of SparsePCA. When set to False, which is the default, the previous","200","  abnormal behaviour still holds. The False value is for backward","201","  compatibility and should not be used.","202","  :issue:`11585` by :user:`Ivan Panico <FollowKenny>`.","204","Metrics","206","- Partial AUC is available via ``max_fpr`` parameter in","210","- Added control over the normalization in","216","- Added ``output_dict`` parameter in :func:`metrics.classification_report`","220","Misc","222","- A new configuration parameter, ``working_memory`` was added to control memory","223","  consumption limits in chunked operations, such as the new","224","  :func:`metrics.pairwise_distances_chunked`.  See :ref:`working_memory`.","225","  :issue:`10280` by `Joel Nothman`_ and :user:`Aman Dalmia <dalmia>`.","227","- An environment variable to use the site joblib instead of the vendored","228","  one was added (:ref:`environment_variable`). The main API of joblib is now","229","  exposed in :mod:`sklearn.utils`.","230","  :issue:`11166` by `Gael Varoquaux`_","232","- A utility method :func:`sklearn.show_versions()` was added to print out","233","  information relevant for debugging. It includes the user system, the","234","  Python executable, the version of the main libraries and BLAS binding","235","  information.","236","  :issue:`11596` by :user:`Alexandre Boucaud <aboucaud>`","238","Enhancements","239","............","241","Classifiers and regressors","243","- In :class:`gaussian_process.GaussianProcessRegressor`, method ``predict``","244","  is faster when using ``return_std=True`` in particular more when called","245","  several times in a row. :issue:`9234` by :user:`andrewww <andrewww>`","246","  and :user:`Minghui Liu <minghui-liu>`.","248","- Add `named_estimators_` parameter in","249","  :class:`ensemble.VotingClassifier` to access fitted","250","  estimators. :issue:`9157` by :user:`Herilalaina Rakotoarison <herilalaina>`.","252","- Add `var_smoothing` parameter in","253","  :class:`naive_bayes.GaussianNB` to give a precise control over","254","  variances calculation. :issue:`9681` by :user:`Dmitry Mottl <Mottl>`.","256","- Add `n_iter_no_change` parameter in","263","- A parameter ``check_inverse`` was added to","264","  :class:`preprocessing.FunctionTransformer` to ensure that ``func`` and","265","  ``inverse_func`` are the inverse of each other.","266","  :issue:`9399` by :user:`Guillaume Lemaitre <glemaitre>`.","268","- Add `sample_weight` parameter to the fit method of","269","  :class:`linear_model.BayesianRidge` for weighted linear regression.","270","  :issue:`10111` by :user:`Peter St. John <pstjohn>`.","272","- :class:`dummy.DummyClassifier` and :class:`dummy.DummyRegressor` now","273","  only require X to be an object with finite length or shape.","274","  :issue:`9832` by :user:`Vrishank Bhardwaj <vrishank97>`.","276","- Add `sample_weight` parameter to the fit method of","277","  :class:`neighbors.KernelDensity` to enables weighting in kernel density","278","  estimation.","279","  :issue:`4394` by :user:`Samuel O. Ronsin <samronsin>`.","281","- :class:`neighbors.RadiusNeighborsRegressor` and","282","  :class:`neighbors.RadiusNeighborsClassifier` are now","283","  parallelized according to ``n_jobs`` regardless of ``algorithm``.","284","  :issue:`8003` by :user:`Jo?l Billaud <recamshak>`.","286","- Memory usage improvement for :func:`_class_means` and :func:`_class_cov`","287","  in :class:`discriminant_analysis`.","288","  :issue:`10898` by :user:`Nanxin Chen <bobchennan>`.`","290","- :func:`manifold.t_sne.trustworthiness` accepts metrics other than","291","  Euclidean. :issue:`9775` by :user:`William de Vazelhes <wdevazelhes>`.","293","- :mod:`Nearest neighbors <neighbors>` query methods are now more memory","294","  efficient when ``algorithm='brute'``. :issue:`11136` by `Joel Nothman`_","295","  and :user:`Aman Dalmia <dalmia>`.","297","Cluster","298","","299","- :class:`cluster.KMeans`, :class:`cluster.MiniBatchKMeans` and","300","  :func:`cluster.k_means` passed with ``algorithm='full'`` now enforces","301","  row-major ordering, improving runtime.","302","  :issue:`10471` by :user:`Gaurav Dhingra <gxyd>`.","303","","304","- :class:`cluster.DBSCAN` now is parallelized according to ``n_jobs``","305","  regardless of ``algorithm``.","306","  :issue:`8003` by :user:`Jo?l Billaud <recamshak>`.","307","","308","Datasets","309","","310","- In :func:`datasets.make_blobs`, one can now pass a list to the `n_samples`","311","  parameter to indicate the number of samples to generate per cluster.","312","  :issue:`8617` by :user:`Maskani Filali Mohamed <maskani-moh>`","313","  and :user:`Konstantinos Katrioplas <kkatrio>`.","314","","315","Preprocessing","316","","317","- :class:`preprocessing.PolynomialFeatures` now supports sparse input.","318","  :issue:`10452` by :user:`Aman Dalmia <dalmia>` and `Joel Nothman`_.","319","","320","- Enable the call to :meth:`get_feature_names` in unfitted","321","  :class:`feature_extraction.text.CountVectorizer` initialized with a","322","  vocabulary. :issue:`10908` by :user:`Mohamed Maskani <maskani-moh>`.","323","","324","- :class:`preprocessing.OneHotEncoder` now supports the","325","  :meth:`get_feature_names` method to obtain the transformed feature names.","326","  :issue:`10181` by  :user:`Nirvan Anjirbag <Nirvan101>` and","327","  `Joris Van den Bossche`_.","328","","329","- The ``transform`` method of :class:`sklearn.preprocessing.MultiLabelBinarizer`","330","  now ignores any unknown classes. A warning is raised stating the unknown classes","331","  classes found which are ignored.","332","  :issue:`10913` by :user:`Rodrigo Agundez <rragundez>`.","333","","334","- NaN values are ignored and handled in the following preprocessing methods:","352","- :class:`preprocessing.RobustScaler` and :func:`preprocessing.robust_scale`","353","  can be fitted using sparse matrices.","356","Model evaluation and meta-estimators","358","- A scorer based on :func:`metrics.brier_score_loss` is also available.","359","  :issue:`9521` by :user:`Hanmin Qin <qinhanmin2014>`.","361","- The default of ``iid`` parameter of :class:`model_selection.GridSearchCV`","362","  and :class:`model_selection.RandomizedSearchCV` will change from ``True`` to","363","  ``False`` in version 0.22 to correspond to the standard definition of","364","  cross-validation, and the parameter will be removed in version 0.24","365","  altogether. This parameter is of greatest practical significance where the","366","  sizes of different test sets in cross-validation were very unequal, i.e. in","367","  group-based CV strategies. :issue:`9085` by :user:`Laurent Direr <ldirer>`","368","  and `Andreas M¨¹ller`_.","370","- The ``predict`` method of :class:`pipeline.Pipeline` now passes keyword","371","  arguments on to the pipeline's last estimator, enabling the use of parameters","372","  such as ``return_std`` in a pipeline with caution.","373","  :issue:`9304` by :user:`Breno Freitas <brenolf>`.","375","- Add `return_estimator` parameter in :func:`model_selection.cross_validate` to","376","  return estimators fitted on each split.","377","  :issue:`9686` by :user:`Aur¨¦lien Bellet <bellet>`.","378","","379","- New ``refit_time_`` attribute will be stored in","380","  :class:`model_selection.GridSearchCV` and","381","  :class:`model_selection.RandomizedSearchCV` if ``refit`` is set to ``True``.","382","  This will allow measuring the complete time it takes to perform","383","  hyperparameter optimization and refitting the best model on the whole","384","  dataset. :issue:`11310` by :user:`Matthias Feurer <mfeurer>`.","385","","386","- Expose `error_score` parameter in :func:`model_selection.cross_validate`,","387","  :func:`model_selection.cross_val_score`,","388","  :func:`model_selection.learning_curve` and","389","  :func:`model_selection.validation_curve` to control the behavior triggered","390","  when an error occurs in :func:`model_selection._fit_and_score`.","391","  :issue:`11576` by :user:`Samuel O. Ronsin <samronsin>`.","392","","393","- `BaseSearchCV` now has an experimental, private interface to support","394","  customized parameter search strategies, through its ``_run_search``","395","  method.  See the implementations in :class:`model_selection.GridSearchCV`","396","  and :class:`model_selection.RandomizedSearchCV` and please provide feedback","397","  if you use this. Note that we do not assure the stability of this API","398","  beyond version 0.20. :issue:`9599` by `Joel Nothman`_","399","","400","Decomposition and manifold learning","401","","402","- Speed improvements for both 'exact' and 'barnes_hut' methods in","403","  :class:`manifold.TSNE`. :issue:`10593` and :issue:`10610` by","404","  `Tom Dupre la Tour`_.","405","","406","- Support sparse input in :meth:`manifold.Isomap.fit`. :issue:`8554` by","407","  :user:`Leland McInnes <lmcinnes>`.","408","","409","Metrics","410","","411","- :func:`metrics.roc_auc_score` now supports binary ``y_true`` other than","412","  ``{0, 1}`` or ``{-1, 1}``.","413","  :issue:`9828` by :user:`Hanmin Qin <qinhanmin2014>`.","414","","415","- :func:`metrics.label_ranking_average_precision_score` now supports vector","416","  ``sample_weight``.","417","  :issue:`10845` by :user:`Jose Perez-Parras Toledano <jopepato>`.","418","","419","- Add ``dense_output`` parameter to :func:`metrics.pairwise.linear_kernel`.","420","  When False and both inputs are sparse, will return a sparse matrix.","421","  :issue:`10999` by :user:`Taylor G Smith <tgsmith61591>`.","422","","423","- :func:`metrics.cluster.silhouette_score` and","424","  :func:`metrics.cluster.silhouette_samples` are more memory efficient and run","425","  faster. This avoids some reported freezes and MemoryErrors.","426","  :issue:`11135` by `Joel Nothman`_.","427","","428","- :func:`metrics.average_precision_score` now supports binary ``y_true``","429","  other than ``{0, 1}`` or ``{-1, 1}`` through ``pos_label`` parameter.","430","  :issue:`9980` by :user:`Hanmin Qin <qinhanmin2014>`.","431","","432","Linear, kernelized and related models","433","","434","- Deprecate ``random_state`` parameter in :class:`svm.OneClassSVM` as the","435","  underlying implementation is not random.","436","  :issue:`9497` by :user:`Albert Thomas <albertcthomas>`.","437","","438","Preprocessing and feature selection","439","","440","- Added select K best features functionality to","441","  :class:`feature_selection.SelectFromModel`.","442","  :issue:`6689` by :user:`Nihar Sheth <nsheth12>` and","443","  :user:`Quazi Rahman <qmaruf>`.","444","","445","Decomposition, manifold learning and clustering","446","","447","- Deprecate ``precomputed`` parameter in function","448","  :func:`manifold.t_sne.trustworthiness`. Instead, the new parameter","449","  ``metric`` should be used with any compatible metric including","450","  'precomputed', in which case the input matrix ``X`` should be a matrix of","451","  pairwise distances or squared distances. :issue:`9775` by","452","  :user:`William de Vazelhes <wdevazelhes>`.","453","","454","Utils","455","","456","- Avoid copying the data in :func:`utils.check_array` when the input data is a","457","  memmap (and ``copy=False``). :issue:`10663` by :user:`Arthur Mensch","458","  <arthurmensch>` and :user:`Lo?c Est¨¨ve <lesteve>`.","459","","460","Miscellaneous","461","","462","- Add ``filename`` attribute to datasets that have a CSV file.","463","  :issue:`9101` by :user:`alex-33 <alex-33>`","464","  and :user:`Maskani Filali Mohamed <maskani-moh>`.","465","","466","- Add almost complete PyPy 3 support. Known unsupported functionalities are","467","  :func:`datasets.load_svmlight_file`, :class:`feature_extraction.FeatureHasher` and","468","  :class:`feature_extraction.text.HashingVectorizer`.  For running on PyPy, PyPy3-v5.10+,","469","  Numpy 1.14.0+, and scipy 1.1.0+ are required.","470","  :issue:`11010` by :user:`Ronan Lamy <rlamy>` and `Roman Yurchak`_.","471","","472","Bug fixes","473",".........","474","","475","Classifiers and regressors","476","","477","- Fixed a bug in :class:`isotonic.IsotonicRegression` which incorrectly","478","  combined weights when fitting a model to data involving points with","479","  identical X values.","480","  :issue:`9432` by :user:`Dallas Card <dallascard>`","481","","482","- Fixed a bug in :class:`neural_network.BaseMultilayerPerceptron`,","483","  :class:`neural_network.MLPRegressor`, and","484","  :class:`neural_network.MLPClassifier` with new ``n_iter_no_change``","485","  parameter now at 10 from previously hardcoded 2.","486","  :issue:`9456` by :user:`Nicholas Nadeau <nnadeau>`.","487","","488","- Fixed a bug in :class:`neural_network.MLPRegressor` where fitting","489","  quit unexpectedly early due to local minima or fluctuations.","490","  :issue:`9456` by :user:`Nicholas Nadeau <nnadeau>`","491","","492","- Fixed a bug in :class:`naive_bayes.GaussianNB` which incorrectly raised","493","  error for prior list which summed to 1.","494","  :issue:`10005` by :user:`Gaurav Dhingra <gxyd>`.","495","","496","- Fixed a bug in :class:`linear_model.LogisticRegression` where when using the","497","  parameter ``multi_class='multinomial'``, the ``predict_proba`` method was","498","  returning incorrect probabilities in the case of binary outcomes.","499","  :issue:`9939` by :user:`Roger Westover <rwolst>`.","500","","501","- Fixed a bug in :class:`linear_model.LogisticRegressionCV` where the","502","  ``score`` method always computes accuracy, not the metric given by","503","  the ``scoring`` parameter.","504","  :issue:`10998` by :user:`Thomas Fan <thomasjpfan>`.","505","","506","- Fixed a bug in :class:`linear_model.LogisticRegressionCV` where the 'ovr'","507","  strategy was always used to compute cross-validation scores in the","508","  multiclass setting, even if 'multinomial' was set.","509","  :issue:`8720` by :user:`William de Vazelhes <wdevazelhes>`.","510","","511","- Fixed a bug in :class:`linear_model.OrthogonalMatchingPursuit` that was","512","  broken when setting ``normalize=False``.","513","  :issue:`10071` by `Alexandre Gramfort`_.","514","","515","- Fixed a bug in :class:`linear_model.ARDRegression` which caused incorrectly","516","  updated estimates for the standard deviation and the coefficients.","517","  :issue:`10153` by :user:`J?rg D?pfert <jdoepfert>`.","518","","519","- Fixed a bug when fitting :class:`ensemble.GradientBoostingClassifier` or","520","  :class:`ensemble.GradientBoostingRegressor` with ``warm_start=True`` which","521","  previously raised a segmentation fault due to a non-conversion of CSC matrix","522","  into CSR format expected by ``decision_function``. Similarly, Fortran-ordered","523","  arrays are converted to C-ordered arrays in the dense case. :issue:`9991` by","524","  :user:`Guillaume Lemaitre <glemaitre>`.","525","","526","- Fixed a bug in :class:`neighbors.NearestNeighbors` where fitting a","527","  NearestNeighbors model fails when a) the distance metric used is a","528","  callable and b) the input to the NearestNeighbors model is sparse.","529","  :issue:`9579` by :user:`Thomas Kober <tttthomasssss>`.","530","","531","- Fixed a bug in :class:`linear_model.RidgeClassifierCV` where","532","  the parameter ``store_cv_values`` was not implemented though","533","  it was documented in ``cv_values`` as a way to set up the storage","534","  of cross-validation values for different alphas. :issue:`10297` by","535","  :user:`Mabel Villalba-Jim¨¦nez <mabelvj>`.","536","","537","- Fixed a bug in :class:`naive_bayes.MultinomialNB` which did not accept vector","538","  valued pseudocounts (alpha).","539","  :issue:`10346` by :user:`Tobias Madsen <TobiasMadsen>`","540","","541","- Fixed a bug in :class:`svm.SVC` where when the argument ``kernel`` is","542","  unicode in Python2, the ``predict_proba`` method was raising an","543","  unexpected TypeError given dense inputs.","544","  :issue:`10412` by :user:`Jiongyan Zhang <qmick>`.","545","","546","- Fixed a bug in :class:`tree.BaseDecisionTree` with `splitter=\"best\"`","547","  where split threshold could become infinite when values in X were","548","  near infinite. :issue:`10536` by :user:`Jonathan Ohayon <Johayon>`.","549","","550","- Fixed a bug in :class:`linear_model.ElasticNet` which caused the input to be","551","  overridden when using parameter ``copy_X=True`` and ``check_input=False``.","552","  :issue:`10581` by :user:`Yacine Mazari <ymazari>`.","553","","554","- Fixed a bug in :class:`sklearn.linear_model.Lasso`","555","  where the coefficient had wrong shape when ``fit_intercept=False``.","556","  :issue:`10687` by :user:`Martin Hahn <martin-hahn>`.","557","","558","- Fixed a bug in :func:`sklearn.linear_model.LogisticRegression` where the","559","  multi_class='multinomial' with binary output with warm_start = True","560","  :issue:`10836` by :user:`Aishwarya Srinivasan <aishgrt1>`.","561","","562","- Fixed a bug in :class:`linear_model.RidgeCV` where using integer ``alphas``","563","  raised an error. :issue:`10393` by :user:`Mabel Villalba-Jim¨¦nez <mabelvj>`.","564","","565","- Fixed condition triggering gap computation in :class:`linear_model.Lasso`","566","  and :class:`linear_model.ElasticNet` when working with sparse matrices.","567","  :issue:`10992` by `Alexandre Gramfort`_.","568","","569","- Fixed a bug in :class:`linear_model.SGDClassifier`,","570","  :class:`linear_model.SGDRegressor`,","571","  :class:`linear_model.PassiveAggressiveClassifier`,","572","  :class:`linear_model.PassiveAggressiveRegressor` and","573","  :class:`linear_model.Perceptron`, where the stopping criterion was stopping","574","  the algorithm before convergence. A parameter `n_iter_no_change` was added","575","  and set by default to 5. Previous behavior is equivalent to setting the","576","  parameter to 1. :issue:`9043` by `Tom Dupre la Tour`_.","577","","578","- Fixed a bug where liblinear and libsvm-based estimators would segfault if","579","  passed a scipy.sparse matrix with 64-bit indices. They now raise a","580","  ValueError.","581","  :issue:`11327` by :user:`Karan Dhingra <kdhingra307>` and `Joel Nothman`_.","582","","583","- Fixed a bug in :class:`ensemble.gradient_boosting.GradientBoostingRegressor`","584","  and :class:`ensemble.gradient_boosting.GradientBoostingClassifier` to have","585","  feature importances summed and then normalized, rather than normalizing on a","586","  per-tree basis. The previous behavior over-weighted the Gini importance of","587","  features that appear in later stages. This issue only affected feature","588","  importances. :issue:`11176` by :user:`Gil Forsyth <gforsyth>`.","589","","590","- Fixed a bug in :class:`tree.MAE` to ensure sample weights are being used","591","  during the calculation of tree MAE impurity. Previous behaviour could","592","  cause suboptimal splits to be chosen since the impurity calculation","593","  considered all samples to be of equal weight importance.","594","  :issue:`11464` by :user:`John Stott <JohnStott>`.","595","","596","- Fixed a bug in :func:`logistic.logistic_regression_path` to ensure that the","597","  returned coefficients are correct when ``multiclass='multinomial'``.","598","  Previously, some of the coefficients would override each other, leading to","599","  incorrect results in :class:`logistic.LogisticRegressionCV`. :issue:`11724`","600","  by :user:`Nicolas Hug <NicolasHug>`.","601","","602","Decomposition, manifold learning and clustering","603","","604","- Fix for uninformative error in :class:`decomposition.IncrementalPCA`:","605","  now an error is raised if the number of components is larger than the","606","  chosen batch size. The ``n_components=None`` case was adapted accordingly.","607","  :issue:`6452`. By :user:`Wally Gauze <wallygauze>`.","608","","609","- Fixed a bug where the ``partial_fit`` method of","610","  :class:`decomposition.IncrementalPCA` used integer division instead of float","611","  division on Python 2 versions. :issue:`9492` by","612","  :user:`James Bourbeau <jrbourbeau>`.","613","","614","- Fixed a bug where the ``fit`` method of","615","  :class:`cluster.AffinityPropagation` stored cluster","616","  centers as 3d array instead of 2d array in case of non-convergence. For the","617","  same class, fixed undefined and arbitrary behavior in case of training data","618","  where all samples had equal similarity.","619","  :issue:`9612`. By :user:`Jonatan Samoocha <jsamoocha>`.","620","","621","- In :class:`decomposition.PCA` selecting a n_components parameter greater than","622","  the number of samples now raises an error.","623","  Similarly, the ``n_components=None`` case now selects the minimum of","624","  n_samples and n_features. :issue:`8484`. By :user:`Wally Gauze <wallygauze>`.","625","","626","- Fixed a bug in :func:`datasets.fetch_kddcup99`, where data were not properly","627","  shuffled. :issue:`9731` by `Nicolas Goix`_.","628","","629","- Fixed a bug in :class:`decomposition.PCA` where users will get unexpected error","630","  with large datasets when ``n_components='mle'`` on Python 3 versions.","631","  :issue:`9886` by :user:`Hanmin Qin <qinhanmin2014>`.","632","","633","- Fixed a bug when setting parameters on meta-estimator, involving both a","634","  wrapped estimator and its parameter. :issue:`9999` by :user:`Marcus Voss","635","  <marcus-voss>` and `Joel Nothman`_.","636","","637","- ``k_means`` now gives a warning, if the number of distinct clusters found","638","  is smaller than ``n_clusters``. This may occur when the number of distinct","639","  points in the data set is actually smaller than the number of cluster one is","640","  looking for. :issue:`10059` by :user:`Christian Braune <christianbraune79>`.","641","","642","- Fixed a bug in :func:`datasets.make_circles`, where no odd number of data","643","  points could be generated. :issue:`10037`","644","  by :user:`Christian Braune <christianbraune79>`.","645","","646","- Fixed a bug in :func:`cluster.spectral_clustering` where the normalization of","647","  the spectrum was using a division instead of a multiplication. :issue:`8129`","648","  by :user:`Jan Margeta <jmargeta>`, :user:`Guillaume Lemaitre <glemaitre>`,","649","  and :user:`Devansh D. <devanshdalal>`.","650","","651","- Fixed a bug in :class:`mixture.BaseMixture` where the reported `n_iter_` was","652","  missing an iteration. It affected :class:`mixture.GaussianMixture` and","653","  :class:`mixture.BayesianGaussianMixture`. :issue:`10740` by :user:`Erich","654","  Schubert <kno10>` and :user:`Guillaume Lemaitre <glemaitre>`.","655","","656","- Fixed a bug in :class:`mixture.BaseMixture` and its subclasses","657","  :class:`mixture.GaussianMixture` and :class:`mixture.BayesianGaussianMixture`","658","  where the ``lower_bound_`` was not the max lower bound across all","659","  initializations (when ``n_init > 1``), but just the lower bound of the last","660","  initialization. :issue:`10869` by :user:`Aur¨¦lien G¨¦ron <ageron>`.","661","","662","- Fixed a bug in :class:`decomposition.SparseCoder` when running OMP sparse","663","  coding in parallel using readonly memory mapped datastructures. :issue:`5956`","664","  by :user:`Vighnesh Birodkar <vighneshbirodkar>` and","665","  :user:`Olivier Grisel <ogrisel>`.","666","","667","- Fixed a bug in :func:`cluster.k_means_elkan` where the returned `iteration`","668","  was 1 less than the correct value. Also added the missing `n_iter_` attribute","669","  in the docstring of :class:`cluster.KMeans`. :issue:`11353` by","670","  :user:`Jeremie du Boisberranger <jeremiedbb>`.","671","","672","Metrics","673","","674","- Fixed a bug in :func:`metrics.precision_recall_fscore_support`","675","  when truncated `range(n_labels)` is passed as value for `labels`.","676","  :issue:`10377` by :user:`Gaurav Dhingra <gxyd>`.","677","","678","- Fixed a bug due to floating point error in :func:`metrics.roc_auc_score` with","679","  non-integer sample weights. :issue:`9786` by :user:`Hanmin Qin <qinhanmin2014>`.","680","","681","- Fixed a bug where :func:`metrics.roc_curve` sometimes starts on y-axis instead","682","  of (0, 0), which is inconsistent with the document and other implementations.","683","  Note that this will not influence the result from :func:`metrics.roc_auc_score`","684","  :issue:`10093` by :user:`alexryndin <alexryndin>`","685","  and :user:`Hanmin Qin <qinhanmin2014>`.","686","","687","- Fixed a bug to avoid integer overflow. Casted product to 64 bits integer in","688","  :func:`metrics.mutual_info_score`.","689","  :issue:`9772` by :user:`Kumar Ashutosh <thechargedneutron>`.","690","","691","- Fixed a bug where :func:`metrics.average_precision_score` will sometimes return","692","  ``nan`` when ``sample_weight`` contains 0.","693","  :issue:`9980` by :user:`Hanmin Qin <qinhanmin2014>`.","694","","695","- Fixed a bug in :func:`metrics.fowlkes_mallows_score` to avoid integer","696","  overflow. Casted return value of `contingency_matrix` to `int64` and computed","697","  product of square roots rather than square root of product.","698","  :issue:`9515` by :user:`Alan Liddell <aliddell>` and","699","  :user:`Manh Dao <manhdao>`.","700","","701","Ensemble","702","","703","- Fix allowing to obtain deterministic with :class:`BaseBagging` estimator,","704","  when comparing results generated at fit time with the one using the object","705","  attributes when ``random_state`` is set. :issue:`9723` by :user:`Guillaume","706","  Lemaitre <glemaitre>`.","707","","708","Neighbors","709","","710","- Fixed a bug so ``predict`` in :class:`neighbors.RadiusNeighborsRegressor` can","711","  handle empty neighbor set when using non uniform weights. Also raises a new","712","  warning when no neighbors are found for samples.  :issue:`9655` by","713","  :user:`Andreas Bjerre-Nielsen <abjer>`.","714","","715","- Fixed a bug in ``KDTree`` construction that results in faster construction","716","  and querying times. :issue:`11556` by :user:`Jake VanderPlas <jakevdp>`","717","","718","Feature Extraction","719","","720","- Fixed a bug in :func:`feature_extraction.image.extract_patches_2d` which would","721","  throw an exception if ``max_patches`` was greater than or equal to the number","722","  of all possible patches rather than simply returning the number of possible","723","  patches. :issue:`10100` by :user:`Varun Agrawal <varunagrawal>`","724","","725","- Fixed a bug in :class:`feature_extraction.text.CountVectorizer`,","726","  :class:`feature_extraction.text.TfidfVectorizer`,","727","  :class:`feature_extraction.text.HashingVectorizer` to support 64 bit sparse","728","  array indexing necessary to process large datasets with more than 2¡¤10\u2079 tokens","729","  (words or n-grams). :issue:`9147` by :user:`Claes-Fredrik Mannby <mannby>`","730","  and `Roman Yurchak`_.","731","","732","- Fixed bug in :class:`feature_extraction.text.TFIDFVectorizer` which","733","  was ignoring the parameter ``dtype``. In addition,","734","  :class:`feature_extraction.text.TFIDFTransformer` will preserve ``dtype``","735","  for floating and raise a warning if ``dtype`` requested is integer.","736","  :issue:`10441` by :user:`Mayur Kulkarni <maykulkarni>` and","737","  :user:`Guillaume Lemaitre <glemaitre>`.","738","","739","Utils","740","","741","- :func:`utils.check_array` yield a ``FutureWarning`` indicating","742","  that arrays of bytes\/strings will be interpreted as decimal numbers","743","  beginning in version 0.22. :issue:`10229` by :user:`Ryan Lee <rtlee9>`","744","","745","Preprocessing","746","","747","- Fixed bugs in :class:`preprocessing.LabelEncoder` which would sometimes throw","748","  errors when ``transform`` or ``inverse_transform`` was called with empty arrays.","749","  :issue:`10458` by :user:`Mayur Kulkarni <maykulkarni>`.","750","","751","- Fix ValueError in :class:`preprocessing.LabelEncoder` when using","755","- Fix bug in :class:`preprocessing.OneHotEncoder` which discarded the ``dtype``","756","  when returning a sparse matrix output. :issue:`11042` by :user:`Daniel","757","  Morales <DanielMorales9>`.","759","- Fix ``fit`` and ``partial_fit`` in :class:`preprocessing.StandardScaler` in","760","  the rare case when `with_mean=False` and `with_std=False` which was crashing","761","  by calling ``fit`` more than once and giving inconsistent results for","762","  ``mean_`` whether the input was a sparse or a dense matrix. ``mean_`` will be","763","  set to ``None`` with both sparse and dense inputs. ``n_samples_seen_`` will","764","  be also reported for both input types.","767","Feature selection","768","","769","- Fixed computation of ``n_features_to_compute`` for edge case with tied CV","770","  scores in :class:`feature_selection.RFECV`. :issue:`9222` by `Nick Hoh","771","  <nickypie>`.","772","","773","Model evaluation and meta-estimators","774","","775","- Add improved error message in :func:`model_selection.cross_val_score` when","776","  multiple metrics are passed in ``scoring`` keyword.","777","  :issue:`11006` by :user:`Ming Li <minggli>`.","778","","779","Datasets","780","","781","- Fixed a bug in :func:`datasets.load_boston` which had a wrong data point.","782","  :issue:`10801` by :user:`Takeshi Yoshizawa <tarcusx>`.","783","","784","- Fixed a bug in :func:`datasets.load_iris` which had two wrong data points.","785","  :issue:`11082` by :user:`Sadhana Srinivasan <rotuna>`","786","  and :user:`Hanmin Qin <qinhanmin2014>`.","787","","788","API changes summary","789","-------------------","790","","791","Classifiers and regressors","792","","793","- The default value of the ``n_estimators`` parameter of","794","  :class:`ensemble.RandomForestClassifier`, :class:`ensemble.RandomForestRegressor`,","795","  :class:`ensemble.ExtraTreesClassifier`, :class:`ensemble.ExtraTreesRegressor`,","796","  and :class:`ensemble.RandomTreesEmbedding` will change from 10 in version 0.20","797","  to 100 in 0.22. A FutureWarning is raised when the default value is used.","798","  :issue:`11542` by :user:`Anna Ayzenshtat <annaayzenshtat>`.","799","","800","Linear, kernelized and related models","801","","802","- Deprecate ``random_state`` parameter in :class:`svm.OneClassSVM` as the","803","  underlying implementation is not random.","804","  :issue:`9497` by :user:`Albert Thomas <albertcthomas>`.","805","","806","- Deprecate ``positive=True`` option in :class:`linear_model.Lars` as the","807","  underlying implementation is broken. Use :class:`linear_model.Lasso` instead.","808","  :issue:`9837` by `Alexandre Gramfort`_.","809","","810","- ``n_iter_`` may vary from previous releases in","811","  :class:`linear_model.LogisticRegression` with ``solver='lbfgs'`` and","812","  :class:`linear_model.HuberRegressor`.  For Scipy <= 1.0.0, the optimizer could","813","  perform more than the requested maximum number of iterations. Now both","814","  estimators will report at most ``max_iter`` iterations even if more were","815","  performed. :issue:`10723` by `Joel Nothman`_.","816","","817","- The default value of ``gamma`` parameter of :class:`svm.SVC`,","818","  :class:`~svm.NuSVC`, :class:`~svm.SVR`, :class:`~svm.NuSVR`,","819","  :class:`~svm.OneClassSVM` will change from ``'auto'`` to ``'scale'`` in","820","  version 0.22 to account better for unscaled features. :issue:`8361` by","821","  :user:`Gaurav Dhingra <gxyd>` and :user:`Ting Neo <neokt>`.","822","","823","- Added convergence warning to :class:`svm.LinearSVC` and","824","  :class:`linear_model.LogisticRegression` when ``verbose`` is set to 0.","825","  :issue:`10881` by :user:`Alexandre Sevin <AlexandreSev>`.","826","","827","Preprocessing","828","","829","- Deprecate ``n_values`` and ``categorical_features`` parameters and","838","Decomposition, manifold learning and clustering","839","","840","- Deprecate ``precomputed`` parameter in function","841","  :func:`manifold.t_sne.trustworthiness`. Instead, the new parameter","842","  ``metric`` should be used with any compatible metric including","843","  'precomputed', in which case the input matrix ``X`` should be a matrix of","844","  pairwise distances or squared distances. :issue:`9775` by","845","  :user:`William de Vazelhes <wdevazelhes>`.","846","","847","- Added function :func:`fit_predict` to :class:`mixture.GaussianMixture` and","848","  :class:`mixture.GaussianMixture`, which is essentially equivalent to calling","849","  :func:`fit` and :func:`predict`. :issue:`10336` by","850","  :user:`Shu Haoran <haoranShu>` and :user:`Andrew Peng <Andrew-peng>`.","851","","852","Metrics","853","","854","- Deprecate ``reorder`` parameter in :func:`metrics.auc` as it's no longer required","855","  for :func:`metrics.roc_auc_score`. Moreover using ``reorder=True`` can hide bugs","856","  due to floating point error in the input.","857","  :issue:`9851` by :user:`Hanmin Qin <qinhanmin2014>`.","858","","859","- In :func:`metrics.normalized_mutual_information_score` and","860","  :func:`metrics.adjusted_mutual_information_score`,","861","  warn that ``average_method``","862","  will have a new default value. In version 0.22, the default normalizer for each","863","  will become the *arithmetic* mean of the entropies of each clustering. Currently,","864","  :func:`metrics.normalized_mutual_information_score` uses the default of","865","  ``average_method='geometric'``, and :func:`metrics.adjusted_mutual_information_score`","866","  uses the default of ``average_method='max'`` to match their behaviors in","867","  version 0.19.","868","  :issue:`11124` by :user:`Arya McCarthy <aryamccarthy>`.","869","","870","- The ``batch_size`` parameter to :func:`metrics.pairwise_distances_argmin_min`","871","  and :func:`metrics.pairwise_distances_argmin` is deprecated to be removed in","872","  v0.22.  It no longer has any effect, as batch size is determined by global","873","  ``working_memory`` config. See :ref:`working_memory`. :issue:`10280` by `Joel","874","  Nothman`_ and :user:`Aman Dalmia <dalmia>`.","875","","876","Cluster","877","","878","- Deprecate ``pooling_func`` unused parameter in","879","  :class:`cluster.AgglomerativeClustering`. :issue:`9875` by :user:`Kumar Ashutosh","882","Ensemble","884","- Classes derived from :class:`ensemble.BaseBagging`. The attribute","885","  ``estimators_samples_`` will return a list of arrays containing the indices","886","  selected for each bootstrap instead of a list of arrays containing the mask","887","  of the samples selected for each bootstrap. Indices allows to repeat samples","888","  while mask does not allow this functionality. :issue:`9524` by","889","  :user:`Guillaume Lemaitre <glemaitre>`.","891","Imputer","893","- Deprecate :class:`preprocessing.Imputer` and move the corresponding module to","894","  :class:`impute.SimpleImputer`. :issue:`9726` by :user:`Kumar Ashutosh","895","  <thechargedneutron>`.","897","- The ``axis`` parameter that was in :class:`preprocessing.Imputer` is no","898","  longer present in :class:`impute.SimpleImputer`. The behavior is equivalent","899","  to ``axis=0`` (impute along columns). Row-wise imputation can be performed","900","  with FunctionTransformer (e.g., ``FunctionTransformer(lambda X:","901","  SimpleImputer().fit_transform(X.T).T)``). :issue:`10829` by :user:`Guillaume","902","  Lemaitre <glemaitre>` and :user:`Gilberto Olimpio <gilbertoolimpio>`.","904","- The :class:`impute.SimpleImputer` has a new strategy, ``'constant'``, to","905","  complete missing values with a fixed one, given by the ``fill_value``","906","  parameter. This strategy supports numeric and non-numeric data, and so does","907","  the ``'most_frequent'`` strategy now. :issue:`11211` by :user:`Jeremie du","908","  Boisberranger <jeremiedbb>`.","910","- The NaN marker for the missing values has been changed between the","911","  :class:`preprocessing.Imputer` and the :class:`impute.SimpleImputer`.","912","  ``missing_values='NaN'``?should now be ``missing_values=np.nan``.","913","  :issue:`11211` by :user:`Jeremie du Boisberranger <jeremiedbb>`.","915","Outlier Detection models","917","- More consistent outlier detection API:","933","- Novelty detection with :class:`neighbors.LocalOutlierFactor`:","934","  Add a ``novelty`` parameter to :class:`neighbors.LocalOutlierFactor`. When","935","  ``novelty`` is set to True, :class:`neighbors.LocalOutlierFactor` can then ","936","  be used for novelty detection, i.e. predict on new unseen data. Available","937","  prediction methods are ``predict``, ``decision_function`` and","938","  ``score_samples``. By default, ``novelty`` is set to ``False``, and only","939","  the ``fit_predict`` method is avaiable.","940","  By :user:`Albert Thomas <albertcthomas>`.","941","","953","Covariance","955","- The :func:`covariance.graph_lasso`, :class:`covariance.GraphLasso` and","956","  :class:`covariance.GraphLassoCV` have been renamed to","957","  :func:`covariance.graphical_lasso`, :class:`covariance.GraphicalLasso` and","958","  :class:`covariance.GraphicalLassoCV` respectively and will be removed in version 0.22.","959","  :issue:`9993` by :user:`Artiem Krinitsyn <artiemq>`","960","","961","Misc","962","","963","- Changed warning type from :class:`UserWarning` to","973","- Changed ValueError exception raised in :class:`model_selection.ParameterSampler`","974","  to a UserWarning for case where the class is instantiated with a greater value of","975","  ``n_iter`` than the total space of parameters in the parameter grid. ``n_iter`` now","976","  acts as an upper bound on iterations.","977","  :issue:`#10982` by :user:`Juliet Lawton <julietcl>`","979","- Invalid input for :class:`model_selection.ParameterGrid` now raises TypeError.","980","  :issue:`10928` by :user:`Solutus Immensus <solutusimmensus>`","982","- :func:`utils.check_array` and :func:`utils.check_X_y` now have","983","  ``accept_large_sparse`` to control whether scipy.sparse matrices with 64-bit","984","  indices should be rejected.","985","  :issue:`11327` by :user:`Karan Dhingra <kdhingra307>` and `Joel Nothman`_.","987","Preprocessing","989","- In :class:`preprocessing.FunctionTransformer`, the default of ``validate``","990","  will be from ``True`` to ``False`` in 0.22.","991","  :issue:`10655` by :user:`Guillaume Lemaitre <glemaitre>`.","993","Model selection","994","","995","- The default number of cross-validation folds ``cv`` and the default number of","996","  splits ``n_splits`` in the :class:`model_selection.KFold`-like splitters will change","997","  from 3 to 5 in 0.22 as 3-fold has a lot of variance.","998","  :issue:`11557` by :user:`Alexandre Boucaud <aboucaud>`."]}],"doc\/themes\/scikit-learn\/static\/css\/bootstrap.css":[{"add":["911",".label-danger,","912",".badge-danger {","913","  \/* XXX: backported from later bootstrap *\/","914","  background-color: #d9534f;","915","}"],"delete":[]}],"doc\/whats_new\/_contributors.rst":[{"add":["6","    It also defines other ReST substitutions.","7","","8",".. role:: raw-html(raw)","9","   :format: html","10","","11",".. role:: raw-latex(raw)","12","   :format: latex","13","","14",".. |MajorFeature| replace:: :raw-html:`<span class=\"label label-success\">Major Feature<\/span>` :raw-latex:`{\\small\\sc [Major Feature]}`","15",".. |Feature| replace:: :raw-html:`<span class=\"label label-success\">Feature<\/span>` :raw-latex:`{\\small\\sc [Feature]}`","16",".. |Efficiency| replace:: :raw-html:`<span class=\"label label-info\">Efficiency<\/span>` :raw-latex:`{\\small\\sc [Efficiency]}`","17",".. |Enhancement| replace:: :raw-html:`<span class=\"label label-info\">Enhancement<\/span>` :raw-latex:`{\\small\\sc [Enhancement]}`","18",".. |Fix| replace:: :raw-html:`<span class=\"label label-danger\">Fix<\/span>` :raw-latex:`{\\small\\sc [Fix]}`","19",".. |API| replace:: :raw-html:`<span class=\"label label-warning\">API Change<\/span>` :raw-latex:`{\\small\\sc [API Change]}`"],"delete":[]}],"doc\/themes\/scikit-learn\/static\/css\/bootstrap.min.css":[{"add":["166",".label-danger,.badge-danger {\/* XXX: backported from later bootstrap *\/background-color: #d9534f;}"],"delete":[]}]}},"6b4e00deb02951ff5ab7cd8a70309381db4226f9":{"changes":{"sklearn\/preprocessing\/_discretization.py":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY"},"diff":{"sklearn\/preprocessing\/_discretization.py":[{"add":["194","            # Fit the OneHotEncoder with toy datasets","195","            # so that it's ready for use after the KBinsDiscretizer is fitted","196","            self._encoder.fit(np.zeros((1, len(self.n_bins_)), dtype=int))","272","        return self._encoder.transform(Xt)"],"delete":["269","        return self._encoder.fit_transform(Xt)"]}],"doc\/whats_new\/v0.20.rst":[{"add":["136","- |Fix| Fixed bug in :class:`preprocessing.OrdinalEncoder` when passing","137","  manually specified categories. :issue:`12365` by `Joris Van den Bossche`_.","138","","139","- |Fix| Fixed bug in :class:`preprocessing.KBinsDiscretizer` where the","140","  ``transform`` method mutates the ``_encoder`` attribute. The ``transform``","141","  method is now thread safe. :issue:`12514` by","142","  :user:`Hanmin Qin <qinhanmin2014>`.","143",""],"delete":["142","- |Fix| Fixed bug in :class:`preprocessing.OrdinalEncoder` when passing","143","  manually specified categories. :issue:`12365` by `Joris Van den Bossche`_.","144",""]}]}},"1b90237b45dfa1652831cfe72bd4b29a31b070ec":{"changes":{"sklearn\/tests\/test_pipeline.py":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/pipeline.py":"MODIFY"},"diff":{"sklearn\/tests\/test_pipeline.py":[{"add":["577","def test_pipeline_correctly_adjusts_steps(passthrough):","578","    X = np.array([[1]])","579","    y = np.array([1])","580","    mult2 = Mult(mult=2)","581","    mult3 = Mult(mult=3)","582","    mult5 = Mult(mult=5)","583","","584","    pipeline = Pipeline([","585","        ('m2', mult2),","586","        ('bad', passthrough),","587","        ('m3', mult3),","588","        ('m5', mult5)","589","    ])","590","","591","    pipeline.fit(X, y)","592","    expected_names = ['m2', 'bad', 'm3', 'm5']","593","    actual_names = [name for name, _ in pipeline.steps]","594","    assert expected_names == actual_names","595","","596","","597","@pytest.mark.parametrize('passthrough', [None, 'passthrough'])"],"delete":[]}],"doc\/whats_new\/v0.20.rst":[{"add":["17",":mod:`sklearn.pipeline`","18",".......................","20","- |Fix| Fixed a regression in :class:`pipeline.Pipeline` where the ``steps``","21","  parameter may not have been updated correctly when a step is set to ``None``","22","  or ``'passthrough'``. :user:`Thomas Fan <thomasjpfan>`."],"delete":[]}],"sklearn\/pipeline.py":[{"add":["186","        for idx, (name, trans) in enumerate(islice(self.steps, 0, stop)):","188","                yield idx, name, trans","221","        for step_idx, name, transformer in self._iter(with_final=False):","342","        for _, name, transform in self._iter(with_final=False):","391","        for _, name, transform in self._iter(with_final=False):","410","        for _, name, transform in self._iter(with_final=False):","429","        for _, name, transform in self._iter(with_final=False):","458","        for _, _, transform in self._iter():","482","        for _, _, transform in self._iter():","489","        for _, _, transform in reverse_iter:","516","        for _, name, transform in self._iter(with_final=False):"],"delete":["186","        for name, trans in islice(self.steps, 0, stop):","188","                yield name, trans","221","        for step_idx, (name, transformer) in enumerate(","222","                self._iter(with_final=False)):","343","        for name, transform in self._iter(with_final=False):","392","        for name, transform in self._iter(with_final=False):","411","        for name, transform in self._iter(with_final=False):","430","        for name, transform in self._iter(with_final=False):","459","        for _, transform in self._iter():","483","        for _, transform in self._iter():","490","        for _, transform in reverse_iter:","517","        for name, transform in self._iter(with_final=False):"]}]}},"fb0e0fcf5f94b4db515749023da4db0ff06a4fd6":{"changes":{"examples\/preprocessing\/plot_discretization_classification.py":"MODIFY","examples\/svm\/plot_svm_scale_c.py":"MODIFY"},"diff":{"examples\/preprocessing\/plot_discretization_classification.py":[{"add":["101","fig, axes = plt.subplots(nrows=len(datasets), ncols=len(classifiers) + 1,","102","                         figsize=(21, 9))","103","","106","","123","    ax = axes[ds_cnt, 0]","138","    for est_idx, (name, (estimator, param_grid)) in \\","139","            enumerate(zip(names, classifiers)):","140","        ax = axes[ds_cnt, est_idx + 1]","187","for i, suptitle in zip([1, 3, 5], suptitles):","188","    ax = axes[0, i]"],"delete":["101","figure = plt.figure(figsize=(21, 9))","104","i = 1","121","    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)","134","    i += 1","137","    for name, (estimator, param_grid) in zip(names, classifiers):","138","        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)","175","        i += 1","186","for i, suptitle in zip([2, 4, 6], suptitles):","187","    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)"]}],"examples\/svm\/plot_svm_scale_c.py":[{"add":["121","for clf, cs, X, y in clf_sets:","123","    fig, axes = plt.subplots(nrows=2, sharey=True, figsize=(9, 10))","140","        for ax, (scaler, name) in zip(axes, scales):","141","            ax.set_xlabel('C')","142","            ax.set_ylabel('CV Score')","144","            ax.semilogx(grid_cs, scores, label=\"fraction %.2f\" %","145","                        train_size, color=colors[k], lw=lw)","146","            ax.set_title('scaling=%s, penalty=%s, loss=%s' %","147","                         (name, clf.penalty, clf.loss))"],"delete":["121","for fignum, (clf, cs, X, y) in enumerate(clf_sets):","123","    plt.figure(fignum, figsize=(9, 10))","140","        for subplotnum, (scaler, name) in enumerate(scales):","141","            plt.subplot(2, 1, subplotnum + 1)","142","            plt.xlabel('C')","143","            plt.ylabel('CV Score')","145","            plt.semilogx(grid_cs, scores, label=\"fraction %.2f\" %","146","                         train_size, color=colors[k], lw=lw)","147","            plt.title('scaling=%s, penalty=%s, loss=%s' %","148","                      (name, clf.penalty, clf.loss))"]}]}},"dca915638729878683b5bca57bf7a7c35acd6045":{"changes":{"doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/neural_network\/multilayer_perceptron.py":"MODIFY","sklearn\/neural_network\/tests\/test_mlp.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.21.rst":[{"add":["194",":mod:`sklearn.neural_network`","195",".............................","196","","197","- |Fix| Fixed a bug in :class:`neural_network.MLPClassifier` and","198","  :class:`neural_network.MLPRegressor` where the option :code:`shuffle=False`","199","  was being ignored. :issue:`12582` by :user:`Sam Waterbury <samwaterbury>`.","200",""],"delete":[]}],"sklearn\/neural_network\/multilayer_perceptron.py":[{"add":["504","                if self.shuffle:","505","                    X, y = shuffle(X, y, random_state=self._random_state)"],"delete":["504","                X, y = shuffle(X, y, random_state=self._random_state)"]}],"sklearn\/neural_network\/tests\/test_mlp.py":[{"add":["497","def test_shuffle():","498","    # Test that the shuffle parameter affects the training process (it should)","499","    X, y = make_regression(n_samples=50, n_features=5, n_targets=1,","500","                           random_state=0)","501","","502","    # The coefficients will be identical if both do or do not shuffle","503","    for shuffle in [True, False]:","504","        mlp1 = MLPRegressor(hidden_layer_sizes=1, max_iter=1, batch_size=1,","505","                            random_state=0, shuffle=shuffle)","506","        mlp2 = MLPRegressor(hidden_layer_sizes=1, max_iter=1, batch_size=1,","507","                            random_state=0, shuffle=shuffle)","508","        mlp1.fit(X, y)","509","        mlp2.fit(X, y)","510","","511","        assert np.array_equal(mlp1.coefs_[0], mlp2.coefs_[0])","512","","513","    # The coefficients will be slightly different if shuffle=True","514","    mlp1 = MLPRegressor(hidden_layer_sizes=1, max_iter=1, batch_size=1,","515","                        random_state=0, shuffle=True)","516","    mlp2 = MLPRegressor(hidden_layer_sizes=1, max_iter=1, batch_size=1,","517","                        random_state=0, shuffle=False)","518","    mlp1.fit(X, y)","519","    mlp2.fit(X, y)","520","","521","    assert not np.array_equal(mlp1.coefs_[0], mlp2.coefs_[0])","522","","523",""],"delete":[]}]}},"2020867b8ffa6325a386591fa8dfcf62ad3128ff":{"changes":{"sklearn\/cluster\/tests\/test_optics.py":"MODIFY","sklearn\/cluster\/optics_.py":"MODIFY"},"diff":{"sklearn\/cluster\/tests\/test_optics.py":[{"add":["90","    msg = \"Specify an epsilon smaller than 0.15. Got 0.3.\"","96","    clust = OPTICS(max_eps=5.0 * 0.03, min_samples=10)","101","def test_bad_reachability():","102","    msg = \"All reachability values are inf. Set a larger max_eps.\"","103","    centers = [[1, 1], [-1, -1], [1, -1]]","104","    X, labels_true = make_blobs(n_samples=750, centers=centers,","105","                                cluster_std=0.4, random_state=0)","106","","107","    clust = OPTICS(max_eps=5.0 * 0.003, min_samples=10)","108","    assert_raise_message(ValueError, msg, clust.fit, X)","109","","110",""],"delete":["90","    msg = \"Specify an epsilon smaller than 0.015. Got 0.3.\"","96","    clust = OPTICS(max_eps=5.0 * 0.003, min_samples=10)"]}],"sklearn\/cluster\/optics_.py":[{"add":["655","    # according to Ankerst M. et.al. 1999 (p. 5), for a small enough","656","    # generative distance epsilong, there should be more than one INF.","657","    if np.all(np.isinf(reachability)):","658","        raise ValueError(\"All reachability values are inf. Set a larger\"","659","                         \" max_eps.\")","660","    normalization_factor = np.max(reachability[reachability < np.inf])","661","    reachability = reachability \/ normalization_factor","806","    if ((avg_reach1 \/ maxima_ratio) > reachability_plot[s] or","807","            (avg_reach2 \/ maxima_ratio) > reachability_plot[s]):","809","        if (avg_reach1 \/ rejection_ratio) < reachability_plot[s]:","812","        if (avg_reach2 \/ rejection_ratio) < reachability_plot[s]:","815","        if ((avg_reach1 \/ rejection_ratio) >= reachability_plot[s] and","816","                (avg_reach2 \/ rejection_ratio) >= reachability_plot[s]):"],"delete":["655","    reachability = reachability \/ np.max(reachability[1:])","800","    if ((avg_reach1 \/ reachability_plot[s]) > maxima_ratio or","801","            (avg_reach2 \/ reachability_plot[s]) > maxima_ratio):","803","        if (avg_reach1 \/ reachability_plot[s]) < rejection_ratio:","806","        if (avg_reach2 \/ reachability_plot[s]) < rejection_ratio:","809","        if ((avg_reach1 \/ reachability_plot[s]) >= rejection_ratio and","810","                (avg_reach2 \/ reachability_plot[s]) >= rejection_ratio):"]}]}},"aae4e337d2c93d9005f5d13c62e80209740dce6a":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/compose\/tests\/test_column_transformer.py":"MODIFY","sklearn\/compose\/_column_transformer.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["27",":mod:`sklearn.compose`","28","......................","29","","30","- |Fix| Fixed an issue in :func:`compose.make_column_transformer` which raises","31","  unexpected error when columns is pandas Index or pandas Series.","32","  :issue:`12704` by :user:`Hanmin Qin <qinhanmin2014>`.","33",""],"delete":[]}],"sklearn\/compose\/tests\/test_column_transformer.py":[{"add":["543","def test_make_column_transformer_pandas():","544","    pd = pytest.importorskip('pandas')","545","    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T","546","    X_df = pd.DataFrame(X_array, columns=['first', 'second'])","547","    norm = Normalizer()","548","    # XXX remove in v0.22","549","    with pytest.warns(DeprecationWarning,","550","                      match='`make_column_transformer` now expects'):","551","        ct1 = make_column_transformer((X_df.columns, norm))","552","    ct2 = make_column_transformer((norm, X_df.columns))","553","    assert_almost_equal(ct1.fit_transform(X_df),","554","                        ct2.fit_transform(X_df))","555","","556",""],"delete":[]}],"sklearn\/compose\/_column_transformer.py":[{"add":["694","        if isinstance(t, six.string_types) and t in ('drop', 'passthrough'):"],"delete":["694","        if t in ('drop', 'passthrough'):"]}]}},"94db3d932c393569be97886642049c8920182a77":{"changes":{"sklearn\/metrics\/scorer.py":"MODIFY","sklearn\/metrics\/tests\/test_score_objects.py":"MODIFY"},"diff":{"sklearn\/metrics\/scorer.py":[{"add":["128","            if y_pred.shape[1] == 2:","129","                y_pred = y_pred[:, 1]","130","            else:","131","                raise ValueError('got predict_proba of shape {},'","132","                                 ' but need classifier with two'","133","                                 ' classes for {} scoring'.format(","134","                                     y_pred.shape, self._score_func.__name__))","191","                    if y_pred.shape[1] == 2:","192","                        y_pred = y_pred[:, 1]","193","                    else:","194","                        raise ValueError('got predict_proba of shape {},'","195","                                         ' but need classifier with two'","196","                                         ' classes for {} scoring'.format(","197","                                             y_pred.shape,","198","                                             self._score_func.__name__))"],"delete":["128","            y_pred = y_pred[:, 1]","185","                    y_pred = y_pred[:, 1]"]}],"sklearn\/metrics\/tests\/test_score_objects.py":[{"add":["188","    # This wraps the _check_multimetric_scoring to take in","189","    # single metric scoring parameter so we can run the tests","190","    # that we will run for check_scoring, for check_multimetric_scoring","191","    # too for single-metric usecases","192","","373","    with pytest.raises(ValueError, match=\"multiclass format is not supported\"):","374","        get_scorer('roc_auc')(clf, X_test, y_test)","375","","376","    # test error is raised with a single class present in model","377","    # (predict_proba shape is not suitable for binary auc)","378","    X, y = make_blobs(random_state=0, centers=2)","379","    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","380","    clf = DecisionTreeClassifier()","381","    clf.fit(X_train, np.zeros_like(y_train))","382","    with pytest.raises(ValueError, match=\"need classifier with two classes\"):","383","        get_scorer('roc_auc')(clf, X_test, y_test)","384","","385","    # for proba scorers","386","    with pytest.raises(ValueError, match=\"need classifier with two classes\"):","387","        get_scorer('neg_log_loss')(clf, X_test, y_test)"],"delete":["188","    # This wraps the _check_multimetric_scoring to take in single metric","189","    # scoring parameter so we can run the tests that we will run for","190","    # check_scoring, for check_multimetric_scoring too for single-metric","191","    # usecases","372","    assert_raises(ValueError, get_scorer('roc_auc'), clf, X_test, y_test)"]}]}},"440c08684fb7edb31c7257e86b6f6481f69ba5c9":{"changes":{"sklearn\/model_selection\/_split.py":"MODIFY","sklearn\/model_selection\/tests\/test_split.py":"MODIFY"},"diff":{"sklearn\/model_selection\/_split.py":[{"add":["1796","            if test_size >= 1. or test_size <= 0:","1798","                    'test_size=%f should be in the (0, 1) range '","1799","                    'or be an integer' % test_size)","1806","            if train_size >= 1. or train_size <= 0:","1807","                raise ValueError('train_size=%f should be in the (0, 1) range '","1808","                                 'or be an integer' % train_size)","1810","                    (","1811","                        (train_size + test_size) > 1. or","1812","                        (train_size + test_size) < 0)):","1814","                                 'should be in the (0, 1) range. Reduce '","1828","            (np.asarray(test_size).dtype.kind == 'i' and","1829","                (test_size >= n_samples or test_size <= 0)) or","1830","            (np.asarray(test_size).dtype.kind == 'f' and","1831","                (test_size <= 0 or test_size >= 1))):","1832","        raise ValueError('test_size=%d should be either positive and smaller '","1833","                         'than the number of samples %d or a float in the '","1834","                         '(0,1) range' % (test_size, n_samples))","1837","            (np.asarray(train_size).dtype.kind == 'i' and","1838","                (train_size >= n_samples or train_size <= 0)) or","1839","            (np.asarray(train_size).dtype.kind == 'f' and","1840","                (train_size <= 0 or train_size >= 1))):","1841","        raise ValueError('train_size=%d should be either positive and smaller '","1842","                         'than the number of samples %d or a float in the '","1843","                         '(0,1) range' % (train_size, n_samples))"],"delete":["1796","            if test_size >= 1.:","1798","                    'test_size=%f should be smaller '","1799","                    'than 1.0 or be an integer' % test_size)","1806","            if train_size >= 1.:","1807","                raise ValueError(\"train_size=%f should be smaller \"","1808","                                 \"than 1.0 or be an integer\" % train_size)","1810","                    (train_size + test_size) > 1.):","1812","                                 'should be smaller than 1.0. Reduce '","1826","            np.asarray(test_size).dtype.kind == 'i' and","1827","            test_size >= n_samples):","1828","        raise ValueError('test_size=%d should be smaller than the number of '","1829","                         'samples %d' % (test_size, n_samples))","1832","            np.asarray(train_size).dtype.kind == 'i' and","1833","            train_size >= n_samples):","1834","        raise ValueError(\"train_size=%d should be smaller than the number of\"","1835","                         \" samples %d\" % (train_size, n_samples))"]}],"sklearn\/model_selection\/tests\/test_split.py":[{"add":["1008","    pytest.raises(ValueError, train_test_split)","1013","        pytest.raises(ValueError, train_test_split, range(3), train_size=1.1)","1015","    pytest.raises(ValueError, train_test_split, range(3), test_size=0.6,","1017","    pytest.raises(ValueError, train_test_split, range(3),","1019","    pytest.raises(ValueError, train_test_split, range(3),","1021","    pytest.raises(ValueError, train_test_split, range(3), test_size=2,","1023","    pytest.raises(TypeError, train_test_split, range(3),","1025","    pytest.raises(ValueError, train_test_split, range(3), range(42))","1026","    pytest.raises(ValueError, train_test_split, range(10),","1029","    with pytest.raises(ValueError,","1030","                       match=r'train_size=11 should be either positive and '","1031","                             r'smaller than the number of samples 10 or a '","1032","                             r'float in the \\(0,1\\) range'):","1033","        train_test_split(range(10), train_size=11, test_size=1)","1034","","1035","","1036","@pytest.mark.parametrize(\"train_size,test_size\", [","1037","    (1.2, 0.8),","1038","    (1., 0.8),","1039","    (0.0, 0.8),","1040","    (-.2, 0.8),","1041","    (0.8, 1.2),","1042","    (0.8, 1.),","1043","    (0.8, 0.),","1044","    (0.8, -.2)])","1045","def test_train_test_split_invalid_sizes1(train_size, test_size):","1046","    with pytest.raises(ValueError, match=r'should be in the \\(0, 1\\) range'):","1047","        train_test_split(range(10), train_size=train_size, test_size=test_size)","1048","","1049","","1050","@pytest.mark.parametrize(\"train_size,test_size\", [","1051","    (-10, 0.8),","1052","    (0, 0.8),","1053","    (11, 0.8),","1054","    (0.8, -10),","1055","    (0.8, 0),","1056","    (0.8, 11)])","1057","def test_train_test_split_invalid_sizes2(train_size, test_size):","1058","    with pytest.raises(ValueError,","1059","                       match=r'should be either positive and smaller'):","1060","        train_test_split(range(10), train_size=train_size, test_size=test_size)","1061",""],"delete":["1008","    assert_raises(ValueError, train_test_split)","1013","        assert_raises(ValueError, train_test_split, range(3), train_size=1.1)","1015","    assert_raises(ValueError, train_test_split, range(3), test_size=0.6,","1017","    assert_raises(ValueError, train_test_split, range(3),","1019","    assert_raises(ValueError, train_test_split, range(3),","1021","    assert_raises(ValueError, train_test_split, range(3), test_size=2,","1023","    assert_raises(TypeError, train_test_split, range(3),","1025","    assert_raises(ValueError, train_test_split, range(3), range(42))","1026","    assert_raises(ValueError, train_test_split, range(10),"]}]}},"cf9a74059851c91b3b7c5b354b85e1e87ff628bf":{"changes":{"sklearn\/utils\/fixes.py":"MODIFY","sklearn\/feature_extraction\/text.py":"MODIFY","sklearn\/neighbors\/tests\/test_neighbors.py":"MODIFY","sklearn\/naive_bayes.py":"MODIFY","sklearn\/preprocessing\/_encoders.py":"MODIFY","sklearn\/datasets\/kddcup99.py":"MODIFY","sklearn\/metrics\/cluster\/supervised.py":"MODIFY","sklearn\/neighbors\/tests\/test_dist_metrics.py":"MODIFY","sklearn\/preprocessing\/imputation.py":"MODIFY","sklearn\/datasets\/tests\/test_svmlight_format.py":"MODIFY","sklearn\/decomposition\/tests\/test_pca.py":"MODIFY","sklearn\/datasets\/rcv1.py":"MODIFY","sklearn\/metrics\/tests\/test_pairwise.py":"MODIFY","sklearn\/preprocessing\/tests\/test_data.py":"MODIFY","sklearn\/utils\/tests\/test_extmath.py":"MODIFY","sklearn\/tree\/tests\/test_tree.py":"MODIFY","sklearn\/datasets\/base.py":"MODIFY","sklearn\/cluster\/hierarchical.py":"MODIFY","sklearn\/metrics\/tests\/test_classification.py":"MODIFY","sklearn\/manifold\/tests\/test_t_sne.py":"MODIFY","sklearn\/neighbors\/tests\/test_kd_tree.py":"MODIFY","sklearn\/datasets\/samples_generator.py":"MODIFY","sklearn\/preprocessing\/base.py":"MODIFY","sklearn\/datasets\/openml.py":"MODIFY","sklearn\/preprocessing\/data.py":"MODIFY","sklearn\/ensemble\/tests\/test_bagging.py":"MODIFY","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/datasets\/covtype.py":"MODIFY","sklearn\/feature_selection\/mutual_info_.py":"MODIFY","sklearn\/svm\/base.py":"MODIFY","sklearn\/feature_extraction\/_hashing.pyx":"MODIFY","sklearn\/metrics\/cluster\/expected_mutual_info_fast.pyx":"MODIFY","sklearn\/cluster\/tests\/test_hierarchical.py":"MODIFY","sklearn\/neighbors\/tests\/test_ball_tree.py":"MODIFY","sklearn\/cluster\/k_means_.py":"MODIFY"},"diff":{"sklearn\/utils\/fixes.py":[{"add":["187","# TODO: replace by copy=False, when only scipy > 1.1 is supported.","188","def _astype_copy_false(X):","189","    \"\"\"Returns the copy=False parameter for","190","    {ndarray, csr_matrix, csc_matrix}.astype when possible,","191","    otherwise don't specify","192","    \"\"\"","193","    if sp_version >= (1, 1) or not sp.issparse(X):","194","        return {'copy': False}","195","    else:","196","        return {}","197","","198",""],"delete":[]}],"sklearn\/feature_extraction\/text.py":[{"add":["32","from ..utils.fixes import _astype_copy_false","1242","            df = _document_frequency(X)","1243","            df = df.astype(dtype, **_astype_copy_false(df))"],"delete":["1241","            df = _document_frequency(X).astype(dtype)"]}],"sklearn\/neighbors\/tests\/test_neighbors.py":[{"add":["827","    score_float = clf.fit(X_train.astype(float, copy=False), Y_train).score(","828","        X_test.astype(float, copy=False), Y_test)"],"delete":["827","    score_float = clf.fit(X_train.astype(float), Y_train).score(","828","        X_test.astype(float), Y_test)"]}],"sklearn\/naive_bayes.py":[{"add":["548","        Y = Y.astype(np.float64, copy=False)","599","        Y = Y.astype(np.float64, copy=False)"],"delete":["548","        Y = Y.astype(np.float64)","599","        Y = Y.astype(np.float64)"]}],"sklearn\/preprocessing\/_encoders.py":[{"add":["992","            labels = X[:, i].astype('int64', copy=False)"],"delete":["992","            labels = X[:, i].astype('int64')"]}],"sklearn\/datasets\/kddcup99.py":[{"add":["141","        data[:, 0] = np.log((data[:, 0] + 0.1).astype(float, copy=False))","142","        data[:, 4] = np.log((data[:, 4] + 0.1).astype(float, copy=False))","143","        data[:, 5] = np.log((data[:, 5] + 0.1).astype(float, copy=False))"],"delete":["141","        data[:, 0] = np.log((data[:, 0] + 0.1).astype(float))","142","        data[:, 4] = np.log((data[:, 4] + 0.1).astype(float))","143","        data[:, 5] = np.log((data[:, 5] + 0.1).astype(float))"]}],"sklearn\/metrics\/cluster\/supervised.py":[{"add":["25","from ...utils.fixes import comb, _astype_copy_false","633","    outer = (pi.take(nzx).astype(np.int64, copy=False)","634","             * pj.take(nzy).astype(np.int64, copy=False))","743","    contingency = contingency.astype(np.float64,","744","                                     **_astype_copy_false(contingency))","855","    contingency = contingency.astype(np.float64,","856","                                     **_astype_copy_false(contingency))","939","                           sparse=True)","940","    c = c.astype(np.int64, **_astype_copy_false(c))"],"delete":["25","from ...utils.fixes import comb","633","    outer = pi.take(nzx).astype(np.int64) * pj.take(nzy).astype(np.int64)","742","    contingency = contingency.astype(np.float64)","853","    contingency = contingency.astype(np.float64)","936","                           sparse=True).astype(np.int64)"]}],"sklearn\/neighbors\/tests\/test_dist_metrics.py":[{"add":["25","X1 = rng.random_sample((n1, d)).astype('float64', copy=False)","26","X2 = rng.random_sample((n2, d)).astype('float64', copy=False)"],"delete":["25","X1 = rng.random_sample((n1, d)).astype('float64')","26","X2 = rng.random_sample((n2, d)).astype('float64')"]}],"sklearn\/preprocessing\/imputation.py":[{"add":["287","                row_mask = np.logical_not(row_mask)"],"delete":["287","                row_mask = np.logical_not(row_mask).astype(np.bool)"]}],"sklearn\/datasets\/tests\/test_svmlight_format.py":[{"add":["275","                            y_dense.astype(dtype, copy=False), y2, 4)","281","                            y_dense.astype(dtype, copy=False), y2, 15)"],"delete":["275","                            y_dense.astype(dtype), y2, 4)","281","                            y_dense.astype(dtype), y2, 15)"]}],"sklearn\/decomposition\/tests\/test_pca.py":[{"add":["721","    X_64 = np.random.RandomState(0).rand(1000, 4).astype(np.float64,","722","                                                         copy=False)","743","    X_i64 = X_i64.astype(np.int64, copy=False)","744","    X_i32 = X_i64.astype(np.int32, copy=False)"],"delete":["721","    X_64 = np.random.RandomState(0).rand(1000, 4).astype(np.float64)","742","    X_i64 = X_i64.astype(np.int64)","743","    X_i32 = X_i64.astype(np.int32)"]}],"sklearn\/datasets\/rcv1.py":[{"add":["181","        sample_id = sample_id.astype(np.uint32, copy=False)"],"delete":["181","        sample_id = sample_id.astype(np.uint32)"]}],"sklearn\/metrics\/tests\/test_pairwise.py":[{"add":["205","_wminkowski_kwds = {'w': np.arange(1, 5).astype('double', copy=False), 'p': 1}"],"delete":["205","_wminkowski_kwds = {'w': np.arange(1, 5).astype('double'), 'p': 1}"]}],"sklearn\/preprocessing\/tests\/test_data.py":[{"add":["207","    Xt_dense = est.fit_transform(X.astype(dtype, copy=False))"],"delete":["207","    Xt_dense = est.fit_transform(X.astype(dtype))"]}],"sklearn\/utils\/tests\/test_extmath.py":[{"add":["171","    X = X.astype(dtype, copy=False)","183","            Xcsr.indptr = Xcsr.indptr.astype(csr_index_dtype, copy=False)","184","            Xcsr.indices = Xcsr.indices.astype(csr_index_dtype, copy=False)"],"delete":["171","    X = X.astype(dtype)","183","            Xcsr.indptr = Xcsr.indptr.astype(csr_index_dtype)","184","            Xcsr.indices = Xcsr.indices.astype(csr_index_dtype)"]}],"sklearn\/tree\/tests\/test_tree.py":[{"add":["1581","    X_small32 = X_small.astype(tree._tree.DTYPE, copy=False)","1590","    X_small32 = csr_matrix(X_small.astype(tree._tree.DTYPE, copy=False))"],"delete":["1581","    X_small32 = X_small.astype(tree._tree.DTYPE)","1590","    X_small32 = csr_matrix(X_small.astype(tree._tree.DTYPE))"]}],"sklearn\/datasets\/base.py":[{"add":["547","    target = data[:, -1].astype(np.int, copy=False)"],"delete":["547","    target = data[:, -1].astype(np.int)"]}],"sklearn\/cluster\/hierarchical.py":[{"add":["24","from ..utils.fixes import _astype_copy_false","90","    connectivity = connectivity.astype('float64',","91","                                       **_astype_copy_false(connectivity))","462","        children_ = out[:, :2].astype(np.int, copy=False)","481","        distances = X[connectivity.row, connectivity.col].astype(","482","            'float64', **_astype_copy_false(X))"],"delete":["89","    connectivity = connectivity.astype('float64')","460","        children_ = out[:, :2].astype(np.int)","479","        distances = X[connectivity.row, connectivity.col].astype('float64')"]}],"sklearn\/metrics\/tests\/test_classification.py":[{"add":["858","        cm = confusion_matrix(y, y,","859","                              sample_weight=weight.astype(dtype, copy=False))","862","        cm = confusion_matrix(y, y,","863","                              sample_weight=weight.astype(dtype, copy=False))"],"delete":["858","        cm = confusion_matrix(y, y, sample_weight=weight.astype(dtype))","861","        cm = confusion_matrix(y, y, sample_weight=weight.astype(dtype))"]}],"sklearn\/manifold\/tests\/test_t_sne.py":[{"add":["142","    neighbors_nn = np.argsort(distances, axis=1)[:, 1:k].astype(np.int64,","143","                                                                copy=False)","155","        neighbors_nn = np.argsort(distances, axis=1)[:, :k].astype(np.int64,","156","                                                                   copy=False)","180","    neighbors_nn = np.argsort(distances, axis=1)[:, :k].astype(np.int64,","181","                                                               copy=False)","537","    neighbors = neighbors.astype(np.int64, copy=False)","609","    X = random_state.randn(50, 2).astype(dt, copy=False)"],"delete":["142","    neighbors_nn = np.argsort(distances, axis=1)[:, 1:k].astype(np.int64)","154","        neighbors_nn = np.argsort(distances, axis=1)[:, :k].astype(np.int64)","178","    neighbors_nn = np.argsort(distances, axis=1)[:, :k].astype(np.int64)","534","    neighbors = neighbors.astype(np.int64)","606","    X = random_state.randn(50, 2).astype(dt)"]}],"sklearn\/neighbors\/tests\/test_kd_tree.py":[{"add":["198","        d_in = rng.random_sample(2 * n_nbrs).astype(DTYPE, copy=False)","214","    vals = rng.random_sample(n_nodes).astype(DTYPE, copy=False)","224","    dist = rng.random_sample((n_rows, n_pts)).astype(DTYPE, copy=False)","225","    ind = (np.arange(n_pts) + np.zeros((n_rows, 1))).astype(ITYPE, copy=False)"],"delete":["198","        d_in = rng.random_sample(2 * n_nbrs).astype(DTYPE)","214","    vals = rng.random_sample(n_nodes).astype(DTYPE)","224","    dist = rng.random_sample((n_rows, n_pts)).astype(DTYPE)","225","    ind = (np.arange(n_pts) + np.zeros((n_rows, 1))).astype(ITYPE)"]}],"sklearn\/datasets\/samples_generator.py":[{"add":["192","                                    generator).astype(float, copy=False)","448","    y = ((X ** 2.0).sum(axis=1) > 9.34).astype(np.float64, copy=False)"],"delete":["192","                                    generator).astype(float)","448","    y = ((X ** 2.0).sum(axis=1) > 9.34).astype(np.float64)"]}],"sklearn\/preprocessing\/base.py":[{"add":["6","from ..utils.fixes import _astype_copy_false","74","        X_not_sel = X[:, ind[not_sel]].astype(dtype, **_astype_copy_false(X))"],"delete":["73","        X_not_sel = X[:, ind[not_sel]].astype(dtype)"]}],"sklearn\/datasets\/openml.py":[{"add":["654","                               y[:, i:i+1].astype(int, copy=False))"],"delete":["654","                               y[:, i:i+1].astype(int))"]}],"sklearn\/preprocessing\/data.py":[{"add":["673","            self.n_samples_seen_ = np.repeat(","674","                self.n_samples_seen_, X.shape[1]).astype(np.int64, copy=False)","689","                self.n_samples_seen_ = (","690","                        X.shape[0] - counts_nan).astype(np.int64, copy=False)"],"delete":["673","            self.n_samples_seen_ = np.repeat(self.n_samples_seen_,","674","                                             X.shape[1]).astype(np.int64)","689","                self.n_samples_seen_ = (X.shape[0] -","690","                                        counts_nan).astype(np.int64)"]}],"sklearn\/ensemble\/tests\/test_bagging.py":[{"add":["812","    X = X.astype('float', copy=True)"],"delete":["812","    X = X.copy().astype('float')"]}],"doc\/whats_new\/v0.21.rst":[{"add":["424","- |Efficiency| Memory copies are avoided when casting arrays to a different","425","  dtype in multiple estimators. :issue:`11973` by :user:`Roman Yurchak`_.","426",""],"delete":[]}],"sklearn\/datasets\/covtype.py":[{"add":["117","        y = Xy[:, -1].astype(np.int32, copy=False)"],"delete":["117","        y = Xy[:, -1].astype(np.int32)"]}],"sklearn\/feature_selection\/mutual_info_.py":[{"add":["11","from ..utils.fixes import _astype_copy_false","277","        X = X.astype(float, **_astype_copy_false(X))"],"delete":["276","        X = X.astype(float)"]}],"sklearn\/svm\/base.py":[{"add":["232","        return column_or_1d(y, warn=True).astype(np.float64, copy=False)"],"delete":["232","        return column_or_1d(y, warn=True).astype(np.float64)"]}],"sklearn\/feature_extraction\/_hashing.pyx":[{"add":["97","        indices_a = indices_a.astype(np.int64, copy=False)","99","        indptr_a = indptr_a.astype(np.int32, copy=False)"],"delete":["97","        indices_a = indices_a.astype(np.int64)","99","        indptr_a = indptr_a.astype(np.int32)"]}],"sklearn\/metrics\/cluster\/expected_mutual_info_fast.pyx":[{"add":["31","    a = np.ravel(contingency.sum(axis=1).astype(np.int32, copy=False))","32","    b = np.ravel(contingency.sum(axis=0).astype(np.int32, copy=False))"],"delete":["31","    a = np.ravel(contingency.sum(axis=1).astype(np.int32))","32","    b = np.ravel(contingency.sum(axis=0).astype(np.int32))"]}],"sklearn\/cluster\/tests\/test_hierarchical.py":[{"add":["285","            children_ = out[:, :2].astype(np.int, copy=False)","484","    keys = np.unique(rng.randint(100, size=10).astype(np.intp, copy=False))","491","    other_keys = np.arange(50, dtype=np.intp)[::2]"],"delete":["285","            children_ = out[:, :2].astype(np.int)","484","    keys = np.unique(rng.randint(100, size=10).astype(np.intp))","491","    other_keys = np.arange(50).astype(np.intp)[::2]"]}],"sklearn\/neighbors\/tests\/test_ball_tree.py":[{"add":["240","        d_in = rng.random_sample(2 * n_nbrs).astype(DTYPE, copy=False)","256","    vals = rng.random_sample(n_nodes).astype(DTYPE, copy=False)","266","    dist = rng.random_sample((n_rows, n_pts)).astype(DTYPE, copy=False)","267","    ind = (np.arange(n_pts) + np.zeros((n_rows, 1))).astype(ITYPE, copy=False)"],"delete":["240","        d_in = rng.random_sample(2 * n_nbrs).astype(DTYPE)","256","    vals = rng.random_sample(n_nodes).astype(DTYPE)","266","    dist = rng.random_sample((n_rows, n_pts)).astype(DTYPE)","267","    ind = (np.arange(n_pts) + np.zeros((n_rows, 1))).astype(ITYPE)"]}],"sklearn\/cluster\/k_means_.py":[{"add":["180","        return (sample_weight * scale).astype(X.dtype, copy=False)","620","    labels = labels.astype(np.int32, copy=False)","1196","                assign_rows_csr(","1197","                        X, new_centers.astype(np.intp, copy=False),","1198","                        np.where(to_reassign)[0].astype(np.intp, copy=False),","1199","                        centers)"],"delete":["180","        return (sample_weight * scale).astype(X.dtype)","620","    labels = labels.astype(np.int32)","1196","                assign_rows_csr(X, new_centers.astype(np.intp),","1197","                                np.where(to_reassign)[0].astype(np.intp),","1198","                                centers)"]}]}},"774f1aa0e767824c37b332e989146c8d6a3ee7a2":{"changes":{"sklearn\/externals\/joblib\/memory.py":"MODIFY"},"diff":{"sklearn\/externals\/joblib\/memory.py":[{"add":["517","        return (self.__class__, (self.func, None),","518","                {k: v for k, v in vars(self).items()","519","                 if k not in ('timestamp', 'func')})","799","","800","        cachedir: str or None, optional","801","","802","            .. deprecated: 0.12","803","                'cachedir' has been deprecated in 0.12 and will be","804","                removed in 0.14. Use the 'location' parameter instead.","810","    def __init__(self, location=None, backend='local', mmap_mode=None,","811","                 compress=False, verbose=1, bytes_limit=None,","812","                 backend_options={}, cachedir=None):","943","        return (self.__class__, (), {k: v for k, v in vars(self).items()","944","                                     if k != 'timestamp'})"],"delete":["517","        return (self.__class__, (self.func, self.store_backend, self.ignore,","518","                self.mmap_mode, self.compress, self._verbose))","777","        cachedir: str or None, optional","778","","779","            .. deprecated: 0.12","780","                'cachedir' has been deprecated in 0.12 and will be","781","                removed in 0.14. Use the 'location' parameter instead.","782","","809","    def __init__(self, location=None, backend='local', cachedir=None,","810","                 mmap_mode=None, compress=False, verbose=1, bytes_limit=None,","811","                 backend_options={}):","942","        # We need to remove 'joblib' from the end of cachedir","943","        location = (repr(self.store_backend)[:-7]","944","                    if self.store_backend is not None else None)","945","        compress = self.store_backend.compress \\","946","            if self.store_backend is not None else False","947","        return (self.__class__, (location, self.backend, self.mmap_mode,","948","                                 compress, self._verbose))"]}]}},"5533deb8e0ad8e1de79209a588800b794f2de13f":{"changes":{"sklearn\/model_selection\/_split.py":"MODIFY","sklearn\/model_selection\/tests\/test_split.py":"MODIFY"},"diff":{"sklearn\/model_selection\/_split.py":[{"add":["1941","    if cv is None or cv is 'warn':"],"delete":["1941","    if cv is 'warn':"]}],"sklearn\/model_selection\/tests\/test_split.py":[{"add":["1446","    assert_warns_message(FutureWarning, CV_WARNING, check_cv, None)"],"delete":["1446",""]}]}},"e1dd0d85c4a19795523668403bb066c6d0b9592b":{"changes":{"sklearn\/utils\/tests\/test_testing.py":"MODIFY","sklearn\/utils\/testing.py":"MODIFY","sklearn\/linear_model\/tests\/test_sgd.py":"MODIFY"},"diff":{"sklearn\/utils\/tests\/test_testing.py":[{"add":["10","import pytest","11","","214","    # Check that passing warning class as first positional argument","215","    warning_class = UserWarning","216","    match = \"'obj' should be a callable.+you should use 'category=UserWarning'\"","217","","218","    with pytest.raises(ValueError, match=match):","219","        silence_warnings_func = ignore_warnings(warning_class)(","220","            _warning_function)","221","        silence_warnings_func()","222","","223","    with pytest.raises(ValueError, match=match):","224","        @ignore_warnings(warning_class)","225","        def test():","226","            pass","227",""],"delete":[]}],"sklearn\/utils\/testing.py":[{"add":["277","    obj : callable or None","278","        callable where you want to ignore the warnings.","294","    if isinstance(obj, type) and issubclass(obj, Warning):","295","        # Avoid common pitfall of passing category as the first positional","296","        # argument which result in the test not being run","297","        warning_name = obj.__name__","298","        raise ValueError(","299","            \"'obj' should be a callable where you want to ignore warnings. \"","300","            \"You passed a warning class instead: 'obj={warning_name}'. \"","301","            \"If you want to pass a warning class to ignore_warnings, \"","302","            \"you should use 'category={warning_name}'\".format(","303","                warning_name=warning_name))","304","    elif callable(obj):"],"delete":["292","    if callable(obj):"]}],"sklearn\/linear_model\/tests\/test_sgd.py":[{"add":["321","    @ignore_warnings(category=ConvergenceWarning)"],"delete":["321","    @ignore_warnings(ConvergenceWarning)"]}]}},"32e5fd4fe8ff9f66886d8ac69c6514a9295d358a":{"changes":{"sklearn\/neighbors\/base.py":"MODIFY"},"diff":{"sklearn\/neighbors\/base.py":[{"add":["285","def _tree_query_parallel_helper(tree, data, n_neighbors, return_distance):","286","    \"\"\"Helper for the Parallel calls in KNeighborsMixin.kneighbors","287","","288","    The Cython method tree.query is not directly picklable by cloudpickle","289","    under PyPy.","290","    \"\"\"","291","    return tree.query(data, n_neighbors, return_distance)","292","","293","","444","                delayed_query = delayed(_tree_query_parallel_helper,","448","                delayed_query = delayed(_tree_query_parallel_helper)","452","                    self._tree, X[s], n_neighbors, return_distance)","573","def _tree_query_radius_parallel_helper(tree, data, radius, return_distance):","574","    \"\"\"Helper for the Parallel calls in RadiusNeighborsMixin.radius_neighbors","575","","576","    The Cython method tree.query_radius is not directly picklable by","577","    cloudpickle under PyPy.","578","    \"\"\"","579","    return tree.query_radius(data, radius, return_distance)","580","","581","","738","                delayed_query = delayed(_tree_query_radius_parallel_helper,","742","                delayed_query = delayed(_tree_query_radius_parallel_helper)","745","                delayed_query(self._tree, X[s], radius, return_distance)"],"delete":["435","                delayed_query = delayed(self._tree.query,","439","                delayed_query = delayed(self._tree.query)","443","                    X[s], n_neighbors, return_distance)","720","                delayed_query = delayed(self._tree.query_radius,","724","                delayed_query = delayed(self._tree.query_radius)","727","                delayed_query(X[s], radius, return_distance)"]}]}},"3e715fdafe14ea4bb7c2329202d078f8de95b192":{"changes":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":"MODIFY","sklearn\/linear_model\/coordinate_descent.py":"MODIFY","sklearn\/linear_model\/tests\/test_sparse_coordinate_descent.py":"MODIFY","sklearn\/linear_model\/cd_fast.pyx":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":[{"add":["830","","831","","832","@pytest.mark.parametrize('klass, n_classes, kwargs',","833","                         [(Lasso, 1, dict(precompute=True)),","834","                          (Lasso, 1, dict(precompute=False)),","835","                          (MultiTaskLasso, 2, dict()),","836","                          (MultiTaskLasso, 2, dict())])","837","def test_enet_coordinate_descent(klass, n_classes, kwargs):","838","    \"\"\"Test that a warning is issued if model does not converge\"\"\"","839","    clf = klass(max_iter=2, **kwargs)","840","    n_samples = 5","841","    n_features = 2","842","    X = np.ones((n_samples, n_features)) * 1e50","843","    y = np.ones((n_samples, n_classes))","844","    if klass == Lasso:","845","        y = y.ravel()","846","    assert_warns(ConvergenceWarning, clf.fit, X, y)"],"delete":[]}],"sklearn\/linear_model\/coordinate_descent.py":[{"add":[],"delete":["25","from ..exceptions import ConvergenceWarning","483","        if dual_gap_ > eps_:","484","            warnings.warn('Objective did not converge.' +","485","                          ' You might want' +","486","                          ' to increase the number of iterations.' +","487","                          ' Fitting data with very small alpha' +","488","                          ' may cause precision problems.',","489","                          ConvergenceWarning)","1814","        if self.dual_gap_ > self.eps_:","1815","            warnings.warn('Objective did not converge, you might want'","1816","                          ' to increase the number of iterations',","1817","                          ConvergenceWarning)","1818",""]}],"sklearn\/linear_model\/tests\/test_sparse_coordinate_descent.py":[{"add":["10","from sklearn.utils.testing import assert_warns","11","from sklearn.exceptions import ConvergenceWarning","294","","295","","296","def test_sparse_enet_coordinate_descent():","297","    \"\"\"Test that a warning is issued if model does not converge\"\"\"","298","    clf = Lasso(max_iter=2)","299","    n_samples = 5","300","    n_features = 2","301","    X = sp.csc_matrix((n_samples, n_features)) * 1e50","302","    y = np.ones(n_samples)","303","    assert_warns(ConvergenceWarning, clf.fit, X, y)"],"delete":[]}],"sklearn\/linear_model\/cd_fast.pyx":[{"add":["17","from ..exceptions import ConvergenceWarning","249","","250","        else:","251","            with gil:","252","                warnings.warn(\"Objective did not converge.\"","253","                \" You might want to increase the number of iterations.\"","254","                \" Duality gap: {}, tolerance: {}\".format(gap, tol),","255","                ConvergenceWarning)","256","","467","        else:","468","            with gil:","469","                warnings.warn(\"Objective did not converge.\"","470","                \" You might want to increase the number of iterations.\"","471","                \" Duality gap: {}, tolerance: {}\".format(gap, tol),","472","                ConvergenceWarning)","473","","622","","623","        with gil:","624","            warnings.warn(\"Objective did not converge.\"","625","            \" You might want to increase the number of iterations.\"","626","            \" Duality gap: {}, tolerance: {}\".format(gap, tol),","627","            ConvergenceWarning)","628","","819","                else:","820","                    with gil:","821","                        warnings.warn(\"Objective did not converge.\"","822","                        \" You might want to increase the number of iterations.\"","823","                        \" Duality gap: {}, tolerance: {}\".format(gap, tol),","824","                        ConvergenceWarning)"],"delete":[]}]}},"0908617f691628d9b94839664bb0e2c20c225645":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["96","  macOS. This appears to be the case on Travis CI servers, but has not been","111","  to set and that scales better, by :user:`Shane <espg>`.","130","- |Enhancement| :class:`cluster.KMeans` now gives a warning if the number of","149","  ``iteration`` was 1 less than the correct value. Also added the missing","150","  ``n_iter_`` attribute in the docstring of :class:`cluster.KMeans`.","193","  `OpenML <http:\/\/openml.org>`_. OpenML is a free, open data sharing platform","198","  ``n_samples`` parameter to indicate the number of samples to generate per","257","  ``n_components=None`` case now selects the minimum of ``n_samples`` and","258","  ``n_features``.","270","  sparse coding in parallel using read-only memory mapped datastructures.","280","  :user:`Nanxin Chen <bobchennan>`.","307","- |Feature| Added ``named_estimators_`` parameter in","472","  multiclass setting, even if ``'multinomial'`` was set.","503","  ``multi_class='multinomial'`` with binary output ``with warm_start=True``","519","  the algorithm before convergence. A parameter ``n_iter_no_change`` was added","804","- |Feature| Add ``sample_weight`` parameter to the fit method of","833","- |Fix| Fixed a bug in :class:`neighbors.KDTree` and :class:`neighbors.BallTree` where","834","  pickled tree objects would change their type to the super class :class:`BinaryTree`.","951","  :class:`preprocessing.StandardScaler` in the rare case when ``with_mean=False``"],"delete":["96","  MacOS. This appears to be the case on Travis CI servers, but has not been","111","  to set and tat scales better, by :user:`Shane <espg>`.","130","- |Enhancement| :class:`cluster.KMeans` now gives a warning, if the number of","149","  `iteration` was 1 less than the correct value. Also added the missing","150","  `n_iter_` attribute in the docstring of :class:`cluster.KMeans`.","193","  `OpenML <http:\/\/openml.org>`. OpenML is a free, open data sharing platform","198","  `n_samples` parameter to indicate the number of samples to generate per","257","  ``n_components=None`` case now selects the minimum of n_samples and","258","  n_features.","270","  sparse coding in parallel using readonly memory mapped datastructures.","280","  :user:`Nanxin Chen <bobchennan>`.`","307","- |Feature| Add `named_estimators_` parameter in","472","  multiclass setting, even if 'multinomial' was set.","503","  multi_class='multinomial' with binary output with warm_start = True","519","  the algorithm before convergence. A parameter `n_iter_no_change` was added","804","- |Feature| Add `sample_weight` parameter to the fit method of","833","- |Fix| Fixed a bug in `neighbors.KDTree` and `neighbors.BallTree` where","834","  pickled tree objects would change their type to the super class `BinaryTree`.","951","  :class:`preprocessing.StandardScaler` in the rare case when `with_mean=False`"]}]}},"e500447596ed4e50dcfb315aad98c77f6a6876d6":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/linear_model\/tests\/test_logistic.py":"MODIFY","sklearn\/linear_model\/logistic.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["589","- Fixed a bug in :func:`logistic.logistic_regression_path` to ensure that the","590","  returned coefficients are correct when ``multiclass='multinomial'``.","591","  Previously, some of the coefficients would override each other, leading to","592","  incorrect results in :class:`logistic.LogisticRegressionCV`. :issue:`11724`","593","  by :user:`Nicolas Hug <NicolasHug>`.","594",""],"delete":[]}],"sklearn\/linear_model\/tests\/test_logistic.py":[{"add":["1309","","1310","","1311","def test_logistic_regression_path_coefs_multinomial():","1312","    # Make sure that the returned coefs by logistic_regression_path when","1313","    # multi_class='multinomial' don't override each other (used to be a","1314","    # bug).","1315","    X, y = make_classification(n_samples=200, n_classes=3, n_informative=2,","1316","                               n_redundant=0, n_clusters_per_class=1,","1317","                               random_state=0, n_features=2)","1318","    Cs = [.00001, 1, 10000]","1319","    coefs, _, _ = logistic_regression_path(X, y, penalty='l1', Cs=Cs,","1320","                                           solver='saga', random_state=0,","1321","                                           multi_class='multinomial')","1322","","1323","    with pytest.raises(AssertionError):","1324","        assert_array_almost_equal(coefs[0], coefs[1], decimal=1)","1325","    with pytest.raises(AssertionError):","1326","        assert_array_almost_equal(coefs[0], coefs[2], decimal=1)","1327","    with pytest.raises(AssertionError):","1328","        assert_array_almost_equal(coefs[1], coefs[2], decimal=1)"],"delete":[]}],"sklearn\/linear_model\/logistic.py":[{"add":["574","        n_features + 1, where the last item represents the intercept. For","575","        ``multiclass='multinomial'``, the shape is (n_classes, n_cs,","576","        n_features) or (n_classes, n_cs, n_features + 1).","766","            coefs.append(multi_w0.copy())","772","    return np.array(coefs), np.array(Cs), n_iter"],"delete":["574","        n_features + 1, where the last item represents the intercept.","764","            coefs.append(multi_w0)","770","    return coefs, np.array(Cs), n_iter"]}]}},"88cdeb85a9303a7b580952b720703a4aca9dc1c0":{"changes":{"sklearn\/cluster\/tests\/test_optics.py":"MODIFY","sklearn\/cluster\/optics_.py":"MODIFY"},"diff":{"sklearn\/cluster\/tests\/test_optics.py":[{"add":["24","n_points_per_cluster = 10","160","    redX = X[::2]  # reduce for speed","211","def test_processing_order():","212","    # Ensure that we consider all unprocessed points,","213","    # not only direct neighbors. when picking the next point.","214","    Y = [[0], [10], [-10], [25]]","215","    clust = OPTICS(min_samples=3, max_eps=15).fit(Y)","216","    assert_array_equal(clust.reachability_, [np.inf, 10, 10, 15])","217","    assert_array_equal(clust.core_distances_, [10, 15, np.inf, np.inf])","218","    assert_array_equal(clust.ordering_, [0, 1, 2, 3])","219","","220","","226","    r1 = [np.inf, 1.0574896366427478, 0.7587934993548423, 0.7290174038973836,","227","          0.7290174038973836, 0.7290174038973836, 0.6861627576116127,","228","          0.7587934993548423, 0.9280118450166668, 1.1748022534146194,","229","          3.3355455741292257, 0.49618389254482587, 0.2552805046961355,","230","          0.2552805046961355, 0.24944622248445714, 0.24944622248445714,","231","          0.24944622248445714, 0.2552805046961355, 0.2552805046961355,","232","          0.3086779122185853, 4.163024452756142, 1.623152630340929,","233","          0.45315840475822655, 0.25468325192031926, 0.2254004358159971,","234","          0.18765711877083036, 0.1821471333893275, 0.1821471333893275,","235","          0.18765711877083036, 0.18765711877083036, 0.2240202988740153,","236","          1.154337614548715, 1.342604473837069, 1.323308536402633,","237","          0.8607514948648837, 0.27219111215810565, 0.13260875220533205,","238","          0.13260875220533205, 0.09890587675958984, 0.09890587675958984,","239","          0.13548790801634494, 0.1575483940837384, 0.17515137170530226,","240","          0.17575920159442388, 0.27219111215810565, 0.6101447895405373,","241","          1.3189208094864302, 1.323308536402633, 2.2509184159764577,","242","          2.4517810628594527, 3.675977064404973, 3.8264795626020365,","243","          2.9130735341510614, 2.9130735341510614, 2.9130735341510614,","244","          2.9130735341510614, 2.8459300127258036, 2.8459300127258036,","245","          2.8459300127258036, 3.0321982337972537]","246","    o1 = [0, 3, 6, 4, 7, 8, 2, 9, 5, 1, 31, 30, 32, 34, 33, 38, 39, 35, 37, 36,","247","          44, 21, 23, 24, 22, 25, 27, 29, 26, 28, 20, 40, 45, 46, 10, 15, 11,","248","          13, 17, 19, 18, 12, 16, 14, 47, 49, 43, 48, 42, 41, 53, 57, 51, 52,","249","          56, 59, 54, 55, 58, 50]","250","    p1 = [-1, 0, 3, 6, 6, 6, 8, 3, 7, 5, 1, 31, 30, 30, 34, 34, 34, 32, 32, 37,","251","          36, 44, 21, 23, 24, 22, 25, 25, 22, 22, 22, 21, 40, 45, 46, 10, 15,","252","          15, 13, 13, 15, 11, 19, 15, 10, 47, 12, 45, 14, 43, 42, 53, 57, 57,","253","          57, 57, 59, 59, 59, 58]","258","    clust1 = OPTICS(min_samples=5).fit(X)","260","    assert_array_equal(clust1.ordering_, np.array(o1))","261","    assert_array_equal(clust1.predecessor_[clust1.ordering_], np.array(p1))","262","    assert_allclose(clust1.reachability_[clust1.ordering_], np.array(r1))","265","    for i in clust1.ordering_[1:]:","266","        assert (clust1.reachability_[i] >=","267","                clust1.core_distances_[clust1.predecessor_[i]])","268","","269","    # Expected values, computed with (future) ELKI 0.7.5 using","270","    r2 = [np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf,","271","          np.inf, np.inf, np.inf, 0.27219111215810565, 0.13260875220533205,","272","          0.13260875220533205, 0.09890587675958984, 0.09890587675958984,","273","          0.13548790801634494, 0.1575483940837384, 0.17515137170530226,","274","          0.17575920159442388, 0.27219111215810565, 0.4928068613197889,","275","          np.inf, 0.2666183922512113, 0.18765711877083036, 0.1821471333893275,","276","          0.1821471333893275, 0.1821471333893275, 0.18715928772277457,","277","          0.18765711877083036, 0.18765711877083036, 0.25468325192031926,","278","          np.inf, 0.2552805046961355, 0.2552805046961355, 0.24944622248445714,","279","          0.24944622248445714, 0.24944622248445714, 0.2552805046961355,","280","          0.2552805046961355, 0.3086779122185853, 0.34466409325984865,","281","          np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf,","282","          np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf,","283","          np.inf, np.inf]","284","    o2 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 11, 13, 17, 19, 18, 12, 16, 14,","285","          47, 46, 20, 22, 25, 23, 27, 29, 24, 26, 28, 21, 30, 32, 34, 33, 38,","286","          39, 35, 37, 36, 31, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53,","287","          54, 55, 56, 57, 58, 59]","288","    p2 = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10, 15, 15, 13, 13, 15,","289","          11, 19, 15, 10, 47, -1, 20, 22, 25, 25, 25, 25, 22, 22, 23, -1, 30,","290","          30, 34, 34, 34, 32, 32, 37, 38, -1, -1, -1, -1, -1, -1, -1, -1, -1,","291","          -1, -1, -1, -1, -1, -1, -1, -1, -1]","292","    clust2 = OPTICS(min_samples=5, max_eps=0.5).fit(X)","293","","294","    assert_array_equal(clust2.ordering_, np.array(o2))","295","    assert_array_equal(clust2.predecessor_[clust2.ordering_], np.array(p2))","296","    assert_allclose(clust2.reachability_[clust2.ordering_], np.array(r2))","297","","298","    index = np.where(clust1.core_distances_ <= 0.5)[0]","299","    assert_allclose(clust1.core_distances_[index],","300","                    clust2.core_distances_[index])","304","    redX = X[::2]"],"delete":["24","n_points_per_cluster = 50","157","def test_auto_extract_hier():","158","    # Tests auto extraction gets correct # of clusters with varying density","159","    clust = OPTICS(min_samples=9).fit(X)","160","    assert_equal(len(set(clust.labels_)), 6)","161","","162","","166","    redX = X[::10]  # reduce for speed","222","    r = [np.inf, 0.7865694338710508, 0.4373157299595305, 0.4121908069391695,","223","         0.302907091394212, 0.20815674060999778, 0.20815674060999778,","224","         0.15190193459676368, 0.15190193459676368, 0.28229645104833345,","225","         0.302907091394212, 0.30507239477026865, 0.30820580778767087,","226","         0.3289019667317037, 0.3458462228589966, 0.3458462228589966,","227","         0.2931114364132193, 0.2931114364132193, 0.2562790168458507,","228","         0.23654635530592025, 0.37903448688824876, 0.3920764620583683,","229","         0.4121908069391695, 0.4364542226186831, 0.45523658462146793,","230","         0.458757846268185, 0.458757846268185, 0.4752907412198826,","231","         0.42350366820623375, 0.42350366820623375, 0.42350366820623375,","232","         0.47758738570352993, 0.47758738570352993, 0.4776963110272057,","233","         0.5272079288923731, 0.5591861752070968, 0.5592057084987357,","234","         0.5609913790596295, 0.5909117211348757, 0.5940470220777727,","235","         0.5940470220777727, 0.6861627576116127, 0.687795873252133,","236","         0.7538541412862811, 0.7865694338710508, 0.8038180561910464,","237","         0.8038180561910464, 0.8242451615289921, 0.8548361202185057,","238","         0.8790098789921685, 2.9281214555815764, 1.3256656984284734,","239","         0.19590944671099267, 0.1339924636672767, 0.1137384200258616,","240","         0.061455005237474075, 0.061455005237474075, 0.061455005237474075,","241","         0.045627777293497276, 0.045627777293497276, 0.045627777293497276,","242","         0.04900902556283447, 0.061455005237474075, 0.06225461602815799,","243","         0.06835750467748272, 0.07882900172724974, 0.07882900172724974,","244","         0.07650735397943846, 0.07650735397943846, 0.07650735397943846,","245","         0.07650735397943846, 0.07650735397943846, 0.07113275489288699,","246","         0.07890196345324527, 0.07052683707634783, 0.07052683707634783,","247","         0.07052683707634783, 0.08284027053523288, 0.08725436842020087,","248","         0.08725436842020087, 0.09010229261951723, 0.09128578974358925,","249","         0.09154172670176584, 0.0968576383038391, 0.12007572768323092,","250","         0.12024155806196564, 0.12141990481584404, 0.1339924636672767,","251","         0.13694322786307633, 0.14275793459246572, 0.15093125027309579,","252","         0.17927454395170142, 0.18151803569400365, 0.1906028449191095,","253","         0.1906028449191095, 0.19604486784973194, 0.2096539172540186,","254","         0.2096539172540186, 0.21614333983312325, 0.22036454909290296,","255","         0.23610322103910933, 0.26028003932256766, 0.2607126030060721,","256","         0.2891824876072483, 0.3258089271514364, 0.35968687619960743,","257","         0.4512973330510512, 0.4746141313843085, 0.5958585488429471,","258","         0.6468718886525733, 0.6878453052524358, 0.6911582799500199,","259","         0.7172169499815705, 0.7209874999572031, 0.6326884657912096,","260","         0.5755681293026617, 0.5755681293026617, 0.5755681293026617,","261","         0.6015042225447333, 0.6756244556376542, 0.4722384908959966,","262","         0.08775739179493615, 0.06665303472021758, 0.056308477780164796,","263","         0.056308477780164796, 0.05507767260835565, 0.05368146914586802,","264","         0.05163427719303039, 0.05163427719303039, 0.05163427719303039,","265","         0.04918757627098621, 0.04918757627098621, 0.05368146914586802,","266","         0.05473720349424546, 0.05473720349424546, 0.048442038421760626,","267","         0.048442038421760626, 0.04598840269934622, 0.03984301937835033,","268","         0.04598840269934622, 0.04598840269934622, 0.04303884892957088,","269","         0.04303884892957088, 0.04303884892957088, 0.0431802780806032,","270","         0.0520412490141781, 0.056308477780164796, 0.05080724020124642,","271","         0.05080724020124642, 0.05080724020124642, 0.06385565101399236,","272","         0.05840878369200427, 0.0474472391259039, 0.0474472391259039,","273","         0.04232512684465669, 0.04232512684465669, 0.04232512684465669,","274","         0.0474472391259039, 0.051802632822946656, 0.051802632822946656,","275","         0.05316405104684577, 0.05316405104684577, 0.05840878369200427,","276","         0.06385565101399236, 0.08025248922898705, 0.08775739179493615,","277","         0.08993337040710143, 0.08993337040710143, 0.08993337040710143,","278","         0.08993337040710143, 0.297457175321605, 0.29763608186278934,","279","         0.3415255849656254, 0.34713336941105105, 0.44108940848708167,","280","         0.35942962652965604, 0.35942962652965604, 0.33609522256535296,","281","         0.5008111387107295, 0.5333587622018111, 0.6223243743872802,","282","         0.6793840035409552, 0.7445032492109848, 0.7445032492109848,","283","         0.6556432627279256, 0.6556432627279256, 0.6556432627279256,","284","         0.8196566935960162, 0.8724089149982351, 0.9352758042365477,","285","         0.9352758042365477, 1.0581847953137133, 1.0684332509194163,","286","         1.0887817699873303, 1.2552604310322708, 1.3993856001769436,","287","         1.4869615658197606, 1.6588098267326852, 1.679969559453028,","288","         1.679969559453028, 1.6860509219163458, 1.6860509219163458,","289","         1.1465697826627317, 0.992866533434785, 0.7691908270707519,","290","         0.578131499171622, 0.578131499171622, 0.578131499171622,","291","         0.5754243919945694, 0.8416199360035114, 0.8722493727270406,","292","         0.9156549976203665, 0.9156549976203665, 0.7472322844356064,","293","         0.715219324518981, 0.715219324518981, 0.715219324518981,","294","         0.7472322844356064, 0.820988298336316, 0.908958489674247,","295","         0.9234036745782839, 0.9519521817942455, 0.992866533434785,","296","         0.992866533434785, 0.9995692674695029, 1.0727415198904493,","297","         1.1395519941203158, 1.1395519941203158, 1.1741737271442092,","298","         1.212860115632712, 0.8724097897372123, 0.8724097897372123,","299","         0.8724097897372123, 1.2439272570611581, 1.2439272570611581,","300","         1.3524538390109015, 1.3524538390109015, 1.2982303284415664,","301","         1.3610655849680207, 1.3802783392089437, 1.3802783392089437,","302","         1.4540636953090629, 1.5879329500533819, 1.5909193228826986,","303","         1.72931779186001, 1.9619075944592093, 2.1994355761906257,","304","         2.2508672067362165, 2.274436122235927, 2.417635732260135,","305","         3.014235905390584, 0.30616929141177107, 0.16449675872754976,","306","         0.09071681523805683, 0.09071681523805683, 0.09071681523805683,","307","         0.08727060912039632, 0.09151721189581336, 0.12277953408786725,","308","         0.14285575406641507, 0.16449675872754976, 0.16321992344119793,","309","         0.1330971730344373, 0.11429891993167259, 0.11429891993167259,","310","         0.11429891993167259, 0.11429891993167259, 0.11429891993167259,","311","         0.0945498340011516, 0.11410457435712089, 0.1196414019798306,","312","         0.12925682285016715, 0.12925682285016715, 0.12925682285016715,","313","         0.12864887158869853, 0.12864887158869853, 0.12864887158869853,","314","         0.13369634918690246, 0.14330826543275352, 0.14877705862323184,","315","         0.15203263952428328, 0.15696350160889708, 0.1585326700393211,","316","         0.1585326700393211, 0.16034306786654595, 0.16034306786654595,","317","         0.15053328296567992, 0.16396729418886688, 0.16763548009617293,","318","         0.1732029325454474, 0.21163390061029352, 0.21497664171864372,","319","         0.22125889949299, 0.240251070192081, 0.240251070192081,","320","         0.2413620965310808, 0.26319419022234064, 0.26319419022234064,","321","         0.27989712380504483, 0.2909782800714374]","322","    o = [0, 3, 6, 7, 15, 4, 27, 28, 49, 17, 35, 47, 46, 39, 13, 19,","323","         22, 29, 30, 38, 34, 32, 43, 8, 25, 9, 37, 23, 33, 40, 44, 11, 36, 5,","324","         45, 48, 41, 26, 24, 20, 31, 2, 16, 10, 18, 14, 42, 12, 1, 21, 234,","325","         132, 112, 115, 107, 110, 120, 114, 100, 131, 137, 145, 130, 121, 134,","326","         116, 149, 108, 111, 113, 142, 148, 119, 104, 126, 133, 138, 127, 101,","327","         105, 103, 106, 125, 140, 123, 147, 144, 129, 141, 117, 143, 136, 128,","328","         122, 124, 102, 109, 249, 146, 118, 135, 245, 139, 224, 241, 217, 202,","329","         248, 233, 214, 236, 211, 206, 231, 212, 221, 229, 244, 208, 226, 83,","330","         76, 53, 77, 88, 62, 66, 65, 89, 93, 79, 95, 74, 70, 82, 51, 73, 87,","331","         67, 94, 56, 52, 63, 80, 75, 57, 96, 60, 69, 90, 86, 58, 68, 81, 64,","332","         84, 85, 97, 59, 98, 61, 71, 78, 92, 50, 91, 55, 54, 72, 99, 210, 201,","333","         216, 239, 203, 218, 219, 222, 240, 294, 243, 246, 204, 220, 200, 215,","334","         230, 225, 205, 207, 237, 223, 235, 209, 228, 238, 227, 285, 232, 256,","335","         281, 270, 260, 252, 272, 268, 292, 298, 269, 275, 257, 250, 284, 283,","336","         286, 295, 297, 293, 289, 258, 299, 282, 262, 296, 287, 267, 255, 263,","337","         288, 276, 251, 266, 274, 271, 277, 261, 279, 290, 253, 254, 291, 259,","338","         280, 278, 273, 247, 265, 242, 264, 213, 199, 174, 154, 152, 180, 186,","339","         195, 170, 181, 176, 187, 173, 157, 159, 158, 172, 182, 183, 151, 197,","340","         177, 160, 156, 171, 175, 184, 193, 161, 179, 196, 185, 192, 165, 166,","341","         164, 189, 155, 162, 188, 153, 178, 169, 194, 150, 163, 198, 190, 191,","342","         168, 167]","343","    p = [-1, 0, 3, 6, 7, 15, 15, 27, 27, 4, 7, 49, 47, 4, 39, 39,","344","         19, 19, 29, 30, 30, 13, 6, 43, 34, 32, 32, 25, 23, 23, 23, 3, 11, 46,","345","         46, 45, 9, 38, 33, 26, 26, 8, 20, 33, 0, 18, 18, 2, 18, 44, 0, 234,","346","         132, 112, 115, 107, 107, 120, 114, 114, 114, 114, 107, 100, 100, 134,","347","         134, 149, 149, 108, 108, 108, 148, 113, 104, 104, 104, 142, 127, 127,","348","         126, 138, 126, 148, 127, 148, 127, 112, 147, 116, 117, 101, 145, 128,","349","         128, 122, 136, 136, 249, 102, 102, 118, 143, 146, 245, 123, 139, 241,","350","         241, 217, 248, 202, 248, 224, 231, 212, 212, 212, 229, 229, 226, 83,","351","         76, 53, 53, 88, 62, 66, 66, 66, 93, 93, 79, 93, 70, 82, 82, 73, 87,","352","         73, 94, 56, 56, 56, 63, 67, 53, 96, 96, 96, 69, 86, 58, 58, 81, 81,","353","         81, 58, 64, 64, 59, 59, 86, 69, 78, 83, 84, 55, 55, 55, 72, 50, 201,","354","         210, 216, 203, 203, 219, 54, 240, 239, 240, 236, 236, 220, 220, 220,","355","         217, 139, 243, 243, 204, 211, 246, 215, 223, 294, 209, 227, 227, 209,","356","         281, 270, 260, 252, 272, 272, 272, 298, 269, 298, 275, 275, 284, 283,","357","         283, 283, 284, 286, 283, 298, 299, 260, 260, 250, 299, 258, 258, 296,","358","         250, 276, 276, 276, 289, 289, 267, 267, 279, 261, 277, 277, 258, 266,","359","         290, 209, 207, 290, 228, 278, 228, 290, 199, 174, 154, 154, 154, 186,","360","         186, 180, 170, 174, 187, 173, 157, 159, 157, 157, 159, 183, 183, 172,","361","         197, 160, 160, 171, 171, 171, 151, 173, 184, 151, 196, 185, 185, 179,","362","         179, 189, 177, 165, 175, 162, 164, 181, 169, 169, 181, 178, 178, 178,","363","         168]","368","    clust = OPTICS(min_samples=5).fit(X)","370","    assert_array_equal(clust.ordering_, np.array(o))","371","    assert_array_equal(clust.predecessor_[clust.ordering_], np.array(p))","372","    assert_allclose(clust.reachability_[clust.ordering_], np.array(r))","375","    for i in clust.ordering_[1:]:","376","        assert (clust.reachability_[i] >=","377","                clust.core_distances_[clust.predecessor_[i]])","381","    redX = X[::10]","390","","391","","392","def test_processing_order():","393","    \"\"\"Early dev version of OPTICS would not consider all unprocessed points,","394","    but only direct neighbors. This tests against this mistake.\"\"\"","395","    Y = [[0], [10], [-10], [25]]","396","    clust = OPTICS(min_samples=3, max_eps=15).fit(Y)","397","    assert_array_equal(clust.reachability_, [np.inf, 10, 10, 15])","398","    assert_array_equal(clust.core_distances_, [10, 15, 20, 25])","399","    assert_array_equal(clust.ordering_, [0, 1, 2, 3])"]}],"sklearn\/cluster\/optics_.py":[{"add":["41","    cluster order. Note that we do not employ a heap to manage the expansion","42","    candidates, so the time complexity will be O(n^2).","200","    cluster order. Note that we do not employ a heap to manage the expansion","201","    candidates, so the time complexity will be O(n^2).","432","        # Here we first do a kNN query for each point, this differs from","433","        # the original OPTICS that only used epsilon range queries.","435","        # OPTICS puts an upper limit on these, use inf for undefined.","436","        self.core_distances_[self.core_distances_ > self.max_eps] = np.inf","490","        # Note that this implementation is O(n^2) theoretically, but","491","        # supposedly with very low constant factors.","494","        for ordering_idx in range(X.shape[0]):","495","            # Choose next based on smallest reachability distance","496","            # (And prefer smaller ids on ties, possibly np.inf!)","497","            index = np.where(processed == 0)[0]","498","            point = index[np.argmin(self.reachability_[index])]","499","","500","            processed[point] = True","501","            ordering[ordering_idx] = point","502","            if self.core_distances_[point] != np.inf:","503","                self._set_reach_dist(point, processed, X, nbrs)","508","        # Assume that radius_neighbors is faster without distances","509","        # and we don't need all distances, nevertheless, this means","510","        # we may be doing some work twice.","517","        # Neighbors of current point are already processed.","519","            return","521","        # Only compute distances to unprocessed neighbors:"],"delete":["41","    cluster order. It also does not employ a heap to manage the expansion","42","    candiates, but rather uses numpy masked arrays. This can be potentially","43","    slower with some parameters (at the benefit from using fast numpy code).","201","    cluster order.","447","","489","        ordering_idx = 0","490","        for point in range(X.shape[0]):","491","            if processed[point]:","492","                continue","493","            if self.core_distances_[point] <= self.max_eps:","494","                while not processed[point]:","495","                    processed[point] = True","496","                    ordering[ordering_idx] = point","497","                    ordering_idx += 1","498","                    point = self._set_reach_dist(point, processed, X, nbrs)","499","            else:  # For very noisy points","500","                ordering[ordering_idx] = point","501","                ordering_idx += 1","502","                processed[point] = True","513","        # Keep n_jobs = 1 in the following lines...please","515","            # Everything is already processed. Return to main loop","516","            return point_index","529","        # Choose next based on smallest reachability distance","530","        # (And prefer smaller ids on ties).","531","        # All unprocessed points qualify, not just new neighbors (\"unproc\")","532","        return (np.ma.array(self.reachability_, mask=processed)","533","                .argmin(fill_value=np.inf))","534",""]}]}},"8681ece37388c771098c3ee9236e9993db9e92d4":{"changes":{"sklearn\/tests\/test_docstring_parameters.py":"MODIFY","sklearn\/utils\/tests\/test_testing.py":"MODIFY","sklearn\/utils\/testing.py":"MODIFY"},"diff":{"sklearn\/tests\/test_docstring_parameters.py":[{"add":["74","            if inspect.isabstract(cls):","88","                    cls.__init__, cdoc)","89","","103","                    method, ignore=param_ignore)","121","","122","    msg = '\\n'.join(incorrect)","124","        raise AssertionError(\"Docstring Error:\\n\" + msg)","140","            source = inspect.getsource(mod)"],"delete":["25","","75","            if isabstract(cls):","87","","90","                    cls.__init__, cdoc, class_name=cname)","104","                    method, ignore=param_ignore, class_name=cname)","122","    msg = '\\n' + '\\n'.join(sorted(list(set(incorrect))))","124","        raise AssertionError(\"Docstring Error: \" + msg)","140","            source = getsource(mod)"]}],"sklearn\/utils\/tests\/test_testing.py":[{"add":["325","def f_too_many_param_docstring(a, b):","326","    \"\"\"Function f","327","","328","    Parameters","329","    ----------","330","    a : int","331","        Parameter a","332","    b : int","333","        Parameter b","334","    c : int","335","        Parameter c","336","","337","    Returns","338","    -------","339","    d : list","340","        Parameter c","341","    \"\"\"","342","    d = a + b","343","    return d","344","","345","","492","","495","","498","","503","    messages = [","504","            [\"In function: sklearn.utils.tests.test_testing.f_bad_order\",","505","             \"There's a parameter name mismatch in function docstring w.r.t.\"","506","             \" function signature, at index 0 diff: 'b' != 'a'\",","507","             \"Full diff:\",","508","             \"- ['b', 'a']\",","509","             \"+ ['a', 'b']\"],","510","","511","            [\"In function: \" +","512","                \"sklearn.utils.tests.test_testing.f_too_many_param_docstring\",","513","             \"Parameters in function docstring have more items w.r.t. function\"","514","             \" signature, first extra item: c\",","515","             \"Full diff:\",","516","             \"- ['a', 'b']\",","517","             \"+ ['a', 'b', 'c']\",","518","             \"?          +++++\"],","519","","520","            [\"In function: sklearn.utils.tests.test_testing.f_missing\",","521","             \"Parameters in function docstring have less items w.r.t. function\"","522","             \" signature, first missing item: b\",","523","             \"Full diff:\",","524","             \"- ['a', 'b']\",","525","             \"+ ['a']\"],","526","","527","            [\"In function: sklearn.utils.tests.test_testing.Klass.f_missing\",","528","             \"Parameters in function docstring have less items w.r.t. function\"","529","             \" signature, first missing item: X\",","530","             \"Full diff:\",","531","             \"- ['X', 'y']\",","532","             \"+ []\"],","533","","534","            [\"In function: \" +","535","             \"sklearn.utils.tests.test_testing.MockMetaEstimator.predict\",","536","             \"There's a parameter name mismatch in function docstring w.r.t.\"","537","             \" function signature, at index 0 diff: 'X' != 'y'\",","538","             \"Full diff:\",","539","             \"- ['X']\",","540","             \"?   ^\",","541","             \"+ ['y']\",","542","             \"?   ^\"],","543","","544","            [\"In function: \" +","545","             \"sklearn.utils.tests.test_testing.MockMetaEstimator.\"","546","             + \"predict_proba\",","547","             \"Parameters in function docstring have less items w.r.t. function\"","548","             \" signature, first missing item: X\",","549","             \"Full diff:\",","550","             \"- ['X']\",","551","             \"+ []\"],","552","","553","            [\"In function: \" +","554","                \"sklearn.utils.tests.test_testing.MockMetaEstimator.score\",","555","             \"Parameters in function docstring have less items w.r.t. function\"","556","             \" signature, first missing item: X\",","557","             \"Full diff:\",","558","             \"- ['X']\",","559","             \"+ []\"],","560","","561","            [\"In function: \" +","562","                \"sklearn.utils.tests.test_testing.MockMetaEstimator.fit\",","563","             \"Parameters in function docstring have less items w.r.t. function\"","564","             \" signature, first missing item: X\",","565","             \"Full diff:\",","566","             \"- ['X', 'y']\",","567","             \"+ []\"],","568","","569","            ]","573","    for msg, f in zip(messages,","574","                      [f_bad_order,","575","                       f_too_many_param_docstring,","576","                       f_missing,","577","                       Klass.f_missing,","578","                       mock_meta.predict,","579","                       mock_meta.predict_proba,","580","                       mock_meta.score,","581","                       mock_meta.fit]):","583","        assert msg == incorrect, ('\\n\"%s\"\\n not in \\n\"%s\"' % (msg, incorrect))"],"delete":["479","    messages = [\"a != b\", \"arg mismatch: ['b']\", \"arg mismatch: ['X', 'y']\",","480","                \"predict y != X\",","481","                \"predict_proba arg mismatch: ['X']\",","482","                \"score arg mismatch: ['X']\",","483","                \".fit arg mismatch: ['X', 'y']\"]","487","    for mess, f in zip(messages,","488","                       [f_bad_order, f_missing, Klass.f_missing,","489","                        mock_meta.predict, mock_meta.predict_proba,","490","                        mock_meta.score, mock_meta.fit]):","492","        assert len(incorrect) >= 1","493","        assert mess in incorrect[0], '\"%s\" not in \"%s\"' % (mess, incorrect[0])"]}],"sklearn\/utils\/testing.py":[{"add":["699","def _get_func_name(func):","716","","717","    qualname = func.__qualname__","718","    if qualname != func.__name__:","719","        parts.append(qualname[:qualname.find('.')])","725","def check_docstring_parameters(func, doc=None, ignore=None):","746","    func_name = _get_func_name(func)","759","    # Get the arguments from the function signature","760","    param_signature = list(filter(lambda x: x not in ignore, _get_args(func)))","762","    if len(param_signature) > 0 and param_signature[0] == 'self':","763","        param_signature.remove('self')","765","    # Analyze function's docstring","776","    param_docs = []","778","        # Type hints are empty only if parameter name ended with :","789","        # Create a list of parameters to compare with the parameters gotten","790","        # from the func signature","792","            param_docs.append(name.split(':')[0].strip('` '))","794","    # If one of the docstring's parameters had an error then return that","795","    # incorrect message","796","    if len(incorrect) > 0:","797","        return incorrect","799","    # Remove the parameters that should be ignored from list","800","    param_docs = list(filter(lambda x: x not in ignore, param_docs))","801","","802","    # The following is derived from pytest, Copyright (c) 2004-2017 Holger","803","    # Krekel and others, Licensed under MIT License. See","804","    # https:\/\/github.com\/pytest-dev\/pytest","805","","806","    message = []","807","    for i in range(min(len(param_docs), len(param_signature))):","808","        if param_signature[i] != param_docs[i]:","809","            message += [\"There's a parameter name mismatch in function\"","810","                        \" docstring w.r.t. function signature, at index %s\"","811","                        \" diff: %r != %r\" %","812","                        (i, param_signature[i], param_docs[i])]","813","            break","814","    if len(param_signature) > len(param_docs):","815","        message += [\"Parameters in function docstring have less items w.r.t.\"","816","                    \" function signature, first missing item: %s\" %","817","                    param_signature[len(param_docs)]]","818","","819","    elif len(param_signature) < len(param_docs):","820","        message += [\"Parameters in function docstring have more items w.r.t.\"","821","                    \" function signature, first extra item: %s\" %","822","                    param_docs[len(param_signature)]]","823","","824","    # If there wasn't any difference in the parameters themselves between","825","    # docstring and signature including having the same length then return","826","    # empty list","827","    if len(message) == 0:","828","        return []","829","","830","    import difflib","831","    import pprint","832","","833","    param_docs_formatted = pprint.pformat(param_docs).splitlines()","834","    param_signature_formatted = pprint.pformat(param_signature).splitlines()","835","","836","    message += [\"Full diff:\"]","837","","838","    message.extend(","839","        line.strip() for line in difflib.ndiff(param_signature_formatted,","840","                                               param_docs_formatted)","841","    )","842","","843","    incorrect.extend(message)","844","","845","    # Prepend function name","846","    incorrect = ['In function: ' + func_name] + incorrect","847",""],"delete":["699","def _get_func_name(func, class_name=None):","706","    class_name : string, optional (default: None)","707","       If ``func`` is a class method and the class name is known specify","708","       class_name for the error message.","719","    if class_name is not None:","720","        parts.append(class_name)","721","    elif hasattr(func, 'im_class'):","722","        parts.append(func.im_class.__name__)","728","def check_docstring_parameters(func, doc=None, ignore=None, class_name=None):","739","    class_name : string, optional (default: None)","740","       If ``func`` is a class method and the class name is known specify","741","       class_name for the error message.","752","    func_name = _get_func_name(func, class_name=class_name)","765","    args = list(filter(lambda x: x not in ignore, _get_args(func)))","767","    if len(args) > 0 and args[0] == 'self':","768","        args.remove('self')","780","    param_names = []","793","            param_names.append(name.split(':')[0].strip('` '))","795","    param_names = list(filter(lambda x: x not in ignore, param_names))","797","    if len(param_names) != len(args):","798","        bad = str(sorted(list(set(param_names) ^ set(args))))","799","        incorrect += [func_name + ' arg mismatch: ' + bad]","800","    else:","801","        for n1, n2 in zip(param_names, args):","802","            if n1 != n2:","803","                incorrect += [func_name + ' ' + n1 + ' != ' + n2]"]}]}},"6581b0d14238e6cd7588eb6ba3511cceb0343bc0":{"changes":{"doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/ensemble\/tests\/test_forest.py":"MODIFY","sklearn\/ensemble\/forest.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.21.rst":[{"add":["79","- |Fix| Fixed a bug in :mod:`ensemble` where the ``predict`` method would","80","   error for multiclass multioutput forests models if any targets were strings.","81","   :issue:`12834` by :user:`Elizabeth Sander <elsander>`.","82",""],"delete":[]}],"sklearn\/ensemble\/tests\/test_forest.py":[{"add":["534","            assert len(proba) == 2","535","            assert proba[0].shape == (4, 2)","536","            assert proba[1].shape == (4, 4)","539","            assert len(log_proba) == 2","540","            assert log_proba[0].shape == (4, 2)","541","            assert log_proba[1].shape == (4, 4)","550","@pytest.mark.filterwarnings('ignore:The default value of n_estimators')","551","@pytest.mark.parametrize('name', FOREST_CLASSIFIERS)","552","def test_multioutput_string(name):","553","    # Check estimators on multi-output problems with string outputs.","554","","555","    X_train = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1], [-2, 1],","556","               [-1, 1], [-1, 2], [2, -1], [1, -1], [1, -2]]","557","    y_train = [[\"red\", \"blue\"], [\"red\", \"blue\"], [\"red\", \"blue\"],","558","               [\"green\", \"green\"], [\"green\", \"green\"], [\"green\", \"green\"],","559","               [\"red\", \"purple\"], [\"red\", \"purple\"], [\"red\", \"purple\"],","560","               [\"green\", \"yellow\"], [\"green\", \"yellow\"], [\"green\", \"yellow\"]]","561","    X_test = [[-1, -1], [1, 1], [-1, 1], [1, -1]]","562","    y_test = [[\"red\", \"blue\"], [\"green\", \"green\"],","563","              [\"red\", \"purple\"], [\"green\", \"yellow\"]]","564","","565","    est = FOREST_ESTIMATORS[name](random_state=0, bootstrap=False)","566","    y_pred = est.fit(X_train, y_train).predict(X_test)","567","    assert_array_equal(y_pred, y_test)","568","","569","    with np.errstate(divide=\"ignore\"):","570","        proba = est.predict_proba(X_test)","571","        assert len(proba) == 2","572","        assert proba[0].shape == (4, 2)","573","        assert proba[1].shape == (4, 4)","574","","575","        log_proba = est.predict_log_proba(X_test)","576","        assert len(log_proba) == 2","577","        assert log_proba[0].shape == (4, 2)","578","        assert log_proba[1].shape == (4, 4)","579","","580",""],"delete":["534","            assert_equal(len(proba), 2)","535","            assert_equal(proba[0].shape, (4, 2))","536","            assert_equal(proba[1].shape, (4, 4))","539","            assert_equal(len(log_proba), 2)","540","            assert_equal(log_proba[0].shape, (4, 2))","541","            assert_equal(log_proba[1].shape, (4, 4))"]}],"sklearn\/ensemble\/forest.py":[{"add":["549","            # all dtypes should be the same, so just take the first","550","            class_type = self.classes_[0].dtype","551","            predictions = np.empty((n_samples, self.n_outputs_),","552","                                   dtype=class_type)"],"delete":["549","            predictions = np.zeros((n_samples, self.n_outputs_))"]}]}},"775bef33c06e21a5f6b730f8df80772c7a11e348":{"changes":{"sklearn\/covariance\/graph_lasso_.py":"MODIFY"},"diff":{"sklearn\/covariance\/graph_lasso_.py":[{"add":["245","            if not np.isfinite(precision_.sum()):","246","                raise FloatingPointError('The system is too ill-conditioned '","247","                                         'for this solver')"],"delete":[]}]}},"b24ef3631ac0d43c25fe5eab7081b2c6a07d45e3":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/linear_model\/tests\/test_logistic.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["89","Known Major Bugs","90","----------------","91","","92","* :issue:`11924`: :class:`LogisticRegressionCV` with `solver='lbfgs'` and","93","  `multi_class='multinomial'` may be non-deterministic or otherwise broken on","94","  MacOS. This appears to be the case on Travis CI servers, but has not been","95","  confirmed on personal MacBooks! This issue has been present in previous","96","  releases.","97",""],"delete":[]}],"sklearn\/linear_model\/tests\/test_logistic.py":[{"add":["1","import sys","1431","        if sys.platform == 'darwin' and solver == 'lbfgs':","1432","            pytest.xfail('Issue #11924: LogisticRegressionCV(solver=\"lbfgs\", '","1433","                         'multi_class=\"multinomial\") is nondterministic on '","1434","                         'MacOS.')  # pragma: no cover"],"delete":[]}]}},"14c816e2b864f238b4751f68c7fc5e69741f028a":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/datasets\/tests\/test_openml.py":"MODIFY","sklearn\/datasets\/openml.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["67","- |Fix| :func:`datasets.fetch_openml` to retry downloading when reading","68","  from local cache fails. :issue:`12517` by :user:`Thomas Fan <thomasjpfan>`.","69",""],"delete":[]}],"sklearn\/datasets\/tests\/test_openml.py":[{"add":["15","                                     _get_local_path,","16","                                     _retry_with_clean_cache)","499","@pytest.mark.parametrize('write_to_disk', [True, False])","500","def test_open_openml_url_unlinks_local_path(","501","        monkeypatch, gzip_response, tmpdir, write_to_disk):","502","    data_id = 61","503","    openml_path = sklearn.datasets.openml._DATA_FILE.format(data_id)","504","    cache_directory = str(tmpdir.mkdir('scikit_learn_data'))","505","    location = _get_local_path(openml_path, cache_directory)","506","","507","    def _mock_urlopen(request):","508","        if write_to_disk:","509","            with open(location, \"w\") as f:","510","                f.write(\"\")","511","        raise ValueError(\"Invalid request\")","512","","513","    monkeypatch.setattr(sklearn.datasets.openml, 'urlopen', _mock_urlopen)","514","","515","    with pytest.raises(ValueError, match=\"Invalid request\"):","516","        _open_openml_url(openml_path, cache_directory)","517","","518","    assert not os.path.exists(location)","519","","520","","521","def test_retry_with_clean_cache(tmpdir):","522","    data_id = 61","523","    openml_path = sklearn.datasets.openml._DATA_FILE.format(data_id)","524","    cache_directory = str(tmpdir.mkdir('scikit_learn_data'))","525","    location = _get_local_path(openml_path, cache_directory)","526","    os.makedirs(os.path.dirname(location))","527","","528","    with open(location, 'w') as f:","529","        f.write(\"\")","530","","531","    @_retry_with_clean_cache(openml_path, cache_directory)","532","    def _load_data():","533","        # The first call will raise an error since location exists","534","        if os.path.exists(location):","535","            raise Exception(\"File exist!\")","536","        return 1","537","","538","    warn_msg = \"Invalid cache, redownloading file\"","539","    with pytest.warns(RuntimeWarning, match=warn_msg):","540","        result = _load_data()","541","    assert result == 1","542","","543","","544","def test_retry_with_clean_cache_http_error(tmpdir):","545","    data_id = 61","546","    openml_path = sklearn.datasets.openml._DATA_FILE.format(data_id)","547","    cache_directory = str(tmpdir.mkdir('scikit_learn_data'))","548","","549","    @_retry_with_clean_cache(openml_path, cache_directory)","550","    def _load_data():","551","        raise HTTPError(url=None, code=412,","552","                        msg='Simulated mock error',","553","                        hdrs=None, fp=None)","554","","555","    error_msg = \"Simulated mock error\"","556","    with pytest.raises(HTTPError, match=error_msg):","557","        _load_data()","558","","559","","560","@pytest.mark.parametrize('gzip_response', [True, False])"],"delete":["15","                                     _get_local_path)"]}],"sklearn\/datasets\/openml.py":[{"add":["6","from contextlib import closing","7","from functools import wraps","8","import warnings","40","def _retry_with_clean_cache(openml_path, data_home):","41","    \"\"\"If the first call to the decorated function fails, the local cached","42","    file is removed, and the function is called again. If ``data_home`` is","43","    ``None``, then the function is called once.","44","    \"\"\"","45","    def decorator(f):","46","        @wraps(f)","47","        def wrapper():","48","            if data_home is None:","49","                return f()","50","            try:","51","                return f()","52","            except HTTPError:","53","                raise","54","            except Exception:","55","                warnings.warn(","56","                    \"Invalid cache, redownloading file\",","57","                    RuntimeWarning)","58","                local_path = _get_local_path(openml_path, data_home)","59","                if os.path.exists(local_path):","60","                    os.unlink(local_path)","61","                return f()","62","        return wrapper","63","    return decorator","64","","65","","108","            with closing(urlopen(req)) as fsrc:","109","                if is_gzip(fsrc):","110","                    with open(local_path, 'wb') as fdst:","111","                        shutil.copyfileobj(fsrc, fdst)","112","                else:","113","                    with gzip.GzipFile(local_path, 'wb') as fdst:","114","                        shutil.copyfileobj(fsrc, fdst)","116","            if os.path.exists(local_path):","117","                os.unlink(local_path)","156","","157","    @_retry_with_clean_cache(url, data_home)","158","    def _load_json():","159","        with closing(_open_openml_url(url, data_home)) as response:","160","            return json.loads(response.read().decode(\"utf-8\"))","161","","163","        return _load_json()","167","        if error.code != 412:","169","","170","    # 412 error, not in except for nicer traceback","171","    if raise_if_error:","172","        raise ValueError(error_message)","173","    return None","354","    @_retry_with_clean_cache(url, data_home)","355","    def _arff_load():","356","        with closing(_open_openml_url(url, data_home)) as response:","357","            if sparse is True:","358","                return_type = _arff.COO","359","            else:","360","                return_type = _arff.DENSE","361","","362","            if PY2:","363","                arff_file = _arff.load(","364","                    response.read(),","365","                    encode_nominal=encode_nominal,","366","                    return_type=return_type,","367","                )","368","            else:","369","                arff_file = _arff.loads(response.read().decode('utf-8'),","370","                                        encode_nominal=encode_nominal,","371","                                        return_type=return_type)","372","        return arff_file","373","","374","    return _arff_load()"],"delete":["72","        fsrc = urlopen(req)","80","            if is_gzip(fsrc):","81","                with open(local_path, 'wb') as fdst:","82","                    shutil.copyfileobj(fsrc, fdst)","83","                    fsrc.close()","84","            else:","85","                with gzip.GzipFile(local_path, 'wb') as fdst:","86","                    shutil.copyfileobj(fsrc, fdst)","87","                    fsrc.close()","89","            os.unlink(local_path)","128","    data_found = True","130","        response = _open_openml_url(url, data_home)","134","        if error.code == 412:","135","            data_found = False","136","        else:","138","    if not data_found:","139","        # not in except for nicer traceback","140","        if raise_if_error:","141","            raise ValueError(error_message)","142","        else:","143","            return None","144","    json_data = json.loads(response.read().decode(\"utf-8\"))","145","    response.close()","146","    return json_data","326","    response = _open_openml_url(url, data_home)","327","    if sparse is True:","328","        return_type = _arff.COO","329","    else:","330","        return_type = _arff.DENSE","332","    if PY2:","333","        arff_file = _arff.load(response.read(), encode_nominal=encode_nominal,","334","                               return_type=return_type, )","335","    else:","336","        arff_file = _arff.loads(response.read().decode('utf-8'),","337","                                encode_nominal=encode_nominal,","338","                                return_type=return_type)","339","    response.close()","340","    return arff_file"]}]}},"36536c6f46ac060d4b9c9e48d79d42fafa3fb344":{"changes":{"sklearn\/model_selection\/tests\/test_search.py":"MODIFY","sklearn\/datasets\/mlcomp.py":"MODIFY","sklearn\/cluster\/tests\/test_k_means.py":"MODIFY","sklearn\/externals\/_arff.py":"MODIFY"},"diff":{"sklearn\/model_selection\/tests\/test_search.py":[{"add":["135","    [(0, TypeError, r'Parameter grid is not a dict or a list \\(0\\)'),","136","     ([{'foo': [0]}, 0], TypeError, r'Parameter grid is not a dict \\(0\\)'),","138","      r\"\\(key='foo', value=0\\)\")]"],"delete":["135","    [(0, TypeError, 'Parameter grid is not a dict or a list \\(0\\)'),","136","     ([{'foo': [0]}, 0], TypeError, 'Parameter grid is not a dict \\(0\\)'),","138","      \"\\(key='foo', value=0\\)\")]"]}],"sklearn\/datasets\/mlcomp.py":[{"add":["26","    r\"\"\"Load a datasets as downloaded from http:\/\/mlcomp.org"],"delete":["26","    \"\"\"Load a datasets as downloaded from http:\/\/mlcomp.org"]}],"sklearn\/cluster\/tests\/test_k_means.py":[{"add":["887","    msg = r\"The shape of the initial centers \\(\\(4L?, 4L?\\)\\) \" \\","971","    assert_raises_regex(ValueError, r'len\\(sample_weight\\)', km.fit, X,"],"delete":["887","    msg = \"The shape of the initial centers \\(\\(4L?, 4L?\\)\\) \" \\","971","    assert_raises_regex(ValueError, 'len\\(sample_weight\\)', km.fit, X,"]}],"sklearn\/externals\/_arff.py":[{"add":["643","        res = re.sub(r'^\\%( )?', '', s)"],"delete":["643","        res = re.sub('^\\%( )?', '', s)"]}]}},"5196657be8c1280b2a8e4149ff78f92d549f22dd":{"changes":{"sklearn\/cluster\/hierarchical.py":"MODIFY"},"diff":{"sklearn\/cluster\/hierarchical.py":[{"add":["232","        X = np.require(X, requirements=\"W\")"],"delete":[]}]}},"bf11d44558d42736575e9ff2d0516a32db625e30":{"changes":{"sklearn\/utils\/random.py":"MODIFY","sklearn\/metrics\/base.py":"MODIFY","examples\/applications\/wikipedia_principal_eigenvector.py":"MODIFY","sklearn\/discriminant_analysis.py":"MODIFY"},"diff":{"sklearn\/utils\/random.py":[{"add":["160","        if not np.isclose(np.sum(class_prob_j), 1.0):"],"delete":["160","        if np.sum(class_prob_j) != 1.0:"]}],"sklearn\/metrics\/base.py":[{"add":["96","        if np.isclose(average_weight.sum(), 0.0):"],"delete":["96","        if average_weight.sum() == 0:"]}],"examples\/applications\/wikipedia_principal_eigenvector.py":[{"add":["206","    dangle = np.asarray(np.where(np.isclose(X.sum(axis=1), 0),","207","                                 1.0 \/ n, 0)).ravel()"],"delete":["206","    dangle = np.asarray(np.where(X.sum(axis=1) == 0, 1.0 \/ n, 0)).ravel()"]}],"sklearn\/discriminant_analysis.py":[{"add":["439","        if not np.isclose(self.priors_.sum(), 1.0):"],"delete":["439","        if self.priors_.sum() != 1:"]}]}},"62117f482e39757d3e5f25568e1180dcfa695363":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/preprocessing\/_encoders.py":"MODIFY","sklearn\/preprocessing\/tests\/test_encoders.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["166","- |Fix| Fixed a bug in :class:`preprocessing.OneHotEncoder` where transform","167","  failed when set to ignore unknown numpy strings of different lengths ","168","  :issue:`12471` by :user:`Gabriel Marzinotto<GMarzinotto>`.","169","","170",""],"delete":[]}],"sklearn\/preprocessing\/_encoders.py":[{"add":["112","                    # cast Xi into the largest string type necessary","113","                    # to handle different lengths of numpy strings","114","                    if (self.categories_[i].dtype.kind in ('U', 'S')","115","                            and self.categories_[i].itemsize > Xi.itemsize):","116","                        Xi = Xi.astype(self.categories_[i].dtype)","117","                    else:","118","                        Xi = Xi.copy()","119",""],"delete":["112","                    Xi = Xi.copy()"]}],"sklearn\/preprocessing\/tests\/test_encoders.py":[{"add":["275","def test_one_hot_encoder_handle_unknown_strings():","276","    X = np.array(['11111111', '22', '333', '4444']).reshape((-1, 1))","277","    X2 = np.array(['55555', '22']).reshape((-1, 1))","278","    # Non Regression test for the issue #12470","279","    # Test the ignore option, when categories are numpy string dtype","280","    # particularly when the known category strings are larger","281","    # than the unknown category strings","282","    oh = OneHotEncoder(handle_unknown='ignore')","283","    oh.fit(X)","284","    X2_passed = X2.copy()","285","    assert_array_equal(","286","        oh.transform(X2_passed).toarray(),","287","        np.array([[0.,  0.,  0.,  0.], [0.,  1.,  0.,  0.]]))","288","    # ensure transformed data was not modified in place","289","    assert_array_equal(X2, X2_passed)","290","","291",""],"delete":[]}]}},"251e58b9e2c098aa805b58dd128864ec66ec782e":{"changes":{"sklearn\/cluster\/tests\/test_optics.py":"MODIFY","sklearn\/cluster\/optics_.py":"MODIFY"},"diff":{"sklearn\/cluster\/tests\/test_optics.py":[{"add":["35","    # check attribute types and sizes","36","    assert clust.core_sample_indices_.ndim == 1","37","    assert clust.core_sample_indices_.size > 0","38","    assert clust.core_sample_indices_.dtype.kind == 'i'","39","","40","    assert clust.labels_.shape == (len(X),)","41","    assert clust.labels_.dtype.kind == 'i'","42","","43","    assert clust.reachability_.shape == (len(X),)","44","    assert clust.reachability_.dtype.kind == 'f'","45","","46","    assert clust.core_distances_.shape == (len(X),)","47","    assert clust.core_distances_.dtype.kind == 'f'","48","","49","    assert clust.ordering_.shape == (len(X),)","50","    assert clust.ordering_.dtype.kind == 'i'","51","    assert set(clust.ordering_) == set(range(len(X)))","52",""],"delete":[]}],"sklearn\/cluster\/optics_.py":[{"add":["357","        self.ordering_ = self._calculate_optics_order(X, nbrs)","370","    # OPTICS helper functions","372","    def _calculate_optics_order(self, X, nbrs):","373","        # Main OPTICS loop. Not parallelizable. The order that entries are","374","        # written to the 'ordering_' list is important!","375","        processed = np.zeros(X.shape[0], dtype=bool)","376","        ordering = np.zeros(X.shape[0], dtype=int)","377","        ordering_idx = 0","378","        for point in range(X.shape[0]):","379","            if processed[point]:","380","                continue","381","            if self.core_distances_[point] <= self.max_eps:","382","                while not processed[point]:","383","                    processed[point] = True","384","                    ordering[ordering_idx] = point","385","                    ordering_idx += 1","386","                    point = self._set_reach_dist(point, processed, X, nbrs)","387","            else:  # For very noisy points","388","                ordering[ordering_idx] = point","389","                ordering_idx += 1","390","                processed[point] = True","391","        return ordering","393","    def _set_reach_dist(self, point_index, processed, X, nbrs):","394","        P = X[point_index:point_index + 1]","399","        unproc = np.compress((~np.take(processed, indices)).ravel(),","402","        if not unproc.size:","403","            # Everything is already processed. Return to main loop","406","        dists = pairwise_distances(P, np.take(X, unproc, axis=0),","407","                                   self.metric, n_jobs=1).ravel()","408","","409","        rdists = np.maximum(dists, self.core_distances_[point_index])","410","        new_reach = np.minimum(np.take(self.reachability_, unproc), rdists)","411","        self.reachability_[unproc] = new_reach","412","","413","        # Define return order based on reachability distance","414","        return (unproc[quick_scan(np.take(self.reachability_, unproc),","415","                                  dists)])","416",""],"delete":["333","        self._processed = np.zeros((n_samples, 1), dtype=bool)","340","        self.ordering_ = []","359","        # Main OPTICS loop. Not parallelizable. The order that entries are","360","        # written to the 'ordering_' list is important!","361","        for point in range(n_samples):","362","            if not self._processed[point]:","363","                self._expand_cluster_order(point, X, nbrs)","376","    # OPTICS helper functions; these should not be public #","378","    def _expand_cluster_order(self, point, X, nbrs):","379","        # As above, not parallelizable. Parallelizing would allow items in","380","        # the 'unprocessed' list to switch to 'processed'","381","        if self.core_distances_[point] <= self.max_eps:","382","            while not self._processed[point]:","383","                self._processed[point] = True","384","                self.ordering_.append(point)","385","                point = self._set_reach_dist(point, X, nbrs)","386","        else:  # For very noisy points","387","            self.ordering_.append(point)","388","            self._processed[point] = True","390","    def _set_reach_dist(self, point_index, X, nbrs):","391","        P = np.array(X[point_index]).reshape(1, -1)","396","        unproc = np.compress((~np.take(self._processed, indices)).ravel(),","399","        if len(unproc) > 0:","400","            dists = pairwise_distances(P, np.take(X, unproc, axis=0),","401","                                       self.metric, n_jobs=None).ravel()","402","","403","            rdists = np.maximum(dists, self.core_distances_[point_index])","404","            new_reach = np.minimum(np.take(self.reachability_, unproc), rdists)","405","            self.reachability_[unproc] = new_reach","406","","407","        # Checks to see if everything is already processed;","408","        # if so, return control to main loop","409","        if unproc.size > 0:","410","            # Define return order based on reachability distance","411","            return(unproc[quick_scan(np.take(self.reachability_, unproc),","412","                                     dists)])","413","        else:"]}]}},"24e46410bd606fd32cc18f6d9cb7e9efe695597e":{"changes":{"sklearn\/base.py":"MODIFY","sklearn\/tests\/test_base.py":"MODIFY"},"diff":{"sklearn\/base.py":[{"add":["50","    elif not hasattr(estimator, 'get_params') or isinstance(estimator, type):"],"delete":["50","    elif not hasattr(estimator, 'get_params'):"]}],"sklearn\/tests\/test_base.py":[{"add":["169","def test_clone_estimator_types():","170","    # Check that clone works for parameters that are types rather than","171","    # instances","172","    clf = MyEstimator(empty=MyEstimator)","173","    clf2 = clone(clf)","174","","175","    assert clf.empty is clf2.empty","176","","177",""],"delete":[]}]}},"98357ec4d4e4626cc70e8aaa1380789894d64a93":{"changes":{"sklearn\/utils\/sparsefuncs.py":"MODIFY","sklearn\/utils\/tests\/test_sparsefuncs.py":"MODIFY"},"diff":{"sklearn\/utils\/sparsefuncs.py":[{"add":["469","            # astype here is for consistency with axis=0 dtype","470","            return out.astype('intp')"],"delete":["469","            return out"]}],"sklearn\/utils\/tests\/test_sparsefuncs.py":[{"add":["445","    assert (count_nonzero(X_csr, axis=0).dtype ==","446","            count_nonzero(X_csr, axis=1).dtype)","447","    assert (count_nonzero(X_csr, axis=0, sample_weight=sample_weight).dtype ==","448","            count_nonzero(X_csr, axis=1, sample_weight=sample_weight).dtype)","449","","450","    # Check dtypes with large sparse matrices too","451","    X_csr.indices = X_csr.indices.astype(np.int64)","452","    X_csr.indptr = X_csr.indptr.astype(np.int64)","453","    assert (count_nonzero(X_csr, axis=0).dtype ==","454","            count_nonzero(X_csr, axis=1).dtype)","455","    assert (count_nonzero(X_csr, axis=0, sample_weight=sample_weight).dtype ==","456","            count_nonzero(X_csr, axis=1, sample_weight=sample_weight).dtype)","457",""],"delete":[]}]}},"a50c03f975c4bbf306c5af1826f46ba5dc5230a0":{"changes":{"sklearn\/base.py":"MODIFY","sklearn\/metrics\/classification.py":"MODIFY","doc\/modules\/preprocessing.rst":"MODIFY","sklearn\/linear_model\/coordinate_descent.py":"MODIFY","sklearn\/preprocessing\/_encoders.py":"MODIFY","sklearn\/impute.py":"MODIFY","sklearn\/utils\/tests\/test_pprint.py":"ADD","sklearn\/neural_network\/rbm.py":"MODIFY","doc\/tutorial\/statistical_inference\/supervised_learning.rst":"MODIFY","doc\/tutorial\/statistical_inference\/unsupervised_learning.rst":"MODIFY","sklearn\/tests\/test_base.py":"MODIFY","sklearn\/svm\/classes.py":"MODIFY","sklearn\/kernel_approximation.py":"MODIFY","doc\/modules\/model_evaluation.rst":"MODIFY","sklearn\/decomposition\/pca.py":"MODIFY","sklearn\/_config.py":"MODIFY","sklearn\/feature_extraction\/dict_vectorizer.py":"MODIFY","sklearn\/linear_model\/passive_aggressive.py":"MODIFY","doc\/modules\/compose.rst":"MODIFY","sklearn\/cluster\/hierarchical.py":"MODIFY","sklearn\/discriminant_analysis.py":"MODIFY","doc\/tutorial\/statistical_inference\/model_selection.rst":"MODIFY","sklearn\/preprocessing\/data.py":"MODIFY","examples\/plot_changed_only_pprint_parameter.py":"ADD","sklearn\/ensemble\/forest.py":"MODIFY","doc\/modules\/linear_model.rst":"MODIFY","sklearn\/tests\/test_config.py":"MODIFY","sklearn\/utils\/_pprint.py":"ADD","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/linear_model\/perceptron.py":"MODIFY"},"diff":{"sklearn\/base.py":[{"add":["226","        from .utils._pprint import _EstimatorPrettyPrinter","227","","228","        N_CHAR_MAX = 700  # number of non-whitespace or newline chars","229","        N_MAX_ELEMENTS_TO_SHOW = 30  # number of elements to show in sequences","230","","231","        # use ellipsis for sequences with a lot of elements","232","        pp = _EstimatorPrettyPrinter(","233","            compact=True, indent=1, indent_at_name=True,","234","            n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)","235","","236","        repr_ = pp.pformat(self)","237","","238","        # Use bruteforce ellipsis if string is very long","239","        if len(''.join(repr_.split())) > N_CHAR_MAX:  # check non-blank chars","240","            lim = N_CHAR_MAX \/\/ 2","241","            repr_ = repr_[:lim] + '...' + repr_[-lim:]","242","        return repr_"],"delete":["226","        class_name = self.__class__.__name__","227","        return '%s(%s)' % (class_name, _pprint(self.get_params(deep=False),","228","                                               offset=len(class_name),),)"]}],"sklearn\/metrics\/classification.py":[{"add":["2078","    >>> est.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","2095","    >>> est.fit(X, Y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["2078","    >>> est.fit(X, y)","2095","    >>> est.fit(X, Y)"]}],"doc\/modules\/preprocessing.rst":[{"add":["490","  >>> enc.fit(X)  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE","516","    >>> enc.fit(X) # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE","534","    >>> enc.fit(X) # doctest: +ELLIPSIS  +NORMALIZE_WHITESPACE"],"delete":["490","  >>> enc.fit(X)  # doctest: +ELLIPSIS","516","    >>> enc.fit(X) # doctest: +ELLIPSIS","534","    >>> enc.fit(X) # doctest: +ELLIPSIS"]}],"sklearn\/linear_model\/coordinate_descent.py":[{"add":["625","    >>> regr.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","905","    ... # doctest: +NORMALIZE_WHITESPACE","1555","    >>> regr.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","1910","    ... # doctest: +NORMALIZE_WHITESPACE"],"delete":["625","    >>> regr.fit(X, y)","1554","    >>> regr.fit(X, y)"]}],"sklearn\/preprocessing\/_encoders.py":[{"add":["247","    ... # doctest: +NORMALIZE_WHITESPACE"],"delete":[]}],"sklearn\/impute.py":[{"add":["466","    >>> indicator.fit(X1)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["466","    >>> indicator.fit(X1)"]}],"sklearn\/utils\/tests\/test_pprint.py":[{"add":[],"delete":[]}],"sklearn\/neural_network\/rbm.py":[{"add":["83","    >>> model.fit(X)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["83","    >>> model.fit(X)"]}],"doc\/tutorial\/statistical_inference\/supervised_learning.rst":[{"add":["336","    ... # doctest: +NORMALIZE_WHITESPACE"],"delete":[]}],"doc\/tutorial\/statistical_inference\/unsupervised_learning.rst":[{"add":["276","    >>> pca.fit(X)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["276","    >>> pca.fit(X)"]}],"sklearn\/tests\/test_base.py":[{"add":["187","    assert_equal(len(repr(some_est)), 495)"],"delete":["187","    assert_equal(len(repr(some_est)), 415)"]}],"sklearn\/svm\/classes.py":[{"add":["119","    >>> clf.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","331","    >>> regr.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["119","    >>> clf.fit(X, y)","331","    >>> regr.fit(X, y)"]}],"sklearn\/kernel_approximation.py":[{"add":["165","    >>> clf.fit(X_features, y)  # doctest: +NORMALIZE_WHITESPACE","285","    >>> clf.fit(X_transformed, y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["165","    >>> clf.fit(X_features, y)","285","    >>> clf.fit(X_transformed, y)"]}],"doc\/modules\/model_evaluation.rst":[{"add":["981","  >>> est.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","999","  >>> est.fit(X, Y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["981","  >>> est.fit(X, y)","999","  >>> est.fit(X, Y)"]}],"sklearn\/decomposition\/pca.py":[{"add":["278","    >>> pca.fit(X)  # doctest: +NORMALIZE_WHITESPACE","296","    >>> pca.fit(X)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["278","    >>> pca.fit(X)","296","    >>> pca.fit(X)"]}],"sklearn\/_config.py":[{"add":["7","    'working_memory': int(os.environ.get('SKLEARN_WORKING_MEMORY', 1024)),","8","    'print_changed_only': False,","23","def set_config(assume_finite=None, working_memory=None,","24","               print_changed_only=None):","47","    print_changed_only : bool, optional","48","        If True, only the parameters that were set to non-default","49","        values will be printed when printing an estimator. For example,","50","        ``print(SVC())`` while True will only print 'SVC()' while the default","51","        behaviour would be to print 'SVC(C=1.0, cache_size=200, ...)' with","52","        all the non-changed parameters.","53","","54","        .. versionadded:: 0.21","60","    if print_changed_only is not None:","61","        _global_config['print_changed_only'] = print_changed_only"],"delete":["7","    'working_memory': int(os.environ.get('SKLEARN_WORKING_MEMORY', 1024))","22","def set_config(assume_finite=None, working_memory=None):"]}],"sklearn\/feature_extraction\/dict_vectorizer.py":[{"add":["347","        ...                                   # doctest: +NORMALIZE_WHITESPACE"],"delete":[]}],"sklearn\/linear_model\/passive_aggressive.py":[{"add":["143","    >>> clf.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","382","    >>> regr.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["143","    >>> clf.fit(X, y)","382","    >>> regr.fit(X, y)"]}],"doc\/modules\/compose.rst":[{"add":["78","    >>> pipe.steps[0]  # doctest: +NORMALIZE_WHITESPACE","84","    >>> pipe.named_steps['reduce_dim']  # doctest: +NORMALIZE_WHITESPACE"],"delete":["78","    >>> pipe.steps[0]","84","    >>> pipe.named_steps['reduce_dim']"]}],"sklearn\/cluster\/hierarchical.py":[{"add":["921","    >>> agglo.fit(X) # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE"],"delete":["921","    >>> agglo.fit(X) # doctest: +ELLIPSIS"]}],"sklearn\/discriminant_analysis.py":[{"add":["244","    >>> clf.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["244","    >>> clf.fit(X, y)"]}],"doc\/tutorial\/statistical_inference\/model_selection.rst":[{"add":["269","    >>> lasso.fit(X_diabetes, y_diabetes)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["269","    >>> lasso.fit(X_diabetes, y_diabetes)"]}],"sklearn\/preprocessing\/data.py":[{"add":["1090","    >>> transformer  # doctest: +NORMALIZE_WHITESPACE"],"delete":["1090","    >>> transformer"]}],"examples\/plot_changed_only_pprint_parameter.py":[{"add":[],"delete":[]}],"sklearn\/ensemble\/forest.py":[{"add":["958","    >>> clf.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","1210","    >>> regr.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","1237","    The default value ``max_features=\"auto\"`` uses ``n_features``","1246","    .. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized","1498","    .. [1] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized"],"delete":["958","    >>> clf.fit(X, y)","1210","    >>> regr.fit(X, y)","1237","    The default value ``max_features=\"auto\"`` uses ``n_features`` ","1246","    .. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized ","1498","    .. [1] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized "]}],"doc\/modules\/linear_model.rst":[{"add":["187","    >>> reg.fit([[0, 0], [1, 1]], [0, 1])  # doctest: +NORMALIZE_WHITESPACE","641","    >>> reg.fit(X, Y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["187","    >>> reg.fit([[0, 0], [1, 1]], [0, 1])","641","    >>> reg.fit(X, Y)"]}],"sklearn\/tests\/test_config.py":[{"add":["5","    assert get_config() == {'assume_finite': False, 'working_memory': 1024,","6","                            'print_changed_only': False}","13","        assert get_config() == {'assume_finite': True, 'working_memory': 1024,","14","                                'print_changed_only': False}","38","    assert get_config() == {'assume_finite': False, 'working_memory': 1024,","39","                            'print_changed_only': False}"],"delete":["5","    assert get_config() == {'assume_finite': False, 'working_memory': 1024}","12","        assert get_config() == {'assume_finite': True, 'working_memory': 1024}","36","    assert get_config() == {'assume_finite': False, 'working_memory': 1024}"]}],"sklearn\/utils\/_pprint.py":[{"add":[],"delete":[]}],"doc\/whats_new\/v0.21.rst":[{"add":["202","  :issue:`12344` by :user:`Adrin Jalali <adrinjalali>`.","208","- The `__repr__()` method of all estimators (used when calling","209","  `print(estimator)`) has been entirely re-written, building on Python's","210","  pretty printing standard library. All parameters are printed by default,","211","  but this can be altered with the ``print_changed_only`` option in","212","  :func:`sklearn.set_config`. :issue:`11705` by :user:`Nicolas Hug","213","  <NicolasHug>`.","214",""],"delete":["202","  :pr:`12344` by :user:`Adrin Jalali <adrinjalali>`."]}],"sklearn\/linear_model\/perceptron.py":[{"add":["133","    >>> clf.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["133","    >>> clf.fit(X, y)"]}]}},"c2f17d0fc0e57a9ed00b895b5f419d956adfc5cf":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/metrics\/pairwise.py":"MODIFY","sklearn\/metrics\/tests\/test_pairwise.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["105",":mod:`sklearn.metrics`","106","......................","107","","108","- |Fix| Fixed a bug in :func:`pairwise.pairwise_distances_argmin_min` which","109","  returned the square root of the distance when the metric parameter was set to","110","  \"euclidean\". :issue:`12481` by :user:`J¨¦r¨¦mie du Boisberranger <jeremiedbb>`.","111",""],"delete":[]}],"sklearn\/metrics\/pairwise.py":[{"add":[],"delete":["360","    if metric == \"euclidean\" and not metric_kwargs.get(\"squared\", False):","361","        np.sqrt(values, values)"]}],"sklearn\/metrics\/tests\/test_pairwise.py":[{"add":["345","    Y = [[-2], [3]]","350","    expected_idx = [0, 1]","351","    expected_vals = [2, 2]","352","    expected_vals_sq = [4, 4]","354","    # euclidean metric","355","    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"euclidean\")","356","    idx2 = pairwise_distances_argmin(X, Y, metric=\"euclidean\")","357","    assert_array_almost_equal(idx, expected_idx)","358","    assert_array_almost_equal(idx2, expected_idx)","359","    assert_array_almost_equal(vals, expected_vals)","361","    idxsp, valssp = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"euclidean\")","362","    assert_array_almost_equal(idxsp, expected_idx)","363","    assert_array_almost_equal(valssp, expected_vals)","365","    assert_equal(type(idxsp), np.ndarray)","366","    assert_equal(type(valssp), np.ndarray)","367","","368","    # euclidean metric squared","369","    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"euclidean\",","370","                                              metric_kwargs={\"squared\": True})","371","    assert_array_almost_equal(idx, expected_idx)","372","    assert_array_almost_equal(vals, expected_vals_sq)","375","    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"manhattan\")","376","    idx2 = pairwise_distances_argmin(X, Y, metric=\"manhattan\")","377","    assert_array_almost_equal(idx, expected_idx)","378","    assert_array_almost_equal(idx2, expected_idx)","379","    assert_array_almost_equal(vals, expected_vals)","380","    # sparse matrix case","381","    idxsp, valssp = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"manhattan\")","382","    assert_array_almost_equal(idxsp, expected_idx)","383","    assert_array_almost_equal(valssp, expected_vals)","386","    idx, vals = pairwise_distances_argmin_min(X, Y, metric=minkowski,","387","                                              metric_kwargs={\"p\": 2})","388","    assert_array_almost_equal(idx, expected_idx)","389","    assert_array_almost_equal(vals, expected_vals)","392","    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"minkowski\",","393","                                              metric_kwargs={\"p\": 2})","394","    assert_array_almost_equal(idx, expected_idx)","395","    assert_array_almost_equal(vals, expected_vals)"],"delete":["345","    Y = [[-1], [2]]","350","    # euclidean metric","351","    D, E = pairwise_distances_argmin_min(X, Y, metric=\"euclidean\")","352","    D2 = pairwise_distances_argmin(X, Y, metric=\"euclidean\")","353","    assert_array_almost_equal(D, [0, 1])","354","    assert_array_almost_equal(D2, [0, 1])","355","    assert_array_almost_equal(D, [0, 1])","356","    assert_array_almost_equal(E, [1., 1.])","359","    Dsp, Esp = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"euclidean\")","360","    assert_array_equal(Dsp, D)","361","    assert_array_equal(Esp, E)","363","    assert_equal(type(Dsp), np.ndarray)","364","    assert_equal(type(Esp), np.ndarray)","367","    D, E = pairwise_distances_argmin_min(X, Y, metric=\"manhattan\")","368","    D2 = pairwise_distances_argmin(X, Y, metric=\"manhattan\")","369","    assert_array_almost_equal(D, [0, 1])","370","    assert_array_almost_equal(D2, [0, 1])","371","    assert_array_almost_equal(E, [1., 1.])","372","    D, E = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"manhattan\")","373","    D2 = pairwise_distances_argmin(Xsp, Ysp, metric=\"manhattan\")","374","    assert_array_almost_equal(D, [0, 1])","375","    assert_array_almost_equal(E, [1., 1.])","378","    D, E = pairwise_distances_argmin_min(X, Y, metric=minkowski,","379","                                         metric_kwargs={\"p\": 2})","380","    assert_array_almost_equal(D, [0, 1])","381","    assert_array_almost_equal(E, [1., 1.])","384","    D, E = pairwise_distances_argmin_min(X, Y, metric=\"minkowski\",","385","                                         metric_kwargs={\"p\": 2})","386","    assert_array_almost_equal(D, [0, 1])","387","    assert_array_almost_equal(E, [1., 1.])"]}]}},"0296916d7d61036eceafa1739599368a9aaf075b":{"changes":{"\/dev\/null":"DELETE","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/cluster\/setup.py":"MODIFY","sklearn\/cluster\/tests\/test_optics.py":"MODIFY","sklearn\/cluster\/optics_.py":"MODIFY"},"diff":{"\/dev\/null":[{"add":[],"delete":[]}],"doc\/whats_new\/v0.21.rst":[{"add":["47","  to set and that scales better, by :user:`Shane <espg>`,","48","  :user:`Adrin Jalali <adrinjalali>`, and :user:`Erich Schubert <kno10>`."],"delete":["47","  to set and that scales better, by :user:`Shane <espg>` and","48","  :user:`Adrin Jalali <adrinjalali>`."]}],"sklearn\/cluster\/setup.py":[{"add":[],"delete":["25","    config.add_extension('_optics_inner',","26","                         sources=['_optics_inner.pyx'],","27","                         include_dirs=[numpy.get_include()],","28","                         libraries=libraries)"]}],"sklearn\/cluster\/tests\/test_optics.py":[{"add":["24","n_points_per_cluster = 50","217","def test_compare_to_ELKI():","218","    # Expected values, computed with (future) ELKI 0.7.5 using:","219","    # java -jar elki.jar cli -dbc.in csv -dbc.filter FixedDBIDsFilter","220","    #   -algorithm clustering.optics.OPTICSHeap -optics.minpts 5","221","    # where the FixedDBIDsFilter gives 0-indexed ids.","222","    r = [np.inf, 0.7865694338710508, 0.4373157299595305, 0.4121908069391695,","223","         0.302907091394212, 0.20815674060999778, 0.20815674060999778,","224","         0.15190193459676368, 0.15190193459676368, 0.28229645104833345,","225","         0.302907091394212, 0.30507239477026865, 0.30820580778767087,","226","         0.3289019667317037, 0.3458462228589966, 0.3458462228589966,","227","         0.2931114364132193, 0.2931114364132193, 0.2562790168458507,","228","         0.23654635530592025, 0.37903448688824876, 0.3920764620583683,","229","         0.4121908069391695, 0.4364542226186831, 0.45523658462146793,","230","         0.458757846268185, 0.458757846268185, 0.4752907412198826,","231","         0.42350366820623375, 0.42350366820623375, 0.42350366820623375,","232","         0.47758738570352993, 0.47758738570352993, 0.4776963110272057,","233","         0.5272079288923731, 0.5591861752070968, 0.5592057084987357,","234","         0.5609913790596295, 0.5909117211348757, 0.5940470220777727,","235","         0.5940470220777727, 0.6861627576116127, 0.687795873252133,","236","         0.7538541412862811, 0.7865694338710508, 0.8038180561910464,","237","         0.8038180561910464, 0.8242451615289921, 0.8548361202185057,","238","         0.8790098789921685, 2.9281214555815764, 1.3256656984284734,","239","         0.19590944671099267, 0.1339924636672767, 0.1137384200258616,","240","         0.061455005237474075, 0.061455005237474075, 0.061455005237474075,","241","         0.045627777293497276, 0.045627777293497276, 0.045627777293497276,","242","         0.04900902556283447, 0.061455005237474075, 0.06225461602815799,","243","         0.06835750467748272, 0.07882900172724974, 0.07882900172724974,","244","         0.07650735397943846, 0.07650735397943846, 0.07650735397943846,","245","         0.07650735397943846, 0.07650735397943846, 0.07113275489288699,","246","         0.07890196345324527, 0.07052683707634783, 0.07052683707634783,","247","         0.07052683707634783, 0.08284027053523288, 0.08725436842020087,","248","         0.08725436842020087, 0.09010229261951723, 0.09128578974358925,","249","         0.09154172670176584, 0.0968576383038391, 0.12007572768323092,","250","         0.12024155806196564, 0.12141990481584404, 0.1339924636672767,","251","         0.13694322786307633, 0.14275793459246572, 0.15093125027309579,","252","         0.17927454395170142, 0.18151803569400365, 0.1906028449191095,","253","         0.1906028449191095, 0.19604486784973194, 0.2096539172540186,","254","         0.2096539172540186, 0.21614333983312325, 0.22036454909290296,","255","         0.23610322103910933, 0.26028003932256766, 0.2607126030060721,","256","         0.2891824876072483, 0.3258089271514364, 0.35968687619960743,","257","         0.4512973330510512, 0.4746141313843085, 0.5958585488429471,","258","         0.6468718886525733, 0.6878453052524358, 0.6911582799500199,","259","         0.7172169499815705, 0.7209874999572031, 0.6326884657912096,","260","         0.5755681293026617, 0.5755681293026617, 0.5755681293026617,","261","         0.6015042225447333, 0.6756244556376542, 0.4722384908959966,","262","         0.08775739179493615, 0.06665303472021758, 0.056308477780164796,","263","         0.056308477780164796, 0.05507767260835565, 0.05368146914586802,","264","         0.05163427719303039, 0.05163427719303039, 0.05163427719303039,","265","         0.04918757627098621, 0.04918757627098621, 0.05368146914586802,","266","         0.05473720349424546, 0.05473720349424546, 0.048442038421760626,","267","         0.048442038421760626, 0.04598840269934622, 0.03984301937835033,","268","         0.04598840269934622, 0.04598840269934622, 0.04303884892957088,","269","         0.04303884892957088, 0.04303884892957088, 0.0431802780806032,","270","         0.0520412490141781, 0.056308477780164796, 0.05080724020124642,","271","         0.05080724020124642, 0.05080724020124642, 0.06385565101399236,","272","         0.05840878369200427, 0.0474472391259039, 0.0474472391259039,","273","         0.04232512684465669, 0.04232512684465669, 0.04232512684465669,","274","         0.0474472391259039, 0.051802632822946656, 0.051802632822946656,","275","         0.05316405104684577, 0.05316405104684577, 0.05840878369200427,","276","         0.06385565101399236, 0.08025248922898705, 0.08775739179493615,","277","         0.08993337040710143, 0.08993337040710143, 0.08993337040710143,","278","         0.08993337040710143, 0.297457175321605, 0.29763608186278934,","279","         0.3415255849656254, 0.34713336941105105, 0.44108940848708167,","280","         0.35942962652965604, 0.35942962652965604, 0.33609522256535296,","281","         0.5008111387107295, 0.5333587622018111, 0.6223243743872802,","282","         0.6793840035409552, 0.7445032492109848, 0.7445032492109848,","283","         0.6556432627279256, 0.6556432627279256, 0.6556432627279256,","284","         0.8196566935960162, 0.8724089149982351, 0.9352758042365477,","285","         0.9352758042365477, 1.0581847953137133, 1.0684332509194163,","286","         1.0887817699873303, 1.2552604310322708, 1.3993856001769436,","287","         1.4869615658197606, 1.6588098267326852, 1.679969559453028,","288","         1.679969559453028, 1.6860509219163458, 1.6860509219163458,","289","         1.1465697826627317, 0.992866533434785, 0.7691908270707519,","290","         0.578131499171622, 0.578131499171622, 0.578131499171622,","291","         0.5754243919945694, 0.8416199360035114, 0.8722493727270406,","292","         0.9156549976203665, 0.9156549976203665, 0.7472322844356064,","293","         0.715219324518981, 0.715219324518981, 0.715219324518981,","294","         0.7472322844356064, 0.820988298336316, 0.908958489674247,","295","         0.9234036745782839, 0.9519521817942455, 0.992866533434785,","296","         0.992866533434785, 0.9995692674695029, 1.0727415198904493,","297","         1.1395519941203158, 1.1395519941203158, 1.1741737271442092,","298","         1.212860115632712, 0.8724097897372123, 0.8724097897372123,","299","         0.8724097897372123, 1.2439272570611581, 1.2439272570611581,","300","         1.3524538390109015, 1.3524538390109015, 1.2982303284415664,","301","         1.3610655849680207, 1.3802783392089437, 1.3802783392089437,","302","         1.4540636953090629, 1.5879329500533819, 1.5909193228826986,","303","         1.72931779186001, 1.9619075944592093, 2.1994355761906257,","304","         2.2508672067362165, 2.274436122235927, 2.417635732260135,","305","         3.014235905390584, 0.30616929141177107, 0.16449675872754976,","306","         0.09071681523805683, 0.09071681523805683, 0.09071681523805683,","307","         0.08727060912039632, 0.09151721189581336, 0.12277953408786725,","308","         0.14285575406641507, 0.16449675872754976, 0.16321992344119793,","309","         0.1330971730344373, 0.11429891993167259, 0.11429891993167259,","310","         0.11429891993167259, 0.11429891993167259, 0.11429891993167259,","311","         0.0945498340011516, 0.11410457435712089, 0.1196414019798306,","312","         0.12925682285016715, 0.12925682285016715, 0.12925682285016715,","313","         0.12864887158869853, 0.12864887158869853, 0.12864887158869853,","314","         0.13369634918690246, 0.14330826543275352, 0.14877705862323184,","315","         0.15203263952428328, 0.15696350160889708, 0.1585326700393211,","316","         0.1585326700393211, 0.16034306786654595, 0.16034306786654595,","317","         0.15053328296567992, 0.16396729418886688, 0.16763548009617293,","318","         0.1732029325454474, 0.21163390061029352, 0.21497664171864372,","319","         0.22125889949299, 0.240251070192081, 0.240251070192081,","320","         0.2413620965310808, 0.26319419022234064, 0.26319419022234064,","321","         0.27989712380504483, 0.2909782800714374]","322","    o = [0, 3, 6, 7, 15, 4, 27, 28, 49, 17, 35, 47, 46, 39, 13, 19,","323","         22, 29, 30, 38, 34, 32, 43, 8, 25, 9, 37, 23, 33, 40, 44, 11, 36, 5,","324","         45, 48, 41, 26, 24, 20, 31, 2, 16, 10, 18, 14, 42, 12, 1, 21, 234,","325","         132, 112, 115, 107, 110, 120, 114, 100, 131, 137, 145, 130, 121, 134,","326","         116, 149, 108, 111, 113, 142, 148, 119, 104, 126, 133, 138, 127, 101,","327","         105, 103, 106, 125, 140, 123, 147, 144, 129, 141, 117, 143, 136, 128,","328","         122, 124, 102, 109, 249, 146, 118, 135, 245, 139, 224, 241, 217, 202,","329","         248, 233, 214, 236, 211, 206, 231, 212, 221, 229, 244, 208, 226, 83,","330","         76, 53, 77, 88, 62, 66, 65, 89, 93, 79, 95, 74, 70, 82, 51, 73, 87,","331","         67, 94, 56, 52, 63, 80, 75, 57, 96, 60, 69, 90, 86, 58, 68, 81, 64,","332","         84, 85, 97, 59, 98, 61, 71, 78, 92, 50, 91, 55, 54, 72, 99, 210, 201,","333","         216, 239, 203, 218, 219, 222, 240, 294, 243, 246, 204, 220, 200, 215,","334","         230, 225, 205, 207, 237, 223, 235, 209, 228, 238, 227, 285, 232, 256,","335","         281, 270, 260, 252, 272, 268, 292, 298, 269, 275, 257, 250, 284, 283,","336","         286, 295, 297, 293, 289, 258, 299, 282, 262, 296, 287, 267, 255, 263,","337","         288, 276, 251, 266, 274, 271, 277, 261, 279, 290, 253, 254, 291, 259,","338","         280, 278, 273, 247, 265, 242, 264, 213, 199, 174, 154, 152, 180, 186,","339","         195, 170, 181, 176, 187, 173, 157, 159, 158, 172, 182, 183, 151, 197,","340","         177, 160, 156, 171, 175, 184, 193, 161, 179, 196, 185, 192, 165, 166,","341","         164, 189, 155, 162, 188, 153, 178, 169, 194, 150, 163, 198, 190, 191,","342","         168, 167]","343","    p = [-1, 0, 3, 6, 7, 15, 15, 27, 27, 4, 7, 49, 47, 4, 39, 39,","344","         19, 19, 29, 30, 30, 13, 6, 43, 34, 32, 32, 25, 23, 23, 23, 3, 11, 46,","345","         46, 45, 9, 38, 33, 26, 26, 8, 20, 33, 0, 18, 18, 2, 18, 44, 0, 234,","346","         132, 112, 115, 107, 107, 120, 114, 114, 114, 114, 107, 100, 100, 134,","347","         134, 149, 149, 108, 108, 108, 148, 113, 104, 104, 104, 142, 127, 127,","348","         126, 138, 126, 148, 127, 148, 127, 112, 147, 116, 117, 101, 145, 128,","349","         128, 122, 136, 136, 249, 102, 102, 118, 143, 146, 245, 123, 139, 241,","350","         241, 217, 248, 202, 248, 224, 231, 212, 212, 212, 229, 229, 226, 83,","351","         76, 53, 53, 88, 62, 66, 66, 66, 93, 93, 79, 93, 70, 82, 82, 73, 87,","352","         73, 94, 56, 56, 56, 63, 67, 53, 96, 96, 96, 69, 86, 58, 58, 81, 81,","353","         81, 58, 64, 64, 59, 59, 86, 69, 78, 83, 84, 55, 55, 55, 72, 50, 201,","354","         210, 216, 203, 203, 219, 54, 240, 239, 240, 236, 236, 220, 220, 220,","355","         217, 139, 243, 243, 204, 211, 246, 215, 223, 294, 209, 227, 227, 209,","356","         281, 270, 260, 252, 272, 272, 272, 298, 269, 298, 275, 275, 284, 283,","357","         283, 283, 284, 286, 283, 298, 299, 260, 260, 250, 299, 258, 258, 296,","358","         250, 276, 276, 276, 289, 289, 267, 267, 279, 261, 277, 277, 258, 266,","359","         290, 209, 207, 290, 228, 278, 228, 290, 199, 174, 154, 154, 154, 186,","360","         186, 180, 170, 174, 187, 173, 157, 159, 157, 157, 159, 183, 183, 172,","361","         197, 160, 160, 171, 171, 171, 151, 173, 184, 151, 196, 185, 185, 179,","362","         179, 189, 177, 165, 175, 162, 164, 181, 169, 169, 181, 178, 178, 178,","363","         168]","364","","366","    # Does NOT work with metric='euclidean', because sklearn euclidean has","367","    # worse numeric precision. 'minkowski' is slower but more accurate.","368","    clust = OPTICS(min_samples=5, metric='minkowski').fit(X)","370","    assert_array_equal(clust.ordering_, np.array(o))","371","    assert_array_equal(clust.predecessor_[clust.ordering_], np.array(p))","372","    assert_allclose(clust.reachability_[clust.ordering_], np.array(r))","373","    # ELKI currently does not print the core distances (which are not used much","374","    # in literature, but we can at least ensure to have this consistency:","375","    for i in clust.ordering_[1:]:","376","        assert (clust.reachability_[i] >=","377","                clust.core_distances_[clust.predecessor_[i]])","390","","391","","392","def test_processing_order():","393","    \"\"\"Early dev version of OPTICS would not consider all unprocessed points,","394","    but only direct neighbors. This tests against this mistake.\"\"\"","395","    Y = [[0], [10], [-10], [25]]","396","    clust = OPTICS(min_samples=3, max_eps=15).fit(Y)","397","    assert_array_equal(clust.reachability_, [np.inf, 10, 10, 15])","398","    assert_array_equal(clust.core_distances_, [10, 15, 20, 25])","399","    assert_array_equal(clust.ordering_, [0, 1, 2, 3])"],"delete":["19","from sklearn.utils import _IS_32BIT","25","n_points_per_cluster = 250","218","def test_reach_dists():","221","    clust = OPTICS(min_samples=10, metric='minkowski').fit(X)","222","","223","    # Expected values, matches 'RD' results from:","224","    # http:\/\/chemometria.us.edu.pl\/download\/optics.py","225","","226","    v = [np.inf, 0.606005, 0.472013, 0.162951, 0.161000, 0.385547, 0.179715,","227","         0.213507, 0.348468, 0.308146, 0.560519, 0.266072, 0.764384, 0.253164,","228","         0.435716, 0.153696, 0.363924, 0.194267, 0.392313, 0.230589, 0.260023,","229","         0.535348, 0.168173, 0.296736, 0.310583, 0.277204, 0.250654, 0.153696,","230","         0.215533, 0.175710, 0.168173, 0.283134, 0.256372, 0.313931, 0.234164,","231","         0.179715, 0.352957, 0.277052, 0.180986, 0.203819, 0.296022, 0.356691,","232","         0.515438, 0.219208, 0.265821, 0.346630, 0.275305, 0.229332, 0.433715,","233","         0.153696, 0.584960, 0.265821, 0.471049, 0.259154, 0.461707, 0.400021,","234","         0.422748, 0.300699, 0.162951, 0.290504, 0.315199, 0.327130, 0.168864,","235","         0.462826, 0.188862, 0.259784, 0.216788, 0.259784, 0.195673, 0.315199,","236","         0.313931, 0.189128, 0.461707, 0.265821, 0.233594, 0.433715, 0.222260,","237","         0.251734, 0.352957, 0.218134, 0.453792, 0.179715, 0.296736, 0.260023,","238","         0.311162, 0.214549, 0.266072, 0.318744, 0.180986, 0.194267, 0.262882,","239","         0.420186, 0.352957, 0.288388, 0.360962, 0.328054, 0.293849, 0.198271,","240","         0.248772, 0.461707, 0.216788, 0.396450, 0.352957, 0.289448, 0.241311,","241","         0.213742, 0.220516, 0.218134, 0.153696, 0.516090, 0.218134, 0.221507,","242","         0.328647, 0.255933, 0.195766, 0.233594, 0.205270, 0.296736, 0.726008,","243","         0.251991, 0.168173, 0.214027, 0.262882, 0.342089, 0.260023, 0.266072,","244","         0.253164, 0.230345, 0.262882, 0.296022, 0.227047, 0.205974, 0.328647,","245","         0.184315, 0.196304, 0.831185, 0.514116, 0.168173, 0.189784, 0.664306,","246","         0.327130, 0.379139, 0.208932, 0.266140, 0.362751, 0.168173, 0.764384,","247","         0.327130, 0.187107, 0.194267, 0.414196, 0.251734, 0.220516, 0.363924,","248","         0.166886, 0.327130, 0.233594, 0.203819, 0.230589, 0.203819, 0.222972,","249","         0.311526, 0.218134, 0.422748, 0.314870, 0.315199, 0.315199, 0.594179,","250","         0.328647, 0.415638, 0.244046, 0.250654, 0.214027, 0.203819, 0.213507,","251","         0.260023, 0.311442, 0.168173, 0.389432, 0.229343, 0.162951, 0.311162,","252","         0.153696, 0.214027, 0.250654, 0.315199, 0.172484, 0.153696, 0.352957,","253","         0.314870, 0.328647, 0.546505, 0.378118, 0.260023, 0.387830, 0.199714,","254","         0.262882, 0.250654, 0.345254, 0.396450, 0.250654, 0.179715, 0.328647,","255","         0.179715, 0.263104, 0.265821, 0.231714, 0.514116, 0.213507, 0.474255,","256","         0.212568, 0.376760, 0.196304, 0.844945, 0.194267, 0.264914, 0.210320,","257","         0.316374, 0.184315, 0.179715, 0.250654, 0.153696, 0.162951, 0.315199,","258","         0.179965, 0.297876, 0.213507, 0.475420, 0.439372, 0.241311, 0.260927,","259","         0.194267, 0.422748, 0.222260, 0.411940, 0.414733, 0.260923, 0.396450,","260","         0.380672, 0.333277, 0.290504, 0.196014, 0.844945, 0.506989, 0.153696,","261","         0.218134, 0.392313, 0.698970, 0.168173, 0.227047, 0.028856, 0.033243,","262","         0.028506, 0.057003, 0.038335, 0.051183, 0.063923, 0.022363, 0.030677,","263","         0.036155, 0.017748, 0.062887, 0.036041, 0.051183, 0.078198, 0.068936,","264","         0.032418, 0.040634, 0.022188, 0.022112, 0.036858, 0.040199, 0.025549,","265","         0.083975, 0.032209, 0.025525, 0.032952, 0.034727, 0.068887, 0.040634,","266","         0.048985, 0.047450, 0.022422, 0.023767, 0.028092, 0.047450, 0.029202,","267","         0.026105, 0.030542, 0.032250, 0.062887, 0.038335, 0.026753, 0.028092,","268","         0.099391, 0.021430, 0.020496, 0.021430, 0.025043, 0.023868, 0.050069,","269","         0.023868, 0.044140, 0.038032, 0.022112, 0.044140, 0.031528, 0.028092,","270","         0.020065, 0.055926, 0.031508, 0.025549, 0.028062, 0.036155, 0.023694,","271","         0.029423, 0.026105, 0.028497, 0.023868, 0.044808, 0.035783, 0.033090,","272","         0.038779, 0.032146, 0.038421, 0.057328, 0.020065, 0.020065, 0.028858,","273","         0.021337, 0.041226, 0.022507, 0.028506, 0.030257, 0.057912, 0.050876,","274","         0.120109, 0.020065, 0.034727, 0.038596, 0.037008, 0.031609, 0.095640,","275","         0.083728, 0.064906, 0.030677, 0.057003, 0.037008, 0.018705, 0.030677,","276","         0.044140, 0.034727, 0.045226, 0.032146, 0.032418, 0.029332, 0.030104,","277","         0.033243, 0.030104, 0.032209, 0.026405, 0.024092, 0.048441, 0.036379,","278","         0.030745, 0.023454, 0.018705, 0.124248, 0.041114, 0.020700, 0.042633,","279","         0.042455, 0.028497, 0.029202, 0.057859, 0.053157, 0.036155, 0.029534,","280","         0.032209, 0.038032, 0.024617, 0.023071, 0.033090, 0.023694, 0.047277,","281","         0.024617, 0.023868, 0.043916, 0.025549, 0.046198, 0.041086, 0.042003,","282","         0.022507, 0.021430, 0.038779, 0.025043, 0.036379, 0.036326, 0.029421,","283","         0.023454, 0.058683, 0.025549, 0.039904, 0.022507, 0.046198, 0.029332,","284","         0.032209, 0.036155, 0.038421, 0.025043, 0.023694, 0.030104, 0.022363,","285","         0.048544, 0.035180, 0.030677, 0.022112, 0.030677, 0.036678, 0.022507,","286","         0.024092, 0.064231, 0.022507, 0.032209, 0.025043, 0.221152, 0.029840,","287","         0.038779, 0.040634, 0.024617, 0.032418, 0.025525, 0.033298, 0.028092,","288","         0.045754, 0.032209, 0.017748, 0.033090, 0.017748, 0.048931, 0.038689,","289","         0.022112, 0.027129, 0.032952, 0.036858, 0.027704, 0.032146, 0.052191,","290","         0.042633, 0.071638, 0.044140, 0.022507, 0.046647, 0.028270, 0.050525,","291","         0.036772, 0.058995, 0.038335, 0.025185, 0.022507, 0.040293, 0.032418,","292","         0.064308, 0.026023, 0.036155, 0.032418, 0.038032, 0.018705, 0.040293,","293","         0.030104, 0.030845, 0.064906, 0.025525, 0.036155, 0.022507, 0.022363,","294","         0.032418, 0.021430, 0.032209, 0.102770, 0.036960, 0.031062, 0.025043,","295","         0.036155, 0.031609, 0.036379, 0.030845, 0.048985, 0.021848, 0.025549,","296","         0.022507, 0.035783, 0.023698, 0.034422, 0.032418, 0.022507, 0.023868,","297","         0.020065, 0.023694, 0.040634, 0.055633, 0.054549, 0.044662, 0.087660,","298","         0.048066, 0.143571, 0.068669, 0.065049, 0.076927, 0.044359, 0.041577,","299","         0.052364, 0.100317, 0.062146, 0.067578, 0.054549, 0.047239, 0.062809,","300","         0.033917, 0.087660, 0.077113, 0.055633, 0.061854, 0.059756, 0.059537,","301","         0.052364, 0.060347, 0.170251, 0.108492, 0.046370, 0.070684, 0.049589,","302","         0.044662, 0.049013, 0.043303, 0.069573, 0.075044, 0.054354, 0.065072,","303","         0.073135, 0.046126, 0.055569, 0.047239, 0.062146, 0.056093, 0.059986,","304","         0.096182, 0.100317, 0.051649, 0.054354, 0.077420, 0.100317, 0.046370,","305","         0.043303, 0.045845, 0.061422, 0.091580, 0.206234, 0.051405, 0.071684,","306","         0.061574, 0.063666, 0.052692, 0.051649, 0.100124, 0.077909, 0.033917,","307","         0.058680, 0.044359, 0.065498, 0.080214, 0.123231, 0.052957, 0.056582,","308","         0.061540, 0.076794, 0.043303, 0.054884, 0.044359, 0.145249, 0.081741,","309","         0.041577, 0.056093, 0.076799, 0.044359, 0.068483, 0.051649, 0.092275,","310","         0.044359, 0.108492, 0.092275, 0.046126, 0.106422, 0.054354, 0.052957,","311","         0.073329, 0.046126, 0.086402, 0.048194, 0.128569, 0.104042, 0.061854,","312","         0.069573, 0.070035, 0.050346, 0.043303, 0.053576, 0.054549, 0.033917,","313","         0.063666, 0.058680, 0.099130, 0.080198, 0.050118, 0.054549, 0.041577,","314","         0.143571, 0.095965, 0.047643, 0.052364, 0.105168, 0.048685, 0.043303,","315","         0.052814, 0.076927, 0.054549, 0.041577, 0.066657, 0.189930, 0.046370,","316","         0.075044, 0.121331, 0.043303, 0.223897, 0.198621, 0.150328, 0.100317,","317","         0.053576, 0.070708, 0.100898, 0.047239, 0.043613, 0.065049, 0.049146,","318","         0.068669, 0.055569, 0.062124, 0.096408, 0.044662, 0.087660, 0.083012,","319","         0.050118, 0.069573, 0.046126, 0.049146, 0.049146, 0.050808, 0.080198,","320","         0.059986, 0.071974, 0.047239, 0.050808, 0.059986, 0.065850, 0.044863,","321","         0.052814, 0.044359, 0.052364, 0.108492, 0.143571, 0.050926, 0.049146,","322","         0.049146, 0.055569, 0.033917, 0.527659, 0.143547, 0.077113, 0.046126,","323","         0.106422, 0.068669, 0.108492, 0.063666, 0.054549, 0.054884, 0.056907,","324","         0.068669, 0.080198, 0.120887, 0.054549, 0.052692, 0.085801, 0.054884,","325","         0.050808, 0.094595, 0.059545, 0.054354, 0.062124, 0.087660, 0.052814,","326","         0.086715, 0.146253, 0.046370, 0.041577, 0.116083, 0.076927, 0.047239,","327","         0.084375, 0.134652, 0.217969, 0.063559, 0.061540, 0.044662, 0.054354,","328","         0.063666, 0.145466, 0.101700, 0.090491, 0.078536, 0.054884, 0.062124,","329","         0.041577, 0.043303, 0.194473, 0.079780, 0.059704, 0.054780, 0.048194,","330","         0.062146, 0.069573, 0.086898, 0.046675, 0.056258, 0.074141, 0.048066,","331","         0.052957, 0.057982, 0.058966, 0.061048, 0.050885, 0.049146, 0.080993,","332","         0.056093, 0.061854, 0.124025, 0.062146, 0.060906, 0.150328, 0.058680,","333","         0.077420, 0.051800, 0.102359, 0.113301, 0.073096, 0.116715, 0.131476,","334","         0.140601, 0.097667, 0.051800, 0.051800, 0.127964, 0.108870, 0.111926,","335","         0.093532, 0.102390, 0.144266, 0.098271, 0.102541, 0.136497, 0.127964,","336","         0.085569, 0.157863, 0.096739, 0.054008, 0.106219, 0.076838, 0.099076,","337","         0.093532, 0.059861, 0.079975, 0.116715, 0.133625, 0.053641, 0.066110,","338","         0.122302, 0.081313, 0.140601, 0.259889, 0.094437, 0.098271, 0.105776,","339","         0.225742, 0.100097, 0.147592, 0.099076, 0.093128, 0.093532, 0.134946,","340","         0.133625, 0.120869, 0.065932, 0.103395, 0.125172, 0.147842, 0.105278,","341","         0.173584, 0.168241, 0.111524, 0.093532, 0.099076, 0.100426, 0.137132,","342","         0.065356, 0.091108, 0.141202, 0.054008, 0.075298, 0.073717, 0.122817,","343","         0.105278, 0.094437, 0.067080, 0.108530, 0.115467, 0.093532, 0.085569,","344","         0.145180, 0.100426, 0.116715, 0.151726, 0.073096, 0.193781, 0.090614,","345","         0.081162, 0.051800, 0.133625, 0.136497, 0.100670, 0.081313, 0.506893,","346","         0.084567, 0.108530, 0.087353, 0.063184, 0.123639, 0.168333, 0.314422,","347","         0.091108, 0.079975, 0.091108, 0.136497, 0.122302, 0.167297, 0.067080,","348","         0.144266, 0.065932, 0.087667, 0.100426, 0.099460, 0.091108, 0.100637,","349","         0.116715, 0.079975, 0.077977, 0.090340, 0.136723, 1.943026, 0.108870,","350","         0.090340, 0.065932, 0.102245, 0.157863, 0.157863, 0.215574, 0.156830,","351","         0.093532, 0.122302, 0.097667, 0.063000, 0.116715, 0.076838, 0.148372,","352","         0.093532, 0.099076, 0.141202, 0.096505, 0.096739, 0.091108, 0.099076,","353","         0.079975, 0.108870, 0.102390, 0.079975, 0.244121, 0.167071, 0.096739,","354","         0.102390, 0.103395, 0.073096, 0.094887, 0.065932, 0.190667, 0.099460,","355","         0.102390, 0.096739, 0.102390, 0.116715, 0.100637, 0.256554, 0.103395,","356","         0.081313, 0.068962, 0.109645, 0.059364, 0.147842, 0.099460, 0.079262,","357","         0.099460, 0.065932, 0.123687, 0.090614, 0.131352, 0.098271, 0.102541,","358","         0.098983, 0.057224, 0.074797, 0.057224, 0.250559, 0.079975, 0.103395,","359","         0.100426, 0.065932, 0.120661, 0.079262, 0.065932, 0.118665, 0.081162,","360","         0.066283, 0.099076, 0.102359, 0.108530, 0.079975, 0.168333, 0.096739,","361","         0.168333, 0.097008, 0.055288, 0.172411, 0.092801, 0.051800, 0.102541,","362","         0.084567, 0.054008, 0.090991, 0.172411, 0.057224, 0.148396, 0.200965,","363","         0.076838, 0.157863, 0.053535, 0.121919, 0.126609, 0.123890, 0.118081,","364","         0.097008, 0.125311, 0.099460, 0.122302, 0.134946, 0.080975, 0.084567,","365","         0.110093, 0.102245, 0.103395, 0.171601, 0.094887, 0.126240, 0.137742,","366","         0.099954, 0.108530, 0.157863, 0.096739, 0.051800, 0.127964, 0.066110,","367","         0.061021, 0.105147, 0.100426, 0.079975, 0.088187, 0.116421, 0.076838,","368","         0.098271, 0.116715, 0.137656, 0.075298, 0.148396, 0.112166, 1.083905,","369","         0.326598, 0.428987, 0.395963, 0.224541, 0.326598, 0.030677, 0.410454,","370","         0.122771, 1.140305, 0.641074, 0.432159, 0.429335, 0.422908, 0.461926,","371","         0.293083, 0.477078, 0.714856, 0.515861, 0.405418, 0.054354, 0.341177,","372","         0.410008, 0.514245, 0.641074, 0.816459, 0.455115, 0.400707, 0.382240,","373","         0.431832, 1.618970, 0.683953, 0.182992, 0.763699, 0.515861, 0.717145,","374","         0.409629, 0.074134, 0.398273, 0.864974, 0.400707, 0.591403, 0.435354,","375","         0.514245, 1.337152, 0.841077, 0.410008, 0.683953, 0.338649, 0.557595,","376","         0.442092, 0.326598, 0.984189, 0.429608, 0.395963, 1.152055, 0.587222,","377","         1.748492, 0.477078, 0.395459, 0.717145, 0.575811, 0.210115, 0.487785,","378","         0.431832, 0.383852, 0.806708, 0.428987, 0.278405, 0.395963, 0.395459,","379","         0.383852, 1.083905, 0.428510, 0.326598, 0.108492, 0.541644, 0.612110,","380","         0.382240, 0.833511, 0.382240, 0.456628, 0.326598, 0.458880, 0.398273,","381","         0.957748, 0.326598, 0.295049, 0.629646, 0.429765, 0.439942, 0.633617,","382","         0.566297, 0.429335, 0.086507, 0.477078, 0.526753, 0.375240, 0.584436,","383","         0.355776, 0.395963, 0.644924, 0.129793, 0.484880, 0.470001, 0.572306,","384","         0.383852, 1.110081, 0.841077, 0.395963, 0.683953, 0.428745, 0.387752,","385","         0.545299, 0.686537, 0.635219, 0.840499, 0.527659, 0.400707, 0.480982,","386","         0.541644, 0.714856, 0.942673, 0.398273, 0.428987, 0.356781, 0.428510,","387","         1.140961, 0.395963, 0.356781, 0.410454, 0.541644, 0.641074, 0.484778,","388","         0.410008, 0.433108, 0.278405, 0.278405, 0.503141, 0.428745, 0.125103,","389","         0.633617, 0.410454, 0.124025, 0.461926, 0.398273, 0.410008, 1.181303,","390","         0.635219, 0.593537, 0.395963, 0.717145, 0.409629, 0.492595, 0.806708,","391","         0.503820, 0.423834, 0.557595, 0.429335, 0.470749, 0.461926, 1.890036,","392","         0.236343, 0.806708, 0.123561, 0.433744, 0.427348, 0.427348, 0.962234,","393","         0.395963, 0.409629, 0.527659, 0.425727, 0.602549, 0.901331, 0.326598,","394","         0.635949, 0.541644, 0.375240, 0.598969, 1.140961, 0.391998, 0.719443,","395","         0.410008, 0.515861, 0.714856, 0.842273, 0.410454, 0.389377, 0.431078,","396","         0.515861, 0.515861, 0.429335, 0.332495, 0.398273, 0.428987, 0.635219,","397","         0.387752, 0.384289, 0.383852, 0.430504, 0.428510, 0.431832, 0.375240,","398","         0.278405, 0.374102, 0.428745, 0.692878, 1.152055, 0.503820, 0.428745,","399","         0.352868, 0.429335, 0.375240, 0.400707, 0.427348, 0.256183, 0.962234,","400","         0.505376, 0.058995, 0.410454, 0.172880, 0.395963, 0.470749, 0.356781,","401","         1.332700, 0.683953, 0.395963, 0.806708, 0.400707, 0.330982, 0.427731,","402","         0.934845, 0.375240, 0.191534, 0.047239, 1.083905, 0.348794, 0.409708,","403","         0.503820, 0.557595, 0.429335, 0.498780, 0.293083, 0.363069, 0.442092,","404","         1.152055, 0.375240, 0.335677, 0.452443, 0.655156, 0.929928, 0.614869,","405","         1.411031, 1.101132, 0.469030, 0.404976, 0.538209, 0.655828, 0.674748,","406","         0.365182, 0.641612, 0.555434, 0.521651, 0.386679, 0.386679, 0.980304,","407","         0.659111, 0.651366, 0.538209, 0.521651, 0.884780, 1.287829, 0.558322,","408","         0.446161, 0.817970, 0.568499, 0.533507, 0.639746, 0.484404, 0.591751,","409","         0.913016, 0.446161, 0.533907, 0.606885, 0.672320, 1.150642, 0.655828,","410","         0.365182, 0.665088, 1.094242, 0.629401, 0.540676, 0.733026, 1.248265,","411","         1.273499, 0.867854, 0.538656, 0.386679, 0.922273, 0.515686, 1.321022,","412","         0.624444, 0.655828, 0.922273, 0.386679, 0.762191, 0.779432, 0.601851,","413","         0.655156, 0.926213, 0.762191, 0.641612, 0.558322, 1.025370, 0.641067,","414","         0.651366, 0.633434, 0.459580, 0.859221, 0.552291, 0.591751, 0.819965,","415","         0.669977, 1.185083, 0.499338, 0.533907, 0.752871, 0.571388, 0.539772,","416","         0.449182, 1.025370, 0.365182, 1.321022, 0.926213, 0.886360, 0.562272,","417","         0.669977, 0.796046, 0.557598, 0.596776, 0.672336, 0.659111, 0.453719,","418","         0.477716, 0.477716, 1.592069, 0.591751, 0.539772, 0.641612, 0.946254,","419","         0.744165, 0.386679, 0.593825, 0.539772, 0.449182, 0.604273, 0.794951,","420","         0.752871, 0.539772, 0.648732, 0.469030, 0.665088, 1.332700, 1.341388,","421","         0.533507, 0.544212, 1.025992, 0.645967, 0.612945, 0.868492, 0.648732,","422","         0.752300, 0.624444, 1.219748, 0.446161, 0.520818, 0.469044, 0.669977,","423","         0.926213, 0.638752, 0.762191, 0.922273, 0.794951, 0.606885, 0.669977,","424","         0.550113, 0.641067, 0.733026, 0.604273, 0.648732, 0.533507, 0.746506,","425","         0.733026, 0.980683, 0.538209, 0.669977, 0.469030, 0.648732, 0.609190,","426","         1.219748, 0.373113, 0.539772, 1.744047, 1.004716, 0.926213, 0.562272,","427","         0.752871, 0.538656, 0.449182, 0.365182, 0.469030, 0.446161, 0.484404,","428","         0.768592, 0.648732, 0.655156, 0.521651, 0.779432, 0.446161, 0.596776,","429","         0.538209, 0.726740, 0.539772, 0.469030, 0.521651, 0.561950, 0.601851,","430","         0.533907, 0.922273, 1.248265, 0.476800, 0.737990, 0.817970, 0.792127,","431","         0.533907, 0.486038, 0.624444, 0.798241, 0.476800, 1.059373, 0.645967,","432","         0.619940, 0.528726, 0.669977, 0.865406, 0.980683, 0.980683, 0.834671,","433","         1.001353, 0.752871, 0.449182, 1.096520, 0.449182, 0.593825, 0.636558,","434","         0.762191, 0.638591, 0.538209, 0.865406, 0.779432, 0.469044, 0.645967,","435","         0.557598, 0.499338, 0.484404, 0.515686, 0.794951, 0.619456, 0.733026,","436","         0.821769, 0.752300, 0.643302, 0.636558, 0.655156, 0.655156, 0.484404,","437","         0.648732, 0.726023, 0.365182, 0.606885, 0.499338, 0.520818, 0.612945,","438","         0.446161, 0.557598, 0.469044, 1.134650, 0.629401, 0.538656, 0.561950,","439","         1.364861, 0.459580, 1.025370, 0.980304, 0.607592, 0.533907, 1.134650,","440","         0.446161, 0.629962]","441","","442","    # FIXME: known failure in 32bit Linux; numerical imprecision results in","443","    # different ordering in quick_scan","444","    if _IS_32BIT:  # pragma: no cover","445","        assert_allclose(clust.reachability_, np.array(v), rtol=1e-2)","446","    else:","447","        # we compare to truncated decimals, so use atol","448","        assert_allclose(clust.reachability_, np.array(v), atol=1e-5)"]}],"sklearn\/cluster\/optics_.py":[{"add":["38","    This implementation deviates from the original OPTICS by first performing","39","    k-nearest-neighborhood searches on all points to identify core sizes, then","40","    computing only the distances to unprocessed points when constructing the","41","    cluster order. It also does not employ a heap to manage the expansion","42","    candiates, but rather uses numpy masked arrays. This can be potentially","43","    slower with some parameters (at the benefit from using fast numpy code).","44","","198","    This implementation deviates from the original OPTICS by first performing","199","    k-nearest-neighborhood searches on all points to identify core sizes, then","200","    computing only the distances to unprocessed points when constructing the","201","    cluster order.","202","","326","        The cluster ordered list of sample indices.","334","        Point that a sample was reached from, indexed by object order.","529","        # Choose next based on smallest reachability distance","530","        # (And prefer smaller ids on ties).","531","        # All unprocessed points qualify, not just new neighbors (\"unproc\")","532","        return (np.ma.array(self.reachability_, mask=processed)","533","                .argmin(fill_value=np.inf))"],"delete":["22","from ._optics_inner import quick_scan","315","        The cluster ordered list of sample indices","323","        Point that a sample was reached from.","518","        # Define return order based on reachability distance","519","        return (unproc[quick_scan(np.take(self.reachability_, unproc),","520","                                  dists)])"]}]}},"a1565241a42aa949e245b3a966343dd334595fce":{"changes":{"sklearn\/feature_extraction\/image.py":"MODIFY"},"diff":{"sklearn\/feature_extraction\/image.py":[{"add":["288","    slices = tuple(slice(None, None, st) for st in extraction_step)"],"delete":["288","    slices = [slice(None, None, st) for st in extraction_step]"]}]}},"d990f7208c2b5488a24f73fdd2c85bb06e43cc0c":{"changes":{"sklearn\/neighbors\/binary_tree.pxi":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/neighbors\/tests\/test_kd_tree.py":"MODIFY","sklearn\/neighbors\/tests\/test_kde.py":"MODIFY","sklearn\/neighbors\/tests\/test_ball_tree.py":"MODIFY"},"diff":{"sklearn\/neighbors\/binary_tree.pxi":[{"add":["1121","        return (newObj, (type(self),), self.__getstate__())","1138","                self.dist_metric,","1139","                self.sample_weight)","1165","        self.sample_weight = state[12]"],"delete":["1121","        return (newObj, (BinaryTree,), self.__getstate__())","1138","                self.dist_metric)"]}],"doc\/whats_new\/v0.20.rst":[{"add":["763","- |Fix| Fixed a bug in `neighbors.KDTree` and `neighbors.BallTree` where","764","  pickled tree objects would change their type to the super class `BinaryTree`.","765","  :issue:`11774` by :user:`Nicolas Hug <NicolasHug>`.","766",""],"delete":[]}],"sklearn\/neighbors\/tests\/test_kd_tree.py":[{"add":["189","        assert isinstance(kdt2, KDTree)"],"delete":[]}],"sklearn\/neighbors\/tests\/test_kde.py":[{"add":["12","from sklearn.externals import joblib","205","","206","","207","def test_pickling(tmpdir):","208","    # Make sure that predictions are the same before and after pickling. Used","209","    # to be a bug because sample_weights wasn't pickled and the resulting tree","210","    # would miss some info.","211","","212","    kde = KernelDensity()","213","    data = np.reshape([1., 2., 3.], (-1, 1))","214","    kde.fit(data)","215","","216","    X = np.reshape([1.1, 2.1], (-1, 1))","217","    scores = kde.score_samples(X)","218","","219","    file_path = str(tmpdir.join('dump.pkl'))","220","    joblib.dump(kde, file_path)","221","    kde = joblib.load(file_path)","222","    scores_pickled = kde.score_samples(X)","223","","224","    assert_allclose(scores, scores_pickled)"],"delete":[]}],"sklearn\/neighbors\/tests\/test_ball_tree.py":[{"add":["230","        assert isinstance(bt2, BallTree)","231",""],"delete":[]}]}},"0b85b0a922fc7e0c9b8f5dea1caf026cd9a75a57":{"changes":{"sklearn\/preprocessing\/data.py":"MODIFY"},"diff":{"sklearn\/preprocessing\/data.py":[{"add":["2539","    [ 1.386... -3.100...]","2541","    [[-1.316... -0.707...]","2542","     [ 0.209... -0.707...]","2543","     [ 1.106...  1.414...]]"],"delete":["2539","    [ 1.38668178 -3.10053309]","2541","    [[-1.31616039 -0.70710678]","2542","     [ 0.20998268 -0.70710678]","2543","     [ 1.1061777   1.41421356]]"]}]}},"5d236e80237d92b8af4b4715db91671aeea6414e":{"changes":{"sklearn\/linear_model\/cd_fast.pyx":"MODIFY"},"diff":{"sklearn\/linear_model\/cd_fast.pyx":[{"add":["143","def enet_coordinate_descent(np.ndarray[floating, ndim=1, mode='c'] w,","310","def sparse_enet_coordinate_descent(floating [::1] w,","530","def enet_coordinate_descent_gram(floating[::1] w,","531","                                 floating alpha, floating beta,"],"delete":["143","def enet_coordinate_descent(np.ndarray[floating, ndim=1] w,","310","def sparse_enet_coordinate_descent(floating [:] w,","530","def enet_coordinate_descent_gram(floating[:] w, floating alpha, floating beta,"]}]}},"c3f973b1de156509b7c59e2d5fafdef1c28f74dd":{"changes":{"doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/datasets\/_svmlight_format.pyx":"MODIFY","sklearn\/datasets\/svmlight_format.py":"MODIFY","sklearn\/datasets\/tests\/test_svmlight_format.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.21.rst":[{"add":["55","","56",":mod:`sklearn.datasets`","57","  ......................","58","","59","  - |Fix| Added support for 64-bit group IDs and pointers in SVMLight files","60","    :class:`datasets.svmlight_format` :issue:`10727` by","61","    :user:`Bryan K Woods <bryan-woods>`,","62","","147","  :issue:`10580` by :user:`Reshama Shaikh <reshamas>` and `Sandra"],"delete":["55","  ","140","  :issue:`10580` by :user:`Reshama Shaikh <reshamas>` and `Sandra "]}],"sklearn\/datasets\/_svmlight_format.pyx":[{"add":["44","","45","    indices = array.array(\"q\")","46","    indptr = array.array(\"q\", [0])","111","        # increment index pointer array size"],"delete":["44","    indices = array.array(\"i\")","45","    indptr = array.array(\"i\", [0])"]}],"sklearn\/datasets\/svmlight_format.py":[{"add":["189","    indices = np.frombuffer(ind, np.longlong)","190","    indptr = np.frombuffer(indptr, dtype=np.longlong)   # never empty"],"delete":["189","    indices = np.frombuffer(ind, np.intc)","190","    indptr = np.frombuffer(indptr, dtype=np.intc)   # never empty"]}],"sklearn\/datasets\/tests\/test_svmlight_format.py":[{"add":["188","@pytest.mark.skip(\"testing the overflow of 32 bit sparse indexing requires a\"","189","                  \" large amount of memory\")","190","def test_load_large_qid():","191","    \"\"\"","192","    load large libsvm \/ svmlight file with qid attribute. Tests 64-bit query ID","193","    \"\"\"","194","    data = b\"\\n\".join((\"3 qid:{0} 1:0.53 2:0.12\\n2 qid:{0} 1:0.13 2:0.1\"","195","                      .format(i).encode() for i in range(1, 40*1000*1000)))","196","    X, y, qid = load_svmlight_file(BytesIO(data), query_id=True)","197","    assert_array_equal(y[-4:], [3, 2, 3, 2])","198","    assert_array_equal(np.unique(qid), np.arange(1, 40*1000*1000))","199","","200",""],"delete":[]}]}},"6f5fec9b6a8354f33489465c9f39ee5b4409e2c1":{"changes":{"doc\/glossary.rst":"MODIFY"},"diff":{"doc\/glossary.rst":[{"add":["228","        conventions <https:\/\/numpydoc.readthedocs.io\/en\/latest\/format.html>`_."],"delete":["228","        conventions <numpydoc.readthedocs.io\/en\/latest\/format.html>`_."]}]}},"bbb0d935f529b57885177fccf79f3b30f7ab568b":{"changes":{"sklearn\/preprocessing\/tests\/test_data.py":"MODIFY","sklearn\/preprocessing\/data.py":"MODIFY"},"diff":{"sklearn\/preprocessing\/tests\/test_data.py":[{"add":["2044","        X_trans_func = power_transform(","2045","            X, method='box-cox',","2046","            standardize=standardize","2047","        )","2071","        X_trans_func = power_transform(","2072","            X, method='box-cox',","2073","            standardize=standardize","2074","        )","2297","","2298","","2299","def test_power_transform_default_method():","2300","    X = np.abs(X_2d)","2301","","2302","    future_warning_message = (","2303","        \"The default value of 'method' \"","2304","        \"will change from 'box-cox'\"","2305","    )","2306","    assert_warns_message(FutureWarning, future_warning_message,","2307","                         power_transform, X)","2308","","2309","    with warnings.catch_warnings():","2310","        warnings.simplefilter('ignore')","2311","        X_trans_default = power_transform(X)","2312","","2313","    X_trans_boxcox = power_transform(X, method='box-cox')","2314","    assert_array_equal(X_trans_boxcox, X_trans_default)"],"delete":["2044","        X_trans_func = power_transform(X, standardize=standardize)","2068","        X_trans_func = power_transform(X, standardize=standardize)"]}],"sklearn\/preprocessing\/data.py":[{"add":["2491","    Yeo-Johnson transform. The optimal parameter for stabilizing variance and","2546","    NaNs are treated as missing values: disregarded in ``fit``, and maintained","2547","    in ``transform``.","2846","def power_transform(X, method='warn', standardize=True, copy=True):","2847","    \"\"\"","2853","    Currently, power_transform supports the Box-Cox transform and the","2854","    Yeo-Johnson transform. The optimal parameter for stabilizing variance and","2855","    minimizing skewness is estimated through maximum likelihood.","2856","","2857","    Box-Cox requires input data to be strictly positive, while Yeo-Johnson","2858","    supports both positive or negative data.","2870","    method : str","2871","        The power transform method. Available methods are:","2872","","2873","        - 'yeo-johnson' [1]_, works with positive and negative values","2874","        - 'box-cox' [2]_, only works with strictly positive values","2875","","2876","        The default method will be changed from 'box-cox' to 'yeo-johnson'","2877","        in version 0.23. To suppress the FutureWarning, explicitly set the","2878","        parameter.","2885","        Set to False to perform inplace computation during transformation.","2886","","2887","    Returns","2888","    -------","2889","    X_trans : array-like, shape (n_samples, n_features)","2890","        The transformed data.","2897","    >>> print(power_transform(data, method='box-cox'))  # doctest: +ELLIPSIS","2904","    PowerTransformer : Equivalent transformation with the","2905","        ``Transformer`` API (e.g. as part of a preprocessing","2906","        :class:`sklearn.pipeline.Pipeline`).","2913","    NaNs are treated as missing values: disregarded in ``fit``, and maintained","2914","    in ``transform``.","2922","","2923","    .. [1] I.K. Yeo and R.A. Johnson, \"A new family of power transformations to","2924","           improve normality or symmetry.\" Biometrika, 87(4), pp.954-959,","2925","           (2000).","2926","","2927","    .. [2] G.E.P. Box and D.R. Cox, \"An Analysis of Transformations\", Journal","2928","           of the Royal Statistical Society B, 26, 211-252 (1964).","2930","    if method == 'warn':","2931","        warnings.warn(\"The default value of 'method' will change from \"","2932","                      \"'box-cox' to 'yeo-johnson' in version 0.23. Set \"","2933","                      \"the 'method' argument explicitly to silence this \"","2934","                      \"warning in the meantime.\",","2935","                      FutureWarning)","2936","        method = 'box-cox'"],"delete":["2491","    Yeo-Johson transform. The optimal parameter for stabilizing variance and","2546","    NaNs are treated as missing values: disregarded in fit, and maintained in","2547","    transform.","2846","def power_transform(X, method='box-cox', standardize=True, copy=True):","2847","    \"\"\"Apply a power transform featurewise to make data more Gaussian-like.","2848","","2854","    Currently, power_transform() supports the Box-Cox transform. Box-Cox","2855","    requires input data to be strictly positive. The optimal parameter","2856","    for stabilizing variance and minimizing skewness is estimated","2857","    through maximum likelihood.","2869","    method : str, (default='box-cox')","2870","        The power transform method. Currently, 'box-cox' (Box-Cox transform)","2871","        is the only option available.","2878","        Set to False to perform inplace computation.","2885","    >>> print(power_transform(data))  # doctest: +ELLIPSIS","2892","    PowerTransformer: Performs power transformation using the ``Transformer``","2893","        API (as part of a preprocessing :class:`sklearn.pipeline.Pipeline`).","2900","    NaNs are treated as missing values: disregarded to compute the statistics,","2901","    and maintained during the data transformation.","2909","    G.E.P. Box and D.R. Cox, \"An Analysis of Transformations\", Journal of the","2910","    Royal Statistical Society B, 26, 211-252 (1964)."]}]}},"e73acef80de4159722b11e3cd6c20920382b9728":{"changes":{"doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/ensemble\/gradient_boosting.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.21.rst":[{"add":["26","- :class:`ensemble.GradientBoostingClassifier` for multiclass","27","  classification. |Fix|","75","- |Fix| Fixed a bug in :class:`ensemble.GradientBoostingClassifier` where","76","  the gradients would be incorrectly computed in multiclass classification","77","  problems. :issue:`12715` by :user:`Nicolas Hug<NicolasHug>`.","78",""],"delete":[]}],"sklearn\/ensemble\/gradient_boosting.py":[{"add":["1165","        # Need to pass a copy of y_pred to negative_gradient() because y_pred","1166","        # is partially updated at the end of the loop in","1167","        # update_terminal_regions(), and gradients need to be evaluated at","1168","        # iteration i - 1.","1169","        y_pred_copy = y_pred.copy()","1170","","1175","            residual = loss.negative_gradient(y, y_pred_copy, k=k,"],"delete":["1169","            residual = loss.negative_gradient(y, y_pred, k=k,"]}]}},"d4802aeac55475171850d6cf121718e879ab93eb":{"changes":{"doc\/modules\/clustering.rst":"MODIFY"},"diff":{"doc\/modules\/clustering.rst":[{"add":["389","    x_i^{t+1} = m(x_i^t)"],"delete":["389","    x_i^{t+1} = x_i^t + m(x_i^t)"]}]}},"036dfdde213498fd9a40210ea92cb24b4474a4b7":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/mixture\/tests\/test_gaussian_mixture.py":"MODIFY","sklearn\/mixture\/base.py":"MODIFY","sklearn\/mixture\/tests\/test_bayesian_mixture.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["109",":mod:`sklearn.mixture`","110","........................","111","","112","- |Fix| Ensure that the ``fit_predict`` method of","113","  :class:`mixture.GaussianMixture` and :class:`mixture.BayesianGaussianMixture`","114","  always yield assignments consistent with ``fit`` followed by ``predict`` even","115","  if the convergence criterion is too loose or not met. :issue:`12451`","116","  by :user:`Olivier Grisel <ogrisel>`.","117",""],"delete":[]}],"sklearn\/mixture\/tests\/test_gaussian_mixture.py":[{"add":["12","import pytest","575","@pytest.mark.filterwarnings(\"ignore:.*did not converge.*\")","576","@pytest.mark.parametrize('seed, max_iter, tol', [","577","    (0, 2, 1e-7),    # strict non-convergence","578","    (1, 2, 1e-1),    # loose non-convergence","579","    (3, 300, 1e-7),  # strict convergence","580","    (4, 300, 1e-1),  # loose convergence","581","])","582","def test_gaussian_mixture_fit_predict(seed, max_iter, tol):","583","    rng = np.random.RandomState(seed)","592","                            covariance_type=covar_type,","593","                            max_iter=max_iter, tol=tol)"],"delete":["574","def test_gaussian_mixture_fit_predict():","575","    rng = np.random.RandomState(0)","584","                            covariance_type=covar_type)"]}],"sklearn\/mixture\/base.py":[{"add":["262","        # Always do a final e-step to guarantee that the labels returned by","263","        # fit_predict(X) are always consistent with fit(X).predict(X)","264","        # for any value of max_iter and tol (and any random_state).","265","        _, log_resp = self._e_step(X)","266",""],"delete":[]}],"sklearn\/mixture\/tests\/test_bayesian_mixture.py":[{"add":["7","import pytest","428","@pytest.mark.filterwarnings(\"ignore:.*did not converge.*\")","429","@pytest.mark.parametrize('seed, max_iter, tol', [","430","    (0, 2, 1e-7),    # strict non-convergence","431","    (1, 2, 1e-1),    # loose non-convergence","432","    (3, 300, 1e-7),  # strict convergence","433","    (4, 300, 1e-1),  # loose convergence","434","])","435","def test_bayesian_mixture_fit_predict(seed, max_iter, tol):","436","    rng = np.random.RandomState(seed)","442","                                        max_iter=max_iter, random_state=rng,","443","                                        tol=tol, reg_covar=0)"],"delete":["427","def test_bayesian_mixture_fit_predict():","428","    rng = np.random.RandomState(0)","434","                                        max_iter=100, random_state=rng,","435","                                        tol=1e-3, reg_covar=0)"]}]}},"1e7cd7df9dee31d035ddb789f8e5138201da0ebc":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/preprocessing\/_encoders.py":"MODIFY","sklearn\/preprocessing\/tests\/test_encoders.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["81","- |Fix| Fixed bug in :class:`preprocessing.OrdinalEncoder` when passing","82","  manually specified categories. :issue:`12365` by `Joris Van den Bossche`_."],"delete":[]}],"sklearn\/preprocessing\/_encoders.py":[{"add":["84","                if handle_unknown == 'error':"],"delete":["84","                if self.handle_unknown == 'error':"]}],"sklearn\/preprocessing\/tests\/test_encoders.py":[{"add":["532","@pytest.mark.parametrize(\"X, X2, cats, cat_dtype\", [","533","    (np.array([['a', 'b']], dtype=object).T,","534","     np.array([['a', 'd']], dtype=object).T,","535","     [['a', 'b', 'c']], np.object_),","536","    (np.array([[1, 2]], dtype='int64').T,","537","     np.array([[1, 4]], dtype='int64').T,","538","     [[1, 2, 3]], np.int64),","539","    (np.array([['a', 'b']], dtype=object).T,","540","     np.array([['a', 'd']], dtype=object).T,","541","     [np.array(['a', 'b', 'c'])], np.object_),","542","    ], ids=['object', 'numeric', 'object-string-cat'])","543","def test_ordinal_encoder_specified_categories(X, X2, cats, cat_dtype):","544","    enc = OrdinalEncoder(categories=cats)","545","    exp = np.array([[0.], [1.]])","546","    assert_array_equal(enc.fit_transform(X), exp)","547","    assert list(enc.categories[0]) == list(cats[0])","548","    assert enc.categories_[0].tolist() == list(cats[0])","549","    # manually specified categories should have same dtype as","550","    # the data when coerced from lists","551","    assert enc.categories_[0].dtype == cat_dtype","552","","553","    # when specifying categories manually, unknown categories should already","554","    # raise when fitting","555","    enc = OrdinalEncoder(categories=cats)","556","    with pytest.raises(ValueError, match=\"Found unknown categories\"):","557","        enc.fit(X2)","558","","559",""],"delete":[]}]}},"a79d44e4a444f9b639234daadf82351f5bd71689":{"changes":{"sklearn\/cluster\/_optics_inner.pyx":"MODIFY"},"diff":{"sklearn\/cluster\/_optics_inner.pyx":[{"add":["7","# as defined in PEP485 (python3.5)","8","cdef inline isclose(double a, ","9","                    double b,","10","                    double rel_tol=1e-09,","11","                    double abs_tol=0.0):","12","    return abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol)","13","","33","        elif isclose(rdists[i], rdist):"],"delete":["26","        if rdists[i] == rdist:"]}]}},"1c88b3c9c76c392741692b57fd379c018bc6cedb":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/utils\/__init__.py":"MODIFY","sklearn\/decomposition\/incremental_pca.py":"MODIFY","sklearn\/decomposition\/tests\/test_incremental_pca.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["14","Changed models","15","--------------","16","","17","The following estimators and functions, when fit with the same data and","18","parameters, may produce different models from the previous version. This often","19","occurs due to changes in the modelling logic (bug fixes or enhancements), or in","20","random sampling procedures.","21","","22","- :class:`decomposition.IncrementalPCA` (bug fix)","23","","67",":mod:`sklearn.decomposition`","68","............................","69","","70","- |Fix| Fixed a regression in :class:`decomposition.IncrementalPCA` where","71","  0.20.0 raised an error if the number of samples in the final batch for","72","   fitting IncrementalPCA was smaller than n_components.","73","  :issue:`12234` by :user:`Ming Li <minggli>`.","74",""],"delete":[]}],"sklearn\/utils\/__init__.py":[{"add":["403","def gen_batches(n, batch_size, min_batch_size=0):","414","    min_batch_size : int, default=0","415","        Minimum batch size to produce.","430","    >>> list(gen_batches(7, 3, min_batch_size=0))","431","    [slice(0, 3, None), slice(3, 6, None), slice(6, 7, None)]","432","    >>> list(gen_batches(7, 3, min_batch_size=2))","433","    [slice(0, 3, None), slice(3, 7, None)]","438","        if end + min_batch_size > n:","439","            continue"],"delete":["403","def gen_batches(n, batch_size):"]}],"sklearn\/decomposition\/incremental_pca.py":[{"add":["198","        for batch in gen_batches(n_samples, self.batch_size_,","199","                                 min_batch_size=self.n_components or 0):"],"delete":["198","        for batch in gen_batches(n_samples, self.batch_size_):"]}],"sklearn\/decomposition\/tests\/test_incremental_pca.py":[{"add":["7","from sklearn.utils.testing import assert_allclose_dense_sparse","178","def test_incremental_pca_batch_rank():","179","    # Test sample size in each batch is always larger or equal to n_components","180","    rng = np.random.RandomState(1999)","181","    n_samples = 100","182","    n_features = 20","183","    X = rng.randn(n_samples, n_features)","184","    all_components = []","185","    batch_sizes = np.arange(20, 90, 3)","186","    for batch_size in batch_sizes:","187","        ipca = IncrementalPCA(n_components=20, batch_size=batch_size).fit(X)","188","        all_components.append(ipca.components_)","189","","190","    for components_i, components_j in zip(all_components[:-1],","191","                                          all_components[1:]):","192","        assert_allclose_dense_sparse(components_i, components_j)","193","","194",""],"delete":[]}]}},"121dd5ab3bb03203480941ccef2df72cf9cf791d":{"changes":{"sklearn\/neural_network\/rbm.py":"MODIFY"},"diff":{"sklearn\/neural_network\/rbm.py":[{"add":["311","        if sp.issparse(v):"],"delete":["21","from ..utils import issparse","312","        if issparse(v):"]}]}},"5d8dfc9677e410de2dbd1daf1963696577869d59":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/utils\/validation.py":"MODIFY","sklearn\/utils\/tests\/test_validation.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["1316","- |Fix| Fixed a bug in validation helpers where passing a Dask DataFrame results","1317","  in an error. :issue:`12462` by :user:`Zachariah Miller <zwmiller>`","1318",""],"delete":[]}],"sklearn\/utils\/validation.py":[{"add":["142","        # Check that shape is returning an integer or default to len","143","        # Dask dataframes may not return numeric shape[0] value","144","        if isinstance(x.shape[0], numbers.Integral):","145","            return x.shape[0]","146","        else:","147","            return len(x)"],"delete":["142","        return x.shape[0]"]}],"sklearn\/utils\/tests\/test_validation.py":[{"add":["43","    _num_samples","789","","790","","791","def test_retrieve_samples_from_non_standard_shape():","792","    class TestNonNumericShape:","793","        def __init__(self):","794","            self.shape = (\"not numeric\",)","795","","796","        def __len__(self):","797","            return len([1, 2, 3])","798","","799","    X = TestNonNumericShape()","800","    assert _num_samples(X) == len(X)"],"delete":[]}]}},"5e101a2a07ea3586fe663598495cdc3893cb7665":{"changes":{"sklearn\/externals\/copy_joblib.sh":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/__init__.py":"MODIFY","sklearn\/externals\/joblib\/__init__.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/_base.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/context.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/process_executor.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/reduction.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/compat.py":"MODIFY","sklearn\/externals\/joblib\/memory.py":"MODIFY"},"diff":{"sklearn\/externals\/copy_joblib.sh":[{"add":["13","pip install --no-cache $JOBLIB --target $INSTALL_FOLDER"],"delete":["13","pip install $JOBLIB --target $INSTALL_FOLDER"]}],"sklearn\/externals\/joblib\/externals\/loky\/__init__.py":[{"add":["5","from ._base import Executor, Future","6","from ._base import wait, as_completed","7","from ._base import TimeoutError, CancelledError","8","from ._base import ALL_COMPLETED, FIRST_COMPLETED, FIRST_EXCEPTION","10","from .backend.context import cpu_count","11","from .reusable_executor import get_reusable_executor","12","from .process_executor import BrokenProcessPool, ProcessPoolExecutor","14","","15","__all__ = [\"get_reusable_executor\", \"cpu_count\", \"wait\", \"as_completed\",","16","           \"Future\", \"Executor\", \"ProcessPoolExecutor\",","17","           \"BrokenProcessPool\", \"CancelledError\", \"TimeoutError\",","18","           \"FIRST_COMPLETED\", \"FIRST_EXCEPTION\", \"ALL_COMPLETED\", ]","19","","20","","21","__version__ = '2.3.0'"],"delete":["5","from .reusable_executor import get_reusable_executor  # noqa: F401","6","from .process_executor import ProcessPoolExecutor  # noqa: F401","7","from .process_executor import BrokenProcessPool  # noqa: F401","9","from .backend.context import cpu_count  # noqa: F401","11","__version__ = '2.2.2'"]}],"sklearn\/externals\/joblib\/__init__.py":[{"add":["108","__version__ = '0.12.4'"],"delete":["108","__version__ = '0.12.3'"]}],"sklearn\/externals\/joblib\/externals\/loky\/_base.py":[{"add":["13","import time","16","import collections","19","if sys.version_info[:2] >= (3, 3):","20","","21","    from concurrent.futures import wait, as_completed","22","    from concurrent.futures import TimeoutError, CancelledError","23","    from concurrent.futures import Executor, Future as _BaseFuture","24","","25","    from concurrent.futures import FIRST_EXCEPTION","26","    from concurrent.futures import ALL_COMPLETED, FIRST_COMPLETED","27","","28","    from concurrent.futures._base import LOGGER","29","    from concurrent.futures._base import PENDING, RUNNING, CANCELLED","30","    from concurrent.futures._base import CANCELLED_AND_NOTIFIED, FINISHED","31","else:","32","","33","    FIRST_COMPLETED = 'FIRST_COMPLETED'","34","    FIRST_EXCEPTION = 'FIRST_EXCEPTION'","35","    ALL_COMPLETED = 'ALL_COMPLETED'","36","    _AS_COMPLETED = '_AS_COMPLETED'","37","","38","    # Possible future states (for internal use by the futures package).","39","    PENDING = 'PENDING'","40","    RUNNING = 'RUNNING'","41","    # The future was cancelled by the user...","42","    CANCELLED = 'CANCELLED'","43","    # ...and _Waiter.add_cancelled() was called by a worker.","44","    CANCELLED_AND_NOTIFIED = 'CANCELLED_AND_NOTIFIED'","45","    FINISHED = 'FINISHED'","46","","47","    _FUTURE_STATES = [","48","        PENDING,","49","        RUNNING,","50","        CANCELLED,","51","        CANCELLED_AND_NOTIFIED,","52","        FINISHED","53","    ]","54","","55","    _STATE_TO_DESCRIPTION_MAP = {","56","        PENDING: \"pending\",","57","        RUNNING: \"running\",","58","        CANCELLED: \"cancelled\",","59","        CANCELLED_AND_NOTIFIED: \"cancelled\",","60","        FINISHED: \"finished\"","61","    }","62","","63","    # Logger for internal use by the futures package.","64","    LOGGER = logging.getLogger(\"concurrent.futures\")","78","    class _Waiter(object):","79","        \"\"\"Provides the event that wait() and as_completed() block on.\"\"\"","80","        def __init__(self):","81","            self.event = threading.Event()","82","            self.finished_futures = []","84","        def add_result(self, future):","85","            self.finished_futures.append(future)","87","        def add_exception(self, future):","88","            self.finished_futures.append(future)","90","        def add_cancelled(self, future):","91","            self.finished_futures.append(future)","93","    class _AsCompletedWaiter(_Waiter):","94","        \"\"\"Used by as_completed().\"\"\"","96","        def __init__(self):","97","            super(_AsCompletedWaiter, self).__init__()","98","            self.lock = threading.Lock()","100","        def add_result(self, future):","101","            with self.lock:","102","                super(_AsCompletedWaiter, self).add_result(future)","105","        def add_exception(self, future):","106","            with self.lock:","107","                super(_AsCompletedWaiter, self).add_exception(future)","108","                self.event.set()","110","        def add_cancelled(self, future):","111","            with self.lock:","112","                super(_AsCompletedWaiter, self).add_cancelled(future)","113","                self.event.set()","114","","115","    class _FirstCompletedWaiter(_Waiter):","116","        \"\"\"Used by wait(return_when=FIRST_COMPLETED).\"\"\"","117","","118","        def add_result(self, future):","119","            super(_FirstCompletedWaiter, self).add_result(future)","121","","122","        def add_exception(self, future):","123","            super(_FirstCompletedWaiter, self).add_exception(future)","124","            self.event.set()","125","","126","        def add_cancelled(self, future):","127","            super(_FirstCompletedWaiter, self).add_cancelled(future)","128","            self.event.set()","129","","130","    class _AllCompletedWaiter(_Waiter):","131","        \"\"\"Used by wait(return_when=FIRST_EXCEPTION and ALL_COMPLETED).\"\"\"","132","","133","        def __init__(self, num_pending_calls, stop_on_exception):","134","            self.num_pending_calls = num_pending_calls","135","            self.stop_on_exception = stop_on_exception","136","            self.lock = threading.Lock()","137","            super(_AllCompletedWaiter, self).__init__()","138","","139","        def _decrement_pending_calls(self):","140","            with self.lock:","141","                self.num_pending_calls -= 1","142","                if not self.num_pending_calls:","143","                    self.event.set()","144","","145","        def add_result(self, future):","146","            super(_AllCompletedWaiter, self).add_result(future)","149","        def add_exception(self, future):","150","            super(_AllCompletedWaiter, self).add_exception(future)","151","            if self.stop_on_exception:","152","                self.event.set()","154","                self._decrement_pending_calls()","156","        def add_cancelled(self, future):","157","            super(_AllCompletedWaiter, self).add_cancelled(future)","158","            self._decrement_pending_calls()","160","    class _AcquireFutures(object):","161","        \"\"\"A context manager that does an ordered acquire of Future conditions.","162","        \"\"\"","164","        def __init__(self, futures):","165","            self.futures = sorted(futures, key=id)","166","","167","        def __enter__(self):","168","            for future in self.futures:","169","                future._condition.acquire()","170","","171","        def __exit__(self, *args):","172","            for future in self.futures:","173","                future._condition.release()","174","","175","    def _create_and_install_waiters(fs, return_when):","176","        if return_when == _AS_COMPLETED:","177","            waiter = _AsCompletedWaiter()","178","        elif return_when == FIRST_COMPLETED:","179","            waiter = _FirstCompletedWaiter()","180","        else:","181","            pending_count = sum(","182","                    f._state not in [CANCELLED_AND_NOTIFIED, FINISHED]","183","                    for f in fs)","184","","185","            if return_when == FIRST_EXCEPTION:","186","                waiter = _AllCompletedWaiter(pending_count,","187","                                             stop_on_exception=True)","188","            elif return_when == ALL_COMPLETED:","189","                waiter = _AllCompletedWaiter(pending_count,","190","                                             stop_on_exception=False)","191","            else:","192","                raise ValueError(\"Invalid return condition: %r\" % return_when)","193","","194","        for f in fs:","195","            f._waiters.append(waiter)","196","","197","        return waiter","198","","199","    def as_completed(fs, timeout=None):","200","        \"\"\"An iterator over the given futures that yields each as it completes.","201","","202","        Args:","203","            fs: The sequence of Futures (possibly created by different","204","                Executors) to iterate over.","205","            timeout: The maximum number of seconds to wait. If None, then there","206","                is no limit on the wait time.","207","","208","        Returns:","209","            An iterator that yields the given Futures as they complete","210","            (finished or cancelled). If any given Futures are duplicated, they","211","            will be returned once.","212","","213","        Raises:","214","            TimeoutError: If the entire result iterator could not be generated","215","                before the given timeout.","216","        \"\"\"","217","        if timeout is not None:","218","            end_time = timeout + time.time()","219","","220","        fs = set(fs)","221","        with _AcquireFutures(fs):","222","            finished = set(","223","                    f for f in fs","224","                    if f._state in [CANCELLED_AND_NOTIFIED, FINISHED])","225","            pending = fs - finished","226","            waiter = _create_and_install_waiters(fs, _AS_COMPLETED)","227","","228","        try:","232","            while pending:","233","                if timeout is None:","234","                    wait_timeout = None","235","                else:","236","                    wait_timeout = end_time - time.time()","237","                    if wait_timeout < 0:","238","                        raise TimeoutError('%d (of %d) futures unfinished' % (","239","                            len(pending), len(fs)))","240","","241","                waiter.event.wait(wait_timeout)","242","","243","                with waiter.lock:","244","                    finished = waiter.finished_futures","245","                    waiter.finished_futures = []","246","                    waiter.event.clear()","247","","248","                for future in finished:","249","                    yield future","250","                    pending.remove(future)","251","","252","        finally:","253","            for f in fs:","254","                with f._condition:","255","                    f._waiters.remove(waiter)","256","","257","    DoneAndNotDoneFutures = collections.namedtuple(","258","            'DoneAndNotDoneFutures', 'done not_done')","259","","260","    def wait(fs, timeout=None, return_when=ALL_COMPLETED):","261","        \"\"\"Wait for the futures in the given sequence to complete.","262","","263","        Args:","264","            fs: The sequence of Futures (possibly created by different","265","                Executors) to wait upon.","266","            timeout: The maximum number of seconds to wait. If None, then there","267","                is no limit on the wait time.","268","            return_when: Indicates when this function should return. The","269","                options are:","270","","271","                FIRST_COMPLETED - Return when any future finishes or is","272","                                cancelled.","273","                FIRST_EXCEPTION - Return when any future finishes by raising an","274","                                exception. If no future raises an exception","275","                                then it is equivalent to ALL_COMPLETED.","276","                ALL_COMPLETED -   Return when all futures finish or are","277","                                cancelled.","278","","279","        Returns:","280","            A named 2-tuple of sets. The first set, named 'done', contains the","281","            futures that completed (is finished or cancelled) before the wait","282","            completed. The second set, named 'not_done', contains uncompleted","283","            futures.","284","        \"\"\"","285","        with _AcquireFutures(fs):","286","            done = set(f for f in fs","287","                       if f._state in [CANCELLED_AND_NOTIFIED, FINISHED])","288","            not_done = set(fs) - done","289","","290","            if (return_when == FIRST_COMPLETED) and done:","291","                return DoneAndNotDoneFutures(done, not_done)","292","            elif (return_when == FIRST_EXCEPTION) and done:","293","                if any(f for f in done","294","                       if not f.cancelled() and f.exception() is not None):","295","                    return DoneAndNotDoneFutures(done, not_done)","296","","297","            if len(done) == len(fs):","298","                return DoneAndNotDoneFutures(done, not_done)","299","","300","            waiter = _create_and_install_waiters(fs, return_when)","301","","302","        waiter.event.wait(timeout)","307","        done.update(waiter.finished_futures)","308","        return DoneAndNotDoneFutures(done, set(fs) - done)","310","    class _BaseFuture(object):","311","        \"\"\"Represents the result of an asynchronous computation.\"\"\"","312","","313","        def __init__(self):","314","            \"\"\"Initializes the future. Should not be called by clients.\"\"\"","315","            self._condition = threading.Condition()","316","            self._state = PENDING","317","            self._result = None","318","            self._exception = None","319","            self._waiters = []","320","            self._done_callbacks = []","321","","322","        def __repr__(self):","323","            with self._condition:","324","                if self._state == FINISHED:","325","                    if self._exception:","326","                        return '<%s at %#x state=%s raised %s>' % (","327","                            self.__class__.__name__,","328","                            id(self),","329","                            _STATE_TO_DESCRIPTION_MAP[self._state],","330","                            self._exception.__class__.__name__)","331","                    else:","332","                        return '<%s at %#x state=%s returned %s>' % (","333","                            self.__class__.__name__,","334","                            id(self),","335","                            _STATE_TO_DESCRIPTION_MAP[self._state],","336","                            self._result.__class__.__name__)","337","                return '<%s at %#x state=%s>' % (","338","                        self.__class__.__name__,","339","                        id(self),","340","                        _STATE_TO_DESCRIPTION_MAP[self._state])","341","","342","        def cancel(self):","343","            \"\"\"Cancel the future if possible.","344","","345","            Returns True if the future was cancelled, False otherwise. A future","346","            cannot be cancelled if it is running or has already completed.","347","            \"\"\"","348","            with self._condition:","349","                if self._state in [RUNNING, FINISHED]:","350","                    return False","351","","352","                if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","353","                    return True","354","","355","                self._state = CANCELLED","356","                self._condition.notify_all()","357","","358","            self._invoke_callbacks()","359","            return True","360","","361","        def cancelled(self):","362","            \"\"\"Return True if the future was cancelled.\"\"\"","363","            with self._condition:","364","                return self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]","365","","366","        def running(self):","367","            \"\"\"Return True if the future is currently executing.\"\"\"","368","            with self._condition:","369","                return self._state == RUNNING","370","","371","        def done(self):","372","            \"\"\"Return True of the future was cancelled or finished executing.","373","            \"\"\"","374","            with self._condition:","375","                return self._state in [CANCELLED, CANCELLED_AND_NOTIFIED,","376","                                       FINISHED]","377","","378","        def __get_result(self):","379","            if self._exception:","380","                raise self._exception","381","            else:","382","                return self._result","383","","384","        def add_done_callback(self, fn):","385","            \"\"\"Attaches a callable that will be called when the future finishes.","386","","387","            Args:","388","                fn: A callable that will be called with this future as its only","389","                    argument when the future completes or is cancelled. The","390","                    callable will always be called by a thread in the same","391","                    process in which it was added. If the future has already","392","                    completed or been cancelled then the callable will be","393","                    called immediately. These callables are called in the order","394","                    that they were added.","395","            \"\"\"","396","            with self._condition:","397","                if self._state not in [CANCELLED, CANCELLED_AND_NOTIFIED,","398","                                       FINISHED]:","399","                    self._done_callbacks.append(fn)","400","                    return","401","            fn(self)","402","","403","        def result(self, timeout=None):","404","            \"\"\"Return the result of the call that the future represents.","405","","406","            Args:","407","                timeout: The number of seconds to wait for the result if the","408","                    future isn't done. If None, then there is no limit on the","409","                    wait time.","410","","411","            Returns:","412","                The result of the call that the future represents.","413","","414","            Raises:","415","                CancelledError: If the future was cancelled.","416","                TimeoutError: If the future didn't finish executing before the","417","                    given timeout.","418","                Exception: If the call raised then that exception will be","419","                raised.","420","            \"\"\"","421","            with self._condition:","422","                if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","423","                    raise CancelledError()","424","                elif self._state == FINISHED:","425","                    return self.__get_result()","426","","427","                self._condition.wait(timeout)","428","","429","                if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","430","                    raise CancelledError()","431","                elif self._state == FINISHED:","432","                    return self.__get_result()","433","                else:","434","                    raise TimeoutError()","435","","436","        def exception(self, timeout=None):","437","            \"\"\"Return the exception raised by the call that the future","438","            represents.","439","","440","            Args:","441","                timeout: The number of seconds to wait for the exception if the","442","                    future isn't done. If None, then there is no limit on the","443","                    wait time.","444","","445","            Returns:","446","                The exception raised by the call that the future represents or","447","                None if the call completed without raising.","448","","449","            Raises:","450","                CancelledError: If the future was cancelled.","451","                TimeoutError: If the future didn't finish executing before the","452","                    given timeout.","453","            \"\"\"","454","","455","            with self._condition:","456","                if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","457","                    raise CancelledError()","458","                elif self._state == FINISHED:","459","                    return self._exception","460","","461","                self._condition.wait(timeout)","462","","463","                if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","464","                    raise CancelledError()","465","                elif self._state == FINISHED:","466","                    return self._exception","467","                else:","468","                    raise TimeoutError()","469","","470","        # The following methods should only be used by Executors and in tests.","471","        def set_running_or_notify_cancel(self):","472","            \"\"\"Mark the future as running or process any cancel notifications.","473","","474","            Should only be used by Executor implementations and unit tests.","475","","476","            If the future has been cancelled (cancel() was called and returned","477","            True) then any threads waiting on the future completing (though","478","            calls to as_completed() or wait()) are notified and False is","479","            returned.","480","","481","            If the future was not cancelled then it is put in the running state","482","            (future calls to running() will return True) and True is returned.","483","","484","            This method should be called by Executor implementations before","485","            executing the work associated with this future. If this method","486","            returns False then the work should not be executed.","487","","488","            Returns:","489","                False if the Future was cancelled, True otherwise.","490","","491","            Raises:","492","                RuntimeError: if this method was already called or if","493","                    set_result() or set_exception() was called.","494","            \"\"\"","495","            with self._condition:","496","                if self._state == CANCELLED:","497","                    self._state = CANCELLED_AND_NOTIFIED","498","                    for waiter in self._waiters:","499","                        waiter.add_cancelled(self)","500","                    # self._condition.notify_all() is not necessary because","501","                    # self.cancel() triggers a notification.","502","                    return False","503","                elif self._state == PENDING:","504","                    self._state = RUNNING","505","                    return True","506","                else:","507","                    LOGGER.critical('Future %s in unexpected state: %s',","508","                                    id(self),","509","                                    self._state)","510","                    raise RuntimeError('Future in unexpected state')","511","","512","        def set_result(self, result):","513","            \"\"\"Sets the return value of work associated with the future.","514","","515","            Should only be used by Executor implementations and unit tests.","516","            \"\"\"","517","            with self._condition:","518","                self._result = result","519","                self._state = FINISHED","520","                for waiter in self._waiters:","521","                    waiter.add_result(self)","522","                self._condition.notify_all()","523","            self._invoke_callbacks()","524","","525","        def set_exception(self, exception):","526","            \"\"\"Sets the result of the future as being the given exception.","527","","528","            Should only be used by Executor implementations and unit tests.","529","            \"\"\"","530","            with self._condition:","531","                self._exception = exception","532","                self._state = FINISHED","533","                for waiter in self._waiters:","534","                    waiter.add_exception(self)","535","                self._condition.notify_all()","536","            self._invoke_callbacks()","537","","538","    class Executor(object):","539","        \"\"\"This is an abstract base class for concrete asynchronous executors.","540","        \"\"\"","541","","542","        def submit(self, fn, *args, **kwargs):","543","            \"\"\"Submits a callable to be executed with the given arguments.","544","","545","            Schedules the callable to be executed as fn(*args, **kwargs) and","546","            returns a Future instance representing the execution of the","547","            callable.","548","","549","            Returns:","550","                A Future representing the given call.","551","            \"\"\"","552","            raise NotImplementedError()","553","","554","        def map(self, fn, *iterables, **kwargs):","555","            \"\"\"Returns an iterator equivalent to map(fn, iter).","556","","557","            Args:","558","                fn: A callable that will take as many arguments as there are","559","                    passed iterables.","560","                timeout: The maximum number of seconds to wait. If None, then","561","                    there is no limit on the wait time.","562","                chunksize: The size of the chunks the iterable will be broken","563","                    into before being passed to a child process. This argument","564","                    is only used by ProcessPoolExecutor; it is ignored by","565","                    ThreadPoolExecutor.","566","","567","            Returns:","568","                An iterator equivalent to: map(func, *iterables) but the calls","569","                may be evaluated out-of-order.","570","","571","            Raises:","572","                TimeoutError: If the entire result iterator could not be","573","                    generated before the given timeout.","574","                Exception: If fn(*args) raises for any values.","575","            \"\"\"","576","            timeout = kwargs.get('timeout')","577","            if timeout is not None:","578","                end_time = timeout + time.time()","579","","580","            fs = [self.submit(fn, *args) for args in zip(*iterables)]","581","","582","            # Yield must be hidden in closure so that the futures are submitted","583","            # before the first iterator value is required.","584","            def result_iterator():","585","                try:","586","                    for future in fs:","587","                        if timeout is None:","588","                            yield future.result()","589","                        else:","590","                            yield future.result(end_time - time.time())","591","                finally:","592","                    for future in fs:","593","                        future.cancel()","594","            return result_iterator()","595","","596","        def shutdown(self, wait=True):","597","            \"\"\"Clean-up the resources associated with the Executor.","598","","599","            It is safe to call this method several times. Otherwise, no other","600","            methods can be called after this one.","601","","602","            Args:","603","                wait: If True then shutdown will not return until all running","604","                    futures have finished executing and the resources used by","605","                    the executor have been reclaimed.","606","            \"\"\"","607","            pass","608","","609","        def __enter__(self):","610","            return self","611","","612","        def __exit__(self, exc_type, exc_val, exc_tb):","613","            self.shutdown(wait=True)","614","            return False","617","# To make loky._base.Future instances awaitable  by concurrent.futures.wait,","618","# derive our custom Future class from _BaseFuture. _invoke_callback is the only","619","# modification made to this class in loky.","620","class Future(_BaseFuture):"],"delete":["13","import collections","16","import time","17","","18","FIRST_COMPLETED = 'FIRST_COMPLETED'","19","FIRST_EXCEPTION = 'FIRST_EXCEPTION'","20","ALL_COMPLETED = 'ALL_COMPLETED'","21","_AS_COMPLETED = '_AS_COMPLETED'","22","","23","# Possible future states (for internal use by the futures package).","24","PENDING = 'PENDING'","25","RUNNING = 'RUNNING'","26","# The future was cancelled by the user...","27","CANCELLED = 'CANCELLED'","28","# ...and _Waiter.add_cancelled() was called by a worker.","29","CANCELLED_AND_NOTIFIED = 'CANCELLED_AND_NOTIFIED'","30","FINISHED = 'FINISHED'","31","","32","_FUTURE_STATES = [","33","    PENDING,","34","    RUNNING,","35","    CANCELLED,","36","    CANCELLED_AND_NOTIFIED,","37","    FINISHED","38","]","39","","40","_STATE_TO_DESCRIPTION_MAP = {","41","    PENDING: \"pending\",","42","    RUNNING: \"running\",","43","    CANCELLED: \"cancelled\",","44","    CANCELLED_AND_NOTIFIED: \"cancelled\",","45","    FINISHED: \"finished\"","46","}","47","","48","# Logger for internal use by the futures package.","49","LOGGER = logging.getLogger(\"concurrent.futures\")","52","if sys.version_info[:2] < (3, 3):","65","else:","66","    from concurrent.futures import CancelledError, TimeoutError","69","class _Waiter(object):","70","    \"\"\"Provides the event that wait() and as_completed() block on.\"\"\"","71","    def __init__(self):","72","        self.event = threading.Event()","73","        self.finished_futures = []","75","    def add_result(self, future):","76","        self.finished_futures.append(future)","78","    def add_exception(self, future):","79","        self.finished_futures.append(future)","81","    def add_cancelled(self, future):","82","        self.finished_futures.append(future)","85","class _AsCompletedWaiter(_Waiter):","86","    \"\"\"Used by as_completed().\"\"\"","87","","88","    def __init__(self):","89","        super(_AsCompletedWaiter, self).__init__()","90","        self.lock = threading.Lock()","91","","92","    def add_result(self, future):","93","        with self.lock:","94","            super(_AsCompletedWaiter, self).add_result(future)","95","            self.event.set()","96","","97","    def add_exception(self, future):","98","        with self.lock:","99","            super(_AsCompletedWaiter, self).add_exception(future)","100","            self.event.set()","101","","102","    def add_cancelled(self, future):","103","        with self.lock:","104","            super(_AsCompletedWaiter, self).add_cancelled(future)","105","            self.event.set()","106","","107","","108","class _FirstCompletedWaiter(_Waiter):","109","    \"\"\"Used by wait(return_when=FIRST_COMPLETED).\"\"\"","110","","111","    def add_result(self, future):","112","        super(_FirstCompletedWaiter, self).add_result(future)","113","        self.event.set()","114","","115","    def add_exception(self, future):","116","        super(_FirstCompletedWaiter, self).add_exception(future)","117","        self.event.set()","118","","119","    def add_cancelled(self, future):","120","        super(_FirstCompletedWaiter, self).add_cancelled(future)","121","        self.event.set()","122","","123","","124","class _AllCompletedWaiter(_Waiter):","125","    \"\"\"Used by wait(return_when=FIRST_EXCEPTION and ALL_COMPLETED).\"\"\"","126","","127","    def __init__(self, num_pending_calls, stop_on_exception):","128","        self.num_pending_calls = num_pending_calls","129","        self.stop_on_exception = stop_on_exception","130","        self.lock = threading.Lock()","131","        super(_AllCompletedWaiter, self).__init__()","132","","133","    def _decrement_pending_calls(self):","134","        with self.lock:","135","            self.num_pending_calls -= 1","136","            if not self.num_pending_calls:","139","    def add_result(self, future):","140","        super(_AllCompletedWaiter, self).add_result(future)","141","        self._decrement_pending_calls()","143","    def add_exception(self, future):","144","        super(_AllCompletedWaiter, self).add_exception(future)","145","        if self.stop_on_exception:","147","        else:","150","    def add_cancelled(self, future):","151","        super(_AllCompletedWaiter, self).add_cancelled(future)","152","        self._decrement_pending_calls()","153","","154","","155","class _AcquireFutures(object):","156","    \"\"\"A context manager that does an ordered acquire of Future conditions.\"\"\"","157","","158","    def __init__(self, futures):","159","        self.futures = sorted(futures, key=id)","160","","161","    def __enter__(self):","162","        for future in self.futures:","163","            future._condition.acquire()","164","","165","    def __exit__(self, *args):","166","        for future in self.futures:","167","            future._condition.release()","168","","169","","170","def _create_and_install_waiters(fs, return_when):","171","    if return_when == _AS_COMPLETED:","172","        waiter = _AsCompletedWaiter()","173","    elif return_when == FIRST_COMPLETED:","174","        waiter = _FirstCompletedWaiter()","175","    else:","176","        pending_count = sum(","177","                f._state not in [CANCELLED_AND_NOTIFIED, FINISHED] for f in fs)","178","","179","        if return_when == FIRST_EXCEPTION:","180","            waiter = _AllCompletedWaiter(pending_count, stop_on_exception=True)","181","        elif return_when == ALL_COMPLETED:","182","            waiter = _AllCompletedWaiter(pending_count,","183","                                         stop_on_exception=False)","184","        else:","185","            raise ValueError(\"Invalid return condition: %r\" % return_when)","186","","187","    for f in fs:","188","        f._waiters.append(waiter)","189","","190","    return waiter","191","","192","","193","def as_completed(fs, timeout=None):","194","    \"\"\"An iterator over the given futures that yields each as it completes.","195","","196","    Args:","197","        fs: The sequence of Futures (possibly created by different Executors)","198","            to iterate over.","199","        timeout: The maximum number of seconds to wait. If None, then there","200","            is no limit on the wait time.","201","","202","    Returns:","203","        An iterator that yields the given Futures as they complete (finished or","204","        cancelled). If any given Futures are duplicated, they will be returned","205","        once.","206","","207","    Raises:","208","        TimeoutError: If the entire result iterator could not be generated","209","            before the given timeout.","210","    \"\"\"","211","    if timeout is not None:","212","        end_time = timeout + time.time()","213","","214","    fs = set(fs)","215","    with _AcquireFutures(fs):","216","        finished = set(","217","                f for f in fs","218","                if f._state in [CANCELLED_AND_NOTIFIED, FINISHED])","219","        pending = fs - finished","220","        waiter = _create_and_install_waiters(fs, _AS_COMPLETED)","221","","222","    try:","223","        for future in finished:","224","            yield future","225","","226","        while pending:","227","            if timeout is None:","228","                wait_timeout = None","230","                wait_timeout = end_time - time.time()","231","                if wait_timeout < 0:","232","                    raise TimeoutError('%d (of %d) futures unfinished' % (","233","                        len(pending), len(fs)))","235","            waiter.event.wait(wait_timeout)","237","            with waiter.lock:","238","                finished = waiter.finished_futures","239","                waiter.finished_futures = []","240","                waiter.event.clear()","244","                pending.remove(future)","246","    finally:","252","DoneAndNotDoneFutures = collections.namedtuple(","253","        'DoneAndNotDoneFutures', 'done not_done')","256","def wait(fs, timeout=None, return_when=ALL_COMPLETED):","257","    \"\"\"Wait for the futures in the given sequence to complete.","258","","259","    Args:","260","        fs: The sequence of Futures (possibly created by different Executors)","261","            to wait upon.","262","        timeout: The maximum number of seconds to wait. If None, then there","263","            is no limit on the wait time.","264","        return_when: Indicates when this function should return. The options","265","            are:","266","","267","            FIRST_COMPLETED - Return when any future finishes or is","268","                              cancelled.","269","            FIRST_EXCEPTION - Return when any future finishes by raising an","270","                              exception. If no future raises an exception","271","                              then it is equivalent to ALL_COMPLETED.","272","            ALL_COMPLETED -   Return when all futures finish or are cancelled.","273","","274","    Returns:","275","        A named 2-tuple of sets. The first set, named 'done', contains the","276","        futures that completed (is finished or cancelled) before the wait","277","        completed. The second set, named 'not_done', contains uncompleted","278","        futures.","279","    \"\"\"","280","    with _AcquireFutures(fs):","281","        done = set(f for f in fs","282","                   if f._state in [CANCELLED_AND_NOTIFIED, FINISHED])","283","        not_done = set(fs) - done","284","","285","        if (return_when == FIRST_COMPLETED) and done:","286","            return DoneAndNotDoneFutures(done, not_done)","287","        elif (return_when == FIRST_EXCEPTION) and done:","288","            if any(f for f in done","289","                   if not f.cancelled() and f.exception() is not None):","290","                return DoneAndNotDoneFutures(done, not_done)","291","","292","        if len(done) == len(fs):","293","            return DoneAndNotDoneFutures(done, not_done)","294","","295","        waiter = _create_and_install_waiters(fs, return_when)","296","","297","    waiter.event.wait(timeout)","298","    for f in fs:","299","        with f._condition:","300","            f._waiters.remove(waiter)","301","","302","    done.update(waiter.finished_futures)","303","    return DoneAndNotDoneFutures(done, set(fs) - done)","304","","305","","306","class Future(object):","307","    \"\"\"Represents the result of an asynchronous computation.\"\"\"","308","","309","    def __init__(self):","310","        \"\"\"Initializes the future. Should not be called by clients.\"\"\"","311","        self._condition = threading.Condition()","312","        self._state = PENDING","313","        self._result = None","314","        self._exception = None","315","        self._waiters = []","316","        self._done_callbacks = []","317","","324","","325","    def __repr__(self):","326","        with self._condition:","327","            if self._state == FINISHED:","328","                if self._exception:","329","                    return '<%s at %#x state=%s raised %s>' % (","330","                        self.__class__.__name__,","331","                        id(self),","332","                        _STATE_TO_DESCRIPTION_MAP[self._state],","333","                        self._exception.__class__.__name__)","334","                else:","335","                    return '<%s at %#x state=%s returned %s>' % (","336","                        self.__class__.__name__,","337","                        id(self),","338","                        _STATE_TO_DESCRIPTION_MAP[self._state],","339","                        self._result.__class__.__name__)","340","            return '<%s at %#x state=%s>' % (","341","                    self.__class__.__name__,","342","                    id(self),","343","                   _STATE_TO_DESCRIPTION_MAP[self._state])","344","","345","    def cancel(self):","346","        \"\"\"Cancel the future if possible.","347","","348","        Returns True if the future was cancelled, False otherwise. A future","349","        cannot be cancelled if it is running or has already completed.","350","        \"\"\"","351","        with self._condition:","352","            if self._state in [RUNNING, FINISHED]:","353","                return False","354","","355","            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","356","                return True","357","","358","            self._state = CANCELLED","359","            self._condition.notify_all()","360","","361","        self._invoke_callbacks()","362","        return True","363","","364","    def cancelled(self):","365","        \"\"\"Return True if the future was cancelled.\"\"\"","366","        with self._condition:","367","            return self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]","368","","369","    def running(self):","370","        \"\"\"Return True if the future is currently executing.\"\"\"","371","        with self._condition:","372","            return self._state == RUNNING","373","","374","    def done(self):","375","        \"\"\"Return True of the future was cancelled or finished executing.\"\"\"","376","        with self._condition:","377","            return self._state in [CANCELLED, CANCELLED_AND_NOTIFIED, FINISHED]","378","","379","    def __get_result(self):","380","        if self._exception:","381","            raise self._exception","382","        else:","383","            return self._result","384","","385","    def add_done_callback(self, fn):","386","        \"\"\"Attaches a callable that will be called when the future finishes.","387","","388","        Args:","389","            fn: A callable that will be called with this future as its only","390","                argument when the future completes or is cancelled. The","391","                callable will always be called by a thread in the same process","392","                in which it was added. If the future has already completed or","393","                been cancelled then the callable will be called immediately.","394","                These callables are called in the order that they were added.","395","        \"\"\"","396","        with self._condition:","397","            if self._state not in [CANCELLED, CANCELLED_AND_NOTIFIED,","398","                                   FINISHED]:","399","                self._done_callbacks.append(fn)","400","                return","401","        fn(self)","402","","403","    def result(self, timeout=None):","404","        \"\"\"Return the result of the call that the future represents.","405","","406","        Args:","407","            timeout: The number of seconds to wait for the result if the future","408","                isn't done. If None, then there is no limit on the wait time.","409","","410","        Returns:","411","            The result of the call that the future represents.","412","","413","        Raises:","414","            CancelledError: If the future was cancelled.","415","            TimeoutError: If the future didn't finish executing before the","416","                given timeout.","417","            Exception: If the call raised then that exception will be raised.","418","        \"\"\"","419","        with self._condition:","420","            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","421","                raise CancelledError()","422","            elif self._state == FINISHED:","423","                return self.__get_result()","424","","425","            self._condition.wait(timeout)","426","","427","            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","428","                raise CancelledError()","429","            elif self._state == FINISHED:","430","                return self.__get_result()","431","            else:","432","                raise TimeoutError()","433","","434","    def exception(self, timeout=None):","435","        \"\"\"Return the exception raised by the call that the future represents.","436","","437","        Args:","438","            timeout: The number of seconds to wait for the exception if the","439","                future isn't done. If None, then there is no limit on the wait","440","                time.","441","","442","        Returns:","443","            The exception raised by the call that the future represents or None","444","            if the call completed without raising.","445","","446","        Raises:","447","            CancelledError: If the future was cancelled.","448","            TimeoutError: If the future didn't finish executing before the","449","                given timeout.","450","        \"\"\"","451","","452","        with self._condition:","453","            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","454","                raise CancelledError()","455","            elif self._state == FINISHED:","456","                return self._exception","457","","458","            self._condition.wait(timeout)","459","","460","            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","461","                raise CancelledError()","462","            elif self._state == FINISHED:","463","                return self._exception","464","            else:","465","                raise TimeoutError()","466","","467","    # The following methods should only be used by Executors and in tests.","468","    def set_running_or_notify_cancel(self):","469","        \"\"\"Mark the future as running or process any cancel notifications.","470","","471","        Should only be used by Executor implementations and unit tests.","472","","473","        If the future has been cancelled (cancel() was called and returned","474","        True) then any threads waiting on the future completing (though calls","475","        to as_completed() or wait()) are notified and False is returned.","476","","477","        If the future was not cancelled then it is put in the running state","478","        (future calls to running() will return True) and True is returned.","479","","480","        This method should be called by Executor implementations before","481","        executing the work associated with this future. If this method returns","482","        False then the work should not be executed.","483","","484","        Returns:","485","            False if the Future was cancelled, True otherwise.","486","","487","        Raises:","488","            RuntimeError: if this method was already called or if set_result()","489","                or set_exception() was called.","490","        \"\"\"","491","        with self._condition:","492","            if self._state == CANCELLED:","493","                self._state = CANCELLED_AND_NOTIFIED","494","                for waiter in self._waiters:","495","                    waiter.add_cancelled(self)","496","                # self._condition.notify_all() is not necessary because","497","                # self.cancel() triggers a notification.","498","                return False","499","            elif self._state == PENDING:","500","                self._state = RUNNING","501","                return True","502","            else:","503","                LOGGER.critical('Future %s in unexpected state: %s',","504","                                id(self),","505","                                self._state)","506","                raise RuntimeError('Future in unexpected state')","507","","508","    def set_result(self, result):","509","        \"\"\"Sets the return value of work associated with the future.","510","","511","        Should only be used by Executor implementations and unit tests.","512","        \"\"\"","513","        with self._condition:","514","            self._result = result","515","            self._state = FINISHED","516","            for waiter in self._waiters:","517","                waiter.add_result(self)","518","            self._condition.notify_all()","519","        self._invoke_callbacks()","520","","521","    def set_exception(self, exception):","522","        \"\"\"Sets the result of the future as being the given exception.","523","","524","        Should only be used by Executor implementations and unit tests.","525","        \"\"\"","526","        with self._condition:","527","            self._exception = exception","528","            self._state = FINISHED","529","            for waiter in self._waiters:","530","                waiter.add_exception(self)","531","            self._condition.notify_all()","532","        self._invoke_callbacks()","533","","534","","535","class Executor(object):","536","    \"\"\"This is an abstract base class for concrete asynchronous executors.\"\"\"","537","","538","    def submit(self, fn, *args, **kwargs):","539","        \"\"\"Submits a callable to be executed with the given arguments.","540","","541","        Schedules the callable to be executed as fn(*args, **kwargs) and","542","        returns a Future instance representing the execution of the callable.","543","","544","        Returns:","545","            A Future representing the given call.","546","        \"\"\"","547","        raise NotImplementedError()","548","","549","    def map(self, fn, *iterables, **kwargs):","550","        \"\"\"Returns an iterator equivalent to map(fn, iter).","551","","552","        Args:","553","            fn: A callable that will take as many arguments as there are","554","                passed iterables.","555","            timeout: The maximum number of seconds to wait. If None, then there","556","                is no limit on the wait time.","557","            chunksize: The size of the chunks the iterable will be broken into","558","                before being passed to a child process. This argument is only","559","                used by ProcessPoolExecutor; it is ignored by","560","                ThreadPoolExecutor.","561","","562","        Returns:","563","            An iterator equivalent to: map(func, *iterables) but the calls may","564","            be evaluated out-of-order.","565","","566","        Raises:","567","            TimeoutError: If the entire result iterator could not be generated","568","                before the given timeout.","569","            Exception: If fn(*args) raises for any values.","570","        \"\"\"","571","        timeout = kwargs.get('timeout')","572","        if timeout is not None:","573","            end_time = timeout + time.time()","574","","575","        fs = [self.submit(fn, *args) for args in zip(*iterables)]","576","","577","        # Yield must be hidden in closure so that the futures are submitted","578","        # before the first iterator value is required.","579","        def result_iterator():","580","            try:","581","                for future in fs:","582","                    if timeout is None:","583","                        yield future.result()","584","                    else:","585","                        yield future.result(end_time - time.time())","586","            finally:","587","                for future in fs:","588","                    future.cancel()","589","        return result_iterator()","590","","591","    def shutdown(self, wait=True):","592","        \"\"\"Clean-up the resources associated with the Executor.","593","","594","        It is safe to call this method several times. Otherwise, no other","595","        methods can be called after this one.","596","","597","        Args:","598","            wait: If True then shutdown will not return until all running","599","                futures have finished executing and the resources used by the","600","                executor have been reclaimed.","601","        \"\"\"","602","        pass","603","","604","    def __enter__(self):","605","        return self","606","","607","    def __exit__(self, exc_type, exc_val, exc_tb):","608","        self.shutdown(wait=True)","609","        return False"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/context.py":[{"add":["108","       ``multiprocessing.cpu_count``;","110","       (available with Python 3.4+ on some Unix systems);","111","     * CFS scheduler CPU bandwidth limit (available on Linux only, typically","112","       set by docker and similar container orchestration systems);","113","     * the value of the LOKY_MAX_CPU_COUNT environment variable if defined.","114","    and is given as the minimum of these constraints.","144","            # Make sure this quantity is an int as math.ceil returns a","145","            # float in python2.7. (See issue #165)","146","            cpu_count_cfs = int(math.ceil(cfs_quota_us \/ cfs_period_us))","148","    # User defined soft-limit passed as an loky specific environment variable.","149","    cpu_count_loky = int(os.environ.get('LOKY_MAX_CPU_COUNT', cpu_count_mp))","150","    aggregate_cpu_count = min(cpu_count_mp, cpu_count_affinity, cpu_count_cfs,","151","                              cpu_count_loky)","152","    return max(aggregate_cpu_count, 1)"],"delete":["108","       ``multiprocessing.cpu_count``","110","       (available with Python 3.4+ on some Unix systems)","111","     * CFS scheduler CPU bandwidth limit","112","       (available on Linux only)","113","    and is given as the minimum of these three constraints.","143","            cpu_count_cfs = math.ceil(cfs_quota_us \/ cfs_period_us)","144","            cpu_count_cfs = max(cpu_count_cfs, 1)","146","    return min(cpu_count_mp, cpu_count_affinity, cpu_count_cfs)"]}],"sklearn\/externals\/joblib\/externals\/loky\/process_executor.py":[{"add":["119","# Minimum time interval between two consecutive memory leak protection checks.","120","_MEMORY_LEAK_CHECK_DELAY = 1.","125","","128","    _USE_PSUTIL = True","137","    _USE_PSUTIL = False","387","    _last_memory_leak_check = None","426","            del r","432","        if _USE_PSUTIL:","436","                _last_memory_leak_check = time()","438","            if time() - _last_memory_leak_check > _MEMORY_LEAK_CHECK_DELAY:","440","                print(mem_usage)","441","                _last_memory_leak_check = time()","450","                _last_memory_leak_check = time()","461","        else:","462","            # if psutil is not installed, trigger gc.collect events","463","            # regularly to limit potential memory leaks due to reference cycles","464","            if ((_last_memory_leak_check is None) or","465","                    (time() - _last_memory_leak_check >","466","                     _MEMORY_LEAK_CHECK_DELAY)):","467","                gc.collect()","468","                _last_memory_leak_check = time()"],"delete":["119","# Minimum time interval between two consecutive memory usage checks.","120","_MEMORY_CHECK_DELAY = 1.","135","    _get_memory_usage = None","385","    _process_last_memory_check = None","429","        if _get_memory_usage is not None:","433","                _process_last_memory_check = time()","435","            if time() - _process_last_memory_check > _MEMORY_CHECK_DELAY:","437","                _process_last_memory_check = time()","446","                _process_last_memory_check = time()"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/reduction.py":[{"add":["183","if not hasattr(sys, \"pypy_version_info\"):","184","    # PyPy uses functions instead of method_descriptors and wrapper_descriptors","185","    def _reduce_method_descriptor(m):","186","        return getattr, (m.__objclass__, m.__name__)","188","    register(type(list.append), _reduce_method_descriptor)","189","    register(type(int.__add__), _reduce_method_descriptor)"],"delete":["183","def _reduce_method_descriptor(m):","184","    return getattr, (m.__objclass__, m.__name__)","186","","187","register(type(list.append), _reduce_method_descriptor)","188","register(type(int.__add__), _reduce_method_descriptor)"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/compat.py":[{"add":["13","","14","from pickle import PicklingError"],"delete":["11","    from _pickle import PicklingError","14","    from pickle import PicklingError"]}],"sklearn\/externals\/joblib\/memory.py":[{"add":["459","","460","        # Wether or not the memorized function must be called","461","        must_call = False","462","","464","        # Compare the function code with the previous to see if the","465","        # function code has changed","475","            must_call = True","504","                must_call = True","505","","506","        if must_call:","507","            out, metadata = self.call(*args, **kwargs)","508","            if self.mmap_mode is not None:","509","                # Memmap the output at the first call to be consistent with","510","                # later calls","511","                if self._verbose:","512","                    msg = _format_load_msg(func_id, args_id,","513","                                           timestamp=self.timestamp,","514","                                           metadata=metadata)","515","                out = self.store_backend.load_item([func_id, args_id], msg=msg,","516","                                                   verbose=self._verbose)"],"delete":["456","        # Compare the function code with the previous to see if the","457","        # function code has changed","471","            out, metadata = self.call(*args, **kwargs)","472","            if self.mmap_mode is not None:","473","                # Memmap the output at the first call to be consistent with","474","                # later calls","475","                if self._verbose:","476","                    msg = _format_load_msg(func_id, args_id,","477","                                           timestamp=self.timestamp,","478","                                           metadata=metadata)","479","                out = self.store_backend.load_item([func_id, args_id], msg=msg,","480","                                                   verbose=self._verbose)","509","                out, metadata = self.call(*args, **kwargs)","510","                args_id = None"]}]}},"4f5dd77d19fc682e5a04f56791e3fd17d1d71e08":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/utils\/validation.py":"MODIFY","sklearn\/utils\/tests\/test_validation.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["48",":mod:`sklearn.utils`","49","....................","50","","51","- |Fix| Calling :func:`utils.check_array` on `pandas.Series` with categorical","52","  data, which raised an error in 0.20.0, now returns the expected output again.","53","  :issue:`12699` by `Joris Van den Bossche`_.","54",""],"delete":[]}],"sklearn\/utils\/validation.py":[{"add":["479","    if hasattr(array, \"dtypes\") and hasattr(array.dtypes, '__array__'):"],"delete":["479","    if hasattr(array, \"dtypes\") and len(array.dtypes):"]}],"sklearn\/utils\/tests\/test_validation.py":[{"add":["703","    # with categorical dtype (not a numpy dtype) (GH12699)","704","    s = pd.Series(['a', 'b', 'c']).astype('category')","705","    res = check_array(s, dtype=None, ensure_2d=False)","706","    assert_array_equal(res, np.array(['a', 'b', 'c'], dtype=object))","707",""],"delete":[]}]}},"c1f58745be7c4923cf0a666f1c6bf052042f131e":{"changes":{"doc\/modules\/linear_model.rst":"MODIFY","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/linear_model\/tests\/test_logistic.py":"MODIFY","doc\/tutorial\/statistical_inference\/supervised_learning.rst":"MODIFY","sklearn\/linear_model\/logistic.py":"MODIFY","sklearn\/linear_model\/sag_fast.pyx":"MODIFY","sklearn\/linear_model\/sag.py":"MODIFY","examples\/linear_model\/plot_logistic_l1_l2_sparsity.py":"MODIFY"},"diff":{"doc\/modules\/linear_model.rst":[{"add":["340","Elastic-Net","392","Multi-task Elastic-Net","732","Rest, or multinomial logistic regression with optional L2, L1 or Elastic-Net","741","optimization problem:","745","Elastic-Net regularization is a combination of L1 and L2, and minimizes the","746","following cost function:","747","","748",".. math:: \\min_{w, c} \\frac{1 - \\rho}{2}w^T w + \\rho \\|w\\|_1 + C \\sum_{i=1}^n \\log(\\exp(- y_i (X_i^T w + c)) + 1),","749","","750","where :math:`\\rho` controls the strengh of L1 regularization vs L2","751","regularization (it corresponds to the `l1_ratio` parameter).","752","","754",":math:`{-1, 1}` at trial :math:`i`. We can also see that Elastic-Net is","755","equivalent to L1 when :math:`\\rho = 1` and equivalent to L2 when","756",":math:`\\rho=0`.","784","non-smooth `penalty=\"l1\"`. This is therefore the solver of choice for sparse","785","multinomial logistic regression. It is also the only solver that supports","786","`penalty=\"elasticnet\"`.","788","In a nutshell, the following table summarizes the penalties supported by","789","each solver:","804","| Elastic-Net                  |       no        |     no      |       no        |    no     |    yes     |","805","+------------------------------+-----------------+-------------+-----------------+-----------+------------+","815","The \"saga\" solver is often the best choice but requires scaling. The","816","\"liblinear\" solver is used by default for historical reasons.","854",":class:`LogisticRegressionCV` implements Logistic Regression with built-in","855","cross-validation support, to find the optimal `C` and `l1_ratio` parameters","856","according to the ``scoring`` attribute. The \"newton-cg\", \"sag\", \"saga\" and","857","\"lbfgs\" solvers are found to be faster for high-dimensional dense data, due","858","to warm-starting (see :term:`Glossary <warm_start>`)."],"delete":["340","Elastic Net","392","Multi-task Elastic Net","732","Rest, or multinomial logistic regression with optional L2 or L1","741","optimization problem","746",":math:`{-1, 1}` at trial :math:`i`.","774","non-smooth `penalty=\"l1\"` option. This is therefore the solver of choice","775","for sparse multinomial logistic regression.","777","In a nutshell, the following table summarizes the penalties supported by each solver:","801","The \"saga\" solver is often the best choice but requires scaling. The \"liblinear\" solver is","802","used by default for historical reasons.","840",":class:`LogisticRegressionCV` implements Logistic Regression with","841","builtin cross-validation to find out the optimal C parameter.","842","\"newton-cg\", \"sag\", \"saga\" and \"lbfgs\" solvers are found to be faster","843","for high-dimensional dense data, due to warm-starting. For the","844","multiclass case, if `multi_class` option is set to \"ovr\", an optimal C","845","is obtained for each class and if the `multi_class` option is set to","846","\"multinomial\", an optimal C is obtained by minimizing the cross-entropy","847","loss."]}],"doc\/whats_new\/v0.21.rst":[{"add":["24","- :class:`linear_model.LogisticRegression` and","25","  :class:`linear_model.LogisticRegressionCV` with 'saga' solver. |Fix|","26","","151",":mod:`sklearn.linear_model`","152","...........................","153","","154","- |Feature| :class:`linear_model.LogisticRegression` and","155","  :class:`linear_model.LogisticRegressionCV` now support Elastic-Net penalty,","156","  with the 'saga' solver. :issue:`11646` by :user:`Nicolas Hug <NicolasHug>`.","157","","158","- |Fix| Fixed a bug in the 'saga' solver where the weights would not be","159","  correctly updated in some cases. :issue:`11646` by `Tom Dupre la Tour`_."],"delete":[]}],"sklearn\/linear_model\/tests\/test_logistic.py":[{"add":["13","from sklearn.model_selection import GridSearchCV","14","from sklearn.model_selection import train_test_split","29","from sklearn.linear_model import SGDClassifier","30","from sklearn.preprocessing import scale","84","@pytest.mark.filterwarnings('ignore: Default solver will be changed')  # 0.22","213","@pytest.mark.filterwarnings('ignore: Default multi_class will')  # 0.22","233","    # all solvers except 'liblinear' and 'saga'","245","    # only saga supports elasticnet. We only test for liblinear because the","246","    # error is raised before for the other solvers (solver %s supports only l2","247","    # penalties)","248","    for solver in ['liblinear']:","249","        msg = (\"Only 'saga' solver supports elasticnet penalty, got \"","250","               \"solver={}.\".format(solver))","251","        lr = LR(solver=solver, penalty='elasticnet')","252","        assert_raise_message(ValueError, msg, lr.fit, X, y)","253","","1397","def test_elastic_net_coeffs():","1398","    # make sure elasticnet penalty gives different coefficients from l1 and l2","1399","    # with saga solver (l1_ratio different from 0 or 1)","1400","    X, y = make_classification(random_state=0)","1401","","1402","    C = 2.","1403","    l1_ratio = .5","1404","    coeffs = list()","1405","    for penalty in ('elasticnet', 'l1', 'l2'):","1406","        lr = LogisticRegression(penalty=penalty, C=C, solver='saga',","1407","                                random_state=0, l1_ratio=l1_ratio)","1408","        lr.fit(X, y)","1409","        coeffs.append(lr.coef_)","1410","","1411","    elastic_net_coeffs, l1_coeffs, l2_coeffs = coeffs","1412","    # make sure coeffs differ by at least .1","1413","    assert not np.allclose(elastic_net_coeffs, l1_coeffs, rtol=0, atol=.1)","1414","    assert not np.allclose(elastic_net_coeffs, l2_coeffs, rtol=0, atol=.1)","1415","    assert not np.allclose(l2_coeffs, l1_coeffs, rtol=0, atol=.1)","1416","","1417","","1418","@pytest.mark.parametrize('C', [.001, .1, 1, 10, 100, 1000, 1e6])","1419","@pytest.mark.parametrize('penalty, l1_ratio',","1420","                         [('l1', 1),","1421","                          ('l2', 0)])","1422","def test_elastic_net_l1_l2_equivalence(C, penalty, l1_ratio):","1423","    # Make sure elasticnet is equivalent to l1 when l1_ratio=1 and to l2 when","1424","    # l1_ratio=0.","1425","    X, y = make_classification(random_state=0)","1426","","1427","    lr_enet = LogisticRegression(penalty='elasticnet', C=C, l1_ratio=l1_ratio,","1428","                                 solver='saga', random_state=0)","1429","    lr_expected = LogisticRegression(penalty=penalty, C=C, solver='saga',","1430","                                     random_state=0)","1431","    lr_enet.fit(X, y)","1432","    lr_expected.fit(X, y)","1433","","1434","    assert_array_almost_equal(lr_enet.coef_, lr_expected.coef_)","1435","","1436","","1437","@pytest.mark.parametrize('C', [.001, 1, 100, 1e6])","1438","def test_elastic_net_vs_l1_l2(C):","1439","    # Make sure that elasticnet with grid search on l1_ratio gives same or","1440","    # better results than just l1 or just l2.","1441","","1442","    X, y = make_classification(500, random_state=0)","1443","    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","1444","","1445","    param_grid = {'l1_ratio': np.linspace(0, 1, 5)}","1446","","1447","    enet_clf = LogisticRegression(penalty='elasticnet', C=C, solver='saga',","1448","                                  random_state=0)","1449","    gs = GridSearchCV(enet_clf, param_grid, cv=5, iid=False, refit=True)","1450","","1451","    l1_clf = LogisticRegression(penalty='l1', C=C, solver='saga',","1452","                                random_state=0)","1453","    l2_clf = LogisticRegression(penalty='l2', C=C, solver='saga',","1454","                                random_state=0)","1455","","1456","    for clf in (gs, l1_clf, l2_clf):","1457","        clf.fit(X_train, y_train)","1458","","1459","    assert gs.score(X_test, y_test) >= l1_clf.score(X_test, y_test)","1460","    assert gs.score(X_test, y_test) >= l2_clf.score(X_test, y_test)","1461","","1462","","1463","@pytest.mark.parametrize('C', np.logspace(-3, 2, 4))","1464","@pytest.mark.parametrize('l1_ratio', [.1, .5, .9])","1465","def test_LogisticRegression_elastic_net_objective(C, l1_ratio):","1466","    # Check that training with a penalty matching the objective leads","1467","    # to a lower objective.","1468","    # Here we train a logistic regression with l2 (a) and elasticnet (b)","1469","    # penalties, and compute the elasticnet objective. That of a should be","1470","    # greater than that of b (both objectives are convex).","1471","    X, y = make_classification(n_samples=1000, n_classes=2, n_features=20,","1472","                               n_informative=10, n_redundant=0,","1473","                               n_repeated=0, random_state=0)","1474","    X = scale(X)","1475","","1476","    lr_enet = LogisticRegression(penalty='elasticnet', solver='saga',","1477","                                 random_state=0, C=C, l1_ratio=l1_ratio,","1478","                                 fit_intercept=False)","1479","    lr_l2 = LogisticRegression(penalty='l2', solver='saga', random_state=0,","1480","                               C=C, fit_intercept=False)","1481","    lr_enet.fit(X, y)","1482","    lr_l2.fit(X, y)","1483","","1484","    def enet_objective(lr):","1485","        coef = lr.coef_.ravel()","1486","        obj = C * log_loss(y, lr.predict_proba(X))","1487","        obj += l1_ratio * np.sum(np.abs(coef))","1488","        obj += (1. - l1_ratio) * 0.5 * np.dot(coef, coef)","1489","        return obj","1490","","1491","    assert enet_objective(lr_enet) < enet_objective(lr_l2)","1492","","1493","","1494","@pytest.mark.filterwarnings('ignore: The default of the `iid`')  # 0.22","1495","@pytest.mark.parametrize('multi_class', ('ovr', 'multinomial'))","1496","def test_LogisticRegressionCV_GridSearchCV_elastic_net(multi_class):","1497","    # make sure LogisticRegressionCV gives same best params (l1 and C) as","1498","    # GridSearchCV when penalty is elasticnet","1499","","1500","    if multi_class == 'ovr':","1501","        # This is actually binary classification, ovr multiclass is treated in","1502","        # test_LogisticRegressionCV_GridSearchCV_elastic_net_ovr","1503","        X, y = make_classification(random_state=0)","1504","    else:","1505","        X, y = make_classification(n_samples=200, n_classes=3, n_informative=3,","1506","                                   random_state=0)","1507","","1508","    cv = StratifiedKFold(5, random_state=0)","1509","","1510","    l1_ratios = np.linspace(0, 1, 5)","1511","    Cs = np.logspace(-4, 4, 5)","1512","","1513","    lrcv = LogisticRegressionCV(penalty='elasticnet', Cs=Cs, solver='saga',","1514","                                cv=cv, l1_ratios=l1_ratios, random_state=0,","1515","                                multi_class=multi_class)","1516","    lrcv.fit(X, y)","1517","","1518","    param_grid = {'C': Cs, 'l1_ratio': l1_ratios}","1519","    lr = LogisticRegression(penalty='elasticnet', solver='saga',","1520","                            random_state=0, multi_class=multi_class)","1521","    gs = GridSearchCV(lr, param_grid, cv=cv)","1522","    gs.fit(X, y)","1523","","1524","    assert gs.best_params_['l1_ratio'] == lrcv.l1_ratio_[0]","1525","    assert gs.best_params_['C'] == lrcv.C_[0]","1526","","1527","","1528","def test_LogisticRegressionCV_GridSearchCV_elastic_net_ovr():","1529","    # make sure LogisticRegressionCV gives same best params (l1 and C) as","1530","    # GridSearchCV when penalty is elasticnet and multiclass is ovr. We can't","1531","    # compare best_params like in the previous test because","1532","    # LogisticRegressionCV with multi_class='ovr' will have one C and one","1533","    # l1_param for each class, while LogisticRegression will share the","1534","    # parameters over the *n_classes* classifiers.","1535","","1536","    X, y = make_classification(n_samples=200, n_classes=3, n_informative=3,","1537","                               random_state=0)","1538","    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","1539","    cv = StratifiedKFold(5, random_state=0)","1540","","1541","    l1_ratios = np.linspace(0, 1, 5)","1542","    Cs = np.logspace(-4, 4, 5)","1543","","1544","    lrcv = LogisticRegressionCV(penalty='elasticnet', Cs=Cs, solver='saga',","1545","                                cv=cv, l1_ratios=l1_ratios, random_state=0,","1546","                                multi_class='ovr')","1547","    lrcv.fit(X_train, y_train)","1548","","1549","    param_grid = {'C': Cs, 'l1_ratio': l1_ratios}","1550","    lr = LogisticRegression(penalty='elasticnet', solver='saga',","1551","                            random_state=0, multi_class='ovr')","1552","    gs = GridSearchCV(lr, param_grid, cv=cv, iid=False)","1553","    gs.fit(X_train, y_train)","1554","","1555","    # Check that predictions are 80% the same","1556","    assert (lrcv.predict(X_train) == gs.predict(X_train)).mean() >= .8","1557","    assert (lrcv.predict(X_test) == gs.predict(X_test)).mean() >= .8","1558","","1559","","1560","@pytest.mark.parametrize('multi_class', ('ovr', 'multinomial'))","1561","def test_LogisticRegressionCV_no_refit(multi_class):","1562","    # Test LogisticRegressionCV attribute shapes when refit is False","1563","","1564","    n_classes = 3","1565","    n_features = 20","1566","    X, y = make_classification(n_samples=200, n_classes=n_classes,","1567","                               n_informative=n_classes, n_features=n_features,","1568","                               random_state=0)","1569","","1570","    Cs = np.logspace(-4, 4, 3)","1571","    l1_ratios = np.linspace(0, 1, 2)","1572","","1573","    lrcv = LogisticRegressionCV(penalty='elasticnet', Cs=Cs, solver='saga',","1574","                                cv=5, l1_ratios=l1_ratios, random_state=0,","1575","                                multi_class=multi_class, refit=False)","1576","    lrcv.fit(X, y)","1577","    assert lrcv.C_.shape == (n_classes,)","1578","    assert lrcv.l1_ratio_.shape == (n_classes,)","1579","    assert lrcv.coef_.shape == (n_classes, n_features)","1580","","1581","","1582","@pytest.mark.filterwarnings('ignore: Default multi_class will')  # 0.22","1583","def test_LogisticRegressionCV_elasticnet_attribute_shapes():","1584","    # Make sure the shapes of scores_ and coefs_paths_ attributes are correct","1585","    # when using elasticnet (added one dimension for l1_ratios)","1586","","1587","    n_classes = 3","1588","    n_features = 20","1589","    X, y = make_classification(n_samples=200, n_classes=n_classes,","1590","                               n_informative=n_classes, n_features=n_features,","1591","                               random_state=0)","1592","","1593","    Cs = np.logspace(-4, 4, 3)","1594","    l1_ratios = np.linspace(0, 1, 2)","1595","","1596","    n_folds = 2","1597","    lrcv = LogisticRegressionCV(penalty='elasticnet', Cs=Cs, solver='saga',","1598","                                cv=n_folds, l1_ratios=l1_ratios,","1599","                                random_state=0)","1600","    lrcv.fit(X, y)","1601","    coefs_paths = np.asarray(list(lrcv.coefs_paths_.values()))","1602","    assert coefs_paths.shape == (n_classes, n_folds, Cs.size,","1603","                                 l1_ratios.size, n_features + 1)","1604","    scores = np.asarray(list(lrcv.scores_.values()))","1605","    assert scores.shape == (n_classes, n_folds, Cs.size, l1_ratios.size)","1606","","1607","    assert lrcv.n_iter_.shape == (n_classes, n_folds, Cs.size, l1_ratios.size)","1608","","1609","","1610","@pytest.mark.parametrize('l1_ratio', (-1, 2, None, 'something_wrong'))","1611","def test_l1_ratio_param(l1_ratio):","1612","","1613","    msg = \"l1_ratio must be between 0 and 1; got (l1_ratio=%r)\" % l1_ratio","1614","    assert_raise_message(ValueError, msg,","1615","                         LogisticRegression(penalty='elasticnet',","1616","                                            solver='saga',","1617","                                            l1_ratio=l1_ratio).fit, X, Y1)","1618","    if l1_ratio is not None:","1619","        msg = (\"l1_ratio parameter is only used when penalty is 'elasticnet'.\"","1620","               \" Got (penalty=l1)\")","1621","        assert_warns_message(UserWarning, msg,","1622","                             LogisticRegression(penalty='l1', solver='saga',","1623","                                                l1_ratio=l1_ratio).fit, X, Y1)","1624","","1625","","1626","@pytest.mark.parametrize('l1_ratios', ([], [.5, 2], None, 'something_wrong'))","1627","def test_l1_ratios_param(l1_ratios):","1628","","1629","    msg = (\"l1_ratios must be a list of numbers between 0 and 1; got \"","1630","           \"(l1_ratios=%r)\" % l1_ratios)","1631","    assert_raise_message(ValueError, msg,","1632","                         LogisticRegressionCV(penalty='elasticnet',","1633","                                              solver='saga',","1634","                                              l1_ratios=l1_ratios, cv=2).fit,","1635","                         X, Y1)","1636","    if l1_ratios is not None:","1637","        msg = (\"l1_ratios parameter is only used when penalty is \"","1638","               \"'elasticnet'. Got (penalty=l1)\")","1639","        function = LogisticRegressionCV(penalty='l1', solver='saga',","1640","                                        l1_ratios=l1_ratios, cv=2).fit","1641","        assert_warns_message(UserWarning, msg, function, X, Y1)","1642","","1643","","1644","@pytest.mark.parametrize('C', np.logspace(-3, 2, 4))","1645","@pytest.mark.parametrize('l1_ratio', [.1, .5, .9])","1646","def test_elastic_net_versus_sgd(C, l1_ratio):","1647","    # Compare elasticnet penalty in LogisticRegression() and SGD(loss='log')","1648","    n_samples = 500","1649","    X, y = make_classification(n_samples=n_samples, n_classes=2, n_features=5,","1650","                               n_informative=5, n_redundant=0, n_repeated=0,","1651","                               random_state=0)","1652","    X = scale(X)","1653","","1654","    sgd = SGDClassifier(","1655","        penalty='elasticnet', random_state=0, fit_intercept=False, tol=-np.inf,","1656","        max_iter=2000, l1_ratio=l1_ratio, alpha=1. \/ C \/ n_samples, loss='log')","1657","    log = LogisticRegression(","1658","        penalty='elasticnet', random_state=0, fit_intercept=False, tol=1e-5,","1659","        max_iter=1000, l1_ratio=l1_ratio, C=C, solver='saga')","1660","","1661","    sgd.fit(X, y)","1662","    log.fit(X, y)","1663","    assert_array_almost_equal(sgd.coef_, log.coef_, decimal=1)","1664","","1665",""],"delete":["227","    # all solvers except 'liblinear'"]}],"doc\/tutorial\/statistical_inference\/supervised_learning.rst":[{"add":["185","","381","        fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100,"],"delete":["380","        fit_intercept=True, intercept_scaling=1, max_iter=100,"]}],"sklearn\/linear_model\/logistic.py":[{"add":["439","    all_penalties = ['l1', 'l2', 'elasticnet']","450","","451","    if penalty == 'elasticnet' and solver != 'saga':","452","        raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"","453","                         \" got solver={}.\".format(solver))","486","                             max_squared_sum=None, sample_weight=None,","487","                             l1_ratio=None):","556","    penalty : str, 'l1', 'l2', or 'elasticnet'","558","        'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is","559","        only supported by the 'saga' solver.","607","    l1_ratio : float or None, optional (default=None)","608","        The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only","609","        used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent","610","        to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent","611","        to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a","612","        combination of L1 and L2.","613","","793","            # alpha is for L2-norm, beta is for L1-norm","797","            elif penalty == 'l2':","800","            else:  # Elastic-Net penalty","801","                alpha = (1. \/ C) * (1 - l1_ratio)","802","                beta = (1. \/ C) * l1_ratio","803","","835","                          max_squared_sum=None, sample_weight=None,","836","                          l1_ratio=None):","898","    penalty : str, 'l1', 'l2', or 'elasticnet'","900","        'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is","901","        only supported by the 'saga' solver.","943","    l1_ratio : float or None, optional (default=None)","944","        The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only","945","        used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent","946","        to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent","947","        to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a","948","        combination of L1 and L2.","949","","978","        X_train, y_train, Cs=Cs, l1_ratio=l1_ratio,","979","        fit_intercept=fit_intercept, solver=solver, max_iter=max_iter,","980","        class_weight=class_weight, pos_class=pos_class,","981","        multi_class=multi_class, tol=tol, verbose=verbose, dual=dual,","982","        penalty=penalty, intercept_scaling=intercept_scaling,","983","        random_state=random_state, check_input=False,","984","        max_squared_sum=max_squared_sum, sample_weight=sample_weight)","1020","","1032","    'sag', 'saga' and 'newton-cg' solvers.)","1035","    'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. It can","1036","    handle both dense and sparse input. Use C-ordered arrays or CSR matrices","1042","    regularization, with a dual formulation only for the L2 penalty. The","1043","    Elastic-Net regularization is only supported by the 'saga' solver.","1049","    penalty : str, 'l1', 'l2', or 'elasticnet', optional (default='l2')","1051","        'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is","1052","        only supported by the 'saga' solver.","1057","    dual : bool, optional (default=False)","1062","    tol : float, optional (default=1e-4)","1065","    C : float, optional (default=1.0)","1070","    fit_intercept : bool, optional (default=True)","1074","    intercept_scaling : float, optional (default=1)","1087","    class_weight : dict or 'balanced', optional (default=None)","1101","    random_state : int, RandomState instance or None, optional (default=None)","1110","             optional (default='liblinear').","1133","    max_iter : int, optional (default=100)","1137","    multi_class : str, {'ovr', 'multinomial', 'auto'}, optional (default='ovr')","1150","    verbose : int, optional (default=0)","1154","    warm_start : bool, optional (default=False)","1170","    l1_ratio : float or None, optional (default=None)","1171","        The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only","1172","        used if ``penalty='elasticnet'`. Setting ``l1_ratio=0`` is equivalent","1173","        to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent","1174","        to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a","1175","        combination of L1 and L2.","1176","","1262","                 multi_class='warn', verbose=0, warm_start=False, n_jobs=None,","1263","                 l1_ratio=None):","1279","        self.l1_ratio = l1_ratio","1304","        solver = _check_solver(self.solver, self.penalty, self.dual)","1305","","1309","        if self.penalty == 'elasticnet':","1310","            if (not isinstance(self.l1_ratio, numbers.Number) or","1311","                    self.l1_ratio < 0 or self.l1_ratio > 1):","1312","                        raise ValueError(\"l1_ratio must be between 0 and 1;\"","1313","                                         \" got (l1_ratio=%r)\" % self.l1_ratio)","1314","        elif self.l1_ratio is not None:","1315","            warnings.warn(\"l1_ratio parameter is only used when penalty is \"","1316","                          \"'elasticnet'. Got \"","1317","                          \"(penalty={})\".format(self.penalty))","1398","                      l1_ratio=self.l1_ratio, fit_intercept=self.fit_intercept,","1399","                      tol=self.tol, verbose=self.verbose, solver=solver,","1403","                      penalty=self.penalty, max_squared_sum=max_squared_sum,","1493","    Elastic-Net penalty is only supported by the saga solver.","1495","    For the grid of `Cs` values and `l1_ratios` values, the best","1496","    hyperparameter is selected by the cross-validator `StratifiedKFold`, but","1497","    it can be changed using the `cv` parameter. The 'newton-cg', 'sag',","1498","    'saga' and 'lbfgs' solvers can warm-start the coefficients (see","1499","    :term:`Glossary<warm_start>`).","1505","    Cs : list of floats or int, optional (default=10)","1512","    fit_intercept : bool, optional (default=True)","1516","    cv : int or cross-validation generator, optional (default=None)","1526","    dual : bool, optional (default=False)","1531","    penalty : str, 'l1', 'l2', or 'elasticnet', optional (default='l2')","1533","        'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is","1534","        only supported by the 'saga' solver.","1536","    scoring : string, callable, or None, optional (default=None)","1544","             optional (default='lbfgs')","1567","    tol : float, optional (default=1e-4)","1570","    max_iter : int, optional (default=100)","1573","    class_weight : dict or 'balanced', optional (default=None)","1593","    verbose : int, optional (default=0)","1597","    refit : bool, optional (default=True)","1604","    intercept_scaling : float, optional (default=1)","1617","    multi_class : str, {'ovr', 'multinomial', 'auto'}, optional (default='ovr')","1630","    random_state : int, RandomState instance or None, optional (default=None)","1636","    l1_ratios : list of float or None, optional (default=None)","1637","        The list of Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``.","1638","        Only used if ``penalty='elasticnet'``. A value of 0 is equivalent to","1639","        using ``penalty='l2'``, while 1 is equivalent to using","1640","        ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a combination","1641","        of L1 and L2.","1642","","1657","    Cs_ : array, shape (n_cs)","1661","    l1_ratios_ : array, shape (n_l1_ratios)","1662","        Array of l1_ratios used for cross-validation. If no l1_ratio is used","1663","        (i.e. penalty is not 'elasticnet'), this is set to ``[None]``","1664","","1665","    coefs_paths_ : array, shape (n_folds, n_cs, n_features) or \\","1666","                   (n_folds, n_cs, n_features + 1)","1672","        Each dict value has shape ``(n_folds, n_cs, n_features)`` or","1673","        ``(n_folds, n_cs, n_features + 1)`` depending on whether the","1674","        intercept is fit or not. If ``penalty='elasticnet'``, the shape is","1675","        ``(n_folds, n_cs, n_l1_ratios_, n_features)`` or","1676","        ``(n_folds, n_cs, n_l1_ratios_, n_features + 1)``.","1683","        all classes, since this is the multinomial class. Each dict value","1684","        has shape ``(n_folds, n_cs`` or ``(n_folds, n_cs, n_l1_ratios)`` if","1685","        ``penalty='elasticnet'``.","1693","    l1_ratio_ : array, shape (n_classes,) or (n_classes - 1,)","1694","        Array of l1_ratio that maps to the best scores across every class. If","1695","        refit is set to False, then for each class, the best l1_ratio is the","1696","        average of the l1_ratio's that correspond to the best scores for each","1697","        fold.  `l1_ratio_` is of shape(n_classes,) when the problem is binary.","1698","","1702","        If ``penalty='elasticnet'``, the shape is ``(n_classes, n_folds,","1703","        n_cs, n_l1_ratios)`` or ``(1, n_folds, n_cs, n_l1_ratios)``.","1704","","1729","                 random_state=None, l1_ratios=None):","1746","        self.l1_ratios = l1_ratios","1776","        if self.penalty == 'elasticnet':","1777","            if self.l1_ratios is None or len(self.l1_ratios) == 0 or any(","1778","                    (not isinstance(l1_ratio, numbers.Number) or l1_ratio < 0","1779","                     or l1_ratio > 1) for l1_ratio in self.l1_ratios):","1780","                raise ValueError(\"l1_ratios must be a list of numbers between \"","1781","                                 \"0 and 1; got (l1_ratios=%r)\" %","1782","                                 self.l1_ratios)","1783","            l1_ratios_ = self.l1_ratios","1784","        else:","1785","            if self.l1_ratios is not None:","1786","                warnings.warn(\"l1_ratios parameter is only used when penalty \"","1787","                              \"is 'elasticnet'. Got (penalty={})\".format(","1788","                                  self.penalty))","1789","","1790","            l1_ratios_ = [None]","1860","","1872","                      sample_weight=sample_weight,","1873","                      l1_ratio=l1_ratio","1876","            for train, test in folds","1877","            for l1_ratio in l1_ratios_)","1879","        # _log_reg_scoring_path will output different shapes depending on the","1880","        # multi_class param, so we need to reshape the outputs accordingly.","1881","        # Cs is of shape (n_classes . n_folds . n_l1_ratios, n_Cs) and all the","1882","        # rows are equal, so we just take the first one.","1883","        # After reshaping,","1884","        # - scores is of shape (n_classes, n_folds, n_Cs . n_l1_ratios)","1885","        # - coefs_paths is of shape","1886","        #  (n_classes, n_folds, n_Cs . n_l1_ratios, n_features)","1887","        # - n_iter is of shape","1888","        #  (n_classes, n_folds, n_Cs . n_l1_ratios) or","1889","        #  (1, n_folds, n_Cs . n_l1_ratios)","1890","        coefs_paths, Cs, scores, n_iter_ = zip(*fold_coefs_)","1891","        self.Cs_ = Cs[0]","1893","            coefs_paths = np.reshape(","1894","                coefs_paths,","1895","                (len(folds),  len(l1_ratios_) * len(self.Cs_), n_classes, -1)","1896","            )","1897","            # equiv to coefs_paths = np.moveaxis(coefs_paths, (0, 1, 2, 3),","1898","            #                                                 (1, 2, 0, 3))","1899","            coefs_paths = np.swapaxes(coefs_paths, 0, 1)","1900","            coefs_paths = np.swapaxes(coefs_paths, 0, 2)","1901","            self.n_iter_ = np.reshape(","1902","                n_iter_,","1903","                (1, len(folds), len(self.Cs_) * len(l1_ratios_))","1904","            )","1905","            # repeat same scores across all classes","1906","            scores = np.tile(scores, (n_classes, 1, 1))","1908","            coefs_paths = np.reshape(","1909","                coefs_paths,","1910","                (n_classes, len(folds), len(self.Cs_) * len(l1_ratios_),","1911","                 -1)","1912","            )","1913","            self.n_iter_ = np.reshape(","1914","                n_iter_,","1915","                (n_classes, len(folds), len(self.Cs_) * len(l1_ratios_))","1916","            )","1919","        self.coefs_paths_ = dict(zip(classes, coefs_paths))","1922","        self.l1_ratio_ = list()","1931","            else:","1932","                # For multinomial, all scores are the same across classes","1933","                scores = scores[0]","1934","                # coefs_paths will keep its original shape because","1935","                # logistic_regression_path expects it this way","1938","                # best_index is between 0 and (n_Cs . n_l1_ratios - 1)","1939","                # for example, with n_cs=2 and n_l1_ratios=3","1940","                # the layout of scores is","1941","                # [c1, c2, c1, c2, c1, c2]","1942","                #   l1_1 ,  l1_2 ,  l1_3","1945","                best_index_C = best_index % len(self.Cs_)","1946","                C_ = self.Cs_[best_index_C]","1948","","1949","                best_index_l1 = best_index \/\/ len(self.Cs_)","1950","                l1_ratio_ = l1_ratios_[best_index_l1]","1951","                self.l1_ratio_.append(l1_ratio_)","1952","","1954","                    coef_init = np.mean(coefs_paths[:, :, best_index, :],","1955","                                        axis=1)","1971","                    sample_weight=sample_weight,","1972","                    l1_ratio=l1_ratio_)","1976","                # Take the best scores across every fold and the average of","1977","                # all coefficients corresponding to the best scores.","1979","                if self.multi_class == 'ovr':","1980","                    w = np.mean([coefs_paths[i, best_indices[i], :]","1981","                                 for i in range(len(folds))], axis=0)","1982","                else:","1983","                    w = np.mean([coefs_paths[:, i, best_indices[i], :]","1984","                                 for i in range(len(folds))], axis=0)","1985","","1986","                best_indices_C = best_indices % len(self.Cs_)","1987","                self.C_.append(np.mean(self.Cs_[best_indices_C]))","1988","","1989","                best_indices_l1 = best_indices \/\/ len(self.Cs_)","1990","                self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))","1994","                self.l1_ratio_ = np.tile(self.l1_ratio_, n_classes)","2004","        self.l1_ratio_ = np.asarray(self.l1_ratio_)","2005","        self.l1_ratios_ = np.asarray(l1_ratios_)","2006","        # if elasticnet was used, add the l1_ratios dimension to some","2007","        # attributes","2008","        if self.l1_ratios is not None:","2009","            for cls, coefs_path in self.coefs_paths_.items():","2010","                self.coefs_paths_[cls] = coefs_path.reshape(","2011","                    (len(folds), self.Cs_.size, self.l1_ratios_.size, -1))","2012","            for cls, score in self.scores_.items():","2013","                self.scores_[cls] = score.reshape(","2014","                    (len(folds), self.Cs_.size, self.l1_ratios_.size))","2015","            self.n_iter_ = self.n_iter_.reshape(","2016","                (-1, len(folds), self.Cs_.size, self.l1_ratios_.size))","2017",""],"delete":["439","    all_penalties = ['l1', 'l2']","476","","483","                             max_squared_sum=None, sample_weight=None):","552","    penalty : str, 'l1' or 'l2'","554","        'sag' and 'lbfgs' solvers support only l2 penalties.","784","            else:","818","                          max_squared_sum=None, sample_weight=None):","880","    penalty : str, 'l1' or 'l2'","882","        'sag' and 'lbfgs' solvers support only l2 penalties.","952","        X_train, y_train, Cs=Cs, fit_intercept=fit_intercept,","953","        solver=solver, max_iter=max_iter, class_weight=class_weight,","954","        pos_class=pos_class, multi_class=multi_class,","955","        tol=tol, verbose=verbose, dual=dual, penalty=penalty,","956","        intercept_scaling=intercept_scaling, random_state=random_state,","957","        check_input=False, max_squared_sum=max_squared_sum,","958","        sample_weight=sample_weight)","1005","    'sag' and 'newton-cg' solvers.)","1008","    'liblinear' library, 'newton-cg', 'sag' and 'lbfgs' solvers. It can handle","1009","    both dense and sparse input. Use C-ordered arrays or CSR matrices","1015","    regularization, with a dual formulation only for the L2 penalty.","1021","    penalty : str, 'l1' or 'l2', default: 'l2'","1023","        'sag' and 'lbfgs' solvers support only l2 penalties.","1028","    dual : bool, default: False","1033","    tol : float, default: 1e-4","1036","    C : float, default: 1.0","1041","    fit_intercept : bool, default: True","1045","    intercept_scaling : float, default 1.","1058","    class_weight : dict or 'balanced', default: None","1072","    random_state : int, RandomState instance or None, optional, default: None","1081","             default: 'liblinear'.","1104","    max_iter : int, default: 100","1108","    multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'","1121","    verbose : int, default: 0","1125","    warm_start : bool, default: False","1226","                 multi_class='warn', verbose=0, warm_start=False, n_jobs=None):","1276","        solver = _check_solver(self.solver, self.penalty, self.dual)","1277","","1351","                      fit_intercept=self.fit_intercept, tol=self.tol,","1352","                      verbose=self.verbose, solver=solver,","1356","                      penalty=self.penalty,","1357","                      max_squared_sum=max_squared_sum,","1448","    For the grid of Cs values (that are set by default to be ten values in","1449","    a logarithmic scale between 1e-4 and 1e4), the best hyperparameter is","1450","    selected by the cross-validator StratifiedKFold, but it can be changed","1451","    using the cv parameter. In the case of newton-cg and lbfgs solvers,","1452","    we warm start along the path i.e guess the initial coefficients of the","1453","    present fit to be the coefficients got after convergence in the previous","1454","    fit, so it is supposed to be faster for high-dimensional dense data.","1455","","1456","    For a multiclass problem, the hyperparameters for each class are computed","1457","    using the best scores got by doing a one-vs-rest in parallel across all","1458","    folds and classes. Hence this is not the true multinomial loss.","1464","    Cs : list of floats | int","1471","    fit_intercept : bool, default: True","1475","    cv : integer or cross-validation generator, default: None","1485","    dual : bool","1490","    penalty : str, 'l1' or 'l2'","1492","        'sag' and 'lbfgs' solvers support only l2 penalties.","1494","    scoring : string, callable, or None","1502","             default: 'lbfgs'.","1525","    tol : float, optional","1528","    max_iter : int, optional","1531","    class_weight : dict or 'balanced', optional","1551","    verbose : int","1555","    refit : bool","1562","    intercept_scaling : float, default 1.","1575","    multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'","1588","    random_state : int, RandomState instance or None, optional, default None","1608","    Cs_ : array","1612","    coefs_paths_ : array, shape ``(n_folds, len(Cs_), n_features)`` or \\","1613","                   ``(n_folds, len(Cs_), n_features + 1)``","1619","        Each dict value has shape ``(n_folds, len(Cs_), n_features)`` or","1620","        ``(n_folds, len(Cs_), n_features + 1)`` depending on whether the","1621","        intercept is fit or not.","1628","        all classes, since this is the multinomial class.","1629","        Each dict value has shape (n_folds, len(Cs))","1664","                 random_state=None):","1790","                      sample_weight=sample_weight","1793","            for train, test in folds)","1796","            multi_coefs_paths, Cs, multi_scores, n_iter_ = zip(*fold_coefs_)","1797","            multi_coefs_paths = np.asarray(multi_coefs_paths)","1798","            multi_scores = np.asarray(multi_scores)","1799","","1800","            # This is just to maintain API similarity between the ovr and","1801","            # multinomial option.","1802","            # Coefs_paths in now n_folds X len(Cs) X n_classes X n_features","1803","            # we need it to be n_classes X len(Cs) X n_folds X n_features","1804","            # to be similar to \"ovr\".","1805","            coefs_paths = np.rollaxis(multi_coefs_paths, 2, 0)","1806","","1807","            # Multinomial has a true score across all labels. Hence the","1808","            # shape is n_folds X len(Cs). We need to repeat this score","1809","            # across all labels for API similarity.","1810","            scores = np.tile(multi_scores, (n_classes, 1, 1))","1811","            self.Cs_ = Cs[0]","1812","            self.n_iter_ = np.reshape(n_iter_, (1, len(folds),","1813","                                                len(self.Cs_)))","1814","","1816","            coefs_paths, Cs, scores, n_iter_ = zip(*fold_coefs_)","1817","            self.Cs_ = Cs[0]","1818","            coefs_paths = np.reshape(coefs_paths, (n_classes, len(folds),","1819","                                                   len(self.Cs_), -1))","1820","            self.n_iter_ = np.reshape(n_iter_, (n_classes, len(folds),","1821","                                                len(self.Cs_)))","1822","","1823","        self.coefs_paths_ = dict(zip(classes, coefs_paths))","1830","","1831","        # hack to iterate only once for multinomial case.","1832","        if multi_class == 'multinomial':","1833","            scores = multi_scores","1834","            coefs_paths = multi_coefs_paths","1835","","1840","                # The scores_ \/ coefs_paths_ dict have unencoded class","1841","                # labels as their keys","1848","                C_ = self.Cs_[best_index]","1851","                    coef_init = np.mean(coefs_paths[:, best_index, :, :],","1852","                                        axis=0)","1868","                    sample_weight=sample_weight)","1872","                # Take the best scores across every fold and the average of all","1873","                # coefficients corresponding to the best scores.","1875","                w = np.mean([coefs_paths[i][best_indices[i]]","1876","                             for i in range(len(folds))], axis=0)","1877","                self.C_.append(np.mean(self.Cs_[best_indices]))"]}],"sklearn\/linear_model\/sag_fast.pyx":[{"add":["610","                    last_update_ind = feature_hist[feature_ind]"],"delete":["570","     ","611","                    last_update_ind = feature_hist[feature_ind] - 1"]}],"sklearn\/linear_model\/sag.py":[{"add":["219","        fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100,"],"delete":["219","        fit_intercept=True, intercept_scaling=1, max_iter=100,"]}],"examples\/linear_model\/plot_logistic_l1_l2_sparsity.py":[{"add":["6","L1, L2 and Elastic-Net penalty are used for different values of C. We can see","7","that large values of C give more freedom to the model.  Conversely, smaller","8","values of C constrain the model more. In the L1 penalty case, this leads to","9","sparser solutions. As expected, the Elastic-Net penalty sparsity is between","10","that of L1 and L2.","38","l1_ratio = 0.5  # L1 weight in the Elastic-Net regularization","39","","40","fig, axes = plt.subplots(3, 3)","43","for i, (C, axes_row) in enumerate(zip((1, 0.1, 0.01), axes)):","47","    clf_en_LR = LogisticRegression(C=C, penalty='elasticnet', solver='saga',","48","                                   l1_ratio=l1_ratio, tol=0.01)","51","    clf_en_LR.fit(X, y)","55","    coef_en_LR = clf_en_LR.coef_.ravel()","62","    sparsity_en_LR = np.mean(coef_en_LR == 0) * 100","65","    print(\"{:<40} {:.2f}%\".format(\"Sparsity with L1 penalty:\", sparsity_l1_LR))","66","    print(\"{:<40} {:.2f}%\".format(\"Sparsity with Elastic-Net penalty:\",","67","                                  sparsity_en_LR))","68","    print(\"{:<40} {:.2f}%\".format(\"Sparsity with L2 penalty:\", sparsity_l2_LR))","69","    print(\"{:<40} {:.2f}\".format(\"Score with L1 penalty:\",","70","                                 clf_l1_LR.score(X, y)))","71","    print(\"{:<40} {:.2f}\".format(\"Score with Elastic-Net penalty:\",","72","                                 clf_en_LR.score(X, y)))","73","    print(\"{:<40} {:.2f}\".format(\"Score with L2 penalty:\",","74","                                 clf_l2_LR.score(X, y)))","77","        axes_row[0].set_title(\"L1 penalty\")","78","        axes_row[1].set_title(\"Elastic-Net\\nl1_ratio = %s\" % l1_ratio)","79","        axes_row[2].set_title(\"L2 penalty\")","81","    for ax, coefs in zip(axes_row, [coef_l1_LR, coef_en_LR, coef_l2_LR]):","82","        ax.imshow(np.abs(coefs.reshape(8, 8)), interpolation='nearest',","83","                  cmap='binary', vmax=1, vmin=0)","84","        ax.set_xticks(())","85","        ax.set_yticks(())","87","    axes_row[0].set_ylabel('C = %s' % C)"],"delete":["6","L1 and L2 penalty are used for different values of C. We can see that large","7","values of C give more freedom to the model.  Conversely, smaller values of C","8","constrain the model more. In the L1 penalty case, this leads to sparser","9","solutions.","39","for i, C in enumerate((1, 0.1, 0.01)):","56","    print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity_l1_LR)","57","    print(\"score with L1 penalty: %.4f\" % clf_l1_LR.score(X, y))","58","    print(\"Sparsity with L2 penalty: %.2f%%\" % sparsity_l2_LR)","59","    print(\"score with L2 penalty: %.4f\" % clf_l2_LR.score(X, y))","61","    l1_plot = plt.subplot(3, 2, 2 * i + 1)","62","    l2_plot = plt.subplot(3, 2, 2 * (i + 1))","64","        l1_plot.set_title(\"L1 penalty\")","65","        l2_plot.set_title(\"L2 penalty\")","67","    l1_plot.imshow(np.abs(coef_l1_LR.reshape(8, 8)), interpolation='nearest',","68","                   cmap='binary', vmax=1, vmin=0)","69","    l2_plot.imshow(np.abs(coef_l2_LR.reshape(8, 8)), interpolation='nearest',","70","                   cmap='binary', vmax=1, vmin=0)","71","    plt.text(-8, 3, \"C = %.2f\" % C)","73","    l1_plot.set_xticks(())","74","    l1_plot.set_yticks(())","75","    l2_plot.set_xticks(())","76","    l2_plot.set_yticks(())"]}]}},"4e8194909ce0f8879ebe8073ae5d37e3fdc8a00f":{"changes":{"sklearn\/utils\/fixes.py":"MODIFY","sklearn\/utils\/tests\/test_fixes.py":"MODIFY"},"diff":{"sklearn\/utils\/fixes.py":[{"add":["311","# numerical or object values for all numpy versions.","312","if np_version < (1, 13):","315","else:","316","    def _object_dtype_isnan(X):","317","        return X != X"],"delete":["311","# numerical or object values for all nupy versions.","312","","313","_nan_object_array = np.array([np.nan], dtype=object)","314","_nan_object_mask = _nan_object_array != _nan_object_array","315","","316","if np.array_equal(_nan_object_mask, np.array([True])):","317","    def _object_dtype_isnan(X):","318","        return X != X","319","","320","else:"]}],"sklearn\/utils\/tests\/test_fixes.py":[{"add":["19","from sklearn.utils.fixes import _object_dtype_isnan","91","","92","","93","@pytest.mark.parametrize(\"dtype, val\", ([object, 1],","94","                                        [object, \"a\"],","95","                                        [float, 1]))","96","def test_object_dtype_isnan(dtype, val):","97","    X = np.array([[val, np.nan],","98","                  [np.nan, val]], dtype=dtype)","99","","100","    expected_mask = np.array([[False, True],","101","                              [True, False]])","102","","103","    mask = _object_dtype_isnan(X)","104","","105","    assert_array_equal(mask, expected_mask)"],"delete":[]}]}},"03c3af5bdec29903567fa3d63f2e6776a2b3041b":{"changes":{"sklearn\/datasets\/tests\/data\/openml\/1119\/api-v1-json-data-1119.json.gz":"ADD","sklearn\/datasets\/tests\/data\/openml\/1119\/api-v1-json-data-list-data_name-adult-census-limit-2-data_version-1.json.gz":"ADD","doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/datasets\/tests\/data\/openml\/1119\/api-v1-json-data-features-1119.json.gz":"ADD","sklearn\/datasets\/tests\/test_openml.py":"MODIFY","sklearn\/datasets\/tests\/data\/openml\/1119\/data-v1-download-54002.arff.gz":"ADD","sklearn\/datasets\/tests\/data\/openml\/1119\/api-v1-json-data-list-data_name-adult-census-limit-2-status-active-.json.gz":"ADD","sklearn\/datasets\/openml.py":"MODIFY"},"diff":{"sklearn\/datasets\/tests\/data\/openml\/1119\/api-v1-json-data-1119.json.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/1119\/api-v1-json-data-list-data_name-adult-census-limit-2-data_version-1.json.gz":[{"add":[],"delete":[]}],"doc\/whats_new\/v0.20.rst":[{"add":["42","- |Fix| :func:`datasets.fetch_openml` to correctly handle ignore attributes and","43","  row id attributes. :issue:`12330` by :user:`Jan N. van Rijn <janvanrijn>`.","44",""],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/1119\/api-v1-json-data-features-1119.json.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/test_openml.py":[{"add":["413","def test_fetch_openml_adultcensus(monkeypatch, gzip_response):","414","    # Check because of the numeric row attribute (issue #12329)","415","    data_id = 1119","416","    data_name = 'adult-census'","417","    data_version = 1","418","    target_column = 'class'","419","    # Not all original instances included for space reasons","420","    expected_observations = 10","421","    expected_features = 14","422","    expected_missing = 0","423","    _monkey_patch_webbased_functions(monkeypatch, data_id, gzip_response)","424","    _fetch_dataset_from_openml(data_id, data_name, data_version, target_column,","425","                               expected_observations, expected_features,","426","                               expected_missing,","427","                               np.float64, object, expect_sparse=False,","428","                               compare_default_target=True)","429","","430","","431","@pytest.mark.parametrize('gzip_response', [True, False])"],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/1119\/data-v1-download-54002.arff.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/1119\/api-v1-json-data-list-data_name-adult-census-limit-2-status-active-.json.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/openml.py":[{"add":["371","def _valid_data_column_names(features_list, target_columns):","372","    # logic for determining on which columns can be learned. Note that from the","373","    # OpenML guide follows that columns that have the `is_row_identifier` or","374","    # `is_ignore` flag, these can not be learned on. Also target columns are","375","    # excluded.","376","    valid_data_column_names = []","377","    for feature in features_list:","378","        if (feature['name'] not in target_columns","379","                and feature['is_ignore'] != 'true'","380","                and feature['is_row_identifier'] != 'true'):","381","            valid_data_column_names.append(feature['name'])","382","    return valid_data_column_names","383","","384","","538","    data_columns = _valid_data_column_names(features_list,","539","                                            target_column)","569","    # nominal attributes is a dict mapping from the attribute name to the","570","    # possible values. Includes also the target column (which will be popped","571","    # off below, before it will be packed in the Bunch object)","573","                          if isinstance(v, list) and","574","                          k in data_columns + target_column}","575",""],"delete":["524","    data_columns = [feature['name'] for feature in features_list","525","                    if (feature['name'] not in target_column and","526","                        feature['is_ignore'] != 'true' and","527","                        feature['is_row_identifier'] != 'true')]","558","                          if isinstance(v, list)}","559","    for feature in features_list:","560","        if 'true' in (feature['is_row_identifier'],","561","                      feature['is_ignore']) and (feature['name'] not in","562","                                                 target_column):","563","            del nominal_attributes[feature['name']]"]}]}},"40441e86f587e8d7066618b328c43d22f8554f96":{"changes":{"\/dev\/null":"DELETE","doc\/modules\/classes.rst":"MODIFY","sklearn\/cluster\/__init__.py":"MODIFY","examples\/cluster\/plot_cluster_comparison.py":"MODIFY","sklearn\/cluster\/tests\/test_optics.py":"MODIFY","sklearn\/cluster\/optics_.py":"MODIFY"},"diff":{"\/dev\/null":[{"add":[],"delete":[]}],"doc\/modules\/classes.rst":[{"add":["121","   cluster.compute_optics_graph","122","   cluster.cluster_optics_dbscan"],"delete":[]}],"sklearn\/cluster\/__init__.py":[{"add":["13","from .optics_ import OPTICS, cluster_optics_dbscan, compute_optics_graph","22","           'cluster_optics_dbscan',","23","           'compute_optics_graph',"],"delete":["13","from .optics_ import OPTICS"]}],"examples\/cluster\/plot_cluster_comparison.py":[{"add":[],"delete":["118","    optics = cluster.OPTICS(min_samples=30, maxima_ratio=.8,","119","                            rejection_ratio=.4)","137","        ('OPTICS', optics),"]}],"sklearn\/cluster\/tests\/test_optics.py":[{"add":["80","    clust = OPTICS(max_eps=5.0 * 0.03,","81","                   cluster_method='dbscan',","82","                   eps=0.3, min_samples=10)","83","    assert_raise_message(ValueError, msg, clust.fit, X)","92","    with pytest.warns(UserWarning, match=msg):","93","        clust = OPTICS(max_eps=5.0 * 0.003, min_samples=10, eps=0.015)","94","        clust.fit(X)","105","    clust = OPTICS(max_eps=1.0, cluster_method='dbscan',","106","                   eps=0.3, min_samples=10)","108","    assert_warns(RuntimeWarning, clust.fit, X)","110","    assert_equal(max(clust.labels_), 2)","123","    op = OPTICS(min_samples=min_samples, cluster_method='dbscan',","124","                eps=eps).fit(X)","129","    contingency = contingency_matrix(db.labels_, op.labels_)","134","    percent_mismatch = np.round((disagree - 1) \/ X.shape[0], 2)","260","def test_wrong_cluster_method():","261","    clust = OPTICS(cluster_method='superfancy')","262","    with pytest.raises(ValueError, match=\"cluster_method should be one of \"):","263","        clust.fit(X)","264","","265","","266","def test_extract_dbscan():","267","    # testing an easy dbscan case. Not including clusters with different","268","    # densities.","269","    rng = np.random.RandomState(0)","270","    n_points_per_cluster = 20","271","    C1 = [-5, -2] + .2 * rng.randn(n_points_per_cluster, 2)","272","    C2 = [4, -1] + .2 * rng.randn(n_points_per_cluster, 2)","273","    C3 = [1, 2] + .2 * rng.randn(n_points_per_cluster, 2)","274","    C4 = [-2, 3] + .2 * rng.randn(n_points_per_cluster, 2)","275","    X = np.vstack((C1, C2, C3, C4))","276","","277","    clust = OPTICS(cluster_method='dbscan', eps=.5).fit(X)","278","    assert_array_equal(np.sort(np.unique(clust.labels_)), [0, 1, 2, 3])","279","","280",""],"delete":["9","from sklearn.cluster.optics_ import _TreeNode, _cluster_tree","10","from sklearn.cluster.optics_ import _find_local_maxima","47","    assert clust.core_sample_indices_.ndim == 1","48","    assert clust.core_sample_indices_.size > 0","49","    assert clust.core_sample_indices_.dtype.kind == 'i'","50","","78","def test_empty_extract():","79","    # Test extract where fit() has not yet been run.","80","    msg = (\"This OPTICS instance is not fitted yet. Call 'fit' with \"","81","           \"appropriate arguments before using this method.\")","82","    clust = OPTICS(max_eps=5.0 * 0.3, min_samples=10)","83","    assert_raise_message(ValueError, msg, clust.extract_dbscan, 0.01)","84","","85","","94","    clust = OPTICS(max_eps=5.0 * 0.03, min_samples=10)","95","    clust2 = clust.fit(X)","96","    assert_raise_message(ValueError, msg, clust2.extract_dbscan, 0.3)","105","    clust = OPTICS(max_eps=5.0 * 0.003, min_samples=10)","106","    assert_raise_message(ValueError, msg, clust.fit, X)","117","    clust = OPTICS(max_eps=1.0, min_samples=10)","118","    clust3 = clust.fit(X)","120","    assert_warns(RuntimeWarning, clust3.extract_dbscan, .3)","122","    assert_equal(max(clust3.extract_dbscan(.3)[1]), 2)","135","    op = OPTICS(min_samples=min_samples).fit(X)","136","    core_optics, labels_optics = op.extract_dbscan(eps)","141","    contingency = contingency_matrix(db.labels_, labels_optics)","146","    # verify core_labels match","147","    assert_array_equal(core_optics, db.core_sample_indices_)","148","","149","    non_core_count = len(labels_optics) - len(core_optics)","150","    percent_mismatch = np.round((disagree - 1) \/ non_core_count, 2)","184","@pytest.mark.parametrize(\"reach, n_child, members\", [","185","    (np.array([np.inf, 0.9, 0.9, 1.0, 0.89, 0.88, 10, .9, .9, .9, 10, 0.9,","186","               0.9, 0.89, 0.88, 10, .9, .9, .9, .9]), 2, np.r_[0:6]),","187","    (np.array([np.inf, 0.9, 0.9, 0.9, 0.89, 0.88, 10, .9, .9, .9, 10, 0.9,","188","               0.9, 0.89, 0.88, 100, .9, .9, .9, .9]), 1, np.r_[0:15])])","189","def test_cluster_sigmin_pruning(reach, n_child, members):","190","    # Tests pruning left and right, insignificant splitpoints, empty nodelists","191","    # Parameters chosen specifically for this task","192","","193","    # Case 1: Three pseudo clusters, 2 of which are too small","194","    # Case 2: Two pseudo clusters, 1 of which are too small","195","    # Normalize","196","    reach = reach \/ np.max(reach[1:])","197","","198","    ordering = np.r_[0:20]","199","    cluster_boundaries = _find_local_maxima(reach, 5)","200","    root = _TreeNode(ordering, 0, 20, None)","201","","202","    # Build cluster tree inplace on root node","203","    _cluster_tree(root, None, cluster_boundaries, reach, ordering,","204","                  5, .75, .7, .4, .3)","205","    assert_equal(root.split_point, cluster_boundaries[0])","206","    assert_equal(n_child, len(root.children))","207","    assert_array_equal(members, root.children[0].points)","208","","209",""]}],"sklearn\/cluster\/optics_.py":[{"add":["7","         Adrin Jalali <adrinjalali@gmail.com>","25","    OPTICS: Ordering Points To Identify the Clustering Structure Closely","26","    related to DBSCAN, finds core sample of high density and expands clusters","27","    from them [1]_. Unlike DBSCAN, keeps cluster hierarchy for a variable","28","    neighborhood radius. Better suited for usage on large datasets than the","29","    current sklearn implementation of DBSCAN.","30","","31","    Clusters are then extracted using a DBSCAN like method [1]_.","88","    cluster_method : string, optional (default='dbscan')","89","        The extraction method used to extract clusters using the calculated","90","        reachability and ordering. Possible values are \"dbscan\".","92","    eps : float, optional (default=0.5)","93","        The maximum distance between two samples for them to be considered","94","        as in the same neighborhood. Used ony when `cluster_method='dbscan'`.","100","        Used only when `extract_method='xi'`.","157","    .. [1] Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel,","158","       and J?rg Sander. \"OPTICS: ordering points to identify the clustering","159","       structure.\" ACM SIGMOD Record 28, no. 2 (1999): 49-60.","161","    .. [2] Schubert, Erich, Michael Gertz.","162","       \"Improving the Cluster Structure Extracted from OPTICS Plots.\" Proc. of","163","       the Conference \"Lernen, Wissen, Daten, Analysen\" (LWDA) (2018): 318-329.","164","","167","    def __init__(self, min_samples=5, max_eps=np.inf, metric='minkowski', p=2,","168","                 metric_params=None, cluster_method='dbscan', eps=0.5,","169","                 min_cluster_size=.005, algorithm='auto', leaf_size=30,","170","                 n_jobs=None):","180","        self.cluster_method = cluster_method","181","        self.eps = eps","218","        if self.min_samples > n_samples:","219","            raise ValueError(\"Number of training samples (n_samples=%d) must \"","220","                             \"be greater than min_samples (min_samples=%d) \"","221","                             \"used for clustering.\" %","222","                             (n_samples, self.min_samples))","224","        if self.cluster_method not in ['dbscan']:","225","            raise ValueError(\"cluster_method should be one of\"","226","                             \" 'dbscan', but is %s\" %","227","                             self.cluster_method)","229","        if self.cluster_method == 'dbscan':","230","            if self.eps > self.max_eps:","231","                raise ValueError('Specify an epsilon smaller than %s. Got %s.'","232","                                 % (self.max_eps, self.eps))","234","            if self.eps * 5.0 > self.max_eps * 1.05:","235","                warnings.warn(","236","                    \"Warning, max_eps (%s) is close to eps (%s): \"","237","                    \"Output may be unstable.\" % (self.max_eps, self.eps),","238","                    RuntimeWarning, stacklevel=2)","239","                # Stability warning is documented in cluster_optics_dbscan","240","                # method...","241","","242","        (self.ordering_, self.core_distances_, self.reachability_,","243","         self.predecessor_) = compute_optics_graph(","244","             X=X, min_samples=self.min_samples, algorithm=self.algorithm,","245","             leaf_size=self.leaf_size, metric=self.metric,","246","             metric_params=self.metric_params, p=self.p, n_jobs=self.n_jobs,","247","             max_eps=self.max_eps)","248","","249","        # Extract clusters from the calculated orders and reachability","250","        if self.cluster_method == 'dbscan':","251","            labels_ = cluster_optics_dbscan(self.reachability_,","252","                                            self.core_distances_,","253","                                            self.ordering_,","254","                                            self.eps)","255","","256","        self.labels_ = labels_","260","# OPTICS helper functions","261","def _compute_core_distances_(X, neighbors, min_samples, working_memory):","262","    \"\"\"Compute the k-th nearest neighbor of each sample","264","    Equivalent to neighbors.kneighbors(X, self.min_samples)[0][:, -1]","265","    but with more memory efficiency.","269","    X : array, shape (n_samples, n_features)","270","        The data.","271","    neighbors : NearestNeighbors instance","272","        The fitted nearest neighbors estimator.","273","    working_memory : int, optional","274","        The sought maximum memory for temporary distance matrix chunks.","275","        When None (default), the value of","276","        ``sklearn.get_config()['working_memory']`` is used.","280","    core_distances : array, shape (n_samples,)","281","        Distance at which each sample becomes a core point.","282","        Points which will never be core have a distance of inf.","283","    \"\"\"","284","    n_samples = len(X)","285","    core_distances = np.empty(n_samples)","286","    core_distances.fill(np.nan)","288","    chunk_n_rows = get_chunk_n_rows(row_bytes=16 * min_samples,","289","                                    max_n_rows=n_samples,","290","                                    working_memory=working_memory)","291","    slices = gen_batches(n_samples, chunk_n_rows)","292","    for sl in slices:","293","        core_distances[sl] = neighbors.kneighbors(","294","            X[sl], min_samples)[0][:, -1]","295","    return core_distances","296","","297","","298","def compute_optics_graph(X, min_samples, max_eps, metric, p, metric_params,","299","                         algorithm, leaf_size, n_jobs):","300","    \"\"\"Computes the OPTICS reachability graph.","301","","302","    Read more in the :ref:`User Guide <optics>`.","303","","304","    Parameters","305","    ----------","306","    X : array, shape (n_samples, n_features)","307","        The data.","308","","309","    min_samples : int (default=5)","310","        The number of samples in a neighborhood for a point to be considered","311","        as a core point.","312","","313","    max_eps : float, optional (default=np.inf)","314","        The maximum distance between two samples for them to be considered","315","        as in the same neighborhood. Default value of \"np.inf\" will identify","316","        clusters across all scales; reducing `max_eps` will result in","317","        shorter run times.","318","","319","    metric : string or callable, optional (default='minkowski')","320","        metric to use for distance computation. Any metric from scikit-learn","321","        or scipy.spatial.distance can be used.","322","","323","        If metric is a callable function, it is called on each","324","        pair of instances (rows) and the resulting value recorded. The callable","325","        should take two arrays as input and return one value indicating the","326","        distance between them. This works for Scipy's metrics, but is less","327","        efficient than passing the metric name as a string.","328","","329","        Distance matrices are not supported.","330","","331","        Valid values for metric are:","332","","333","        - from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',","334","          'manhattan']","335","","336","        - from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',","337","          'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski',","338","          'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao',","339","          'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',","340","          'yule']","341","","342","        See the documentation for scipy.spatial.distance for details on these","343","        metrics.","344","","345","    p : integer, optional (default=2)","346","        Parameter for the Minkowski metric from","347","        :class:`sklearn.metrics.pairwise_distances`. When p = 1, this is","348","        equivalent to using manhattan_distance (l1), and euclidean_distance","349","        (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.","350","","351","    metric_params : dict, optional (default=None)","352","        Additional keyword arguments for the metric function.","353","","354","    algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional","355","        Algorithm used to compute the nearest neighbors:","356","","357","        - 'ball_tree' will use :class:`BallTree`","358","        - 'kd_tree' will use :class:`KDTree`","359","        - 'brute' will use a brute-force search.","360","        - 'auto' will attempt to decide the most appropriate algorithm","361","          based on the values passed to :meth:`fit` method. (default)","362","","363","        Note: fitting on sparse input will override the setting of","364","        this parameter, using brute force.","365","","366","    leaf_size : int, optional (default=30)","367","        Leaf size passed to :class:`BallTree` or :class:`KDTree`. This can","368","        affect the speed of the construction and query, as well as the memory","369","        required to store the tree. The optimal value depends on the","370","        nature of the problem.","371","","372","    n_jobs : int or None, optional (default=None)","373","        The number of parallel jobs to run for neighbors search.","374","        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.","375","        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`","376","        for more details.","377","","378","    Returns","379","    -------","380","    ordering_ : array, shape (n_samples,)","381","        The cluster ordered list of sample indices.","382","","383","    core_distances_ : array, shape (n_samples,)","384","        Distance at which each sample becomes a core point, indexed by object","385","        order. Points which will never be core have a distance of inf. Use","386","        ``clust.core_distances_[clust.ordering_]`` to access in cluster order.","387","","388","    reachability_ : array, shape (n_samples,)","389","        Reachability distances per sample, indexed by object order. Use","390","        ``clust.reachability_[clust.ordering_]`` to access in cluster order.","391","","392","    predecessor_ : array, shape (n_samples,)","393","        Point that a sample was reached from, indexed by object order.","394","        Seed points have a predecessor of -1.","395","","396","    References","397","    ----------","398","    .. [1] Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel,","399","       and J?rg Sander. \"OPTICS: ordering points to identify the clustering","400","       structure.\" ACM SIGMOD Record 28, no. 2 (1999): 49-60.","401","    \"\"\"","402","    n_samples = len(X)","403","    # Start all points as 'unprocessed' ##","404","    reachability_ = np.empty(n_samples)","405","    reachability_.fill(np.inf)","406","    predecessor_ = np.empty(n_samples, dtype=int)","407","    predecessor_.fill(-1)","408","","409","    nbrs = NearestNeighbors(n_neighbors=min_samples,","410","                            algorithm=algorithm,","411","                            leaf_size=leaf_size,","412","                            metric=metric,","413","                            metric_params=metric_params,","414","                            p=p,","415","                            n_jobs=n_jobs)","416","","417","    nbrs.fit(X)","418","    # Here we first do a kNN query for each point, this differs from","419","    # the original OPTICS that only used epsilon range queries.","420","    # TODO: handle working_memory somehow?","421","    core_distances_ = _compute_core_distances_(X=X, neighbors=nbrs,","422","                                               min_samples=min_samples,","423","                                               working_memory=None)","424","    # OPTICS puts an upper limit on these, use inf for undefined.","425","    core_distances_[core_distances_ > max_eps] = np.inf","426","","427","    # Main OPTICS loop. Not parallelizable. The order that entries are","428","    # written to the 'ordering_' list is important!","429","    # Note that this implementation is O(n^2) theoretically, but","430","    # supposedly with very low constant factors.","431","    processed = np.zeros(X.shape[0], dtype=bool)","432","    ordering = np.zeros(X.shape[0], dtype=int)","433","    for ordering_idx in range(X.shape[0]):","434","        # Choose next based on smallest reachability distance","435","        # (And prefer smaller ids on ties, possibly np.inf!)","436","        index = np.where(processed == 0)[0]","437","        point = index[np.argmin(reachability_[index])]","438","","439","        processed[point] = True","440","        ordering[ordering_idx] = point","441","        if core_distances_[point] != np.inf:","442","            _set_reach_dist(core_distances_=core_distances_,","443","                            reachability_=reachability_,","444","                            predecessor_=predecessor_,","445","                            point_index=point,","446","                            processed=processed, X=X, nbrs=nbrs,","447","                            metric=metric, metric_params=metric_params,","448","                            p=p, max_eps=max_eps)","449","    if np.all(np.isinf(reachability_)):","450","        warnings.warn(\"All reachability values are inf. Set a larger\"","451","                      \" max_eps or all data will be considered outliers.\",","452","                      UserWarning)","453","    return ordering, core_distances_, reachability_, predecessor_","454","","455","","456","def _set_reach_dist(core_distances_, reachability_, predecessor_,","457","                    point_index, processed, X, nbrs, metric, metric_params,","458","                    p, max_eps):","459","    P = X[point_index:point_index + 1]","460","    # Assume that radius_neighbors is faster without distances","461","    # and we don't need all distances, nevertheless, this means","462","    # we may be doing some work twice.","463","    indices = nbrs.radius_neighbors(P, radius=max_eps,","464","                                    return_distance=False)[0]","465","","466","    # Getting indices of neighbors that have not been processed","467","    unproc = np.compress((~np.take(processed, indices)).ravel(),","468","                         indices, axis=0)","469","    # Neighbors of current point are already processed.","470","    if not unproc.size:","471","        return","472","","473","    # Only compute distances to unprocessed neighbors:","474","    if metric == 'precomputed':","475","        dists = X[point_index, unproc]","476","    else:","477","        _params = dict() if metric_params is None else metric_params.copy()","478","        if metric == 'minkowski' and 'p' not in _params:","479","            # the same logic as neighbors, p is ignored if explicitly set","480","            # in the dict params","481","            _params['p'] = p","482","        dists = pairwise_distances(P, np.take(X, unproc, axis=0),","483","                                   metric, n_jobs=None,","484","                                   **_params).ravel()","485","","486","    rdists = np.maximum(dists, core_distances_[point_index])","487","    improved = np.where(rdists < np.take(reachability_, unproc))","488","    reachability_[unproc[improved]] = rdists[improved]","489","    predecessor_[unproc[improved]] = point_index","490","","491","","492","def cluster_optics_dbscan(reachability, core_distances, ordering, eps=0.5):","493","    \"\"\"Performs DBSCAN extraction for an arbitrary epsilon.","494","","495","    Extracting the clusters runs in linear time. Note that if the `max_eps`","496","    OPTICS parameter was set to < inf for extracting reachability and ordering","497","    arrays, DBSCAN extractions will be unstable for `eps` values close to","498","    `max_eps`. Setting `eps` < (`max_eps` \/ 5.0) will guarantee extraction","499","    parity with DBSCAN.","500","","501","    Parameters","502","    ----------","503","    reachability : array, shape (n_samples,)","504","        Reachability distances calculated by OPTICS (`reachability_`)","505","","506","    core_distances : array, shape (n_samples,)","507","        Distances at which points become core (`core_distances_`)","508","","509","    ordering : array, shape (n_samples,)","510","        OPTICS ordered point indices (`ordering_`)","511","","512","    eps : float, optional (default=0.5)","513","        DBSCAN `eps` parameter. Must be set to < `max_eps`. Results","514","        will be close to DBSCAN algorithm if `eps` is < (`max_eps` \/ 5)","515","","516","    Returns","517","    -------","521","    \"\"\"","529","    return labels"],"delete":["7","         Amy X. Zhang <axz@mit.edu>","17","from ..utils.validation import check_is_fitted","26","    OPTICS: Ordering Points To Identify the Clustering Structure","27","    Closely related to DBSCAN, finds core sample of high density and expands","28","    clusters from them. Unlike DBSCAN, keeps cluster hierarchy for a variable","29","    neighborhood radius. Better suited for usage on large point datasets than","30","    the current sklearn implementation of DBSCAN.","87","    maxima_ratio : float, optional (default=.75)","88","        The maximum ratio we allow of average height of clusters on the","89","        right and left to the local maxima in question. The higher the","90","        ratio, the more generous the algorithm is to preserving local","91","        minima, and the more cuts the resulting tree will have.","93","    rejection_ratio : float, optional (default=.7)","94","        Adjusts the fitness of the clustering. When the maxima_ratio is","95","        exceeded, determine which of the clusters to the left and right to","96","        reject based on rejection_ratio. Higher values will result in points","97","        being more readily classified as noise; conversely, lower values will","98","        result in more points being clustered.","99","","100","    similarity_threshold : float, optional (default=.4)","101","        Used to check if nodes can be moved up one level, that is, if the","102","        new cluster created is too \"similar\" to its parent, given the","103","        similarity threshold. Similarity can be determined by 1) the size","104","        of the new cluster relative to the size of the parent node or","105","        2) the average of the reachability values of the new cluster","106","        relative to the average of the reachability values of the parent","107","        node. A lower value for the similarity threshold means less levels","108","        in the tree.","109","","110","    significant_min : float, optional (default=.003)","111","        Sets a lower threshold on how small a significant maxima can be.","117","","118","    min_maxima_ratio : float, optional (default=.001)","119","        Used to determine neighborhood size for minimum cluster membership.","120","        Each local maxima should be a largest value in a neighborhood","121","        of the `size min_maxima_ratio * len(X)` from left and right.","149","    core_sample_indices_ : array, shape (n_core_samples,)","150","        Indices of core samples.","151","","181","    Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel, and J?rg Sander.","182","    \"OPTICS: ordering points to identify the clustering structure.\" ACM SIGMOD","183","    Record 28, no. 2 (1999): 49-60.","185","    Schubert, Erich, Michael Gertz.","186","    \"Improving the Cluster Structure Extracted from OPTICS Plots.\" Proc. of","187","    the Conference \"Lernen, Wissen, Daten, Analysen\" (LWDA) (2018): 318-329.","190","    def __init__(self, min_samples=5, max_eps=np.inf, metric='minkowski',","191","                 p=2, metric_params=None, maxima_ratio=.75,","192","                 rejection_ratio=.7, similarity_threshold=0.4,","193","                 significant_min=.003, min_cluster_size=.005,","194","                 min_maxima_ratio=0.001, algorithm='auto',","195","                 leaf_size=30, n_jobs=None):","199","        self.maxima_ratio = maxima_ratio","200","        self.rejection_ratio = rejection_ratio","201","        self.similarity_threshold = similarity_threshold","202","        self.significant_min = significant_min","204","        self.min_maxima_ratio = min_maxima_ratio","235","        if self.min_samples > n_samples:","236","            raise ValueError(\"Number of training samples (n_samples=%d) must \"","237","                             \"be greater than min_samples (min_samples=%d) \"","238","                             \"used for clustering.\" %","239","                             (n_samples, self.min_samples))","240","","252","        # Start all points as 'unprocessed' ##","253","        self.reachability_ = np.empty(n_samples)","254","        self.reachability_.fill(np.inf)","255","        self.predecessor_ = np.empty(n_samples, dtype=int)","256","        self.predecessor_.fill(-1)","257","        # Start all points as noise ##","258","        self.labels_ = np.full(n_samples, -1, dtype=int)","260","        nbrs = NearestNeighbors(n_neighbors=self.min_samples,","261","                                algorithm=self.algorithm,","262","                                leaf_size=self.leaf_size, metric=self.metric,","263","                                metric_params=self.metric_params, p=self.p,","264","                                n_jobs=self.n_jobs)","266","        nbrs.fit(X)","267","        # Here we first do a kNN query for each point, this differs from","268","        # the original OPTICS that only used epsilon range queries.","269","        self.core_distances_ = self._compute_core_distances_(X, nbrs)","270","        # OPTICS puts an upper limit on these, use inf for undefined.","271","        self.core_distances_[self.core_distances_ > self.max_eps] = np.inf","272","        self.ordering_ = self._calculate_optics_order(X, nbrs)","274","        indices_, self.labels_ = _extract_optics(self.ordering_,","275","                                                 self.reachability_,","276","                                                 self.maxima_ratio,","277","                                                 self.rejection_ratio,","278","                                                 self.similarity_threshold,","279","                                                 self.significant_min,","280","                                                 self.min_cluster_size,","281","                                                 self.min_maxima_ratio)","282","        self.core_sample_indices_ = indices_","285","    # OPTICS helper functions","286","    def _compute_core_distances_(self, X, neighbors, working_memory=None):","287","        \"\"\"Compute the k-th nearest neighbor of each sample","289","        Equivalent to neighbors.kneighbors(X, self.min_samples)[0][:, -1]","290","        but with more memory efficiency.","292","        Parameters","293","        ----------","294","        X : array, shape (n_samples, n_features)","295","            The data.","296","        neighbors : NearestNeighbors instance","297","            The fitted nearest neighbors estimator.","298","        working_memory : int, optional","299","            The sought maximum memory for temporary distance matrix chunks.","300","            When None (default), the value of","301","            ``sklearn.get_config()['working_memory']`` is used.","302","","303","        Returns","304","        -------","305","        core_distances : array, shape (n_samples,)","306","            Distance at which each sample becomes a core point.","307","            Points which will never be core have a distance of inf.","308","        \"\"\"","309","        n_samples = len(X)","310","        core_distances = np.empty(n_samples)","311","        core_distances.fill(np.nan)","312","","313","        chunk_n_rows = get_chunk_n_rows(row_bytes=16 * self.min_samples,","314","                                        max_n_rows=n_samples,","315","                                        working_memory=working_memory)","316","        slices = gen_batches(n_samples, chunk_n_rows)","317","        for sl in slices:","318","            core_distances[sl] = neighbors.kneighbors(","319","                X[sl], self.min_samples)[0][:, -1]","320","        return core_distances","321","","322","    def _calculate_optics_order(self, X, nbrs):","323","        # Main OPTICS loop. Not parallelizable. The order that entries are","324","        # written to the 'ordering_' list is important!","325","        # Note that this implementation is O(n^2) theoretically, but","326","        # supposedly with very low constant factors.","327","        processed = np.zeros(X.shape[0], dtype=bool)","328","        ordering = np.zeros(X.shape[0], dtype=int)","329","        for ordering_idx in range(X.shape[0]):","330","            # Choose next based on smallest reachability distance","331","            # (And prefer smaller ids on ties, possibly np.inf!)","332","            index = np.where(processed == 0)[0]","333","            point = index[np.argmin(self.reachability_[index])]","334","","335","            processed[point] = True","336","            ordering[ordering_idx] = point","337","            if self.core_distances_[point] != np.inf:","338","                self._set_reach_dist(point, processed, X, nbrs)","339","        return ordering","340","","341","    def _set_reach_dist(self, point_index, processed, X, nbrs):","342","        P = X[point_index:point_index + 1]","343","        # Assume that radius_neighbors is faster without distances","344","        # and we don't need all distances, nevertheless, this means","345","        # we may be doing some work twice.","346","        indices = nbrs.radius_neighbors(P, radius=self.max_eps,","347","                                        return_distance=False)[0]","348","","349","        # Getting indices of neighbors that have not been processed","350","        unproc = np.compress((~np.take(processed, indices)).ravel(),","351","                             indices, axis=0)","352","        # Neighbors of current point are already processed.","353","        if not unproc.size:","354","            return","355","","356","        # Only compute distances to unprocessed neighbors:","357","        if self.metric == 'precomputed':","358","            dists = X[point_index, unproc]","359","        else:","360","            dists = pairwise_distances(P, np.take(X, unproc, axis=0),","361","                                       self.metric, n_jobs=None).ravel()","362","","363","        rdists = np.maximum(dists, self.core_distances_[point_index])","364","        improved = np.where(rdists < np.take(self.reachability_, unproc))","365","        self.reachability_[unproc[improved]] = rdists[improved]","366","        self.predecessor_[unproc[improved]] = point_index","367","","368","    def extract_dbscan(self, eps):","369","        \"\"\"Performs DBSCAN extraction for an arbitrary epsilon.","370","","371","        Extraction runs in linear time. Note that if the `max_eps` OPTICS","372","        parameter was set to < inf for extracting reachability and ordering","373","        arrays, DBSCAN extractions will be unstable for `eps` values close to","374","        `max_eps`. Setting `eps` < (`max_eps` \/ 5.0) will guarantee","375","        extraction parity with DBSCAN.","376","","377","        Parameters","378","        ----------","379","        eps : float or int, required","380","            DBSCAN `eps` parameter. Must be set to < `max_eps`. Equivalence","381","            with DBSCAN algorithm is achieved if `eps` is < (`max_eps` \/ 5)","382","","383","        Returns","384","        -------","385","        core_sample_indices_ : array, shape (n_core_samples,)","386","            The indices of the core samples.","387","","388","        labels_ : array, shape (n_samples,)","389","            The estimated labels.","390","        \"\"\"","391","        check_is_fitted(self, 'reachability_')","392","","393","        if eps > self.max_eps:","394","            raise ValueError('Specify an epsilon smaller than %s. Got %s.'","395","                             % (self.max_eps, eps))","396","","397","        if eps * 5.0 > (self.max_eps * 1.05):","398","            warnings.warn(","399","                \"Warning, max_eps (%s) is close to eps (%s): \"","400","                \"Output may be unstable.\" % (self.max_eps, eps),","401","                RuntimeWarning, stacklevel=2)","402","        # Stability warning is documented in _extract_dbscan method...","403","","404","        return _extract_dbscan(self.ordering_, self.core_distances_,","405","                               self.reachability_, eps)","406","","407","","408","def _extract_dbscan(ordering, core_distances, reachability, eps):","409","    \"\"\"Performs DBSCAN extraction for an arbitrary epsilon (`eps`).","413","    ordering : array, shape (n_samples,)","414","        OPTICS ordered point indices (`ordering_`)","415","    core_distances : array, shape (n_samples,)","416","        Distances at which points become core (`core_distances_`)","417","    reachability : array, shape (n_samples,)","418","        Reachability distances calculated by OPTICS (`reachability_`)","419","    eps : float or int","420","        DBSCAN `eps` parameter","424","    core_sample_indices_ : array, shape (n_core_samples,)","425","        The indices of the core samples.","429","    \"\"\"","432","    is_core = np.zeros(n_samples, dtype=bool)","439","    is_core[near_core] = True","440","    return np.arange(n_samples)[is_core], labels","441","","442","","443","def _extract_optics(ordering, reachability, maxima_ratio=.75,","444","                    rejection_ratio=.7, similarity_threshold=0.4,","445","                    significant_min=.003, min_cluster_size=.005,","446","                    min_maxima_ratio=0.001):","447","    \"\"\"Performs automatic cluster extraction for variable density data.","448","","449","    Parameters","450","    ----------","451","    ordering : array, shape (n_samples,)","452","        OPTICS ordered point indices (`ordering_`)","453","","454","    reachability : array, shape (n_samples,)","455","        Reachability distances calculated by OPTICS (`reachability_`)","456","","457","    maxima_ratio : float, optional","458","        The maximum ratio we allow of average height of clusters on the","459","        right and left to the local maxima in question. The higher the","460","        ratio, the more generous the algorithm is to preserving local","461","        minima, and the more cuts the resulting tree will have.","462","","463","    rejection_ratio : float, optional","464","        Adjusts the fitness of the clustering. When the maxima_ratio is","465","        exceeded, determine which of the clusters to the left and right to","466","        reject based on rejection_ratio. Higher values will result in points","467","        being more readily classified as noise; conversely, lower values will","468","        result in more points being clustered.","469","","470","    similarity_threshold : float, optional","471","        Used to check if nodes can be moved up one level, that is, if the","472","        new cluster created is too \"similar\" to its parent, given the","473","        similarity threshold. Similarity can be determined by 1) the size","474","        of the new cluster relative to the size of the parent node or","475","        2) the average of the reachability values of the new cluster","476","        relative to the average of the reachability values of the parent","477","        node. A lower value for the similarity threshold means less levels","478","        in the tree.","479","","480","    significant_min : float, optional","481","        Sets a lower threshold on how small a significant maxima can be.","482","","483","    min_cluster_size : int > 1 or float between 0 and 1","484","        Minimum number of samples in an OPTICS cluster, expressed as an","485","        absolute number or a fraction of the number of samples (rounded","486","        to be at least 2).","487","","488","    min_maxima_ratio : float, optional","489","        Used to determine neighborhood size for minimum cluster membership.","490","","491","    Returns","492","    -------","493","    core_sample_indices_ : array, shape (n_core_samples,)","494","        The indices of the core samples.","495","","496","    labels_ : array, shape (n_samples,)","497","        The estimated labels.","498","    \"\"\"","499","","500","    # Extraction wrapper","501","    # according to Ankerst M. et.al. 1999 (p. 5), for a small enough","502","    # generative distance epsilong, there should be more than one INF.","503","    if np.all(np.isinf(reachability)):","504","        raise ValueError(\"All reachability values are inf. Set a larger\"","505","                         \" max_eps.\")","506","    normalization_factor = np.max(reachability[reachability < np.inf])","507","    reachability = reachability \/ normalization_factor","508","    reachability_plot = reachability[ordering].tolist()","509","    root_node = _automatic_cluster(reachability_plot, ordering,","510","                                   maxima_ratio, rejection_ratio,","511","                                   similarity_threshold, significant_min,","512","                                   min_cluster_size, min_maxima_ratio)","513","    leaves = _get_leaves(root_node, [])","514","    # Start cluster id's at 0","515","    clustid = 0","516","    n_samples = len(reachability)","517","    is_core = np.zeros(n_samples, dtype=bool)","518","    labels = np.full(n_samples, -1, dtype=int)","519","    # Start all points as non-core noise","520","    for leaf in leaves:","521","        index = ordering[leaf.start:leaf.end]","522","        labels[index] = clustid","523","        is_core[index] = 1","524","        clustid += 1","525","    return np.arange(n_samples)[is_core], labels","526","","527","","528","def _automatic_cluster(reachability_plot, ordering,","529","                       maxima_ratio, rejection_ratio,","530","                       similarity_threshold, significant_min,","531","                       min_cluster_size, min_maxima_ratio):","532","    \"\"\"Converts reachability plot to cluster tree and returns root node.","533","","534","    Parameters","535","    ----------","536","","537","    reachability_plot : list, required","538","        Reachability distances ordered by OPTICS ordering index.","539","","540","    \"\"\"","541","","542","    min_neighborhood_size = 2","543","    if min_cluster_size <= 1:","544","        min_cluster_size = max(2, min_cluster_size * len(ordering))","545","    neighborhood_size = int(min_maxima_ratio * len(ordering))","546","","547","    # Again, should this check < min_samples, should the parameter be public?","548","    if neighborhood_size < min_neighborhood_size:","549","        neighborhood_size = min_neighborhood_size","550","","551","    local_maxima_points = _find_local_maxima(reachability_plot,","552","                                             neighborhood_size)","553","    root_node = _TreeNode(ordering, 0, len(ordering), None)","554","    _cluster_tree(root_node, None, local_maxima_points,","555","                  reachability_plot, ordering, min_cluster_size,","556","                  maxima_ratio, rejection_ratio,","557","                  similarity_threshold, significant_min)","558","","559","    return root_node","560","","561","","562","class _TreeNode:","563","    # automatic cluster helper classes and functions","564","    def __init__(self, points, start, end, parent_node):","565","        self.points = points","566","        self.start = start","567","        self.end = end","568","        self.parent_node = parent_node","569","        self.children = []","570","        self.split_point = -1","571","","572","","573","def _is_local_maxima(index, reachability_plot, neighborhood_size):","574","    right_idx = slice(index + 1, index + neighborhood_size + 1)","575","    left_idx = slice(max(1, index - neighborhood_size - 1), index)","576","    return (np.all(reachability_plot[index] >= reachability_plot[left_idx]) and","577","            np.all(reachability_plot[index] >= reachability_plot[right_idx]))","578","","579","","580","def _find_local_maxima(reachability_plot, neighborhood_size):","581","    local_maxima_points = {}","582","    # 1st and last points on Reachability Plot are not taken","583","    # as local maxima points","584","    for i in range(1, len(reachability_plot) - 1):","585","        # if the point is a local maxima on the reachability plot with","586","        # regard to neighborhood_size, insert it into priority queue and","587","        # maxima list","588","        if (reachability_plot[i] > reachability_plot[i - 1] and","589","            reachability_plot[i] >= reachability_plot[i + 1] and","590","            _is_local_maxima(i, np.array(reachability_plot),","591","                             neighborhood_size) == 1):","592","            local_maxima_points[i] = reachability_plot[i]","593","","594","    return sorted(local_maxima_points,","595","                  key=local_maxima_points.__getitem__, reverse=True)","596","","597","","598","def _cluster_tree(node, parent_node, local_maxima_points,","599","                  reachability_plot, reachability_ordering,","600","                  min_cluster_size, maxima_ratio, rejection_ratio,","601","                  similarity_threshold, significant_min):","602","    \"\"\"Recursively builds cluster tree to hold hierarchical cluster structure","603","","604","    node is a node or the root of the tree in the first call","605","    parent_node is parent node of N or None if node is root of the tree","606","    local_maxima_points is list of local maxima points sorted in","607","    descending order of reachability","608","    \"\"\"","609","","610","    if len(local_maxima_points) == 0:","611","        return  # parent_node is a leaf","612","","613","    # take largest local maximum as possible separation between clusters","614","    s = local_maxima_points[0]","615","    node.split_point = s","616","    local_maxima_points = local_maxima_points[1:]","617","","618","    # create two new nodes and add to list of nodes","619","    node_1 = _TreeNode(reachability_ordering[node.start:s],","620","                       node.start, s, node)","621","    node_2 = _TreeNode(reachability_ordering[s + 1:node.end],","622","                       s + 1, node.end, node)","623","    local_max_1 = []","624","    local_max_2 = []","625","","626","    for i in local_maxima_points:","627","        if i < s:","628","            local_max_1.append(i)","629","        if i > s:","630","            local_max_2.append(i)","631","","632","    node_list = []","633","    node_list.append((node_1, local_max_1))","634","    node_list.append((node_2, local_max_2))","635","","636","    if reachability_plot[s] < significant_min:","637","        node.split_point = -1","638","        # if split_point is not significant, ignore this split and continue","639","        return","640","","641","    # only check a certain ratio of points in the child","642","    # nodes formed to the left and right of the maxima","643","    # ...should check_ratio be a user settable parameter?","644","    check_ratio = .8","645","    check_value_1 = int(np.round(check_ratio * len(node_1.points)))","646","    check_value_2 = int(np.round(check_ratio * len(node_2.points)))","647","    avg_reach1 = np.mean(reachability_plot[(node_1.end -","648","                                            check_value_1):node_1.end])","649","    avg_reach2 = np.mean(reachability_plot[node_2.start:(node_2.start","650","                                                         + check_value_2)])","651","","652","    if ((avg_reach1 \/ maxima_ratio) > reachability_plot[s] or","653","            (avg_reach2 \/ maxima_ratio) > reachability_plot[s]):","654","","655","        if (avg_reach1 \/ rejection_ratio) < reachability_plot[s]:","656","            # reject node 2","657","            node_list.remove((node_2, local_max_2))","658","        if (avg_reach2 \/ rejection_ratio) < reachability_plot[s]:","659","            # reject node 1","660","            node_list.remove((node_1, local_max_1))","661","        if ((avg_reach1 \/ rejection_ratio) >= reachability_plot[s] and","662","                (avg_reach2 \/ rejection_ratio) >= reachability_plot[s]):","663","            # since split_point is not significant,","664","            # ignore this split and continue (reject both child nodes)","665","            node.split_point = -1","666","            _cluster_tree(node, parent_node, local_maxima_points,","667","                          reachability_plot, reachability_ordering,","668","                          min_cluster_size, maxima_ratio, rejection_ratio,","669","                          similarity_threshold, significant_min)","670","            return","671","","672","    # remove clusters that are too small","673","    if (len(node_1.points) < min_cluster_size and","674","            node_list.count((node_1, local_max_1)) > 0):","675","        # cluster 1 is too small","676","        node_list.remove((node_1, local_max_1))","677","    if (len(node_2.points) < min_cluster_size and","678","            node_list.count((node_2, local_max_2)) > 0):","679","        # cluster 2 is too small","680","        node_list.remove((node_2, local_max_2))","681","    if not node_list:","682","        # parent_node will be a leaf","683","        node.split_point = -1","684","        return","685","","686","    # Check if nodes can be moved up one level - the new cluster created","687","    # is too \"similar\" to its parent, given the similarity threshold.","688","    bypass_node = 0","689","    if parent_node is not None:","690","        if ((node.end - node.start) \/ (parent_node.end - parent_node.start) >","691","                similarity_threshold):","692","","693","            parent_node.children.remove(node)","694","            bypass_node = 1","695","","696","    for nl in node_list:","697","        if bypass_node == 1:","698","            parent_node.children.append(nl[0])","699","            _cluster_tree(nl[0], parent_node, nl[1],","700","                          reachability_plot, reachability_ordering,","701","                          min_cluster_size, maxima_ratio, rejection_ratio,","702","                          similarity_threshold, significant_min)","703","        else:","704","            node.children.append(nl[0])","705","            _cluster_tree(nl[0], node, nl[1], reachability_plot,","706","                          reachability_ordering, min_cluster_size,","707","                          maxima_ratio, rejection_ratio,","708","                          similarity_threshold, significant_min)","709","","710","","711","def _get_leaves(node, arr):","712","    if node is not None:","713","        if node.split_point == -1:","714","            arr.append(node)","715","        for n in node.children:","716","            _get_leaves(n, arr)","717","    return arr"]}]}},"876b14907f96a42e63c3ef576a46755b120c3c01":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/metrics\/pairwise.py":"MODIFY","sklearn\/metrics\/tests\/test_pairwise.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["48",":mod:`sklearn.metrics`","49","......................","50","","51","- |Fix| Fixed a bug in :func:`metrics.pairwise_distances` and","52","  :func:`metrics.pairwise_distances_chunked` where parameters ``V`` of","53","  ``\"seuclidean\"`` and ``VI`` of ``\"mahalanobis\"`` metrics were computed after","54","  the data was split into chunks instead of being pre-computed on whole data.","55","  :issue:`12701` by :user:`Jeremie du Boisberranger <jeremiedbb>`.","56","","57",""],"delete":[]}],"sklearn\/metrics\/pairwise.py":[{"add":["1131","def _precompute_metric_params(X, Y, metric=None, **kwds):","1132","    \"\"\"Precompute data-derived metric parameters if not provided","1133","    \"\"\"","1134","    if metric == \"seuclidean\" and 'V' not in kwds:","1135","        if X is Y:","1136","            V = np.var(X, axis=0, ddof=1)","1137","        else:","1138","            V = np.var(np.vstack([X, Y]), axis=0, ddof=1)","1139","        return {'V': V}","1140","    if metric == \"mahalanobis\" and 'VI' not in kwds:","1141","        if X is Y:","1142","            VI = np.linalg.inv(np.cov(X.T)).T","1143","        else:","1144","            VI = np.linalg.inv(np.cov(np.vstack([X, Y]).T)).T","1145","        return {'VI': VI}","1146","    return {}","1147","","1148","","1284","    # precompute data-derived metric params","1285","    params = _precompute_metric_params(X, Y, metric=metric, **kwds)","1286","    kwds.update(**params)","1287","","1419","        # precompute data-derived metric params","1420","        params = _precompute_metric_params(X, Y, metric=metric, **kwds)","1421","        kwds.update(**params)","1422",""],"delete":[]}],"sklearn\/metrics\/tests\/test_pairwise.py":[{"add":["7","from scipy.spatial.distance import cdist, pdist, squareform","11","from sklearn import config_context","12","","898","","899","","900","@pytest.mark.parametrize(\"n_jobs\", [1, 2])","901","@pytest.mark.parametrize(\"metric\", [\"seuclidean\", \"mahalanobis\"])","902","@pytest.mark.parametrize(\"dist_function\",","903","                         [pairwise_distances, pairwise_distances_chunked])","904","@pytest.mark.parametrize(\"y_is_x\", [True, False], ids=[\"Y is X\", \"Y is not X\"])","905","def test_pairwise_distances_data_derived_params(n_jobs, metric, dist_function,","906","                                                y_is_x):","907","    # check that pairwise_distances give the same result in sequential and","908","    # parallel, when metric has data-derived parameters.","909","    with config_context(working_memory=0.1):  # to have more than 1 chunk","910","        rng = np.random.RandomState(0)","911","        X = rng.random_sample((1000, 10))","912","","913","        if y_is_x:","914","            Y = X","915","            expected_dist_default_params = squareform(pdist(X, metric=metric))","916","            if metric == \"seuclidean\":","917","                params = {'V': np.var(X, axis=0, ddof=1)}","918","            else:","919","                params = {'VI': np.linalg.inv(np.cov(X.T)).T}","920","        else:","921","            Y = rng.random_sample((1000, 10))","922","            expected_dist_default_params = cdist(X, Y, metric=metric)","923","            if metric == \"seuclidean\":","924","                params = {'V': np.var(np.vstack([X, Y]), axis=0, ddof=1)}","925","            else:","926","                params = {'VI': np.linalg.inv(np.cov(np.vstack([X, Y]).T)).T}","927","","928","        expected_dist_explicit_params = cdist(X, Y, metric=metric, **params)","929","        dist = np.vstack(dist_function(X, Y, metric=metric, n_jobs=n_jobs))","930","","931","        assert_allclose(dist, expected_dist_explicit_params)","932","        assert_allclose(dist, expected_dist_default_params)"],"delete":[]}]}},"d25da1be2054170034548b63ce87bd459ed8bee0":{"changes":{"sklearn\/neighbors\/tests\/test_neighbors.py":"MODIFY","examples\/compose\/plot_compare_reduction.py":"MODIFY","sklearn\/tests\/test_site_joblib.py":"MODIFY","sklearn\/utils\/testing.py":"MODIFY","sklearn\/covariance\/graph_lasso_.py":"MODIFY","README.rst":"MODIFY","sklearn\/utils\/_joblib.py":"MODIFY","sklearn\/datasets\/rcv1.py":"MODIFY","sklearn\/multioutput.py":"MODIFY","sklearn\/utils\/tests\/test_utils.py":"MODIFY","doc\/tutorial\/basic\/tutorial.rst":"MODIFY","benchmarks\/bench_saga.py":"MODIFY","sklearn\/ensemble\/base.py":"MODIFY","sklearn\/model_selection\/_search.py":"MODIFY","sklearn\/datasets\/species_distributions.py":"MODIFY","build_tools\/circle\/build_doc.sh":"MODIFY","sklearn\/datasets\/california_housing.py":"MODIFY","sklearn\/datasets\/olivetti_faces.py":"MODIFY","sklearn\/linear_model\/logistic.py":"MODIFY","sklearn\/ensemble\/tests\/test_forest.py":"MODIFY","sklearn\/linear_model\/omp.py":"MODIFY","sklearn\/utils\/__init__.py":"MODIFY","doc\/modules\/model_persistence.rst":"MODIFY","sklearn\/cluster\/mean_shift_.py":"MODIFY","sklearn\/ensemble\/forest.py":"MODIFY","sklearn\/metrics\/tests\/test_score_objects.py":"MODIFY","sklearn\/tests\/test_pipeline.py":"MODIFY","sklearn\/datasets\/covtype.py":"MODIFY","examples\/applications\/wikipedia_principal_eigenvector.py":"MODIFY","sklearn\/metrics\/pairwise.py":"MODIFY","sklearn\/utils\/validation.py":"MODIFY","benchmarks\/bench_mnist.py":"MODIFY","sklearn\/neighbors\/base.py":"MODIFY","sklearn\/pipeline.py":"MODIFY","benchmarks\/bench_tsne_mnist.py":"MODIFY","sklearn\/datasets\/svmlight_format.py":"MODIFY","sklearn\/linear_model\/tests\/test_sgd.py":"MODIFY","sklearn\/multiclass.py":"MODIFY","sklearn\/compose\/_column_transformer.py":"MODIFY","sklearn\/utils\/tests\/test_validation.py":"MODIFY","sklearn\/datasets\/lfw.py":"MODIFY","sklearn\/tests\/test_docstring_parameters.py":"MODIFY","sklearn\/linear_model\/coordinate_descent.py":"MODIFY","sklearn\/decomposition\/online_lda.py":"MODIFY","sklearn\/manifold\/mds.py":"MODIFY","sklearn\/datasets\/kddcup99.py":"MODIFY","benchmarks\/bench_plot_nmf.py":"MODIFY","examples\/cluster\/plot_feature_agglomeration_vs_univariate_selection.py":"MODIFY","sklearn\/neighbors\/tests\/test_kde.py":"MODIFY","sklearn\/utils\/tests\/test_estimator_checks.py":"MODIFY","benchmarks\/bench_covertype.py":"MODIFY","sklearn\/ensemble\/partial_dependence.py":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY","doc\/modules\/classes.rst":"MODIFY","sklearn\/feature_selection\/rfe.py":"MODIFY","sklearn\/linear_model\/theil_sen.py":"MODIFY","sklearn\/datasets\/twenty_newsgroups.py":"MODIFY","benchmarks\/bench_rcv1_logreg_convergence.py":"MODIFY","sklearn\/utils\/estimator_checks.py":"MODIFY","sklearn\/tests\/test_multioutput.py":"MODIFY","sklearn\/linear_model\/base.py":"MODIFY","sklearn\/ensemble\/bagging.py":"MODIFY","sklearn\/ensemble\/tests\/test_bagging.py":"MODIFY","sklearn\/linear_model\/stochastic_gradient.py":"MODIFY","sklearn\/model_selection\/_validation.py":"MODIFY","sklearn\/decomposition\/dict_learning.py":"MODIFY","sklearn\/ensemble\/voting_classifier.py":"MODIFY","sklearn\/cluster\/k_means_.py":"MODIFY","sklearn\/linear_model\/least_angle.py":"MODIFY"},"diff":{"sklearn\/neighbors\/tests\/test_neighbors.py":[{"add":["29","from sklearn.utils._joblib import joblib","30","from sklearn.utils._joblib import parallel_backend","51","JOBLIB_BACKENDS = list(joblib.parallel.BACKENDS.keys())","1325","@pytest.mark.parametrize('backend', JOBLIB_BACKENDS)"],"delete":["29","from sklearn.externals.joblib import parallel_backend","1323","@pytest.mark.parametrize('backend', ['loky', 'multiprocessing', 'threading'])"]}],"examples\/compose\/plot_compare_reduction.py":[{"add":["107","from joblib import Memory"],"delete":["107","from sklearn.utils import Memory"]}],"sklearn\/tests\/test_site_joblib.py":[{"add":["4","from sklearn.utils._joblib import Parallel, delayed, Memory, parallel_backend"],"delete":["4","from sklearn.utils import Parallel, delayed, Memory, parallel_backend"]}],"sklearn\/utils\/testing.py":[{"add":["46","from sklearn.utils._joblib import joblib"],"delete":["46","from sklearn.externals import joblib"]}],"sklearn\/covariance\/graph_lasso_.py":[{"add":["25","from ..utils._joblib import Parallel, delayed"],"delete":["25","from ..utils import Parallel, delayed"]}],"README.rst":[{"add":["60","require scikit-image >= 0.11.3, a few examples require pandas >= 0.17.1","61","and a few example require joblib >= 0.11."],"delete":["60","require scikit-image >= 0.11.3 and a few examples require pandas >= 0.17.1."]}],"sklearn\/utils\/_joblib.py":[{"add":["12","        import joblib","14","        from joblib import dump, load","15","        from joblib import __version__","16","        from joblib import effective_n_jobs","17","        from joblib import hash","18","        from joblib import cpu_count, Parallel, Memory, delayed","19","        from joblib import parallel_backend, register_parallel_backend","21","    from ..externals import joblib","22","    from ..externals.joblib import logger","23","    from ..externals.joblib import dump, load","24","    from ..externals.joblib import __version__","25","    from ..externals.joblib import effective_n_jobs","26","    from ..externals.joblib import hash","27","    from ..externals.joblib import cpu_count, Parallel, Memory, delayed","28","    from ..externals.joblib import parallel_backend, register_parallel_backend","29","","30","","31","__all__ = [\"parallel_backend\", \"register_parallel_backend\", \"cpu_count\",","32","           \"Parallel\", \"Memory\", \"delayed\", \"effective_n_jobs\", \"hash\",","33","           \"logger\", \"dump\", \"load\", \"joblib\", \"__version__\"]"],"delete":["12","        from joblib import __all__","13","        from joblib import *  # noqa","14","        from joblib import __version__","17","    from ..externals.joblib import __all__   # noqa","18","    from ..externals.joblib import *  # noqa","19","    from ..externals.joblib import __version__  # noqa","20","    from ..externals.joblib import logger  # noqa"]}],"sklearn\/datasets\/rcv1.py":[{"add":["24","from ..utils import _joblib","184","        _joblib.dump(X, samples_path, compress=9)","185","        _joblib.dump(sample_id, sample_id_path, compress=9)","192","        X = _joblib.load(samples_path)","193","        sample_id = _joblib.load(sample_id_path)","243","        _joblib.dump(y, sample_topics_path, compress=9)","244","        _joblib.dump(categories, topics_path, compress=9)","246","        y = _joblib.load(sample_topics_path)","247","        categories = _joblib.load(topics_path)"],"delete":["24","from ..externals import joblib","184","        joblib.dump(X, samples_path, compress=9)","185","        joblib.dump(sample_id, sample_id_path, compress=9)","192","        X = joblib.load(samples_path)","193","        sample_id = joblib.load(sample_id_path)","243","        joblib.dump(y, sample_topics_path, compress=9)","244","        joblib.dump(categories, topics_path, compress=9)","246","        y = joblib.load(sample_topics_path)","247","        categories = joblib.load(topics_path)"]}],"sklearn\/multioutput.py":[{"add":["27","from .utils._joblib import Parallel, delayed"],"delete":["27","from .utils import Parallel, delayed"]}],"sklearn\/utils\/tests\/test_utils.py":[{"add":["277","","278","","279","def dummy_func():","280","    pass","281","","282","","283","def test_deprecation_joblib_api(tmpdir):","284","    def check_warning(*args, **kw):","285","        return assert_warns_message(","286","            DeprecationWarning, \"deprecated in version 0.20.1\", *args, **kw)","287","","288","    # Ensure that the joblib API is deprecated in sklearn.util","289","    from sklearn.utils import Parallel, Memory, delayed","290","    from sklearn.utils import cpu_count, hash, effective_n_jobs","291","    check_warning(Memory, str(tmpdir))","292","    check_warning(hash, 1)","293","    check_warning(Parallel)","294","    check_warning(cpu_count)","295","    check_warning(effective_n_jobs, 1)","296","    check_warning(delayed, dummy_func)","297","","298","    # Only parallel_backend and register_parallel_backend are not deprecated in","299","    # sklearn.utils","300","    from sklearn.utils import parallel_backend, register_parallel_backend","301","    assert_no_warnings(parallel_backend, 'loky', None)","302","    assert_no_warnings(register_parallel_backend, 'failing', None)","303","","304","    # Ensure that the deprecation have no side effect in sklearn.utils._joblib","305","    from sklearn.utils._joblib import Parallel, Memory, delayed","306","    from sklearn.utils._joblib import cpu_count, hash, effective_n_jobs","307","    from sklearn.utils._joblib import parallel_backend","308","    from sklearn.utils._joblib import register_parallel_backend","309","    assert_no_warnings(Memory, str(tmpdir))","310","    assert_no_warnings(hash, 1)","311","    assert_no_warnings(Parallel)","312","    assert_no_warnings(cpu_count)","313","    assert_no_warnings(effective_n_jobs, 1)","314","    assert_no_warnings(delayed, dummy_func)","315","    assert_no_warnings(parallel_backend, 'loky', None)","316","    assert_no_warnings(register_parallel_backend, 'failing', None)","317","","318","    from sklearn.utils._joblib import joblib","319","    del joblib.parallel.BACKENDS['failing']"],"delete":[]}],"doc\/tutorial\/basic\/tutorial.rst":[{"add":["240","  >>> from joblib import dump, load","241","  >>> dump(clf, 'filename.joblib') # doctest: +SKIP","246","  >>> clf = load('filename.joblib') # doctest:+SKIP"],"delete":["240","  >>> from sklearn.externals import joblib","241","  >>> joblib.dump(clf, 'filename.joblib') # doctest: +SKIP","246","  >>> clf = joblib.load('filename.joblib') # doctest:+SKIP"]}],"benchmarks\/bench_saga.py":[{"add":["9","from joblib import delayed, Parallel, Memory"],"delete":["14","from sklearn.utils import delayed, Parallel, Memory"]}],"sklearn\/ensemble\/base.py":[{"add":["14","from ..utils._joblib import effective_n_jobs"],"delete":["15","from ..externals.joblib import effective_n_jobs"]}],"sklearn\/model_selection\/_search.py":[{"add":["31","from ..utils._joblib import Parallel, delayed"],"delete":["31","from ..utils import Parallel, delayed"]}],"sklearn\/datasets\/species_distributions.py":[{"add":["53","from sklearn.utils import _joblib","267","        _joblib.dump(bunch, archive_path, compress=9)","269","        bunch = _joblib.load(archive_path)"],"delete":["53","from sklearn.externals import joblib","267","        joblib.dump(bunch, archive_path, compress=9)","269","        bunch = joblib.load(archive_path)"]}],"build_tools\/circle\/build_doc.sh":[{"add":["122","  scikit-image=\"${SCIKIT_IMAGE_VERSION:-*}\" pandas=\"${PANDAS_VERSION:-*}\" \\","123","  joblib"],"delete":["122","  scikit-image=\"${SCIKIT_IMAGE_VERSION:-*}\" pandas=\"${PANDAS_VERSION:-*}\""]}],"sklearn\/datasets\/california_housing.py":[{"add":["35","from ..utils import _joblib","126","            _joblib.dump(cal_housing, filepath, compress=6)","130","        cal_housing = _joblib.load(filepath)"],"delete":["35","from ..externals import joblib","126","            joblib.dump(cal_housing, filepath, compress=6)","130","        cal_housing = joblib.load(filepath)"]}],"sklearn\/datasets\/olivetti_faces.py":[{"add":["25","from ..utils import _joblib","106","        _joblib.dump(faces, filepath, compress=6)","109","        faces = _joblib.load(filepath)"],"delete":["26","from ..externals import joblib","106","        joblib.dump(faces, filepath, compress=6)","109","        faces = joblib.load(filepath)"]}],"sklearn\/linear_model\/logistic.py":[{"add":["34","from ..utils._joblib import Parallel, delayed, effective_n_jobs"],"delete":["34","from ..utils import Parallel, delayed, effective_n_jobs"]}],"sklearn\/ensemble\/tests\/test_forest.py":[{"add":["24","from sklearn.utils._joblib import joblib","25","from sklearn.utils._joblib import parallel_backend","26","from sklearn.utils._joblib import register_parallel_backend","27","from sklearn.utils._joblib import __version__ as __joblib_version__","88","# Get the default backend in joblib to test parallelism and interaction with","89","# different backends","90","DEFAULT_JOBLIB_BACKEND = joblib.parallel.get_active_backend()[0].__class__","91","","452","","750","    est = ForestEstimator(min_samples_split=0.5, n_estimators=1,","751","                          random_state=0)","1280","class MyBackend(DEFAULT_JOBLIB_BACKEND):","1293","@pytest.mark.skipif(__joblib_version__ < LooseVersion('0.12'),"],"delete":["24","from sklearn.utils import _joblib","25","from sklearn.utils import parallel_backend","26","from sklearn.utils import register_parallel_backend","27","from sklearn.externals.joblib.parallel import LokyBackend","745","    est = ForestEstimator(min_samples_split=0.5, n_estimators=1, random_state=0)","1274","class MyBackend(LokyBackend):","1287","@pytest.mark.skipif(_joblib.__version__ < LooseVersion('0.12'),"]}],"sklearn\/linear_model\/omp.py":[{"add":["18","from ..utils._joblib import Parallel, delayed"],"delete":["18","from ..utils import Parallel, delayed"]}],"sklearn\/utils\/__init__.py":[{"add":["7","import warnings","12","from .class_weight import compute_class_weight, compute_sample_weight","13","from . import _joblib","14","from ..exceptions import DataConversionWarning","15","from .fixes import _Sequence as Sequence","16","from .deprecation import deprecated","24","","25","# Do not deprecate parallel_backend and register_parallel_backend as they are","26","# needed to tune `scikit-learn` behavior and have different effect if called","27","# from the vendored version or or the site-package version. The other are","28","# utilities that are independent of scikit-learn so they are not part of","29","# scikit-learn public API.","30","parallel_backend = _joblib.parallel_backend","31","register_parallel_backend = _joblib.register_parallel_backend","32","","33","# deprecate the joblib API in sklearn in favor of using directly joblib","34","msg = (\"deprecated in version 0.20.1 to be removed in version 0.23. \"","35","       \"Please import this functionality directly from joblib, which can \"","36","       \"be installed with: pip install joblib.\")","37","deprecate = deprecated(msg)","38","","39","delayed = deprecate(_joblib.delayed)","40","cpu_count = deprecate(_joblib.cpu_count)","41","hash = deprecate(_joblib.hash)","42","effective_n_jobs = deprecate(_joblib.effective_n_jobs)","43","","44","","45","# for classes, deprecated will change the object in _joblib module so we need","46","# to subclass them.","47","@deprecate","48","class Memory(_joblib.Memory):","49","    pass","50","","51","","52","@deprecate","53","class Parallel(_joblib.Parallel):","54","    pass","55","","56",""],"delete":["9","import warnings","17","from .class_weight import compute_class_weight, compute_sample_weight","18","from ._joblib import cpu_count, Parallel, Memory, delayed, hash","19","from ._joblib import parallel_backend, register_parallel_backend","20","from ._joblib import effective_n_jobs","21","from ..exceptions import DataConversionWarning","22","from ..utils.fixes import _Sequence as Sequence","23","from .deprecation import deprecated"]}],"doc\/modules\/model_persistence.rst":[{"add":["37","In the specific case of scikit-learn, it may be better to use joblib's","38","replacement of pickle (``dump`` & ``load``), which is more efficient on","39","objects that carry large numpy arrays internally as is often the case for","40","fitted scikit-learn estimators, but can only pickle to the disk and not to a","41","string::","43","  >>> from joblib import dump, load","44","  >>> dump(clf, 'filename.joblib') # doctest: +SKIP","49","  >>> clf = load('filename.joblib') # doctest:+SKIP","53","   ``dump`` and ``load`` functions also accept file-like object","55","   available `here <https:\/\/joblib.readthedocs.io\/en\/latest\/persistence.html>`_."],"delete":["37","In the specific case of scikit-learn, it may be better to use","38","joblib's replacement of pickle (``joblib.dump`` & ``joblib.load``),","39","which is more efficient on objects that carry large numpy arrays internally as","40","is often the case for fitted scikit-learn estimators, but can only pickle to the","41","disk and not to a string::","43","  >>> from sklearn.externals import joblib","44","  >>> joblib.dump(clf, 'filename.joblib') # doctest: +SKIP","49","  >>> clf = joblib.load('filename.joblib') # doctest:+SKIP","53","   ``joblib.dump`` and ``joblib.load`` functions also accept file-like object","55","   available `here <https:\/\/pythonhosted.org\/joblib\/persistence.html>`_."]}],"sklearn\/cluster\/mean_shift_.py":[{"add":["26","from ..utils._joblib import Parallel","27","from ..utils._joblib import delayed"],"delete":["26","from ..utils import Parallel","27","from ..utils import delayed"]}],"sklearn\/ensemble\/forest.py":[{"add":["52","from ..utils._joblib import Parallel, delayed"],"delete":["52","from ..utils import Parallel, delayed"]}],"sklearn\/metrics\/tests\/test_score_objects.py":[{"add":["41","from sklearn.utils import _joblib","100","    _joblib.dump((X, y, y_ml), filename)","101","    X_mm, y_mm, y_ml_mm = _joblib.load(filename, mmap_mode='r')"],"delete":["41","from sklearn.externals import joblib","100","    joblib.dump((X, y, y_ml), filename)","101","    X_mm, y_mm, y_ml_mm = joblib.load(filename, mmap_mode='r')"]}],"sklearn\/tests\/test_pipeline.py":[{"add":["35","from sklearn.utils._joblib import Memory","926","                        \" have the same interface as joblib.Memory.\"","948","                        \" have the same interface as joblib.Memory.\""],"delete":["35","from sklearn.utils import Memory","926","                        \" have the same interface as \"","927","                        \"sklearn.utils.Memory.\"","949","                        \" have the same interface as \"","950","                        \"sklearn.utils.Memory.\""]}],"sklearn\/datasets\/covtype.py":[{"add":["29","from ..utils import _joblib","120","        _joblib.dump(X, samples_path, compress=9)","121","        _joblib.dump(y, targets_path, compress=9)","128","        X = _joblib.load(samples_path)","129","        y = _joblib.load(targets_path)"],"delete":["29","from ..externals import joblib","120","        joblib.dump(X, samples_path, compress=9)","121","        joblib.dump(y, targets_path, compress=9)","128","        X = joblib.load(samples_path)","129","        y = joblib.load(targets_path)"]}],"examples\/applications\/wikipedia_principal_eigenvector.py":[{"add":["46","from joblib import Memory","47",""],"delete":["47","from sklearn.utils import Memory"]}],"sklearn\/metrics\/pairwise.py":[{"add":["27","from ..utils._joblib import Parallel","28","from ..utils._joblib import delayed","29","from ..utils._joblib import effective_n_jobs"],"delete":["27","from ..utils import Parallel","28","from ..utils import delayed","29","from ..utils import effective_n_jobs"]}],"sklearn\/utils\/validation.py":[{"add":["21","from .fixes import signature","26","from ._joblib import Memory","27","from ._joblib import __version__ as joblib_version","190","    joblib.Memory instance (typically a str denoting the ``location``)","191","    or has the same interface (has a ``cache`` method).","214","                         \" interface as joblib.Memory.\""],"delete":["21","from ..utils.fixes import signature","26","from ..utils._joblib import Memory","27","from ..utils._joblib import __version__ as joblib_version","190","    sklearn.utils.Memory instance (typically a str denoting the","191","    ``cachedir``) or has the same interface (has a ``cache`` method).","214","                         \" interface as sklearn.utils.Memory.\""]}],"benchmarks\/bench_mnist.py":[{"add":["37","from joblib import Memory"],"delete":["43","from sklearn.utils import Memory"]}],"sklearn\/neighbors\/base.py":[{"add":["28","from ..utils._joblib import Parallel, delayed, effective_n_jobs","29","from ..utils._joblib import __version__ as joblib_version"],"delete":["27","from ..utils import Parallel, delayed, effective_n_jobs","28","from ..utils._joblib import __version__ as joblib_version"]}],"sklearn\/pipeline.py":[{"add":["18","from .utils._joblib import Parallel, delayed"],"delete":["18","from .utils import Parallel, delayed"]}],"benchmarks\/bench_tsne_mnist.py":[{"add":["16","from joblib import Memory"],"delete":["17","from sklearn.utils import Memory"]}],"sklearn\/datasets\/svmlight_format.py":[{"add":["143","        from joblib import Memory"],"delete":["143","        from sklearn.utils import Memory"]}],"sklearn\/linear_model\/tests\/test_sgd.py":[{"add":["31","","33","from sklearn.utils._joblib import parallel_backend"],"delete":["21","from sklearn.utils import parallel_backend"]}],"sklearn\/multiclass.py":[{"add":["54","from .utils._joblib import Parallel","55","from .utils._joblib import delayed"],"delete":["54","from .utils import Parallel","55","from .utils import delayed"]}],"sklearn\/compose\/_column_transformer.py":[{"add":["16","from ..utils._joblib import Parallel, delayed"],"delete":["16","from ..utils import Parallel, delayed"]}],"sklearn\/utils\/tests\/test_validation.py":[{"add":["747","                        \" have the same interface as joblib.Memory.\"","751","                        \" have the same interface as joblib.Memory.\"","752","                        \" Got memory='{}' instead.\".format(dummy),","753","                        check_memory, dummy)"],"delete":["747","                        \" have the same interface as \"","748","                        \"sklearn.utils.Memory.\"","752","                        \" have the same interface as \"","753","                        \"sklearn.utils.Memory. Got memory='{}' \"","754","                        \"instead.\".format(dummy), check_memory, dummy)"]}],"sklearn\/datasets\/lfw.py":[{"add":["21","from ..utils._joblib import Memory","23","from ..utils import _joblib","330","    if LooseVersion(_joblib.__version__) < LooseVersion('0.12'):","501","    if LooseVersion(_joblib.__version__) < LooseVersion('0.12'):"],"delete":["21","from ..utils import Memory","22","from ..utils._joblib import __version__ as joblib_version","330","    if LooseVersion(joblib_version) < LooseVersion('0.12'):","501","    if LooseVersion(joblib_version) < LooseVersion('0.12'):"]}],"sklearn\/tests\/test_docstring_parameters.py":[{"add":["34","    'sklearn.utils._joblib'"],"delete":[]}],"sklearn\/linear_model\/coordinate_descent.py":[{"add":["20","from ..utils._joblib import Parallel, delayed, effective_n_jobs"],"delete":["20","from ..utils import Parallel, delayed, effective_n_jobs"]}],"sklearn\/decomposition\/online_lda.py":[{"add":["22","from ..utils._joblib import Parallel, delayed, effective_n_jobs"],"delete":["22","from ..utils import Parallel, delayed, effective_n_jobs"]}],"sklearn\/manifold\/mds.py":[{"add":["14","from ..utils._joblib import Parallel","15","from ..utils._joblib import delayed","16","from ..utils._joblib import effective_n_jobs"],"delete":["14","from ..utils import Parallel","15","from ..utils import delayed","16","from ..utils import effective_n_jobs"]}],"sklearn\/datasets\/kddcup99.py":[{"add":["23","from ..externals import six","25","from ..utils import _joblib","296","        _joblib.dump(X, samples_path, compress=0)","297","        _joblib.dump(y, targets_path, compress=0)","305","        X = _joblib.load(samples_path)","306","        y = _joblib.load(targets_path)"],"delete":["24","from ..externals import joblib, six","295","        joblib.dump(X, samples_path, compress=0)","296","        joblib.dump(y, targets_path, compress=0)","304","        X = joblib.load(samples_path)","305","        y = joblib.load(targets_path)"]}],"benchmarks\/bench_plot_nmf.py":[{"add":["16","from joblib import Memory"],"delete":["24","from sklearn.utils import Memory"]}],"examples\/cluster\/plot_feature_agglomeration_vs_univariate_selection.py":[{"add":["26","from joblib import Memory"],"delete":["32","from sklearn.utils import Memory"]}],"sklearn\/neighbors\/tests\/test_kde.py":[{"add":["12","from sklearn.utils import _joblib","220","    _joblib.dump(kde, file_path)","221","    kde = _joblib.load(file_path)"],"delete":["12","from sklearn.externals import joblib","220","    joblib.dump(kde, file_path)","221","    kde = joblib.load(file_path)"]}],"sklearn\/utils\/tests\/test_estimator_checks.py":[{"add":["10","from sklearn.utils import _joblib","387","            old_hash = _joblib.hash(est)","389","        assert_equal(old_hash, _joblib.hash(est))","398","            old_hash = _joblib.hash(est)","400","        assert_equal(old_hash, _joblib.hash(est))"],"delete":["7","from sklearn.externals import joblib","387","            old_hash = joblib.hash(est)","389","        assert_equal(old_hash, joblib.hash(est))","398","            old_hash = joblib.hash(est)","400","        assert_equal(old_hash, joblib.hash(est))"]}],"benchmarks\/bench_covertype.py":[{"add":["52","from joblib import Memory"],"delete":["61","from sklearn.utils import Memory"]}],"sklearn\/ensemble\/partial_dependence.py":[{"add":["12","from ..utils._joblib import Parallel, delayed"],"delete":["12","from ..utils import Parallel, delayed"]}],"doc\/whats_new\/v0.20.rst":[{"add":["182","- |API| Removed all mentions of ``sklearn.externals.joblib``, and deprecated","183","  joblib methods exposed in ``sklearn.utils``, except for","184","  :func:`utils.parallel_backend` and :func:`utils.register_parallel_backend`,","185","  which allow users to configure parallel computation in scikit-learn.","186","  Other functionalities are part of `joblib <https:\/\/joblib.readthedocs.io\/>`_.","187","  package and should be used directly, by installing it.","188","  The goal of this change is to prepare for","189","  unvendoring joblib in future version of scikit-learn.","190","  :issue:`12345` by :user:`Thomas Moreau <tomMoral>`","191",""],"delete":["186","Miscellaneous","187",".............","188",""]}],"doc\/modules\/classes.rst":[{"add":["1487","   utils.register_parallel_backend","1497","   :template: deprecated_class.rst","1498","","1499","   utils.Memory","1500","   utils.Parallel","1501","","1502",".. autosummary::","1503","   :toctree: generated\/","1506","   utils.cpu_count","1507","   utils.delayed"],"delete":["1484","   :template: class.rst","1485","","1486","   utils.Memory","1487","   utils.Parallel","1488","","1489",".. autosummary::","1490","   :toctree: generated\/","1493","   utils.cpu_count","1494","   utils.delayed"]}],"sklearn\/feature_selection\/rfe.py":[{"add":["17","from ..utils._joblib import Parallel, delayed, effective_n_jobs"],"delete":["17","from ..utils import Parallel, delayed, effective_n_jobs"]}],"sklearn\/linear_model\/theil_sen.py":[{"add":["22","from ..utils import check_X_y","23","from ..utils._joblib import Parallel, delayed, effective_n_jobs"],"delete":["22","from ..utils import check_X_y, effective_n_jobs","23","from ..utils import Parallel, delayed"]}],"sklearn\/datasets\/twenty_newsgroups.py":[{"add":["45","from ..utils import deprecated","46","from ..utils import _joblib","47","from ..utils import check_random_state, Bunch","405","        X_train, X_test = _joblib.load(target_file)","410","        _joblib.dump((X_train, X_test), target_file, compress=9)"],"delete":["43","from ..utils import check_random_state, Bunch","44","from ..utils import deprecated","47","from ..externals import joblib","405","        X_train, X_test = joblib.load(target_file)","410","        joblib.dump((X_train, X_test), target_file, compress=9)"]}],"benchmarks\/bench_rcv1_logreg_convergence.py":[{"add":["6","from joblib import Memory"],"delete":["10","from sklearn.utils import Memory"]}],"sklearn\/utils\/estimator_checks.py":[{"add":["16","from sklearn.utils import _joblib","17","from sklearn.utils._joblib import Memory","1959","        assert_equal(_joblib.hash(new_value), _joblib.hash(original_value),"],"delete":["16","from sklearn.utils._joblib import hash, Memory","1958","        assert_equal(hash(new_value), hash(original_value),"]}],"sklearn\/tests\/test_multioutput.py":[{"add":["21","from sklearn.utils._joblib import cpu_count"],"delete":["21","from sklearn.utils import cpu_count"]}],"sklearn\/linear_model\/base.py":[{"add":["26","from ..utils._joblib import Parallel, delayed"],"delete":["26","from ..utils import Parallel, delayed"]}],"sklearn\/ensemble\/bagging.py":[{"add":["15","from ..utils._joblib import Parallel, delayed"],"delete":["15","from ..utils import Parallel, delayed"]}],"sklearn\/ensemble\/tests\/test_bagging.py":[{"add":["35","from sklearn.utils import check_random_state","36","from sklearn.utils import _joblib","229","        self.training_hash_ = _joblib.hash(X)"],"delete":["35","from sklearn.utils import check_random_state, hash","228","        self.training_hash_ = hash(X)"]}],"sklearn\/linear_model\/stochastic_gradient.py":[{"add":["11","from ..utils._joblib import Parallel, delayed"],"delete":["11","from ..utils import Parallel, delayed"]}],"sklearn\/model_selection\/_validation.py":[{"add":["26","from ..utils._joblib import Parallel, delayed"],"delete":["26","from ..utils import Parallel, delayed"]}],"sklearn\/decomposition\/dict_learning.py":[{"add":["16","from ..utils._joblib import Parallel, delayed, effective_n_jobs"],"delete":["16","from ..utils import Parallel, delayed, effective_n_jobs"]}],"sklearn\/ensemble\/voting_classifier.py":[{"add":["19","from ..utils._joblib import Parallel, delayed"],"delete":["19","from ..utils import Parallel, delayed"]}],"sklearn\/cluster\/k_means_.py":[{"add":["31","from ..utils._joblib import Parallel","32","from ..utils._joblib import delayed","33","from ..utils._joblib import effective_n_jobs"],"delete":["31","from ..utils import Parallel","32","from ..utils import delayed","33","from ..utils import effective_n_jobs"]}],"sklearn\/linear_model\/least_angle.py":[{"add":["25","from ..utils._joblib import Parallel, delayed"],"delete":["25","from ..utils import Parallel, delayed"]}]}},"67130a583206f0ccf2f5a224129bdf90b2c5ece7":{"changes":{"sklearn\/cluster\/k_means_.py":"MODIFY"},"diff":{"sklearn\/cluster\/k_means_.py":[{"add":["109","        # XXX: numerical imprecision can result in a candidate_id out of range","110","        np.clip(candidate_ids, None, closest_dist_sq.size - 1,","111","                out=candidate_ids)"],"delete":[]}]}},"8cbb13161dab31780dd18a1d42072e8cd618e1d1":{"changes":{"sklearn\/externals\/joblib\/externals\/loky\/__init__.py":"MODIFY","sklearn\/externals\/joblib\/externals\/cloudpickle\/cloudpickle.py":"MODIFY","sklearn\/externals\/joblib\/__init__.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/spawn.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/cloudpickle_wrapper.py":"ADD","sklearn\/externals\/joblib\/externals\/cloudpickle\/__init__.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/context.py":"MODIFY","sklearn\/externals\/joblib\/numpy_pickle.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/process_executor.py":"MODIFY","sklearn\/externals\/joblib\/_store_backends.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/popen_loky_win32.py":"MODIFY","sklearn\/externals\/joblib\/memory.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/process.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/queues.py":"MODIFY","sklearn\/externals\/joblib\/_parallel_backends.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/popen_loky_posix.py":"MODIFY","sklearn\/externals\/joblib\/_multiprocessing_helpers.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/utils.py":"MODIFY","sklearn\/externals\/joblib\/parallel.py":"MODIFY","sklearn\/externals\/joblib\/func_inspect.py":"MODIFY"},"diff":{"sklearn\/externals\/joblib\/externals\/loky\/__init__.py":[{"add":["11","__version__ = '2.2.2'"],"delete":["11","__version__ = '2.2.0'"]}],"sklearn\/externals\/joblib\/externals\/cloudpickle\/cloudpickle.py":[{"add":["165","# relevant opcodes","175","    return getattr(func, '__name__') == '<lambda>'","272","            else:","273","                raise","277","","284","        dispatch[buffer] = save_buffer  # noqa: F821 'buffer' was removed in Python 3","306","","327","","336","        try:","337","            should_special_case = obj in _BUILTIN_TYPE_CONSTRUCTORS","338","        except TypeError:","339","            # Methods of builtin types aren't hashable in python 2.","340","            should_special_case = False","341","","342","        if should_special_case:","425","","433","","439","                # A concurrent thread could mutate sys.modules,","440","                # make sure we iterate over a copy to avoid exceptions","441","                for name in list(sys.modules):","448","                            self.save(sys.modules[name])","463","        # For ABCMeta in python3.7+, remove _abc_impl as it is not picklable.","464","        # This is a fix which breaks the cache but this only makes the first","465","        # calls to issubclass slower.","466","        if \"_abc_impl\" in clsdict:","467","            import abc","468","            (registry, _, _, _) = abc._get_dump(obj)","469","            clsdict[\"_abc_impl\"] = [subclass_weakref()","470","                                    for subclass_weakref in registry]","471","","564","            'module': func.__module__,","565","            'name': func.__name__,","566","            'doc': func.__doc__,","568","        if hasattr(func, '__annotations__'):","569","            state['annotations'] = func.__annotations__","594","                out_names = {names[oparg] for _, oparg in _walk_global_ops(co)}","635","        base_globals = self.globals_ref.get(id(func.__globals__), None)","636","        if base_globals is None:","637","            # For functions defined in __main__, use vars(__main__) for","638","            # base_global. This is necessary to share the global variables","639","            # across multiple functions in this module.","640","            if func.__module__ == \"__main__\":","641","                base_globals = \"__main__\"","642","            else:","643","                base_globals = {}","652","","691","                                 obj=obj)","692","","746","","752","","763","            items = (items,)","794","            import StringIO as pystringIO  # we can't use cStringIO as it lacks the name attribute","798","        if not hasattr(obj, 'name') or not hasattr(obj, 'mode'):","801","            return self.save_reduce(getattr, (sys, 'stdout'), obj=obj)","803","            return self.save_reduce(getattr, (sys, 'stderr'), obj=obj)","838","    try:               # Python 2","840","    except NameError:  # Python 3","841","        dispatch[io.TextIOWrapper] = save_file","856","    def save_root_logger(self, obj):","857","        self.save_reduce(logging.getLogger, (), obj=obj)","858","","859","    dispatch[logging.RootLogger] = save_root_logger","860","","966","            except Exception:","975","# object generators:","983","","987","","1048","    # Only set global variables that do not exist.","1049","    for k, v in state['globals'].items():","1050","        if k not in func.__globals__:","1051","            func.__globals__[k] = v","1052","","1055","    if 'annotations' in state:","1056","        func.__annotations__ = state['annotations']","1057","    if 'doc' in state:","1058","        func.__doc__  = state['doc']","1059","    if 'name' in state:","1060","        func.__name__ = state['name']","1091","    elif isinstance(base_globals, str):","1092","        base_globals = vars(sys.modules[base_globals])","1108","    registry = None","1110","        if attrname == \"_abc_impl\":","1111","            registry = attr","1112","        else:","1113","            setattr(skeleton_class, attrname, attr)","1114","    if registry is not None:","1115","        for subclass in registry:","1116","            skeleton_class.register(subclass)","1117","","1124","    This function is able to find submodules (e.g. scikit.tree)","1135","","1139",""],"delete":["165","#relevant opcodes","175","    return getattr(func,'__name__') == '<lambda>'","280","        dispatch[buffer] = save_buffer","282","    def save_unsupported(self, obj):","283","        raise pickle.PicklingError(\"Cannot pickle objects of type %s\" % type(obj))","284","    dispatch[types.GeneratorType] = save_unsupported","285","","286","    # itertools objects do not pickle!","287","    for v in itertools.__dict__.values():","288","        if type(v) is type:","289","            dispatch[v] = save_unsupported","339","        if obj in _BUILTIN_TYPE_CONSTRUCTORS:","434","                for name, module in sys.modules.items():","441","                            self.save(module)","547","            'module': func.__module__,","574","                out_names = set(names[oparg]","575","                                for op, oparg in _walk_global_ops(co))","616","        base_globals = self.globals_ref.get(id(func.__globals__), {})","663","                         obj=obj)","732","            items = (items, )","763","            import StringIO as pystringIO #we can't use cStringIO as it lacks the name attribute","767","        if not hasattr(obj, 'name') or  not hasattr(obj, 'mode'):","770","            return self.save_reduce(getattr, (sys,'stdout'), obj=obj)","772","            return self.save_reduce(getattr, (sys,'stderr'), obj=obj)","807","    if PY3:","808","        dispatch[io.TextIOWrapper] = save_file","809","    else:","930","            except Exception as e:","939","#object generators:","1010","    func.__globals__.update(state['globals'])","1059","        setattr(skeleton_class, attrname, attr)","1066","    This function is able to find submodules (e.g. sickit.tree)"]}],"sklearn\/externals\/joblib\/__init__.py":[{"add":["14","    **Documentation:**       https:\/\/joblib.readthedocs.io","108","__version__ = '0.12.3'"],"delete":["14","    **Documentation:**       http:\/\/pythonhosted.org\/joblib","108","__version__ = '0.12.2'"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/spawn.py":[{"add":["14","from sklearn.externals.joblib.externals.loky.backend import context","15","","96","        except BaseException:"],"delete":["12","import multiprocessing as mp","28","if sys.version_info[:2] < (3, 4):","29","    def get_command_line(pipe_handle, **kwds):","30","        '''","31","        Returns prefix of command line used for spawning a child process","32","        '''","33","        if getattr(sys, 'frozen', False):","34","            return ([sys.executable, '--multiprocessing-fork', pipe_handle])","35","        else:","36","            prog = 'from multiprocessing.forking import main; main()'","37","            opts = util._args_from_interpreter_flags()","38","            return [_python_exe] + opts + [","39","                '-c', prog, '--multiprocessing-fork', pipe_handle]","40","else:","41","    from multiprocessing.spawn import get_command_line","42","","110","        except:","167","    if hasattr(mp, 'set_start_method'):","168","        mp.set_start_method('loky', force=True)","169",""]}],"sklearn\/externals\/joblib\/externals\/loky\/cloudpickle_wrapper.py":[{"add":[],"delete":[]}],"sklearn\/externals\/joblib\/externals\/cloudpickle\/__init__.py":[{"add":["4","__version__ = '0.5.5'"],"delete":["4","__version__ = '0.5.2'"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/context.py":[{"add":["20","from .process import LokyProcess, LokyInitMainProcess","21","","22","START_METHODS = ['loky', 'loky_init_main']","23","_DEFAULT_START_METHOD = None","26","    from multiprocessing import get_context as mp_get_context","30","    START_METHODS += ['spawn']","31","    if sys.platform != 'win32':","32","        START_METHODS += ['fork', 'forkserver']","33","","34","    def get_context(method=None):","35","        # Try to overload the default context","36","        method = method or _DEFAULT_START_METHOD or \"loky\"","38","            # If 'fork' is explicitly requested, warn user about potential","39","            # issues.","40","            warnings.warn(\"`fork` start method should not be used with \"","41","                          \"`loky` as it does not respect POSIX. Try using \"","42","                          \"`spawn` or `loky` instead.\", UserWarning)","43","        try:","44","            context = mp_get_context(method)","45","        except ValueError:","46","            raise ValueError(\"Unknown context '{}'. Value should be in {}.\"","47","                             .format(method, START_METHODS))","48","","49","        return context","54","        # Mechanism to check that the current thread is spawning a process","77","    def get_context(method=None):","78","        method = method or _DEFAULT_START_METHOD or 'loky'","84","            raise ValueError(\"Unknown context '{}'. Value should be in {}.\"","85","                             .format(method, START_METHODS))","86","","87","","88","def set_start_method(method, force=False):","89","    global _DEFAULT_START_METHOD","90","    if _DEFAULT_START_METHOD is not None and not force:","91","        raise RuntimeError('context has already been set')","92","    assert method is None or method in START_METHODS, (","93","        \"'{}' is not a valid start_method. It should be in {}\"","94","        .format(method, START_METHODS))","95","","96","    _DEFAULT_START_METHOD = method","97","","98","","99","def get_start_method():","100","    return _DEFAULT_START_METHOD","172","            return self._name","250","    _name = 'loky_init_main'","251","    Process = LokyInitMainProcess","256","    ctx_loky = LokyContext()","257","    mp.context._concrete_contexts['loky'] = ctx_loky"],"delete":["20","from .process import LokyProcess","23","    from multiprocessing import get_context as get_mp_context","27","    def get_context(method=\"loky\"):","29","            warnings.warn(\"`fork` start method should not be used with `loky` \"","30","                          \"as it does not respect POSIX. Try using `spawn` or \"","31","                          \"`loky` instead.\", UserWarning)","32","        return get_mp_context(method)","35","    METHODS = ['loky', 'loky_init_main']","38","        # Mecanism to check that the current thread is spawning a child process","61","    def get_context(method=\"loky\"):","67","            raise ValueError(\"Method {} is not implemented. The available \"","68","                             \"methods are {}\".format(method, METHODS))","140","            return \"loky\"","218","    def Process(self, *args, **kwargs):","219","        kwargs.pop('init_main_module', True)","220","        return LokyProcess(*args, init_main_module=True, **kwargs)","225","    mp.context._concrete_contexts['loky'] = LokyContext()"]}],"sklearn\/externals\/joblib\/numpy_pickle.py":[{"add":["437","    # LZ4 compression is only supported and installation checked with","438","    # python 3+.","439","    if compress_method == 'lz4' and lz4 is None and PY3_OR_LATER:"],"delete":["437","    if compress_method == 'lz4' and lz4 is None:"]}],"sklearn\/externals\/joblib\/externals\/loky\/process_executor.py":[{"add":["62","import gc","65","import struct","71","from time import time","83","from .cloudpickle_wrapper import _wrap_non_picklable_objects","267","    def __getstate__(self):","268","        return (","269","            self.work_id,","270","            _wrap_non_picklable_objects(self.fn),","271","            [_wrap_non_picklable_objects(a) for a in self.args],","272","            {k: _wrap_non_picklable_objects(a) for k, a in self.kwargs.items()}","273","        )","275","    def __setstate__(self, state):","276","        self.work_id, self.fn, self.args, self.kwargs = state","290","            # format traceback only works on python3","291","            if isinstance(e, struct.error):","292","                raised_error = RuntimeError(","293","                    \"The task could not be sent to the workers as it is too \"","294","                    \"large for `send_bytes`.\")","295","            else:","296","                raised_error = PicklingError(","297","                    \"Could not pickle the task to send it to the workers.\")","300","            raised_error.__cause__ = _RemoteTraceback(","308","                work_item.future.set_exception(raised_error)","384","    _process_reference_size = None","385","    _process_last_memory_check = None","404","            previous_tb = traceback.format_exc()","405","            try:","406","                result_queue.put(_RemoteTraceback(previous_tb))","407","            except BaseException:","408","                # If we cannot format correctly the exception, at least print","409","                # the traceback.","410","                print(previous_tb)","430","            if _process_reference_size is None:","432","                _process_reference_size = _get_memory_usage(pid, force_gc=True)","433","                _process_last_memory_check = time()","435","            if time() - _process_last_memory_check > _MEMORY_CHECK_DELAY:","437","                _process_last_memory_check = time()","438","                if mem_usage - _process_reference_size < _MAX_MEMORY_LEAK_SIZE:","446","                _process_last_memory_check = time()","447","                if mem_usage - _process_reference_size < _MAX_MEMORY_LEAK_SIZE:","613","                if isinstance(result_item, _RemoteTraceback):","614","                    cause = result_item.tb","615","                    broken = (\"A task has failed to un-serialize\", cause)","860","        self._initializer = _wrap_non_picklable_objects(initializer)","861","        self._initargs = [_wrap_non_picklable_objects(a) for a in initargs]"],"delete":["72","from time import time","73","import gc","265","    try:","266","        # If cloudpickle is present on the system, use it to pickle the","267","        # function. This permits to use interactive terminal for loky calls.","268","        # TODO: Add option to deactivate, as it increases pickling time.","269","        from .backend import LOKY_PICKLER","270","        assert LOKY_PICKLER is None or LOKY_PICKLER == \"\"","272","        import cloudpickle  # noqa: F401","273","","274","        def __getstate__(self):","275","            from cloudpickle import dumps","276","            if isinstance(self.fn, (types.FunctionType,","277","                                    types.LambdaType,","278","                                    partial)):","279","                cp = True","280","                fn = dumps(self.fn)","281","            else:","282","                cp = False","283","                fn = self.fn","284","            return (self.work_id, self.args, self.kwargs, fn, cp)","285","","286","        def __setstate__(self, state):","287","            self.work_id, self.args, self.kwargs, self.fn, cp = state","288","            if cp:","289","                from cloudpickle import loads","290","                self.fn = loads(self.fn)","291","","292","    except (ImportError, AssertionError) as e:","293","        pass","307","            # fromat traceback only on python3","308","            pickling_error = PicklingError(","309","                \"Could not pickle the task to send it to the workers.\")","312","            pickling_error.__cause__ = _RemoteTraceback(","320","                work_item.future.set_exception(pickling_error)","396","    _REFERENCE_PROCESS_SIZE = None","397","    _LAST_MEMORY_CHECK = None","416","            traceback.print_exc()","436","            if _REFERENCE_PROCESS_SIZE is None:","438","                _REFERENCE_PROCESS_SIZE = _get_memory_usage(pid, force_gc=True)","439","                _LAST_MEMORY_CHECK = time()","441","            if time() - _LAST_MEMORY_CHECK > _MEMORY_CHECK_DELAY:","443","                _LAST_MEMORY_CHECK = time()","444","                if mem_usage - _REFERENCE_PROCESS_SIZE < _MAX_MEMORY_LEAK_SIZE:","452","                _LAST_MEMORY_CHECK = time()","453","                if mem_usage - _REFERENCE_PROCESS_SIZE < _MAX_MEMORY_LEAK_SIZE:","863","        self._initializer = initializer","864","        self._initargs = initargs"]}],"sklearn\/externals\/joblib\/_store_backends.py":[{"add":["37","    location = None","38","","331","        return '{class_name}(location=\"{location}\")'.format(","332","            class_name=self.__class__.__name__, location=self.location)","389","    def configure(self, location, verbose=1, backend_options=None):","394","        if backend_options is None:","395","            backend_options = {}","403","        self.compress = backend_options.get('compress', False)","407","        mmap_mode = backend_options.get('mmap_mode')","408","        if self.compress and mmap_mode is not None:","409","            warnings.warn('Compressed items cannot be memmapped in a '","410","                          'filesystem store. Option will be ignored.',","411","                          stacklevel=2)"],"delete":["329","        return self.location","386","    def configure(self, location, verbose=1, backend_options={}):","398","        self.compress = backend_options['compress']","402","        mmap_mode = None","403","        if 'mmap_mode' in backend_options:","404","            mmap_mode = backend_options['mmap_mode']","405","            if self.compress and mmap_mode is not None:","406","                warnings.warn('Compressed items cannot be memmapped in a '","407","                              'filesystem store. Option will be ignored.',","408","                              stacklevel=2)"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/popen_loky_win32.py":[{"add":["2","from pickle import load","3","from multiprocessing import process, util","7","from .context import get_spawning_popen, set_spawning_popen","45","            process_obj._name, getattr(process_obj, \"init_main_module\", True))","53","        cmd = get_command_line(parent_pid=os.getpid(), pipe_handle=rhandle)","66","                except BaseException as e:","99","","100","","101","if sys.version_info[:2] >= (3, 4):","102","    from multiprocessing.spawn import get_command_line","103","else:","104","    # compatibility for python2.7. Duplicate here the code from","105","    # multiprocessing.forking.main to call our prepare function and correctly","106","    # set the default start_methods in loky.","107","","108","    def get_command_line(pipe_handle, **kwds):","109","        '''","110","        Returns prefix of command line used for spawning a child process","111","        '''","112","        if getattr(sys, 'frozen', False):","113","            return ([sys.executable, '--multiprocessing-fork', pipe_handle])","114","        else:","115","            prog = 'from sklearn.externals.joblib.externals.loky.backend.popen_loky_win32 import main; main()'","116","            opts = util._args_from_interpreter_flags()","117","            return [spawn.get_executable()] + opts + [","118","                '-c', prog, '--multiprocessing-fork', pipe_handle]","119","","120","    def is_forking(argv):","121","        '''","122","        Return whether commandline indicates we are forking","123","        '''","124","        if len(argv) >= 2 and argv[1] == '--multiprocessing-fork':","125","            assert len(argv) == 3","126","            return True","127","        else:","128","            return False","129","","130","    def main():","131","        '''","132","        Run code specified by data received over pipe","133","        '''","134","        assert is_forking(sys.argv)","135","","136","        handle = int(sys.argv[-1])","137","        fd = msvcrt.open_osfhandle(handle, os.O_RDONLY)","138","        from_parent = os.fdopen(fd, 'rb')","139","","140","        process.current_process()._inheriting = True","141","        preparation_data = load(from_parent)","142","        spawn.prepare(preparation_data)","143","        self = load(from_parent)","144","        process.current_process()._inheriting = False","145","","146","        from_parent.close()","147","","148","        exitcode = self._bootstrap()","149","        exit(exitcode)"],"delete":["3","from .context import get_spawning_popen, set_spawning_popen","6","from multiprocessing import util","44","            process_obj._name, process_obj.init_main_module)","52","        cmd = spawn.get_command_line(parent_pid=os.getpid(),","53","                                     pipe_handle=rhandle)","66","                except:"]}],"sklearn\/externals\/joblib\/memory.py":[{"add":["98","def _store_backend_factory(backend, location, verbose=0, backend_options=None):","100","    if backend_options is None:","101","        backend_options = {}","102","","213","        if isinstance(func, _basestring):","214","            self.func = func","215","        else:","216","            self.func = self.func_id","260","                        location=self.store_backend.location,","264","","265","    def __getstate__(self):","266","        state = self.__dict__.copy()","267","        state['timestamp'] = None","268","        return state","392","","428","    def _cached_call(self, args, kwargs, shelving=False):","433","        Arguments:","434","        ----------","435","","436","        args, kwargs: list and dict","437","            input arguments for wrapped function","438","","439","        shelving: bool","440","            True when called via the call_and_shelve function.","441","","442","","445","        output: value or tuple or None","446","            Output of the wrapped function.","447","            If shelving is True and the call has been already cached,","448","            output is None.","451","            Hash of function arguments.","454","            Some metadata about wrapped function call (see _persist_input()).","488","","489","                if not shelving:","490","                    # When shelving, we do not need to load the output","491","                    out = self.store_backend.load_item(","492","                        [func_id, args_id],","493","                        msg=msg,","494","                        verbose=self._verbose)","495","                else:","496","                    out = None","497","","529","        _, args_id, metadata = self._cached_call(args, kwargs, shelving=True)","537","    def __getstate__(self):","541","        state = self.__dict__.copy()","542","        state['timestamp'] = None","543","        return state","771","        return '{class_name}(func={func}, location={location})'.format(","772","            class_name=self.__class__.__name__,","773","            func=self.func,","774","            location=self.store_backend.location,)","803","        cachedir: str or None, optional","804","","805","            .. deprecated: 0.12","806","                'cachedir' has been deprecated in 0.12 and will be","807","                removed in 0.14. Use the 'location' parameter instead.","808","","835","    def __init__(self, location=None, backend='local', cachedir=None,","836","                 mmap_mode=None, compress=False, verbose=1, bytes_limit=None,","837","                 backend_options=None):","845","        self.compress = compress","846","        if backend_options is None:","847","            backend_options = {}","848","        self.backend_options = backend_options","849","","929","        return MemorizedFunc(func, location=self.store_backend,","930","                             backend=self.backend,","931","                             ignore=ignore, mmap_mode=mmap_mode,","932","                             compress=self.compress,","933","                             verbose=verbose, timestamp=self.timestamp)","966","        return '{class_name}(location={location})'.format(","967","            class_name=self.__class__.__name__,","968","            location=(None if self.store_backend is None","969","                      else self.store_backend.location))","971","    def __getstate__(self):","975","        state = self.__dict__.copy()","976","        state['timestamp'] = None","977","        return state"],"delete":["98","def _store_backend_factory(backend, location, verbose=0, backend_options={}):","209","        self.func = func","254","                        location=self.store_backend,","258","    def __reduce__(self):","259","        return (self.__class__,","260","                (self.store_backend, self.func, self.args_id),","261","                {'mmap_mode': self.mmap_mode})","326","    def __reduce__(self):","327","        return (self.__class__, (self.func,))","328","","423","    def _cached_call(self, args, kwargs):","430","        output: value or tuple","431","            what is returned by wrapped function","434","            hash of function arguments","437","            some metadata about wrapped function call (see _persist_input())","471","                out = self.store_backend.load_item([func_id, args_id], msg=msg,","472","                                                   verbose=self._verbose)","504","        _, args_id, metadata = self._cached_call(args, kwargs)","512","    def __reduce__(self):","515","            In addition, when unpickling, we run the __init__","517","        return (self.__class__, (self.func, None),","518","                {k: v for k, v in vars(self).items()","519","                 if k not in ('timestamp', 'func')})","747","        return (\"{0}(func={1}, location={2})\".format(self.__class__.__name__,","748","                                                     self.func,","749","                                                     self.store_backend,))","799","","800","        cachedir: str or None, optional","801","","802","            .. deprecated: 0.12","803","                'cachedir' has been deprecated in 0.12 and will be","804","                removed in 0.14. Use the 'location' parameter instead.","810","    def __init__(self, location=None, backend='local', mmap_mode=None,","811","                 compress=False, verbose=1, bytes_limit=None,","812","                 backend_options={}, cachedir=None):","899","        return MemorizedFunc(func, self.store_backend, mmap_mode=mmap_mode,","900","                             ignore=ignore, verbose=verbose,","901","                             timestamp=self.timestamp)","934","        return '{0}(location={1})'.format(","935","            self.__class__.__name__, (repr(None) if self.store_backend is None","936","                                      else repr(self.store_backend)))","938","    def __reduce__(self):","941","            In addition, when unpickling, we run the __init__","943","        return (self.__class__, (), {k: v for k, v in vars(self).items()","944","                                     if k != 'timestamp'})"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/process.py":[{"add":["75","        def _bootstrap(self):","76","            from .context import set_start_method","77","            set_start_method(self._start_method)","78","            super(LokyProcess, self)._bootstrap()","79","","80","","81","class LokyInitMainProcess(LokyProcess):","82","    _start_method = 'loky_init_main'","83","","84","    def __init__(self, group=None, target=None, name=None, args=(),","85","                 kwargs={}, daemon=None):","86","        super(LokyInitMainProcess, self).__init__(","87","            group=group, target=target, name=name, args=args, kwargs=kwargs,","88","            daemon=daemon, init_main_module=True)","89",""],"delete":[]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/queues.py":[{"add":["149","                        obj_ = CustomizableLokyPickler.dumps(","152","                            send_bytes(obj_)","156","                                send_bytes(obj_)","159","                        # Remove references early to avoid leaking memory","160","                        del obj, obj_"],"delete":["149","                        obj = CustomizableLokyPickler.dumps(","152","                            send_bytes(obj)","156","                                send_bytes(obj)"]}],"sklearn\/externals\/joblib\/_parallel_backends.py":[{"add":["349","            raise FallbackToBackend(","350","                SequentialBackend(nesting_level=self.nesting_level))","423","            raise FallbackToBackend(","424","                SequentialBackend(nesting_level=self.nesting_level))","465","            raise FallbackToBackend(","466","                SequentialBackend(nesting_level=self.nesting_level))"],"delete":["132","","350","            raise FallbackToBackend(SequentialBackend())","423","            raise FallbackToBackend(SequentialBackend())","464","            raise FallbackToBackend(SequentialBackend())"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/popen_loky_posix.py":[{"add":["129","                    process_obj._name,","130","                    getattr(process_obj, \"init_main_module\", True))","155","                util.debug(\"launched python with pid {} and cmd:\\n{}\"","156","                           .format(pid, cmd_python))"],"delete":["129","                    process_obj._name, process_obj.init_main_module)","152","                util.debug(\"launch python with cmd:\\n%s\" % cmd_python)"]}],"sklearn\/externals\/joblib\/_multiprocessing_helpers.py":[{"add":["6","import sys","24","        # Use the spawn context","25","        if sys.version_info < (3, 3):","26","            Semaphore = mp.Semaphore","27","        else:","28","            # Using mp.Semaphore has a border effect and set the default","29","            # backend for multiprocessing. To avoid that, we use the 'spawn'","30","            # context which is available on all supported platforms.","31","            ctx = mp.get_context('spawn')","32","            Semaphore = ctx.Semaphore","33","        _sem = Semaphore()"],"delete":["23","        _sem = mp.Semaphore()"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/utils.py":[{"add":["32","    # Kill the children in reverse order to avoid killing the parents before","33","    # the children in cases where there are more processes nested.","34","    for child in children[::-1]:","36","            child.kill()"],"delete":["32","    for child in children:","34","            child.terminate()","38","    gone, still_alive = psutil.wait_procs(children, timeout=5)","39","    for child_process in still_alive:","40","        child_process.kill()","41",""]}],"sklearn\/externals\/joblib\/parallel.py":[{"add":["198","DEFAULT_MP_CONTEXT = None","201","    if method is not None:","202","        DEFAULT_MP_CONTEXT = mp.get_context(method=method)","681","        elif hasattr(mp, \"get_context\"):","682","            self._backend_args['context'] = mp.get_context()"],"delete":["200","    DEFAULT_MP_CONTEXT = mp.get_context(method=method)","201","else:","202","    DEFAULT_MP_CONTEXT = None"]}],"sklearn\/externals\/joblib\/func_inspect.py":[{"add":["277","                arg_dict[arg_name] = kwargs[arg_name]"],"delete":["277","                arg_dict[arg_name] = kwargs.pop(arg_name)"]}]}},"c6455fa77f519481f516ded02da66ecaf4b044c9":{"changes":{"sklearn\/tree\/setup.py":"MODIFY"},"diff":{"sklearn\/tree\/setup.py":[{"add":["33","    config.add_data_files(\"_criterion.pxd\")","34","    config.add_data_files(\"_splitter.pxd\")","35","    config.add_data_files(\"_tree.pxd\")","36","    config.add_data_files(\"_utils.pxd\")"],"delete":[]}]}},"38e7c8b1170ff906c4fab2992dc4962e1368bd5b":{"changes":{"sklearn\/linear_model\/logistic.py":"MODIFY"},"diff":{"sklearn\/linear_model\/logistic.py":[{"add":["63","    c : float","64","        The intercept."],"delete":["63","    X : {array-like, sparse matrix}, shape (n_samples, n_features)","64","        Training data. Unchanged."]}]}},"c34c5626aa0fa08595e8af1d5e4acbe478149f49":{"changes":{"sklearn\/random_projection.py":"MODIFY"},"diff":{"sklearn\/random_projection.py":[{"add":["152","                         n_features)"],"delete":["152","                         n_components)"]}]}},"a1d0e96791ec6b4404303c5821e305caf6a5f777":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/utils\/extmath.py":"MODIFY","sklearn\/preprocessing\/tests\/test_data.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["88",":mod:`sklearn.utils`","89","........................","90","","91","- |Fix| Use float64 for mean accumulator to avoid floating point","92","  precision issues in :class:`preprocessing.StandardScaler` and","93","  :class:`decomposition.IncrementalPCA` when using float32 datasets.","94","  :issue:`12338` by :user:`bauks <bauks>`.","95",""],"delete":[]}],"sklearn\/utils\/extmath.py":[{"add":["712","    if np.issubdtype(X.dtype, np.floating) and X.dtype.itemsize < 8:","713","        # Use at least float64 for the accumulator to avoid precision issues;","714","        # see https:\/\/github.com\/numpy\/numpy\/issues\/9393","715","        new_sum = np.nansum(X, axis=0, dtype=np.float64).astype(X.dtype)","716","    else:","717","        new_sum = np.nansum(X, axis=0)"],"delete":["712","    new_sum = np.nansum(X, axis=0)"]}],"sklearn\/preprocessing\/tests\/test_data.py":[{"add":["232","def test_standard_scaler_dtype():","233","    # Ensure scaling does not affect dtype","234","    rng = np.random.RandomState(0)","235","    n_samples = 10","236","    n_features = 3","237","    for dtype in [np.float16, np.float32, np.float64]:","238","        X = rng.randn(n_samples, n_features).astype(dtype)","239","        scaler = StandardScaler()","240","        X_scaled = scaler.fit(X).transform(X)","241","        assert X.dtype == X_scaled.dtype","242","        assert scaler.mean_.dtype == np.float64","243","        assert scaler.scale_.dtype == np.float64","244","","245",""],"delete":[]}]}},"4140657700cc55830347c871134c8e982d29fab5":{"changes":{"doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/tests\/test_discriminant_analysis.py":"MODIFY","sklearn\/discriminant_analysis.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.21.rst":[{"add":["19","- :class:`discriminant_analysis.LinearDiscriminantAnalysis` for multiclass","20","  classification. |Fix|","21","- :class:`discriminant_analysis.LinearDiscriminantAnalysis` with 'eigen'","22","  solver. |Fix|","113","- |Fix| Fixed a bug in :class:`discriminant_analysis.LinearDiscriminantAnalysis`","114","  where the predicted probabilities would be incorrectly computed in the","115","  multiclass case. :issue:`6848`, by :user:`Agamemnon Krasoulis","116","  <agamemnonc>` and `Guillaume Lemaitre <glemaitre>`.","117","","118","- |Fix| Fixed a bug in :class:`discriminant_analysis.LinearDiscriminantAnalysis`","119","  where the predicted probabilities would be incorrectly computed with ``eigen``","120","  solver. :issue:`11727`, by :user:`Agamemnon Krasoulis","121","  <agamemnonc>`.","122",""],"delete":[]}],"sklearn\/tests\/test_discriminant_analysis.py":[{"add":["4","from numpy.testing import assert_allclose","5","from scipy import linalg","6","","100","@pytest.mark.parametrize(\"n_classes\", [2, 3])","101","@pytest.mark.parametrize(\"solver\", [\"svd\", \"lsqr\", \"eigen\"])","102","def test_lda_predict_proba(solver, n_classes):","103","    def generate_dataset(n_samples, centers, covariances, random_state=None):","104","        \"\"\"Generate a multivariate normal data given some centers and","105","        covariances\"\"\"","106","        rng = check_random_state(random_state)","107","        X = np.vstack([rng.multivariate_normal(mean, cov,","108","                                               size=n_samples \/\/ len(centers))","109","                       for mean, cov in zip(centers, covariances)])","110","        y = np.hstack([[clazz] * (n_samples \/\/ len(centers))","111","                       for clazz in range(len(centers))])","112","        return X, y","113","","114","    blob_centers = np.array([[0, 0], [-10, 40], [-30, 30]])[:n_classes]","115","    blob_stds = np.array([[[10, 10], [10, 100]]] * len(blob_centers))","116","    X, y = generate_dataset(","117","        n_samples=90000, centers=blob_centers, covariances=blob_stds,","118","        random_state=42","119","    )","120","    lda = LinearDiscriminantAnalysis(solver=solver, store_covariance=True,","121","                                     shrinkage=None).fit(X, y)","122","    # check that the empirical means and covariances are close enough to the","123","    # one used to generate the data","124","    assert_allclose(lda.means_, blob_centers, atol=1e-1)","125","    assert_allclose(lda.covariance_, blob_stds[0], atol=1)","126","","127","    # implement the method to compute the probability given in The Elements","128","    # of Statistical Learning (cf. p.127, Sect. 4.4.5 \"Logistic Regression","129","    # or LDA?\")","130","    precision = linalg.inv(blob_stds[0])","131","    alpha_k = []","132","    alpha_k_0 = []","133","    for clazz in range(len(blob_centers) - 1):","134","        alpha_k.append(","135","            np.dot(precision,","136","                   (blob_centers[clazz] - blob_centers[-1])[:, np.newaxis]))","137","        alpha_k_0.append(","138","            np.dot(- 0.5 * (blob_centers[clazz] +","139","                            blob_centers[-1])[np.newaxis, :], alpha_k[-1]))","140","","141","    sample = np.array([[-22, 22]])","142","","143","    def discriminant_func(sample, coef, intercept, clazz):","144","        return np.exp(intercept[clazz] + np.dot(sample, coef[clazz]))","145","","146","    prob = np.array([float(","147","        discriminant_func(sample, alpha_k, alpha_k_0, clazz) \/","148","        (1 + sum([discriminant_func(sample, alpha_k, alpha_k_0, clazz)","149","                  for clazz in range(n_classes - 1)]))) for clazz in range(","150","                      n_classes - 1)])","151","","152","    prob_ref = 1 - np.sum(prob)","153","","154","    # check the consistency of the computed probability","155","    # all probabilities should sum to one","156","    prob_ref_2 = float(","157","        1 \/ (1 + sum([discriminant_func(sample, alpha_k, alpha_k_0, clazz)","158","                      for clazz in range(n_classes - 1)]))","159","    )","160","","161","    assert prob_ref == pytest.approx(prob_ref_2)","162","    # check that the probability of LDA are close to the theoretical","163","    # probabilties","164","    assert_allclose(lda.predict_proba(sample),","165","                    np.hstack([prob, prob_ref])[np.newaxis],","166","                    atol=1e-2)","167","","168","","303","    # Test for solver 'lsqr' and 'eigen'","319","    # Test for SVD solver, the default is to not set the covariances_ attribute"],"delete":["231","    # Test for slover 'lsqr' and 'eigen'","247","    # Test for SVD slover, the default is to not set the covariances_ attribute"]}],"sklearn\/discriminant_analysis.py":[{"add":["24","from .utils.extmath import softmax","533","        check_is_fitted(self, 'classes_')","534","","535","        decision = self.decision_function(X)","536","        if self.classes_.size == 2:","537","            proba = expit(decision)","538","            return np.vstack([1-proba, proba]).T","540","            return softmax(decision)"],"delete":["340","        evecs \/= np.linalg.norm(evecs, axis=0)","533","        prob = self.decision_function(X)","534","        expit(prob, out=prob)","535","        if len(self.classes_) == 2:  # binary case","536","            return np.column_stack([1 - prob, prob])","538","            # OvR normalization, like LibLinear's predict_probability","539","            prob \/= prob.sum(axis=1).reshape((prob.shape[0], -1))","540","            return prob"]}]}}}
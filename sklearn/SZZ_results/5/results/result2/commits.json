{"a50c03f975c4bbf306c5af1826f46ba5dc5230a0":{"changes":{"sklearn\/base.py":"MODIFY","sklearn\/metrics\/classification.py":"MODIFY","doc\/modules\/preprocessing.rst":"MODIFY","sklearn\/linear_model\/coordinate_descent.py":"MODIFY","sklearn\/preprocessing\/_encoders.py":"MODIFY","sklearn\/impute.py":"MODIFY","sklearn\/utils\/tests\/test_pprint.py":"ADD","sklearn\/neural_network\/rbm.py":"MODIFY","doc\/tutorial\/statistical_inference\/supervised_learning.rst":"MODIFY","doc\/tutorial\/statistical_inference\/unsupervised_learning.rst":"MODIFY","sklearn\/tests\/test_base.py":"MODIFY","sklearn\/svm\/classes.py":"MODIFY","sklearn\/kernel_approximation.py":"MODIFY","doc\/modules\/model_evaluation.rst":"MODIFY","sklearn\/decomposition\/pca.py":"MODIFY","sklearn\/_config.py":"MODIFY","sklearn\/feature_extraction\/dict_vectorizer.py":"MODIFY","sklearn\/linear_model\/passive_aggressive.py":"MODIFY","doc\/modules\/compose.rst":"MODIFY","sklearn\/cluster\/hierarchical.py":"MODIFY","sklearn\/discriminant_analysis.py":"MODIFY","doc\/tutorial\/statistical_inference\/model_selection.rst":"MODIFY","sklearn\/preprocessing\/data.py":"MODIFY","examples\/plot_changed_only_pprint_parameter.py":"ADD","sklearn\/ensemble\/forest.py":"MODIFY","doc\/modules\/linear_model.rst":"MODIFY","sklearn\/tests\/test_config.py":"MODIFY","sklearn\/utils\/_pprint.py":"ADD","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/linear_model\/perceptron.py":"MODIFY"},"diff":{"sklearn\/base.py":[{"add":["226","        from .utils._pprint import _EstimatorPrettyPrinter","227","","228","        N_CHAR_MAX = 700  # number of non-whitespace or newline chars","229","        N_MAX_ELEMENTS_TO_SHOW = 30  # number of elements to show in sequences","230","","231","        # use ellipsis for sequences with a lot of elements","232","        pp = _EstimatorPrettyPrinter(","233","            compact=True, indent=1, indent_at_name=True,","234","            n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)","235","","236","        repr_ = pp.pformat(self)","237","","238","        # Use bruteforce ellipsis if string is very long","239","        if len(''.join(repr_.split())) > N_CHAR_MAX:  # check non-blank chars","240","            lim = N_CHAR_MAX \/\/ 2","241","            repr_ = repr_[:lim] + '...' + repr_[-lim:]","242","        return repr_"],"delete":["226","        class_name = self.__class__.__name__","227","        return '%s(%s)' % (class_name, _pprint(self.get_params(deep=False),","228","                                               offset=len(class_name),),)"]}],"sklearn\/metrics\/classification.py":[{"add":["2078","    >>> est.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","2095","    >>> est.fit(X, Y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["2078","    >>> est.fit(X, y)","2095","    >>> est.fit(X, Y)"]}],"doc\/modules\/preprocessing.rst":[{"add":["490","  >>> enc.fit(X)  # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE","516","    >>> enc.fit(X) # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE","534","    >>> enc.fit(X) # doctest: +ELLIPSIS  +NORMALIZE_WHITESPACE"],"delete":["490","  >>> enc.fit(X)  # doctest: +ELLIPSIS","516","    >>> enc.fit(X) # doctest: +ELLIPSIS","534","    >>> enc.fit(X) # doctest: +ELLIPSIS"]}],"sklearn\/linear_model\/coordinate_descent.py":[{"add":["625","    >>> regr.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","905","    ... # doctest: +NORMALIZE_WHITESPACE","1555","    >>> regr.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","1910","    ... # doctest: +NORMALIZE_WHITESPACE"],"delete":["625","    >>> regr.fit(X, y)","1554","    >>> regr.fit(X, y)"]}],"sklearn\/preprocessing\/_encoders.py":[{"add":["247","    ... # doctest: +NORMALIZE_WHITESPACE"],"delete":[]}],"sklearn\/impute.py":[{"add":["466","    >>> indicator.fit(X1)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["466","    >>> indicator.fit(X1)"]}],"sklearn\/utils\/tests\/test_pprint.py":[{"add":[],"delete":[]}],"sklearn\/neural_network\/rbm.py":[{"add":["83","    >>> model.fit(X)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["83","    >>> model.fit(X)"]}],"doc\/tutorial\/statistical_inference\/supervised_learning.rst":[{"add":["336","    ... # doctest: +NORMALIZE_WHITESPACE"],"delete":[]}],"doc\/tutorial\/statistical_inference\/unsupervised_learning.rst":[{"add":["276","    >>> pca.fit(X)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["276","    >>> pca.fit(X)"]}],"sklearn\/tests\/test_base.py":[{"add":["187","    assert_equal(len(repr(some_est)), 495)"],"delete":["187","    assert_equal(len(repr(some_est)), 415)"]}],"sklearn\/svm\/classes.py":[{"add":["119","    >>> clf.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","331","    >>> regr.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["119","    >>> clf.fit(X, y)","331","    >>> regr.fit(X, y)"]}],"sklearn\/kernel_approximation.py":[{"add":["165","    >>> clf.fit(X_features, y)  # doctest: +NORMALIZE_WHITESPACE","285","    >>> clf.fit(X_transformed, y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["165","    >>> clf.fit(X_features, y)","285","    >>> clf.fit(X_transformed, y)"]}],"doc\/modules\/model_evaluation.rst":[{"add":["981","  >>> est.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","999","  >>> est.fit(X, Y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["981","  >>> est.fit(X, y)","999","  >>> est.fit(X, Y)"]}],"sklearn\/decomposition\/pca.py":[{"add":["278","    >>> pca.fit(X)  # doctest: +NORMALIZE_WHITESPACE","296","    >>> pca.fit(X)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["278","    >>> pca.fit(X)","296","    >>> pca.fit(X)"]}],"sklearn\/_config.py":[{"add":["7","    'working_memory': int(os.environ.get('SKLEARN_WORKING_MEMORY', 1024)),","8","    'print_changed_only': False,","23","def set_config(assume_finite=None, working_memory=None,","24","               print_changed_only=None):","47","    print_changed_only : bool, optional","48","        If True, only the parameters that were set to non-default","49","        values will be printed when printing an estimator. For example,","50","        ``print(SVC())`` while True will only print 'SVC()' while the default","51","        behaviour would be to print 'SVC(C=1.0, cache_size=200, ...)' with","52","        all the non-changed parameters.","53","","54","        .. versionadded:: 0.21","60","    if print_changed_only is not None:","61","        _global_config['print_changed_only'] = print_changed_only"],"delete":["7","    'working_memory': int(os.environ.get('SKLEARN_WORKING_MEMORY', 1024))","22","def set_config(assume_finite=None, working_memory=None):"]}],"sklearn\/feature_extraction\/dict_vectorizer.py":[{"add":["347","        ...                                   # doctest: +NORMALIZE_WHITESPACE"],"delete":[]}],"sklearn\/linear_model\/passive_aggressive.py":[{"add":["143","    >>> clf.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","382","    >>> regr.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["143","    >>> clf.fit(X, y)","382","    >>> regr.fit(X, y)"]}],"doc\/modules\/compose.rst":[{"add":["78","    >>> pipe.steps[0]  # doctest: +NORMALIZE_WHITESPACE","84","    >>> pipe.named_steps['reduce_dim']  # doctest: +NORMALIZE_WHITESPACE"],"delete":["78","    >>> pipe.steps[0]","84","    >>> pipe.named_steps['reduce_dim']"]}],"sklearn\/cluster\/hierarchical.py":[{"add":["921","    >>> agglo.fit(X) # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE"],"delete":["921","    >>> agglo.fit(X) # doctest: +ELLIPSIS"]}],"sklearn\/discriminant_analysis.py":[{"add":["244","    >>> clf.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["244","    >>> clf.fit(X, y)"]}],"doc\/tutorial\/statistical_inference\/model_selection.rst":[{"add":["269","    >>> lasso.fit(X_diabetes, y_diabetes)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["269","    >>> lasso.fit(X_diabetes, y_diabetes)"]}],"sklearn\/preprocessing\/data.py":[{"add":["1090","    >>> transformer  # doctest: +NORMALIZE_WHITESPACE"],"delete":["1090","    >>> transformer"]}],"examples\/plot_changed_only_pprint_parameter.py":[{"add":[],"delete":[]}],"sklearn\/ensemble\/forest.py":[{"add":["958","    >>> clf.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","1210","    >>> regr.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE","1237","    The default value ``max_features=\"auto\"`` uses ``n_features``","1246","    .. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized","1498","    .. [1] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized"],"delete":["958","    >>> clf.fit(X, y)","1210","    >>> regr.fit(X, y)","1237","    The default value ``max_features=\"auto\"`` uses ``n_features`` ","1246","    .. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized ","1498","    .. [1] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized "]}],"doc\/modules\/linear_model.rst":[{"add":["187","    >>> reg.fit([[0, 0], [1, 1]], [0, 1])  # doctest: +NORMALIZE_WHITESPACE","641","    >>> reg.fit(X, Y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["187","    >>> reg.fit([[0, 0], [1, 1]], [0, 1])","641","    >>> reg.fit(X, Y)"]}],"sklearn\/tests\/test_config.py":[{"add":["5","    assert get_config() == {'assume_finite': False, 'working_memory': 1024,","6","                            'print_changed_only': False}","13","        assert get_config() == {'assume_finite': True, 'working_memory': 1024,","14","                                'print_changed_only': False}","38","    assert get_config() == {'assume_finite': False, 'working_memory': 1024,","39","                            'print_changed_only': False}"],"delete":["5","    assert get_config() == {'assume_finite': False, 'working_memory': 1024}","12","        assert get_config() == {'assume_finite': True, 'working_memory': 1024}","36","    assert get_config() == {'assume_finite': False, 'working_memory': 1024}"]}],"sklearn\/utils\/_pprint.py":[{"add":[],"delete":[]}],"doc\/whats_new\/v0.21.rst":[{"add":["202","  :issue:`12344` by :user:`Adrin Jalali <adrinjalali>`.","208","- The `__repr__()` method of all estimators (used when calling","209","  `print(estimator)`) has been entirely re-written, building on Python's","210","  pretty printing standard library. All parameters are printed by default,","211","  but this can be altered with the ``print_changed_only`` option in","212","  :func:`sklearn.set_config`. :issue:`11705` by :user:`Nicolas Hug","213","  <NicolasHug>`.","214",""],"delete":["202","  :pr:`12344` by :user:`Adrin Jalali <adrinjalali>`."]}],"sklearn\/linear_model\/perceptron.py":[{"add":["133","    >>> clf.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE"],"delete":["133","    >>> clf.fit(X, y)"]}]}},"c2f17d0fc0e57a9ed00b895b5f419d956adfc5cf":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/metrics\/pairwise.py":"MODIFY","sklearn\/metrics\/tests\/test_pairwise.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["105",":mod:`sklearn.metrics`","106","......................","107","","108","- |Fix| Fixed a bug in :func:`pairwise.pairwise_distances_argmin_min` which","109","  returned the square root of the distance when the metric parameter was set to","110","  \"euclidean\". :issue:`12481` by :user:`J¨¦r¨¦mie du Boisberranger <jeremiedbb>`.","111",""],"delete":[]}],"sklearn\/metrics\/pairwise.py":[{"add":[],"delete":["360","    if metric == \"euclidean\" and not metric_kwargs.get(\"squared\", False):","361","        np.sqrt(values, values)"]}],"sklearn\/metrics\/tests\/test_pairwise.py":[{"add":["345","    Y = [[-2], [3]]","350","    expected_idx = [0, 1]","351","    expected_vals = [2, 2]","352","    expected_vals_sq = [4, 4]","354","    # euclidean metric","355","    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"euclidean\")","356","    idx2 = pairwise_distances_argmin(X, Y, metric=\"euclidean\")","357","    assert_array_almost_equal(idx, expected_idx)","358","    assert_array_almost_equal(idx2, expected_idx)","359","    assert_array_almost_equal(vals, expected_vals)","361","    idxsp, valssp = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"euclidean\")","362","    assert_array_almost_equal(idxsp, expected_idx)","363","    assert_array_almost_equal(valssp, expected_vals)","365","    assert_equal(type(idxsp), np.ndarray)","366","    assert_equal(type(valssp), np.ndarray)","367","","368","    # euclidean metric squared","369","    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"euclidean\",","370","                                              metric_kwargs={\"squared\": True})","371","    assert_array_almost_equal(idx, expected_idx)","372","    assert_array_almost_equal(vals, expected_vals_sq)","375","    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"manhattan\")","376","    idx2 = pairwise_distances_argmin(X, Y, metric=\"manhattan\")","377","    assert_array_almost_equal(idx, expected_idx)","378","    assert_array_almost_equal(idx2, expected_idx)","379","    assert_array_almost_equal(vals, expected_vals)","380","    # sparse matrix case","381","    idxsp, valssp = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"manhattan\")","382","    assert_array_almost_equal(idxsp, expected_idx)","383","    assert_array_almost_equal(valssp, expected_vals)","386","    idx, vals = pairwise_distances_argmin_min(X, Y, metric=minkowski,","387","                                              metric_kwargs={\"p\": 2})","388","    assert_array_almost_equal(idx, expected_idx)","389","    assert_array_almost_equal(vals, expected_vals)","392","    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"minkowski\",","393","                                              metric_kwargs={\"p\": 2})","394","    assert_array_almost_equal(idx, expected_idx)","395","    assert_array_almost_equal(vals, expected_vals)"],"delete":["345","    Y = [[-1], [2]]","350","    # euclidean metric","351","    D, E = pairwise_distances_argmin_min(X, Y, metric=\"euclidean\")","352","    D2 = pairwise_distances_argmin(X, Y, metric=\"euclidean\")","353","    assert_array_almost_equal(D, [0, 1])","354","    assert_array_almost_equal(D2, [0, 1])","355","    assert_array_almost_equal(D, [0, 1])","356","    assert_array_almost_equal(E, [1., 1.])","359","    Dsp, Esp = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"euclidean\")","360","    assert_array_equal(Dsp, D)","361","    assert_array_equal(Esp, E)","363","    assert_equal(type(Dsp), np.ndarray)","364","    assert_equal(type(Esp), np.ndarray)","367","    D, E = pairwise_distances_argmin_min(X, Y, metric=\"manhattan\")","368","    D2 = pairwise_distances_argmin(X, Y, metric=\"manhattan\")","369","    assert_array_almost_equal(D, [0, 1])","370","    assert_array_almost_equal(D2, [0, 1])","371","    assert_array_almost_equal(E, [1., 1.])","372","    D, E = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"manhattan\")","373","    D2 = pairwise_distances_argmin(Xsp, Ysp, metric=\"manhattan\")","374","    assert_array_almost_equal(D, [0, 1])","375","    assert_array_almost_equal(E, [1., 1.])","378","    D, E = pairwise_distances_argmin_min(X, Y, metric=minkowski,","379","                                         metric_kwargs={\"p\": 2})","380","    assert_array_almost_equal(D, [0, 1])","381","    assert_array_almost_equal(E, [1., 1.])","384","    D, E = pairwise_distances_argmin_min(X, Y, metric=\"minkowski\",","385","                                         metric_kwargs={\"p\": 2})","386","    assert_array_almost_equal(D, [0, 1])","387","    assert_array_almost_equal(E, [1., 1.])"]}]}},"0296916d7d61036eceafa1739599368a9aaf075b":{"changes":{"\/dev\/null":"DELETE","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/cluster\/setup.py":"MODIFY","sklearn\/cluster\/tests\/test_optics.py":"MODIFY","sklearn\/cluster\/optics_.py":"MODIFY"},"diff":{"\/dev\/null":[{"add":[],"delete":[]}],"doc\/whats_new\/v0.21.rst":[{"add":["47","  to set and that scales better, by :user:`Shane <espg>`,","48","  :user:`Adrin Jalali <adrinjalali>`, and :user:`Erich Schubert <kno10>`."],"delete":["47","  to set and that scales better, by :user:`Shane <espg>` and","48","  :user:`Adrin Jalali <adrinjalali>`."]}],"sklearn\/cluster\/setup.py":[{"add":[],"delete":["25","    config.add_extension('_optics_inner',","26","                         sources=['_optics_inner.pyx'],","27","                         include_dirs=[numpy.get_include()],","28","                         libraries=libraries)"]}],"sklearn\/cluster\/tests\/test_optics.py":[{"add":["24","n_points_per_cluster = 50","217","def test_compare_to_ELKI():","218","    # Expected values, computed with (future) ELKI 0.7.5 using:","219","    # java -jar elki.jar cli -dbc.in csv -dbc.filter FixedDBIDsFilter","220","    #   -algorithm clustering.optics.OPTICSHeap -optics.minpts 5","221","    # where the FixedDBIDsFilter gives 0-indexed ids.","222","    r = [np.inf, 0.7865694338710508, 0.4373157299595305, 0.4121908069391695,","223","         0.302907091394212, 0.20815674060999778, 0.20815674060999778,","224","         0.15190193459676368, 0.15190193459676368, 0.28229645104833345,","225","         0.302907091394212, 0.30507239477026865, 0.30820580778767087,","226","         0.3289019667317037, 0.3458462228589966, 0.3458462228589966,","227","         0.2931114364132193, 0.2931114364132193, 0.2562790168458507,","228","         0.23654635530592025, 0.37903448688824876, 0.3920764620583683,","229","         0.4121908069391695, 0.4364542226186831, 0.45523658462146793,","230","         0.458757846268185, 0.458757846268185, 0.4752907412198826,","231","         0.42350366820623375, 0.42350366820623375, 0.42350366820623375,","232","         0.47758738570352993, 0.47758738570352993, 0.4776963110272057,","233","         0.5272079288923731, 0.5591861752070968, 0.5592057084987357,","234","         0.5609913790596295, 0.5909117211348757, 0.5940470220777727,","235","         0.5940470220777727, 0.6861627576116127, 0.687795873252133,","236","         0.7538541412862811, 0.7865694338710508, 0.8038180561910464,","237","         0.8038180561910464, 0.8242451615289921, 0.8548361202185057,","238","         0.8790098789921685, 2.9281214555815764, 1.3256656984284734,","239","         0.19590944671099267, 0.1339924636672767, 0.1137384200258616,","240","         0.061455005237474075, 0.061455005237474075, 0.061455005237474075,","241","         0.045627777293497276, 0.045627777293497276, 0.045627777293497276,","242","         0.04900902556283447, 0.061455005237474075, 0.06225461602815799,","243","         0.06835750467748272, 0.07882900172724974, 0.07882900172724974,","244","         0.07650735397943846, 0.07650735397943846, 0.07650735397943846,","245","         0.07650735397943846, 0.07650735397943846, 0.07113275489288699,","246","         0.07890196345324527, 0.07052683707634783, 0.07052683707634783,","247","         0.07052683707634783, 0.08284027053523288, 0.08725436842020087,","248","         0.08725436842020087, 0.09010229261951723, 0.09128578974358925,","249","         0.09154172670176584, 0.0968576383038391, 0.12007572768323092,","250","         0.12024155806196564, 0.12141990481584404, 0.1339924636672767,","251","         0.13694322786307633, 0.14275793459246572, 0.15093125027309579,","252","         0.17927454395170142, 0.18151803569400365, 0.1906028449191095,","253","         0.1906028449191095, 0.19604486784973194, 0.2096539172540186,","254","         0.2096539172540186, 0.21614333983312325, 0.22036454909290296,","255","         0.23610322103910933, 0.26028003932256766, 0.2607126030060721,","256","         0.2891824876072483, 0.3258089271514364, 0.35968687619960743,","257","         0.4512973330510512, 0.4746141313843085, 0.5958585488429471,","258","         0.6468718886525733, 0.6878453052524358, 0.6911582799500199,","259","         0.7172169499815705, 0.7209874999572031, 0.6326884657912096,","260","         0.5755681293026617, 0.5755681293026617, 0.5755681293026617,","261","         0.6015042225447333, 0.6756244556376542, 0.4722384908959966,","262","         0.08775739179493615, 0.06665303472021758, 0.056308477780164796,","263","         0.056308477780164796, 0.05507767260835565, 0.05368146914586802,","264","         0.05163427719303039, 0.05163427719303039, 0.05163427719303039,","265","         0.04918757627098621, 0.04918757627098621, 0.05368146914586802,","266","         0.05473720349424546, 0.05473720349424546, 0.048442038421760626,","267","         0.048442038421760626, 0.04598840269934622, 0.03984301937835033,","268","         0.04598840269934622, 0.04598840269934622, 0.04303884892957088,","269","         0.04303884892957088, 0.04303884892957088, 0.0431802780806032,","270","         0.0520412490141781, 0.056308477780164796, 0.05080724020124642,","271","         0.05080724020124642, 0.05080724020124642, 0.06385565101399236,","272","         0.05840878369200427, 0.0474472391259039, 0.0474472391259039,","273","         0.04232512684465669, 0.04232512684465669, 0.04232512684465669,","274","         0.0474472391259039, 0.051802632822946656, 0.051802632822946656,","275","         0.05316405104684577, 0.05316405104684577, 0.05840878369200427,","276","         0.06385565101399236, 0.08025248922898705, 0.08775739179493615,","277","         0.08993337040710143, 0.08993337040710143, 0.08993337040710143,","278","         0.08993337040710143, 0.297457175321605, 0.29763608186278934,","279","         0.3415255849656254, 0.34713336941105105, 0.44108940848708167,","280","         0.35942962652965604, 0.35942962652965604, 0.33609522256535296,","281","         0.5008111387107295, 0.5333587622018111, 0.6223243743872802,","282","         0.6793840035409552, 0.7445032492109848, 0.7445032492109848,","283","         0.6556432627279256, 0.6556432627279256, 0.6556432627279256,","284","         0.8196566935960162, 0.8724089149982351, 0.9352758042365477,","285","         0.9352758042365477, 1.0581847953137133, 1.0684332509194163,","286","         1.0887817699873303, 1.2552604310322708, 1.3993856001769436,","287","         1.4869615658197606, 1.6588098267326852, 1.679969559453028,","288","         1.679969559453028, 1.6860509219163458, 1.6860509219163458,","289","         1.1465697826627317, 0.992866533434785, 0.7691908270707519,","290","         0.578131499171622, 0.578131499171622, 0.578131499171622,","291","         0.5754243919945694, 0.8416199360035114, 0.8722493727270406,","292","         0.9156549976203665, 0.9156549976203665, 0.7472322844356064,","293","         0.715219324518981, 0.715219324518981, 0.715219324518981,","294","         0.7472322844356064, 0.820988298336316, 0.908958489674247,","295","         0.9234036745782839, 0.9519521817942455, 0.992866533434785,","296","         0.992866533434785, 0.9995692674695029, 1.0727415198904493,","297","         1.1395519941203158, 1.1395519941203158, 1.1741737271442092,","298","         1.212860115632712, 0.8724097897372123, 0.8724097897372123,","299","         0.8724097897372123, 1.2439272570611581, 1.2439272570611581,","300","         1.3524538390109015, 1.3524538390109015, 1.2982303284415664,","301","         1.3610655849680207, 1.3802783392089437, 1.3802783392089437,","302","         1.4540636953090629, 1.5879329500533819, 1.5909193228826986,","303","         1.72931779186001, 1.9619075944592093, 2.1994355761906257,","304","         2.2508672067362165, 2.274436122235927, 2.417635732260135,","305","         3.014235905390584, 0.30616929141177107, 0.16449675872754976,","306","         0.09071681523805683, 0.09071681523805683, 0.09071681523805683,","307","         0.08727060912039632, 0.09151721189581336, 0.12277953408786725,","308","         0.14285575406641507, 0.16449675872754976, 0.16321992344119793,","309","         0.1330971730344373, 0.11429891993167259, 0.11429891993167259,","310","         0.11429891993167259, 0.11429891993167259, 0.11429891993167259,","311","         0.0945498340011516, 0.11410457435712089, 0.1196414019798306,","312","         0.12925682285016715, 0.12925682285016715, 0.12925682285016715,","313","         0.12864887158869853, 0.12864887158869853, 0.12864887158869853,","314","         0.13369634918690246, 0.14330826543275352, 0.14877705862323184,","315","         0.15203263952428328, 0.15696350160889708, 0.1585326700393211,","316","         0.1585326700393211, 0.16034306786654595, 0.16034306786654595,","317","         0.15053328296567992, 0.16396729418886688, 0.16763548009617293,","318","         0.1732029325454474, 0.21163390061029352, 0.21497664171864372,","319","         0.22125889949299, 0.240251070192081, 0.240251070192081,","320","         0.2413620965310808, 0.26319419022234064, 0.26319419022234064,","321","         0.27989712380504483, 0.2909782800714374]","322","    o = [0, 3, 6, 7, 15, 4, 27, 28, 49, 17, 35, 47, 46, 39, 13, 19,","323","         22, 29, 30, 38, 34, 32, 43, 8, 25, 9, 37, 23, 33, 40, 44, 11, 36, 5,","324","         45, 48, 41, 26, 24, 20, 31, 2, 16, 10, 18, 14, 42, 12, 1, 21, 234,","325","         132, 112, 115, 107, 110, 120, 114, 100, 131, 137, 145, 130, 121, 134,","326","         116, 149, 108, 111, 113, 142, 148, 119, 104, 126, 133, 138, 127, 101,","327","         105, 103, 106, 125, 140, 123, 147, 144, 129, 141, 117, 143, 136, 128,","328","         122, 124, 102, 109, 249, 146, 118, 135, 245, 139, 224, 241, 217, 202,","329","         248, 233, 214, 236, 211, 206, 231, 212, 221, 229, 244, 208, 226, 83,","330","         76, 53, 77, 88, 62, 66, 65, 89, 93, 79, 95, 74, 70, 82, 51, 73, 87,","331","         67, 94, 56, 52, 63, 80, 75, 57, 96, 60, 69, 90, 86, 58, 68, 81, 64,","332","         84, 85, 97, 59, 98, 61, 71, 78, 92, 50, 91, 55, 54, 72, 99, 210, 201,","333","         216, 239, 203, 218, 219, 222, 240, 294, 243, 246, 204, 220, 200, 215,","334","         230, 225, 205, 207, 237, 223, 235, 209, 228, 238, 227, 285, 232, 256,","335","         281, 270, 260, 252, 272, 268, 292, 298, 269, 275, 257, 250, 284, 283,","336","         286, 295, 297, 293, 289, 258, 299, 282, 262, 296, 287, 267, 255, 263,","337","         288, 276, 251, 266, 274, 271, 277, 261, 279, 290, 253, 254, 291, 259,","338","         280, 278, 273, 247, 265, 242, 264, 213, 199, 174, 154, 152, 180, 186,","339","         195, 170, 181, 176, 187, 173, 157, 159, 158, 172, 182, 183, 151, 197,","340","         177, 160, 156, 171, 175, 184, 193, 161, 179, 196, 185, 192, 165, 166,","341","         164, 189, 155, 162, 188, 153, 178, 169, 194, 150, 163, 198, 190, 191,","342","         168, 167]","343","    p = [-1, 0, 3, 6, 7, 15, 15, 27, 27, 4, 7, 49, 47, 4, 39, 39,","344","         19, 19, 29, 30, 30, 13, 6, 43, 34, 32, 32, 25, 23, 23, 23, 3, 11, 46,","345","         46, 45, 9, 38, 33, 26, 26, 8, 20, 33, 0, 18, 18, 2, 18, 44, 0, 234,","346","         132, 112, 115, 107, 107, 120, 114, 114, 114, 114, 107, 100, 100, 134,","347","         134, 149, 149, 108, 108, 108, 148, 113, 104, 104, 104, 142, 127, 127,","348","         126, 138, 126, 148, 127, 148, 127, 112, 147, 116, 117, 101, 145, 128,","349","         128, 122, 136, 136, 249, 102, 102, 118, 143, 146, 245, 123, 139, 241,","350","         241, 217, 248, 202, 248, 224, 231, 212, 212, 212, 229, 229, 226, 83,","351","         76, 53, 53, 88, 62, 66, 66, 66, 93, 93, 79, 93, 70, 82, 82, 73, 87,","352","         73, 94, 56, 56, 56, 63, 67, 53, 96, 96, 96, 69, 86, 58, 58, 81, 81,","353","         81, 58, 64, 64, 59, 59, 86, 69, 78, 83, 84, 55, 55, 55, 72, 50, 201,","354","         210, 216, 203, 203, 219, 54, 240, 239, 240, 236, 236, 220, 220, 220,","355","         217, 139, 243, 243, 204, 211, 246, 215, 223, 294, 209, 227, 227, 209,","356","         281, 270, 260, 252, 272, 272, 272, 298, 269, 298, 275, 275, 284, 283,","357","         283, 283, 284, 286, 283, 298, 299, 260, 260, 250, 299, 258, 258, 296,","358","         250, 276, 276, 276, 289, 289, 267, 267, 279, 261, 277, 277, 258, 266,","359","         290, 209, 207, 290, 228, 278, 228, 290, 199, 174, 154, 154, 154, 186,","360","         186, 180, 170, 174, 187, 173, 157, 159, 157, 157, 159, 183, 183, 172,","361","         197, 160, 160, 171, 171, 171, 151, 173, 184, 151, 196, 185, 185, 179,","362","         179, 189, 177, 165, 175, 162, 164, 181, 169, 169, 181, 178, 178, 178,","363","         168]","364","","366","    # Does NOT work with metric='euclidean', because sklearn euclidean has","367","    # worse numeric precision. 'minkowski' is slower but more accurate.","368","    clust = OPTICS(min_samples=5, metric='minkowski').fit(X)","370","    assert_array_equal(clust.ordering_, np.array(o))","371","    assert_array_equal(clust.predecessor_[clust.ordering_], np.array(p))","372","    assert_allclose(clust.reachability_[clust.ordering_], np.array(r))","373","    # ELKI currently does not print the core distances (which are not used much","374","    # in literature, but we can at least ensure to have this consistency:","375","    for i in clust.ordering_[1:]:","376","        assert (clust.reachability_[i] >=","377","                clust.core_distances_[clust.predecessor_[i]])","390","","391","","392","def test_processing_order():","393","    \"\"\"Early dev version of OPTICS would not consider all unprocessed points,","394","    but only direct neighbors. This tests against this mistake.\"\"\"","395","    Y = [[0], [10], [-10], [25]]","396","    clust = OPTICS(min_samples=3, max_eps=15).fit(Y)","397","    assert_array_equal(clust.reachability_, [np.inf, 10, 10, 15])","398","    assert_array_equal(clust.core_distances_, [10, 15, 20, 25])","399","    assert_array_equal(clust.ordering_, [0, 1, 2, 3])"],"delete":["19","from sklearn.utils import _IS_32BIT","25","n_points_per_cluster = 250","218","def test_reach_dists():","221","    clust = OPTICS(min_samples=10, metric='minkowski').fit(X)","222","","223","    # Expected values, matches 'RD' results from:","224","    # http:\/\/chemometria.us.edu.pl\/download\/optics.py","225","","226","    v = [np.inf, 0.606005, 0.472013, 0.162951, 0.161000, 0.385547, 0.179715,","227","         0.213507, 0.348468, 0.308146, 0.560519, 0.266072, 0.764384, 0.253164,","228","         0.435716, 0.153696, 0.363924, 0.194267, 0.392313, 0.230589, 0.260023,","229","         0.535348, 0.168173, 0.296736, 0.310583, 0.277204, 0.250654, 0.153696,","230","         0.215533, 0.175710, 0.168173, 0.283134, 0.256372, 0.313931, 0.234164,","231","         0.179715, 0.352957, 0.277052, 0.180986, 0.203819, 0.296022, 0.356691,","232","         0.515438, 0.219208, 0.265821, 0.346630, 0.275305, 0.229332, 0.433715,","233","         0.153696, 0.584960, 0.265821, 0.471049, 0.259154, 0.461707, 0.400021,","234","         0.422748, 0.300699, 0.162951, 0.290504, 0.315199, 0.327130, 0.168864,","235","         0.462826, 0.188862, 0.259784, 0.216788, 0.259784, 0.195673, 0.315199,","236","         0.313931, 0.189128, 0.461707, 0.265821, 0.233594, 0.433715, 0.222260,","237","         0.251734, 0.352957, 0.218134, 0.453792, 0.179715, 0.296736, 0.260023,","238","         0.311162, 0.214549, 0.266072, 0.318744, 0.180986, 0.194267, 0.262882,","239","         0.420186, 0.352957, 0.288388, 0.360962, 0.328054, 0.293849, 0.198271,","240","         0.248772, 0.461707, 0.216788, 0.396450, 0.352957, 0.289448, 0.241311,","241","         0.213742, 0.220516, 0.218134, 0.153696, 0.516090, 0.218134, 0.221507,","242","         0.328647, 0.255933, 0.195766, 0.233594, 0.205270, 0.296736, 0.726008,","243","         0.251991, 0.168173, 0.214027, 0.262882, 0.342089, 0.260023, 0.266072,","244","         0.253164, 0.230345, 0.262882, 0.296022, 0.227047, 0.205974, 0.328647,","245","         0.184315, 0.196304, 0.831185, 0.514116, 0.168173, 0.189784, 0.664306,","246","         0.327130, 0.379139, 0.208932, 0.266140, 0.362751, 0.168173, 0.764384,","247","         0.327130, 0.187107, 0.194267, 0.414196, 0.251734, 0.220516, 0.363924,","248","         0.166886, 0.327130, 0.233594, 0.203819, 0.230589, 0.203819, 0.222972,","249","         0.311526, 0.218134, 0.422748, 0.314870, 0.315199, 0.315199, 0.594179,","250","         0.328647, 0.415638, 0.244046, 0.250654, 0.214027, 0.203819, 0.213507,","251","         0.260023, 0.311442, 0.168173, 0.389432, 0.229343, 0.162951, 0.311162,","252","         0.153696, 0.214027, 0.250654, 0.315199, 0.172484, 0.153696, 0.352957,","253","         0.314870, 0.328647, 0.546505, 0.378118, 0.260023, 0.387830, 0.199714,","254","         0.262882, 0.250654, 0.345254, 0.396450, 0.250654, 0.179715, 0.328647,","255","         0.179715, 0.263104, 0.265821, 0.231714, 0.514116, 0.213507, 0.474255,","256","         0.212568, 0.376760, 0.196304, 0.844945, 0.194267, 0.264914, 0.210320,","257","         0.316374, 0.184315, 0.179715, 0.250654, 0.153696, 0.162951, 0.315199,","258","         0.179965, 0.297876, 0.213507, 0.475420, 0.439372, 0.241311, 0.260927,","259","         0.194267, 0.422748, 0.222260, 0.411940, 0.414733, 0.260923, 0.396450,","260","         0.380672, 0.333277, 0.290504, 0.196014, 0.844945, 0.506989, 0.153696,","261","         0.218134, 0.392313, 0.698970, 0.168173, 0.227047, 0.028856, 0.033243,","262","         0.028506, 0.057003, 0.038335, 0.051183, 0.063923, 0.022363, 0.030677,","263","         0.036155, 0.017748, 0.062887, 0.036041, 0.051183, 0.078198, 0.068936,","264","         0.032418, 0.040634, 0.022188, 0.022112, 0.036858, 0.040199, 0.025549,","265","         0.083975, 0.032209, 0.025525, 0.032952, 0.034727, 0.068887, 0.040634,","266","         0.048985, 0.047450, 0.022422, 0.023767, 0.028092, 0.047450, 0.029202,","267","         0.026105, 0.030542, 0.032250, 0.062887, 0.038335, 0.026753, 0.028092,","268","         0.099391, 0.021430, 0.020496, 0.021430, 0.025043, 0.023868, 0.050069,","269","         0.023868, 0.044140, 0.038032, 0.022112, 0.044140, 0.031528, 0.028092,","270","         0.020065, 0.055926, 0.031508, 0.025549, 0.028062, 0.036155, 0.023694,","271","         0.029423, 0.026105, 0.028497, 0.023868, 0.044808, 0.035783, 0.033090,","272","         0.038779, 0.032146, 0.038421, 0.057328, 0.020065, 0.020065, 0.028858,","273","         0.021337, 0.041226, 0.022507, 0.028506, 0.030257, 0.057912, 0.050876,","274","         0.120109, 0.020065, 0.034727, 0.038596, 0.037008, 0.031609, 0.095640,","275","         0.083728, 0.064906, 0.030677, 0.057003, 0.037008, 0.018705, 0.030677,","276","         0.044140, 0.034727, 0.045226, 0.032146, 0.032418, 0.029332, 0.030104,","277","         0.033243, 0.030104, 0.032209, 0.026405, 0.024092, 0.048441, 0.036379,","278","         0.030745, 0.023454, 0.018705, 0.124248, 0.041114, 0.020700, 0.042633,","279","         0.042455, 0.028497, 0.029202, 0.057859, 0.053157, 0.036155, 0.029534,","280","         0.032209, 0.038032, 0.024617, 0.023071, 0.033090, 0.023694, 0.047277,","281","         0.024617, 0.023868, 0.043916, 0.025549, 0.046198, 0.041086, 0.042003,","282","         0.022507, 0.021430, 0.038779, 0.025043, 0.036379, 0.036326, 0.029421,","283","         0.023454, 0.058683, 0.025549, 0.039904, 0.022507, 0.046198, 0.029332,","284","         0.032209, 0.036155, 0.038421, 0.025043, 0.023694, 0.030104, 0.022363,","285","         0.048544, 0.035180, 0.030677, 0.022112, 0.030677, 0.036678, 0.022507,","286","         0.024092, 0.064231, 0.022507, 0.032209, 0.025043, 0.221152, 0.029840,","287","         0.038779, 0.040634, 0.024617, 0.032418, 0.025525, 0.033298, 0.028092,","288","         0.045754, 0.032209, 0.017748, 0.033090, 0.017748, 0.048931, 0.038689,","289","         0.022112, 0.027129, 0.032952, 0.036858, 0.027704, 0.032146, 0.052191,","290","         0.042633, 0.071638, 0.044140, 0.022507, 0.046647, 0.028270, 0.050525,","291","         0.036772, 0.058995, 0.038335, 0.025185, 0.022507, 0.040293, 0.032418,","292","         0.064308, 0.026023, 0.036155, 0.032418, 0.038032, 0.018705, 0.040293,","293","         0.030104, 0.030845, 0.064906, 0.025525, 0.036155, 0.022507, 0.022363,","294","         0.032418, 0.021430, 0.032209, 0.102770, 0.036960, 0.031062, 0.025043,","295","         0.036155, 0.031609, 0.036379, 0.030845, 0.048985, 0.021848, 0.025549,","296","         0.022507, 0.035783, 0.023698, 0.034422, 0.032418, 0.022507, 0.023868,","297","         0.020065, 0.023694, 0.040634, 0.055633, 0.054549, 0.044662, 0.087660,","298","         0.048066, 0.143571, 0.068669, 0.065049, 0.076927, 0.044359, 0.041577,","299","         0.052364, 0.100317, 0.062146, 0.067578, 0.054549, 0.047239, 0.062809,","300","         0.033917, 0.087660, 0.077113, 0.055633, 0.061854, 0.059756, 0.059537,","301","         0.052364, 0.060347, 0.170251, 0.108492, 0.046370, 0.070684, 0.049589,","302","         0.044662, 0.049013, 0.043303, 0.069573, 0.075044, 0.054354, 0.065072,","303","         0.073135, 0.046126, 0.055569, 0.047239, 0.062146, 0.056093, 0.059986,","304","         0.096182, 0.100317, 0.051649, 0.054354, 0.077420, 0.100317, 0.046370,","305","         0.043303, 0.045845, 0.061422, 0.091580, 0.206234, 0.051405, 0.071684,","306","         0.061574, 0.063666, 0.052692, 0.051649, 0.100124, 0.077909, 0.033917,","307","         0.058680, 0.044359, 0.065498, 0.080214, 0.123231, 0.052957, 0.056582,","308","         0.061540, 0.076794, 0.043303, 0.054884, 0.044359, 0.145249, 0.081741,","309","         0.041577, 0.056093, 0.076799, 0.044359, 0.068483, 0.051649, 0.092275,","310","         0.044359, 0.108492, 0.092275, 0.046126, 0.106422, 0.054354, 0.052957,","311","         0.073329, 0.046126, 0.086402, 0.048194, 0.128569, 0.104042, 0.061854,","312","         0.069573, 0.070035, 0.050346, 0.043303, 0.053576, 0.054549, 0.033917,","313","         0.063666, 0.058680, 0.099130, 0.080198, 0.050118, 0.054549, 0.041577,","314","         0.143571, 0.095965, 0.047643, 0.052364, 0.105168, 0.048685, 0.043303,","315","         0.052814, 0.076927, 0.054549, 0.041577, 0.066657, 0.189930, 0.046370,","316","         0.075044, 0.121331, 0.043303, 0.223897, 0.198621, 0.150328, 0.100317,","317","         0.053576, 0.070708, 0.100898, 0.047239, 0.043613, 0.065049, 0.049146,","318","         0.068669, 0.055569, 0.062124, 0.096408, 0.044662, 0.087660, 0.083012,","319","         0.050118, 0.069573, 0.046126, 0.049146, 0.049146, 0.050808, 0.080198,","320","         0.059986, 0.071974, 0.047239, 0.050808, 0.059986, 0.065850, 0.044863,","321","         0.052814, 0.044359, 0.052364, 0.108492, 0.143571, 0.050926, 0.049146,","322","         0.049146, 0.055569, 0.033917, 0.527659, 0.143547, 0.077113, 0.046126,","323","         0.106422, 0.068669, 0.108492, 0.063666, 0.054549, 0.054884, 0.056907,","324","         0.068669, 0.080198, 0.120887, 0.054549, 0.052692, 0.085801, 0.054884,","325","         0.050808, 0.094595, 0.059545, 0.054354, 0.062124, 0.087660, 0.052814,","326","         0.086715, 0.146253, 0.046370, 0.041577, 0.116083, 0.076927, 0.047239,","327","         0.084375, 0.134652, 0.217969, 0.063559, 0.061540, 0.044662, 0.054354,","328","         0.063666, 0.145466, 0.101700, 0.090491, 0.078536, 0.054884, 0.062124,","329","         0.041577, 0.043303, 0.194473, 0.079780, 0.059704, 0.054780, 0.048194,","330","         0.062146, 0.069573, 0.086898, 0.046675, 0.056258, 0.074141, 0.048066,","331","         0.052957, 0.057982, 0.058966, 0.061048, 0.050885, 0.049146, 0.080993,","332","         0.056093, 0.061854, 0.124025, 0.062146, 0.060906, 0.150328, 0.058680,","333","         0.077420, 0.051800, 0.102359, 0.113301, 0.073096, 0.116715, 0.131476,","334","         0.140601, 0.097667, 0.051800, 0.051800, 0.127964, 0.108870, 0.111926,","335","         0.093532, 0.102390, 0.144266, 0.098271, 0.102541, 0.136497, 0.127964,","336","         0.085569, 0.157863, 0.096739, 0.054008, 0.106219, 0.076838, 0.099076,","337","         0.093532, 0.059861, 0.079975, 0.116715, 0.133625, 0.053641, 0.066110,","338","         0.122302, 0.081313, 0.140601, 0.259889, 0.094437, 0.098271, 0.105776,","339","         0.225742, 0.100097, 0.147592, 0.099076, 0.093128, 0.093532, 0.134946,","340","         0.133625, 0.120869, 0.065932, 0.103395, 0.125172, 0.147842, 0.105278,","341","         0.173584, 0.168241, 0.111524, 0.093532, 0.099076, 0.100426, 0.137132,","342","         0.065356, 0.091108, 0.141202, 0.054008, 0.075298, 0.073717, 0.122817,","343","         0.105278, 0.094437, 0.067080, 0.108530, 0.115467, 0.093532, 0.085569,","344","         0.145180, 0.100426, 0.116715, 0.151726, 0.073096, 0.193781, 0.090614,","345","         0.081162, 0.051800, 0.133625, 0.136497, 0.100670, 0.081313, 0.506893,","346","         0.084567, 0.108530, 0.087353, 0.063184, 0.123639, 0.168333, 0.314422,","347","         0.091108, 0.079975, 0.091108, 0.136497, 0.122302, 0.167297, 0.067080,","348","         0.144266, 0.065932, 0.087667, 0.100426, 0.099460, 0.091108, 0.100637,","349","         0.116715, 0.079975, 0.077977, 0.090340, 0.136723, 1.943026, 0.108870,","350","         0.090340, 0.065932, 0.102245, 0.157863, 0.157863, 0.215574, 0.156830,","351","         0.093532, 0.122302, 0.097667, 0.063000, 0.116715, 0.076838, 0.148372,","352","         0.093532, 0.099076, 0.141202, 0.096505, 0.096739, 0.091108, 0.099076,","353","         0.079975, 0.108870, 0.102390, 0.079975, 0.244121, 0.167071, 0.096739,","354","         0.102390, 0.103395, 0.073096, 0.094887, 0.065932, 0.190667, 0.099460,","355","         0.102390, 0.096739, 0.102390, 0.116715, 0.100637, 0.256554, 0.103395,","356","         0.081313, 0.068962, 0.109645, 0.059364, 0.147842, 0.099460, 0.079262,","357","         0.099460, 0.065932, 0.123687, 0.090614, 0.131352, 0.098271, 0.102541,","358","         0.098983, 0.057224, 0.074797, 0.057224, 0.250559, 0.079975, 0.103395,","359","         0.100426, 0.065932, 0.120661, 0.079262, 0.065932, 0.118665, 0.081162,","360","         0.066283, 0.099076, 0.102359, 0.108530, 0.079975, 0.168333, 0.096739,","361","         0.168333, 0.097008, 0.055288, 0.172411, 0.092801, 0.051800, 0.102541,","362","         0.084567, 0.054008, 0.090991, 0.172411, 0.057224, 0.148396, 0.200965,","363","         0.076838, 0.157863, 0.053535, 0.121919, 0.126609, 0.123890, 0.118081,","364","         0.097008, 0.125311, 0.099460, 0.122302, 0.134946, 0.080975, 0.084567,","365","         0.110093, 0.102245, 0.103395, 0.171601, 0.094887, 0.126240, 0.137742,","366","         0.099954, 0.108530, 0.157863, 0.096739, 0.051800, 0.127964, 0.066110,","367","         0.061021, 0.105147, 0.100426, 0.079975, 0.088187, 0.116421, 0.076838,","368","         0.098271, 0.116715, 0.137656, 0.075298, 0.148396, 0.112166, 1.083905,","369","         0.326598, 0.428987, 0.395963, 0.224541, 0.326598, 0.030677, 0.410454,","370","         0.122771, 1.140305, 0.641074, 0.432159, 0.429335, 0.422908, 0.461926,","371","         0.293083, 0.477078, 0.714856, 0.515861, 0.405418, 0.054354, 0.341177,","372","         0.410008, 0.514245, 0.641074, 0.816459, 0.455115, 0.400707, 0.382240,","373","         0.431832, 1.618970, 0.683953, 0.182992, 0.763699, 0.515861, 0.717145,","374","         0.409629, 0.074134, 0.398273, 0.864974, 0.400707, 0.591403, 0.435354,","375","         0.514245, 1.337152, 0.841077, 0.410008, 0.683953, 0.338649, 0.557595,","376","         0.442092, 0.326598, 0.984189, 0.429608, 0.395963, 1.152055, 0.587222,","377","         1.748492, 0.477078, 0.395459, 0.717145, 0.575811, 0.210115, 0.487785,","378","         0.431832, 0.383852, 0.806708, 0.428987, 0.278405, 0.395963, 0.395459,","379","         0.383852, 1.083905, 0.428510, 0.326598, 0.108492, 0.541644, 0.612110,","380","         0.382240, 0.833511, 0.382240, 0.456628, 0.326598, 0.458880, 0.398273,","381","         0.957748, 0.326598, 0.295049, 0.629646, 0.429765, 0.439942, 0.633617,","382","         0.566297, 0.429335, 0.086507, 0.477078, 0.526753, 0.375240, 0.584436,","383","         0.355776, 0.395963, 0.644924, 0.129793, 0.484880, 0.470001, 0.572306,","384","         0.383852, 1.110081, 0.841077, 0.395963, 0.683953, 0.428745, 0.387752,","385","         0.545299, 0.686537, 0.635219, 0.840499, 0.527659, 0.400707, 0.480982,","386","         0.541644, 0.714856, 0.942673, 0.398273, 0.428987, 0.356781, 0.428510,","387","         1.140961, 0.395963, 0.356781, 0.410454, 0.541644, 0.641074, 0.484778,","388","         0.410008, 0.433108, 0.278405, 0.278405, 0.503141, 0.428745, 0.125103,","389","         0.633617, 0.410454, 0.124025, 0.461926, 0.398273, 0.410008, 1.181303,","390","         0.635219, 0.593537, 0.395963, 0.717145, 0.409629, 0.492595, 0.806708,","391","         0.503820, 0.423834, 0.557595, 0.429335, 0.470749, 0.461926, 1.890036,","392","         0.236343, 0.806708, 0.123561, 0.433744, 0.427348, 0.427348, 0.962234,","393","         0.395963, 0.409629, 0.527659, 0.425727, 0.602549, 0.901331, 0.326598,","394","         0.635949, 0.541644, 0.375240, 0.598969, 1.140961, 0.391998, 0.719443,","395","         0.410008, 0.515861, 0.714856, 0.842273, 0.410454, 0.389377, 0.431078,","396","         0.515861, 0.515861, 0.429335, 0.332495, 0.398273, 0.428987, 0.635219,","397","         0.387752, 0.384289, 0.383852, 0.430504, 0.428510, 0.431832, 0.375240,","398","         0.278405, 0.374102, 0.428745, 0.692878, 1.152055, 0.503820, 0.428745,","399","         0.352868, 0.429335, 0.375240, 0.400707, 0.427348, 0.256183, 0.962234,","400","         0.505376, 0.058995, 0.410454, 0.172880, 0.395963, 0.470749, 0.356781,","401","         1.332700, 0.683953, 0.395963, 0.806708, 0.400707, 0.330982, 0.427731,","402","         0.934845, 0.375240, 0.191534, 0.047239, 1.083905, 0.348794, 0.409708,","403","         0.503820, 0.557595, 0.429335, 0.498780, 0.293083, 0.363069, 0.442092,","404","         1.152055, 0.375240, 0.335677, 0.452443, 0.655156, 0.929928, 0.614869,","405","         1.411031, 1.101132, 0.469030, 0.404976, 0.538209, 0.655828, 0.674748,","406","         0.365182, 0.641612, 0.555434, 0.521651, 0.386679, 0.386679, 0.980304,","407","         0.659111, 0.651366, 0.538209, 0.521651, 0.884780, 1.287829, 0.558322,","408","         0.446161, 0.817970, 0.568499, 0.533507, 0.639746, 0.484404, 0.591751,","409","         0.913016, 0.446161, 0.533907, 0.606885, 0.672320, 1.150642, 0.655828,","410","         0.365182, 0.665088, 1.094242, 0.629401, 0.540676, 0.733026, 1.248265,","411","         1.273499, 0.867854, 0.538656, 0.386679, 0.922273, 0.515686, 1.321022,","412","         0.624444, 0.655828, 0.922273, 0.386679, 0.762191, 0.779432, 0.601851,","413","         0.655156, 0.926213, 0.762191, 0.641612, 0.558322, 1.025370, 0.641067,","414","         0.651366, 0.633434, 0.459580, 0.859221, 0.552291, 0.591751, 0.819965,","415","         0.669977, 1.185083, 0.499338, 0.533907, 0.752871, 0.571388, 0.539772,","416","         0.449182, 1.025370, 0.365182, 1.321022, 0.926213, 0.886360, 0.562272,","417","         0.669977, 0.796046, 0.557598, 0.596776, 0.672336, 0.659111, 0.453719,","418","         0.477716, 0.477716, 1.592069, 0.591751, 0.539772, 0.641612, 0.946254,","419","         0.744165, 0.386679, 0.593825, 0.539772, 0.449182, 0.604273, 0.794951,","420","         0.752871, 0.539772, 0.648732, 0.469030, 0.665088, 1.332700, 1.341388,","421","         0.533507, 0.544212, 1.025992, 0.645967, 0.612945, 0.868492, 0.648732,","422","         0.752300, 0.624444, 1.219748, 0.446161, 0.520818, 0.469044, 0.669977,","423","         0.926213, 0.638752, 0.762191, 0.922273, 0.794951, 0.606885, 0.669977,","424","         0.550113, 0.641067, 0.733026, 0.604273, 0.648732, 0.533507, 0.746506,","425","         0.733026, 0.980683, 0.538209, 0.669977, 0.469030, 0.648732, 0.609190,","426","         1.219748, 0.373113, 0.539772, 1.744047, 1.004716, 0.926213, 0.562272,","427","         0.752871, 0.538656, 0.449182, 0.365182, 0.469030, 0.446161, 0.484404,","428","         0.768592, 0.648732, 0.655156, 0.521651, 0.779432, 0.446161, 0.596776,","429","         0.538209, 0.726740, 0.539772, 0.469030, 0.521651, 0.561950, 0.601851,","430","         0.533907, 0.922273, 1.248265, 0.476800, 0.737990, 0.817970, 0.792127,","431","         0.533907, 0.486038, 0.624444, 0.798241, 0.476800, 1.059373, 0.645967,","432","         0.619940, 0.528726, 0.669977, 0.865406, 0.980683, 0.980683, 0.834671,","433","         1.001353, 0.752871, 0.449182, 1.096520, 0.449182, 0.593825, 0.636558,","434","         0.762191, 0.638591, 0.538209, 0.865406, 0.779432, 0.469044, 0.645967,","435","         0.557598, 0.499338, 0.484404, 0.515686, 0.794951, 0.619456, 0.733026,","436","         0.821769, 0.752300, 0.643302, 0.636558, 0.655156, 0.655156, 0.484404,","437","         0.648732, 0.726023, 0.365182, 0.606885, 0.499338, 0.520818, 0.612945,","438","         0.446161, 0.557598, 0.469044, 1.134650, 0.629401, 0.538656, 0.561950,","439","         1.364861, 0.459580, 1.025370, 0.980304, 0.607592, 0.533907, 1.134650,","440","         0.446161, 0.629962]","441","","442","    # FIXME: known failure in 32bit Linux; numerical imprecision results in","443","    # different ordering in quick_scan","444","    if _IS_32BIT:  # pragma: no cover","445","        assert_allclose(clust.reachability_, np.array(v), rtol=1e-2)","446","    else:","447","        # we compare to truncated decimals, so use atol","448","        assert_allclose(clust.reachability_, np.array(v), atol=1e-5)"]}],"sklearn\/cluster\/optics_.py":[{"add":["38","    This implementation deviates from the original OPTICS by first performing","39","    k-nearest-neighborhood searches on all points to identify core sizes, then","40","    computing only the distances to unprocessed points when constructing the","41","    cluster order. It also does not employ a heap to manage the expansion","42","    candiates, but rather uses numpy masked arrays. This can be potentially","43","    slower with some parameters (at the benefit from using fast numpy code).","44","","198","    This implementation deviates from the original OPTICS by first performing","199","    k-nearest-neighborhood searches on all points to identify core sizes, then","200","    computing only the distances to unprocessed points when constructing the","201","    cluster order.","202","","326","        The cluster ordered list of sample indices.","334","        Point that a sample was reached from, indexed by object order.","529","        # Choose next based on smallest reachability distance","530","        # (And prefer smaller ids on ties).","531","        # All unprocessed points qualify, not just new neighbors (\"unproc\")","532","        return (np.ma.array(self.reachability_, mask=processed)","533","                .argmin(fill_value=np.inf))"],"delete":["22","from ._optics_inner import quick_scan","315","        The cluster ordered list of sample indices","323","        Point that a sample was reached from.","518","        # Define return order based on reachability distance","519","        return (unproc[quick_scan(np.take(self.reachability_, unproc),","520","                                  dists)])"]}]}},"042843a2ddf72441ac60234016b0e2b362ecc92c":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/preprocessing\/tests\/test_data.py":"MODIFY","sklearn\/preprocessing\/data.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["151","- |Fix| Fixed a bug in :class:`preprocessing.PowerTransformer` where the","152","  Yeo-Johnson transform was incorrect for lambda parameters outside of `[0, 2]`","153","  :issue:`12522` by :user:`Nicolas Hug<NicolasHug>`.","154",""],"delete":[]}],"sklearn\/preprocessing\/tests\/test_data.py":[{"add":["2347","def test_yeo_johnson_darwin_example():","2348","    # test from original paper \"A new family of power transformations to","2349","    # improve normality or symmetry\" by Yeo and Johnson.","2350","    X = [6.1, -8.4, 1.0, 2.0, 0.7, 2.9, 3.5, 5.1, 1.8, 3.6, 7.0, 3.0, 9.3,","2351","         7.5, -6.0]","2352","    X = np.array(X).reshape(-1, 1)","2353","    lmbda = PowerTransformer(method='yeo-johnson').fit(X).lambdas_","2354","    assert np.allclose(lmbda, 1.305, atol=1e-3)","2355","","2356",""],"delete":[]}],"sklearn\/preprocessing\/data.py":[{"add":["2539","    [ 1.38668178 -3.10053309]","2721","        x_inv = np.zeros_like(x)","2725","        if abs(lmbda) < np.spacing(1.):","2731","        if abs(lmbda - 2) > np.spacing(1.):","2744","        out = np.zeros_like(x)","2748","        if abs(lmbda) < np.spacing(1.):","2749","            out[pos] = np.log1p(x[pos])","2754","        if abs(lmbda - 2) > np.spacing(1.):","2757","            out[~pos] = -np.log1p(-x[~pos])","2786","            loglike = -n_samples \/ 2 * np.log(x_trans.var())","2787","            loglike += (lmbda - 1) * (np.sign(x) * np.log1p(np.abs(x))).sum()"],"delete":["2539","    [1.38668178e+00 5.93926346e-09]","2720","","2721","        Notes","2722","        -----","2723","        We're comparing lmbda to 1e-19 instead of strict equality to 0. See","2724","        scipy\/special\/_boxcox.pxd for a rationale behind this","2726","        x_inv = np.zeros(x.shape, dtype=x.dtype)","2730","        if lmbda < 1e-19:","2736","        if lmbda < 2 - 1e-19:","2747","","2748","        Notes","2749","        -----","2750","        We're comparing lmbda to 1e-19 instead of strict equality to 0. See","2751","        scipy\/special\/_boxcox.pxd for a rationale behind this","2754","        out = np.zeros(shape=x.shape, dtype=x.dtype)","2758","        if lmbda < 1e-19:","2759","            out[pos] = np.log(x[pos] + 1)","2764","        if lmbda < 2 - 1e-19:","2767","            out[~pos] = -np.log(-x[~pos] + 1)","2796","            # Estimated mean and variance of the normal distribution","2797","            est_mean = x_trans.sum() \/ n_samples","2798","            est_var = np.power(x_trans - est_mean, 2).sum() \/ n_samples","2799","","2800","            loglike = -n_samples \/ 2 * np.log(est_var)","2801","            loglike += (lmbda - 1) * (np.sign(x) * np.log(np.abs(x) + 1)).sum()"]}]}},"774f1aa0e767824c37b332e989146c8d6a3ee7a2":{"changes":{"sklearn\/externals\/joblib\/memory.py":"MODIFY"},"diff":{"sklearn\/externals\/joblib\/memory.py":[{"add":["517","        return (self.__class__, (self.func, None),","518","                {k: v for k, v in vars(self).items()","519","                 if k not in ('timestamp', 'func')})","799","","800","        cachedir: str or None, optional","801","","802","            .. deprecated: 0.12","803","                'cachedir' has been deprecated in 0.12 and will be","804","                removed in 0.14. Use the 'location' parameter instead.","810","    def __init__(self, location=None, backend='local', mmap_mode=None,","811","                 compress=False, verbose=1, bytes_limit=None,","812","                 backend_options={}, cachedir=None):","943","        return (self.__class__, (), {k: v for k, v in vars(self).items()","944","                                     if k != 'timestamp'})"],"delete":["517","        return (self.__class__, (self.func, self.store_backend, self.ignore,","518","                self.mmap_mode, self.compress, self._verbose))","777","        cachedir: str or None, optional","778","","779","            .. deprecated: 0.12","780","                'cachedir' has been deprecated in 0.12 and will be","781","                removed in 0.14. Use the 'location' parameter instead.","782","","809","    def __init__(self, location=None, backend='local', cachedir=None,","810","                 mmap_mode=None, compress=False, verbose=1, bytes_limit=None,","811","                 backend_options={}):","942","        # We need to remove 'joblib' from the end of cachedir","943","        location = (repr(self.store_backend)[:-7]","944","                    if self.store_backend is not None else None)","945","        compress = self.store_backend.compress \\","946","            if self.store_backend is not None else False","947","        return (self.__class__, (location, self.backend, self.mmap_mode,","948","                                 compress, self._verbose))"]}]}},"0b85b0a922fc7e0c9b8f5dea1caf026cd9a75a57":{"changes":{"sklearn\/preprocessing\/data.py":"MODIFY"},"diff":{"sklearn\/preprocessing\/data.py":[{"add":["2539","    [ 1.386... -3.100...]","2541","    [[-1.316... -0.707...]","2542","     [ 0.209... -0.707...]","2543","     [ 1.106...  1.414...]]"],"delete":["2539","    [ 1.38668178 -3.10053309]","2541","    [[-1.31616039 -0.70710678]","2542","     [ 0.20998268 -0.70710678]","2543","     [ 1.1061777   1.41421356]]"]}]}},"5d236e80237d92b8af4b4715db91671aeea6414e":{"changes":{"sklearn\/linear_model\/cd_fast.pyx":"MODIFY"},"diff":{"sklearn\/linear_model\/cd_fast.pyx":[{"add":["143","def enet_coordinate_descent(np.ndarray[floating, ndim=1, mode='c'] w,","310","def sparse_enet_coordinate_descent(floating [::1] w,","530","def enet_coordinate_descent_gram(floating[::1] w,","531","                                 floating alpha, floating beta,"],"delete":["143","def enet_coordinate_descent(np.ndarray[floating, ndim=1] w,","310","def sparse_enet_coordinate_descent(floating [:] w,","530","def enet_coordinate_descent_gram(floating[:] w, floating alpha, floating beta,"]}]}},"7f5aa85db6ce8a0204c9efc996a3c03378a94b15":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/neighbors\/dist_metrics.pyx":"MODIFY","sklearn\/neighbors\/tests\/test_dist_metrics.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["14","Changed models","15","--------------","16","","17","The following estimators and functions, when fit with the same data and","18","parameters, may produce different models from the previous version. This often","19","occurs due to changes in the modelling logic (bug fixes or enhancements), or in","20","random sampling procedures.","21","","22","- :mod:`sklearn.neighbors` when ``metric=='jaccard'`` (bug fix)","23","","34",":mod:`sklearn.neighbors`","35","........................","36","","37","- |Fix| Fixed :class:`sklearn.neighbors.DistanceMetric` jaccard distance","38","  function to return 0 when two all-zero vectors are compared.","39","  :issue:`12685` by :user:`Thomas Fan <thomasjpfan>`."],"delete":[]}],"sklearn\/neighbors\/dist_metrics.pyx":[{"add":["790","        # Based on https:\/\/github.com\/scipy\/scipy\/pull\/7373","791","        # When comparing two all-zero vectors, scipy>=1.2.0 jaccard metric","792","        # was changed to return 0, instead of nan.","793","        if nnz == 0:","794","            return 0"],"delete":[]}],"sklearn\/neighbors\/tests\/test_dist_metrics.py":[{"add":["8","from distutils.version import LooseVersion","9","from scipy import __version__ as scipy_version","105","    # Based on https:\/\/github.com\/scipy\/scipy\/pull\/7373","106","    # When comparing two all-zero vectors, scipy>=1.2.0 jaccard metric","107","    # was changed to return 0, instead of nan.","108","    if metric == 'jaccard' and LooseVersion(scipy_version) < '1.2.0':","109","        D_true[np.isnan(D_true)] = 0"],"delete":[]}]}},"90570ab0319c39ad89ea94ce1884ffefb6c79090":{"changes":{"sklearn\/tree\/_splitter.pxd":"MODIFY","sklearn\/tree\/_criterion.pyx":"MODIFY","sklearn\/tree\/_criterion.pxd":"MODIFY","sklearn\/tree\/_tree.pyx":"MODIFY","sklearn\/tree\/_utils.pxd":"MODIFY","sklearn\/tree\/_splitter.pyx":"MODIFY"},"diff":{"sklearn\/tree\/_splitter.pxd":[{"add":["0","# cython: language_level=3","1","","18","from ._tree cimport DTYPE_t          # Type of X","19","from ._tree cimport DOUBLE_t         # Type of y, sample_weight","20","from ._tree cimport SIZE_t           # Type for indices and counters","21","from ._tree cimport INT32_t          # Signed 32 bit integer","22","from ._tree cimport UINT32_t         # Unsigned 32 bit integer","64","    cdef const DOUBLE_t[:, ::1] y","84","    cdef int init(self, object X, const DOUBLE_t[:, ::1] y,"],"delete":["16","ctypedef np.npy_float32 DTYPE_t          # Type of X","17","ctypedef np.npy_float64 DOUBLE_t         # Type of y, sample_weight","18","ctypedef np.npy_intp SIZE_t              # Type for indices and counters","19","ctypedef np.npy_int32 INT32_t            # Signed 32 bit integer","20","ctypedef np.npy_uint32 UINT32_t          # Unsigned 32 bit integer","62","    cdef DOUBLE_t* y","63","    cdef SIZE_t y_stride","83","    cdef int init(self, object X, np.ndarray y,"]}],"sklearn\/tree\/_criterion.pyx":[{"add":["53","    cdef int init(self, const DOUBLE_t[:, ::1] y, DOUBLE_t* sample_weight,","278","    cdef int init(self, const DOUBLE_t[:, ::1] y,","336","                c = <SIZE_t> self.y[i, k]","445","                    label_index = k * self.sum_stride + <SIZE_t> self.y[i, k]","460","                    label_index = k * self.sum_stride + <SIZE_t> self.y[i, k]","739","    cdef int init(self, const DOUBLE_t[:, ::1] y, DOUBLE_t* sample_weight,","771","                y_ik = self.y[i, k]","837","                    sum_left[k] += w * self.y[i, k]","850","                    sum_left[k] -= w * self.y[i, k]","937","        cdef DOUBLE_t y_ik","954","                y_ik = self.y[i, k]","1023","    cdef int init(self, const DOUBLE_t[:, ::1] y, DOUBLE_t* sample_weight,","1062","                (<WeightedMedianCalculator> right_child[k]).push(self.y[i, k], w)","1167","                    (<WeightedMedianCalculator> right_child[k]).remove(self.y[i, k], w)","1169","                    (<WeightedMedianCalculator> left_child[k]).push(self.y[i, k], w)","1183","                    (<WeightedMedianCalculator> left_child[k]).remove(self.y[i, k], w)","1184","                    (<WeightedMedianCalculator> right_child[k]).push(self.y[i, k], w)","1217","                impurity += fabs(self.y[i, k] - self.node_medians[k]) * w","1252","                impurity_left += fabs(self.y[i, k] - median) * w","1264","                impurity_right += fabs(self.y[i, k] - median) * w"],"delete":["53","    cdef int init(self, DOUBLE_t* y, SIZE_t y_stride, DOUBLE_t* sample_weight,","65","        y_stride : SIZE_t","66","            y_stride is used to index the kth output value as follows:","67","            y[i, k] = y[i * y_stride + k]","226","        self.y = NULL","227","        self.y_stride = 0","283","    cdef int init(self, DOUBLE_t* y, SIZE_t y_stride,","296","        y_stride : SIZE_t","297","            The stride between elements in the buffer, important if there","298","            are multiple targets (multi-output)","312","        self.y_stride = y_stride","345","                c = <SIZE_t> y[i * y_stride + k]","420","        cdef DOUBLE_t* y = self.y","455","                    label_index = (k * self.sum_stride +","456","                                   <SIZE_t> y[i * self.y_stride + k])","471","                    label_index = (k * self.sum_stride +","472","                                   <SIZE_t> y[i * self.y_stride + k])","716","        self.y = NULL","717","        self.y_stride = 0","753","    cdef int init(self, DOUBLE_t* y, SIZE_t y_stride, DOUBLE_t* sample_weight,","760","        self.y_stride = y_stride","786","                y_ik = y[i * y_stride + k]","829","        cdef DOUBLE_t* y = self.y","836","        cdef DOUBLE_t y_ik","854","                    y_ik = y[i * self.y_stride + k]","855","                    sum_left[k] += w * y_ik","868","                    y_ik = y[i * self.y_stride + k]","869","                    sum_left[k] -= w * y_ik","949","","950","        cdef DOUBLE_t* y = self.y","966","        cdef DOUBLE_t y_ik","975","                y_ik = y[i * self.y_stride + k]","1016","        self.y = NULL","1017","        self.y_stride = 0","1046","    cdef int init(self, DOUBLE_t* y, SIZE_t y_stride, DOUBLE_t* sample_weight,","1053","        cdef DOUBLE_t y_ik","1058","        self.y_stride = y_stride","1084","                y_ik = y[i * y_stride + k]","1085","","1089","                (<WeightedMedianCalculator> right_child[k]).push(y_ik, w)","1174","        cdef DOUBLE_t* y = self.y","1179","        cdef DOUBLE_t y_ik","1195","                    y_ik = y[i * self.y_stride + k]","1197","                    (<WeightedMedianCalculator> right_child[k]).remove(y_ik, w)","1199","                    (<WeightedMedianCalculator> left_child[k]).push(y_ik, w)","1212","                    y_ik = y[i * self.y_stride + k]","1214","                    (<WeightedMedianCalculator> left_child[k]).remove(y_ik, w)","1215","                    (<WeightedMedianCalculator> right_child[k]).push(y_ik, w)","1235","        cdef DOUBLE_t* y = self.y","1239","        cdef DOUBLE_t y_ik","1247","                y_ik = y[i * self.y_stride + k]","1248","","1252","                impurity += fabs(y_ik - self.node_medians[k]) * w","1263","        cdef DOUBLE_t* y = self.y","1272","        cdef DOUBLE_t y_ik","1286","                y_ik = y[i * self.y_stride + k]","1287","","1291","                impurity_left += fabs(y_ik - median) * w","1300","                y_ik = y[i * self.y_stride + k]","1301","","1305","                impurity_right += fabs(y_ik - median) * w"]}],"sklearn\/tree\/_criterion.pxd":[{"add":["0","# cython: language_level=3","15","from ._tree cimport DTYPE_t          # Type of X","16","from ._tree cimport DOUBLE_t         # Type of y, sample_weight","17","from ._tree cimport SIZE_t           # Type for indices and counters","18","from ._tree cimport INT32_t          # Signed 32 bit integer","19","from ._tree cimport UINT32_t         # Unsigned 32 bit integer","27","    cdef const DOUBLE_t[:, ::1] y        # Values of y","55","    cdef int init(self, const DOUBLE_t[:, ::1] y, DOUBLE_t* sample_weight,"],"delete":["14","ctypedef np.npy_float32 DTYPE_t          # Type of X","15","ctypedef np.npy_float64 DOUBLE_t         # Type of y, sample_weight","16","ctypedef np.npy_intp SIZE_t              # Type for indices and counters","17","ctypedef np.npy_int32 INT32_t            # Signed 32 bit integer","18","ctypedef np.npy_uint32 UINT32_t          # Unsigned 32 bit integer","26","    cdef DOUBLE_t* y                     # Values of y","27","    cdef SIZE_t y_stride                 # Stride in y (since n_outputs >= 1)","55","    cdef int init(self, DOUBLE_t* y, SIZE_t y_stride, DOUBLE_t* sample_weight,"]}],"sklearn\/tree\/_tree.pyx":[{"add":["795","        cdef DTYPE_t[:, :] X_ndarray = X","812","                    if X_ndarray[i, node.feature] <= node.threshold:","915","        cdef DTYPE_t[:, :] X_ndarray = X","942","                    if X_ndarray[i, node.feature] <= node.threshold:"],"delete":["795","        cdef np.ndarray X_ndarray = X","796","        cdef DTYPE_t* X_ptr = <DTYPE_t*> X_ndarray.data","797","        cdef SIZE_t X_sample_stride = <SIZE_t> X.strides[0] \/ <SIZE_t> X.itemsize","798","        cdef SIZE_t X_fx_stride = <SIZE_t> X.strides[1] \/ <SIZE_t> X.itemsize","815","                    if X_ptr[X_sample_stride * i +","816","                             X_fx_stride * node.feature] <= node.threshold:","919","        cdef np.ndarray X_ndarray = X","920","        cdef DTYPE_t* X_ptr = <DTYPE_t*> X_ndarray.data","921","        cdef SIZE_t X_sample_stride = <SIZE_t> X.strides[0] \/ <SIZE_t> X.itemsize","922","        cdef SIZE_t X_fx_stride = <SIZE_t> X.strides[1] \/ <SIZE_t> X.itemsize","949","                    if X_ptr[X_sample_stride * i +","950","                             X_fx_stride * node.feature] <= node.threshold:"]}],"sklearn\/tree\/_utils.pxd":[{"add":["0","# cython: language_level=3","1","","14","from ._tree cimport Node"],"delete":["12","from _tree cimport Node"]}],"sklearn\/tree\/_splitter.pyx":[{"add":["118","                   DOUBLE_t[:, ::1] y,","179","        self.y = y","238","    cdef DTYPE_t[:, :] X","262","                  DOUBLE_t[:, ::1] y,","274","        self.X = X","412","                            Xf[p] = self.X[j, current.feature]","416","                        Xf[i] = self.X[samples[i], current.feature]","481","                if self.X[samples[p], best.feature] <= best.threshold:","735","                min_feature_value = self.X[samples[start], current.feature]","740","                    current_feature_value = self.X[samples[p], current.feature]","813","                    if self.X[samples[p], best.feature] <= best.threshold:","878","                  DOUBLE_t[:, ::1] y,"],"delete":["94","        self.y = NULL","95","        self.y_stride = 0","120","                   np.ndarray[DOUBLE_t, ndim=2, mode=\"c\"] y,","181","        self.y = <DOUBLE_t*> y.data","182","        self.y_stride = <SIZE_t> y.strides[0] \/ <SIZE_t> y.itemsize","208","                            self.y_stride,","242","    cdef DTYPE_t* X","243","    cdef SIZE_t X_sample_stride","244","    cdef SIZE_t X_feature_stride","256","        self.X = NULL","257","        self.X_sample_stride = 0","258","        self.X_feature_stride = 0","271","                  np.ndarray[DOUBLE_t, ndim=2, mode=\"c\"] y,","283","        # Initialize X","284","        cdef np.ndarray X_ndarray = X","285","","286","        self.X = <DTYPE_t*> X_ndarray.data","287","        self.X_sample_stride = <SIZE_t> X.strides[0] \/ <SIZE_t> X.itemsize","288","        self.X_feature_stride = <SIZE_t> X.strides[1] \/ <SIZE_t> X.itemsize","329","        cdef DTYPE_t* X = self.X","331","        cdef SIZE_t X_sample_stride = self.X_sample_stride","332","        cdef SIZE_t X_feature_stride = self.X_feature_stride","416","                feature_offset = self.X_feature_stride * current.feature","430","                            Xf[p] = X[self.X_sample_stride * j + feature_offset]","434","                        Xf[i] = X[self.X_sample_stride * samples[i] + feature_offset]","495","            feature_offset = X_feature_stride * best.feature","500","                if X[X_sample_stride * samples[p] + feature_offset] <= best.threshold:","677","        cdef DTYPE_t* X = self.X","679","        cdef SIZE_t X_sample_stride = self.X_sample_stride","680","        cdef SIZE_t X_feature_stride = self.X_feature_stride","755","                feature_stride = X_feature_stride * current.feature","758","                min_feature_value = X[X_sample_stride * samples[start] + feature_stride]","763","                    current_feature_value = X[X_sample_stride * samples[p] + feature_stride]","830","        feature_stride = X_feature_stride * best.feature","837","                    if X[X_sample_stride * samples[p] + feature_stride] <= best.threshold:","902","                  np.ndarray[DOUBLE_t, ndim=2, mode=\"c\"] y,"]}]}},"42073c2cc8d14a9b87c348685c35d171904a1df0":{"changes":{"sklearn\/decomposition\/tests\/test_nmf.py":"MODIFY","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/decomposition\/nmf.py":"MODIFY"},"diff":{"sklearn\/decomposition\/tests\/test_nmf.py":[{"add":["55","    for init in ['nndsvd', 'nndsvda', 'nndsvdar']:","56","        msg = (\"init = '{}' can only be used when \"","57","               \"n_components <= min(n_samples, n_features)\"","58","               .format(init))","59","        assert_raise_message(ValueError, msg, NMF(3, init).fit, A)","60","        assert_raise_message(ValueError, msg, nmf._initialize_nmf, A,","61","                             3, init)","62","","207","    for init in ['random', 'nndsvd']:","208","        for solver in ('cd', 'mu'):","209","            W_nmf, H, _ = non_negative_factorization(","210","                A, init=init, solver=solver, random_state=1, tol=1e-2)","211","            W_nmf_2, _, _ = non_negative_factorization(","212","                A, H=H, update_H=False, init=init, solver=solver,","213","                random_state=1, tol=1e-2)","215","            model_class = NMF(init=init, solver=solver, random_state=1,","216","                              tol=1e-2)","217","            W_cls = model_class.fit_transform(A)","218","            W_cls_2 = model_class.transform(A)","219","","220","            assert_array_almost_equal(W_nmf, W_cls, decimal=10)","221","            assert_array_almost_equal(W_nmf_2, W_cls_2, decimal=10)"],"delete":["199","    for solver in ('cd', 'mu'):","200","        W_nmf, H, _ = non_negative_factorization(","201","            A, solver=solver, random_state=1, tol=1e-2)","202","        W_nmf_2, _, _ = non_negative_factorization(","203","            A, H=H, update_H=False, solver=solver, random_state=1, tol=1e-2)","205","        model_class = NMF(solver=solver, random_state=1, tol=1e-2)","206","        W_cls = model_class.fit_transform(A)","207","        W_cls_2 = model_class.transform(A)","208","        assert_array_almost_equal(W_nmf, W_cls, decimal=10)","209","        assert_array_almost_equal(W_nmf_2, W_cls_2, decimal=10)"]}],"doc\/whats_new\/v0.21.rst":[{"add":["78",":mod:`sklearn.decomposition`","79","............................","80","","81","- |Fix| Fixed a bug in :class:`decomposition.NMF` where `init = 'nndsvd'`,","82","  `init = 'nndsvda'`, and `init = 'nndsvdar'` are allowed when","83","  `n_components < n_features` instead of","84","  `n_components <= min(n_samples, n_features)`. ","85","  :issue:`11650` by :user:`Hossein Pourbozorg <hossein-pourbozorg>` and","86","  :user:`Zijie (ZJ) Poh <zjpoh>`.","87",""],"delete":[]}],"sklearn\/decomposition\/nmf.py":[{"add":["263","        - None: 'nndsvd' if n_components <= min(n_samples, n_features),","264","            otherwise 'random'.","307","    if (init is not None and init != 'random'","308","            and n_components > min(n_samples, n_features)):","309","        raise ValueError(\"init = '{}' can only be used when \"","310","                         \"n_components <= min(n_samples, n_features)\"","311","                         .format(init))","312","","314","        if n_components <= min(n_samples, n_features):","1113","        - None: 'nndsvd' if n_components <= min(n_samples, n_features),","1114","            otherwise random."],"delete":["263","        - None: 'nndsvd' if n_components < n_features, otherwise 'random'.","307","        if n_components < n_features:","1106","        - None: 'nndsvd' if n_components < n_features, otherwise random."]}]}},"036dfdde213498fd9a40210ea92cb24b4474a4b7":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/mixture\/tests\/test_gaussian_mixture.py":"MODIFY","sklearn\/mixture\/base.py":"MODIFY","sklearn\/mixture\/tests\/test_bayesian_mixture.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["109",":mod:`sklearn.mixture`","110","........................","111","","112","- |Fix| Ensure that the ``fit_predict`` method of","113","  :class:`mixture.GaussianMixture` and :class:`mixture.BayesianGaussianMixture`","114","  always yield assignments consistent with ``fit`` followed by ``predict`` even","115","  if the convergence criterion is too loose or not met. :issue:`12451`","116","  by :user:`Olivier Grisel <ogrisel>`.","117",""],"delete":[]}],"sklearn\/mixture\/tests\/test_gaussian_mixture.py":[{"add":["12","import pytest","575","@pytest.mark.filterwarnings(\"ignore:.*did not converge.*\")","576","@pytest.mark.parametrize('seed, max_iter, tol', [","577","    (0, 2, 1e-7),    # strict non-convergence","578","    (1, 2, 1e-1),    # loose non-convergence","579","    (3, 300, 1e-7),  # strict convergence","580","    (4, 300, 1e-1),  # loose convergence","581","])","582","def test_gaussian_mixture_fit_predict(seed, max_iter, tol):","583","    rng = np.random.RandomState(seed)","592","                            covariance_type=covar_type,","593","                            max_iter=max_iter, tol=tol)"],"delete":["574","def test_gaussian_mixture_fit_predict():","575","    rng = np.random.RandomState(0)","584","                            covariance_type=covar_type)"]}],"sklearn\/mixture\/base.py":[{"add":["262","        # Always do a final e-step to guarantee that the labels returned by","263","        # fit_predict(X) are always consistent with fit(X).predict(X)","264","        # for any value of max_iter and tol (and any random_state).","265","        _, log_resp = self._e_step(X)","266",""],"delete":[]}],"sklearn\/mixture\/tests\/test_bayesian_mixture.py":[{"add":["7","import pytest","428","@pytest.mark.filterwarnings(\"ignore:.*did not converge.*\")","429","@pytest.mark.parametrize('seed, max_iter, tol', [","430","    (0, 2, 1e-7),    # strict non-convergence","431","    (1, 2, 1e-1),    # loose non-convergence","432","    (3, 300, 1e-7),  # strict convergence","433","    (4, 300, 1e-1),  # loose convergence","434","])","435","def test_bayesian_mixture_fit_predict(seed, max_iter, tol):","436","    rng = np.random.RandomState(seed)","442","                                        max_iter=max_iter, random_state=rng,","443","                                        tol=tol, reg_covar=0)"],"delete":["427","def test_bayesian_mixture_fit_predict():","428","    rng = np.random.RandomState(0)","434","                                        max_iter=100, random_state=rng,","435","                                        tol=1e-3, reg_covar=0)"]}]}},"1e7cd7df9dee31d035ddb789f8e5138201da0ebc":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/preprocessing\/_encoders.py":"MODIFY","sklearn\/preprocessing\/tests\/test_encoders.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["81","- |Fix| Fixed bug in :class:`preprocessing.OrdinalEncoder` when passing","82","  manually specified categories. :issue:`12365` by `Joris Van den Bossche`_."],"delete":[]}],"sklearn\/preprocessing\/_encoders.py":[{"add":["84","                if handle_unknown == 'error':"],"delete":["84","                if self.handle_unknown == 'error':"]}],"sklearn\/preprocessing\/tests\/test_encoders.py":[{"add":["532","@pytest.mark.parametrize(\"X, X2, cats, cat_dtype\", [","533","    (np.array([['a', 'b']], dtype=object).T,","534","     np.array([['a', 'd']], dtype=object).T,","535","     [['a', 'b', 'c']], np.object_),","536","    (np.array([[1, 2]], dtype='int64').T,","537","     np.array([[1, 4]], dtype='int64').T,","538","     [[1, 2, 3]], np.int64),","539","    (np.array([['a', 'b']], dtype=object).T,","540","     np.array([['a', 'd']], dtype=object).T,","541","     [np.array(['a', 'b', 'c'])], np.object_),","542","    ], ids=['object', 'numeric', 'object-string-cat'])","543","def test_ordinal_encoder_specified_categories(X, X2, cats, cat_dtype):","544","    enc = OrdinalEncoder(categories=cats)","545","    exp = np.array([[0.], [1.]])","546","    assert_array_equal(enc.fit_transform(X), exp)","547","    assert list(enc.categories[0]) == list(cats[0])","548","    assert enc.categories_[0].tolist() == list(cats[0])","549","    # manually specified categories should have same dtype as","550","    # the data when coerced from lists","551","    assert enc.categories_[0].dtype == cat_dtype","552","","553","    # when specifying categories manually, unknown categories should already","554","    # raise when fitting","555","    enc = OrdinalEncoder(categories=cats)","556","    with pytest.raises(ValueError, match=\"Found unknown categories\"):","557","        enc.fit(X2)","558","","559",""],"delete":[]}]}},"afa0694d129e6f04d61073131ac75c84ef038f7b":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/datasets\/tests\/test_openml.py":"MODIFY","sklearn\/datasets\/openml.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["39","- |Fix| :func:`dataset.fetch_openml` to correctly use the local cache.","40","  :issue:`12246` by :user:`Jan N. van Rijn <janvanrijn>`.","41",""],"delete":[]}],"sklearn\/datasets\/tests\/test_openml.py":[{"add":["14","                                     _download_data_arff,","15","                                     _get_local_path)","80","    # Please note that cache=False is crucial, as the monkey patched files are","81","    # not consistent with reality","143","    # monkey patches the urlopen function. Important note: Do NOT use this","144","    # in combination with a regular cache directory, as the files that are","145","    # stored as cache should not be mixed up with real openml datasets","461","def test_open_openml_url_cache(monkeypatch, gzip_response, tmpdir):","467","    cache_directory = str(tmpdir.mkdir('scikit_learn_data'))","469","    response1 = _open_openml_url(openml_path, cache_directory)","471","    location = _get_local_path(openml_path, cache_directory)","474","    response2 = _open_openml_url(openml_path, cache_directory)","479","def test_fetch_openml_cache(monkeypatch, gzip_response, tmpdir):","480","    def _mock_urlopen_raise(request):","481","        raise ValueError('This mechanism intends to test correct cache'","482","                         'handling. As such, urlopen should never be '","483","                         'accessed. URL: %s' % request.get_full_url())","484","    data_id = 2","485","    cache_directory = str(tmpdir.mkdir('scikit_learn_data'))","486","    _monkey_patch_webbased_functions(","487","        monkeypatch, data_id, gzip_response)","488","    X_fetched, y_fetched = fetch_openml(data_id=data_id, cache=True,","489","                                        data_home=cache_directory,","490","                                        return_X_y=True)","491","","492","    monkeypatch.setattr(sklearn.datasets.openml, 'urlopen',","493","                        _mock_urlopen_raise)","494","","495","    X_cached, y_cached = fetch_openml(data_id=data_id, cache=True,","496","                                      data_home=cache_directory,","497","                                      return_X_y=True)","498","    np.testing.assert_array_equal(X_fetched, X_cached)","499","    np.testing.assert_array_equal(y_fetched, y_cached)","500","","501","","502","@pytest.mark.parametrize('gzip_response', [True, False])"],"delete":["14","                                     _download_data_arff)","455","def test_open_openml_url_cache(monkeypatch, gzip_response):","461","    test_directory = os.path.join(os.path.expanduser('~'), 'scikit_learn_data')","463","    response1 = _open_openml_url(openml_path, test_directory)","465","    location = os.path.join(test_directory, 'openml.org', openml_path + '.gz')","468","    response2 = _open_openml_url(openml_path, test_directory)"]}],"sklearn\/datasets\/openml.py":[{"add":["33","def _get_local_path(openml_path, data_home):","34","    return os.path.join(data_home, 'openml.org', openml_path + \".gz\")","35","","36","","56","    def is_gzip(_fsrc):","57","        return _fsrc.info().get('Content-Encoding', '') == 'gzip'","58","","63","        fsrc = urlopen(req)","64","        if is_gzip(fsrc):","70","    local_path = _get_local_path(openml_path, data_home)","72","        fsrc = urlopen(req)","80","            if is_gzip(fsrc):","81","                with open(local_path, 'wb') as fdst:","82","                    shutil.copyfileobj(fsrc, fdst)","83","                    fsrc.close()","84","            else:","85","                with gzip.GzipFile(local_path, 'wb') as fdst:","86","                    shutil.copyfileobj(fsrc, fdst)","87","                    fsrc.close()","91","","92","    # XXX: First time, decompression will not be necessary (by using fsrc), but","93","    # it will happen nonetheless","94","    return gzip.GzipFile(local_path, 'rb')"],"delete":["54","    fsrc = urlopen(req)","55","    is_gzip = fsrc.info().get('Content-Encoding', '') == 'gzip'","58","        if is_gzip:","64","    local_path = os.path.join(data_home, 'openml.org', openml_path + \".gz\")","73","            with open(local_path, 'wb') as fdst:","74","                shutil.copyfileobj(fsrc, fdst)","75","                fsrc.close()","79","    # XXX: unnecessary decompression on first access","80","    if is_gzip:","81","        return gzip.GzipFile(local_path, 'rb')","82","    return fsrc"]}]}},"5e101a2a07ea3586fe663598495cdc3893cb7665":{"changes":{"sklearn\/externals\/copy_joblib.sh":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/__init__.py":"MODIFY","sklearn\/externals\/joblib\/__init__.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/_base.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/context.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/process_executor.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/reduction.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/compat.py":"MODIFY","sklearn\/externals\/joblib\/memory.py":"MODIFY"},"diff":{"sklearn\/externals\/copy_joblib.sh":[{"add":["13","pip install --no-cache $JOBLIB --target $INSTALL_FOLDER"],"delete":["13","pip install $JOBLIB --target $INSTALL_FOLDER"]}],"sklearn\/externals\/joblib\/externals\/loky\/__init__.py":[{"add":["5","from ._base import Executor, Future","6","from ._base import wait, as_completed","7","from ._base import TimeoutError, CancelledError","8","from ._base import ALL_COMPLETED, FIRST_COMPLETED, FIRST_EXCEPTION","10","from .backend.context import cpu_count","11","from .reusable_executor import get_reusable_executor","12","from .process_executor import BrokenProcessPool, ProcessPoolExecutor","14","","15","__all__ = [\"get_reusable_executor\", \"cpu_count\", \"wait\", \"as_completed\",","16","           \"Future\", \"Executor\", \"ProcessPoolExecutor\",","17","           \"BrokenProcessPool\", \"CancelledError\", \"TimeoutError\",","18","           \"FIRST_COMPLETED\", \"FIRST_EXCEPTION\", \"ALL_COMPLETED\", ]","19","","20","","21","__version__ = '2.3.0'"],"delete":["5","from .reusable_executor import get_reusable_executor  # noqa: F401","6","from .process_executor import ProcessPoolExecutor  # noqa: F401","7","from .process_executor import BrokenProcessPool  # noqa: F401","9","from .backend.context import cpu_count  # noqa: F401","11","__version__ = '2.2.2'"]}],"sklearn\/externals\/joblib\/__init__.py":[{"add":["108","__version__ = '0.12.4'"],"delete":["108","__version__ = '0.12.3'"]}],"sklearn\/externals\/joblib\/externals\/loky\/_base.py":[{"add":["13","import time","16","import collections","19","if sys.version_info[:2] >= (3, 3):","20","","21","    from concurrent.futures import wait, as_completed","22","    from concurrent.futures import TimeoutError, CancelledError","23","    from concurrent.futures import Executor, Future as _BaseFuture","24","","25","    from concurrent.futures import FIRST_EXCEPTION","26","    from concurrent.futures import ALL_COMPLETED, FIRST_COMPLETED","27","","28","    from concurrent.futures._base import LOGGER","29","    from concurrent.futures._base import PENDING, RUNNING, CANCELLED","30","    from concurrent.futures._base import CANCELLED_AND_NOTIFIED, FINISHED","31","else:","32","","33","    FIRST_COMPLETED = 'FIRST_COMPLETED'","34","    FIRST_EXCEPTION = 'FIRST_EXCEPTION'","35","    ALL_COMPLETED = 'ALL_COMPLETED'","36","    _AS_COMPLETED = '_AS_COMPLETED'","37","","38","    # Possible future states (for internal use by the futures package).","39","    PENDING = 'PENDING'","40","    RUNNING = 'RUNNING'","41","    # The future was cancelled by the user...","42","    CANCELLED = 'CANCELLED'","43","    # ...and _Waiter.add_cancelled() was called by a worker.","44","    CANCELLED_AND_NOTIFIED = 'CANCELLED_AND_NOTIFIED'","45","    FINISHED = 'FINISHED'","46","","47","    _FUTURE_STATES = [","48","        PENDING,","49","        RUNNING,","50","        CANCELLED,","51","        CANCELLED_AND_NOTIFIED,","52","        FINISHED","53","    ]","54","","55","    _STATE_TO_DESCRIPTION_MAP = {","56","        PENDING: \"pending\",","57","        RUNNING: \"running\",","58","        CANCELLED: \"cancelled\",","59","        CANCELLED_AND_NOTIFIED: \"cancelled\",","60","        FINISHED: \"finished\"","61","    }","62","","63","    # Logger for internal use by the futures package.","64","    LOGGER = logging.getLogger(\"concurrent.futures\")","78","    class _Waiter(object):","79","        \"\"\"Provides the event that wait() and as_completed() block on.\"\"\"","80","        def __init__(self):","81","            self.event = threading.Event()","82","            self.finished_futures = []","84","        def add_result(self, future):","85","            self.finished_futures.append(future)","87","        def add_exception(self, future):","88","            self.finished_futures.append(future)","90","        def add_cancelled(self, future):","91","            self.finished_futures.append(future)","93","    class _AsCompletedWaiter(_Waiter):","94","        \"\"\"Used by as_completed().\"\"\"","96","        def __init__(self):","97","            super(_AsCompletedWaiter, self).__init__()","98","            self.lock = threading.Lock()","100","        def add_result(self, future):","101","            with self.lock:","102","                super(_AsCompletedWaiter, self).add_result(future)","105","        def add_exception(self, future):","106","            with self.lock:","107","                super(_AsCompletedWaiter, self).add_exception(future)","108","                self.event.set()","110","        def add_cancelled(self, future):","111","            with self.lock:","112","                super(_AsCompletedWaiter, self).add_cancelled(future)","113","                self.event.set()","114","","115","    class _FirstCompletedWaiter(_Waiter):","116","        \"\"\"Used by wait(return_when=FIRST_COMPLETED).\"\"\"","117","","118","        def add_result(self, future):","119","            super(_FirstCompletedWaiter, self).add_result(future)","121","","122","        def add_exception(self, future):","123","            super(_FirstCompletedWaiter, self).add_exception(future)","124","            self.event.set()","125","","126","        def add_cancelled(self, future):","127","            super(_FirstCompletedWaiter, self).add_cancelled(future)","128","            self.event.set()","129","","130","    class _AllCompletedWaiter(_Waiter):","131","        \"\"\"Used by wait(return_when=FIRST_EXCEPTION and ALL_COMPLETED).\"\"\"","132","","133","        def __init__(self, num_pending_calls, stop_on_exception):","134","            self.num_pending_calls = num_pending_calls","135","            self.stop_on_exception = stop_on_exception","136","            self.lock = threading.Lock()","137","            super(_AllCompletedWaiter, self).__init__()","138","","139","        def _decrement_pending_calls(self):","140","            with self.lock:","141","                self.num_pending_calls -= 1","142","                if not self.num_pending_calls:","143","                    self.event.set()","144","","145","        def add_result(self, future):","146","            super(_AllCompletedWaiter, self).add_result(future)","149","        def add_exception(self, future):","150","            super(_AllCompletedWaiter, self).add_exception(future)","151","            if self.stop_on_exception:","152","                self.event.set()","154","                self._decrement_pending_calls()","156","        def add_cancelled(self, future):","157","            super(_AllCompletedWaiter, self).add_cancelled(future)","158","            self._decrement_pending_calls()","160","    class _AcquireFutures(object):","161","        \"\"\"A context manager that does an ordered acquire of Future conditions.","162","        \"\"\"","164","        def __init__(self, futures):","165","            self.futures = sorted(futures, key=id)","166","","167","        def __enter__(self):","168","            for future in self.futures:","169","                future._condition.acquire()","170","","171","        def __exit__(self, *args):","172","            for future in self.futures:","173","                future._condition.release()","174","","175","    def _create_and_install_waiters(fs, return_when):","176","        if return_when == _AS_COMPLETED:","177","            waiter = _AsCompletedWaiter()","178","        elif return_when == FIRST_COMPLETED:","179","            waiter = _FirstCompletedWaiter()","180","        else:","181","            pending_count = sum(","182","                    f._state not in [CANCELLED_AND_NOTIFIED, FINISHED]","183","                    for f in fs)","184","","185","            if return_when == FIRST_EXCEPTION:","186","                waiter = _AllCompletedWaiter(pending_count,","187","                                             stop_on_exception=True)","188","            elif return_when == ALL_COMPLETED:","189","                waiter = _AllCompletedWaiter(pending_count,","190","                                             stop_on_exception=False)","191","            else:","192","                raise ValueError(\"Invalid return condition: %r\" % return_when)","193","","194","        for f in fs:","195","            f._waiters.append(waiter)","196","","197","        return waiter","198","","199","    def as_completed(fs, timeout=None):","200","        \"\"\"An iterator over the given futures that yields each as it completes.","201","","202","        Args:","203","            fs: The sequence of Futures (possibly created by different","204","                Executors) to iterate over.","205","            timeout: The maximum number of seconds to wait. If None, then there","206","                is no limit on the wait time.","207","","208","        Returns:","209","            An iterator that yields the given Futures as they complete","210","            (finished or cancelled). If any given Futures are duplicated, they","211","            will be returned once.","212","","213","        Raises:","214","            TimeoutError: If the entire result iterator could not be generated","215","                before the given timeout.","216","        \"\"\"","217","        if timeout is not None:","218","            end_time = timeout + time.time()","219","","220","        fs = set(fs)","221","        with _AcquireFutures(fs):","222","            finished = set(","223","                    f for f in fs","224","                    if f._state in [CANCELLED_AND_NOTIFIED, FINISHED])","225","            pending = fs - finished","226","            waiter = _create_and_install_waiters(fs, _AS_COMPLETED)","227","","228","        try:","232","            while pending:","233","                if timeout is None:","234","                    wait_timeout = None","235","                else:","236","                    wait_timeout = end_time - time.time()","237","                    if wait_timeout < 0:","238","                        raise TimeoutError('%d (of %d) futures unfinished' % (","239","                            len(pending), len(fs)))","240","","241","                waiter.event.wait(wait_timeout)","242","","243","                with waiter.lock:","244","                    finished = waiter.finished_futures","245","                    waiter.finished_futures = []","246","                    waiter.event.clear()","247","","248","                for future in finished:","249","                    yield future","250","                    pending.remove(future)","251","","252","        finally:","253","            for f in fs:","254","                with f._condition:","255","                    f._waiters.remove(waiter)","256","","257","    DoneAndNotDoneFutures = collections.namedtuple(","258","            'DoneAndNotDoneFutures', 'done not_done')","259","","260","    def wait(fs, timeout=None, return_when=ALL_COMPLETED):","261","        \"\"\"Wait for the futures in the given sequence to complete.","262","","263","        Args:","264","            fs: The sequence of Futures (possibly created by different","265","                Executors) to wait upon.","266","            timeout: The maximum number of seconds to wait. If None, then there","267","                is no limit on the wait time.","268","            return_when: Indicates when this function should return. The","269","                options are:","270","","271","                FIRST_COMPLETED - Return when any future finishes or is","272","                                cancelled.","273","                FIRST_EXCEPTION - Return when any future finishes by raising an","274","                                exception. If no future raises an exception","275","                                then it is equivalent to ALL_COMPLETED.","276","                ALL_COMPLETED -   Return when all futures finish or are","277","                                cancelled.","278","","279","        Returns:","280","            A named 2-tuple of sets. The first set, named 'done', contains the","281","            futures that completed (is finished or cancelled) before the wait","282","            completed. The second set, named 'not_done', contains uncompleted","283","            futures.","284","        \"\"\"","285","        with _AcquireFutures(fs):","286","            done = set(f for f in fs","287","                       if f._state in [CANCELLED_AND_NOTIFIED, FINISHED])","288","            not_done = set(fs) - done","289","","290","            if (return_when == FIRST_COMPLETED) and done:","291","                return DoneAndNotDoneFutures(done, not_done)","292","            elif (return_when == FIRST_EXCEPTION) and done:","293","                if any(f for f in done","294","                       if not f.cancelled() and f.exception() is not None):","295","                    return DoneAndNotDoneFutures(done, not_done)","296","","297","            if len(done) == len(fs):","298","                return DoneAndNotDoneFutures(done, not_done)","299","","300","            waiter = _create_and_install_waiters(fs, return_when)","301","","302","        waiter.event.wait(timeout)","307","        done.update(waiter.finished_futures)","308","        return DoneAndNotDoneFutures(done, set(fs) - done)","310","    class _BaseFuture(object):","311","        \"\"\"Represents the result of an asynchronous computation.\"\"\"","312","","313","        def __init__(self):","314","            \"\"\"Initializes the future. Should not be called by clients.\"\"\"","315","            self._condition = threading.Condition()","316","            self._state = PENDING","317","            self._result = None","318","            self._exception = None","319","            self._waiters = []","320","            self._done_callbacks = []","321","","322","        def __repr__(self):","323","            with self._condition:","324","                if self._state == FINISHED:","325","                    if self._exception:","326","                        return '<%s at %#x state=%s raised %s>' % (","327","                            self.__class__.__name__,","328","                            id(self),","329","                            _STATE_TO_DESCRIPTION_MAP[self._state],","330","                            self._exception.__class__.__name__)","331","                    else:","332","                        return '<%s at %#x state=%s returned %s>' % (","333","                            self.__class__.__name__,","334","                            id(self),","335","                            _STATE_TO_DESCRIPTION_MAP[self._state],","336","                            self._result.__class__.__name__)","337","                return '<%s at %#x state=%s>' % (","338","                        self.__class__.__name__,","339","                        id(self),","340","                        _STATE_TO_DESCRIPTION_MAP[self._state])","341","","342","        def cancel(self):","343","            \"\"\"Cancel the future if possible.","344","","345","            Returns True if the future was cancelled, False otherwise. A future","346","            cannot be cancelled if it is running or has already completed.","347","            \"\"\"","348","            with self._condition:","349","                if self._state in [RUNNING, FINISHED]:","350","                    return False","351","","352","                if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","353","                    return True","354","","355","                self._state = CANCELLED","356","                self._condition.notify_all()","357","","358","            self._invoke_callbacks()","359","            return True","360","","361","        def cancelled(self):","362","            \"\"\"Return True if the future was cancelled.\"\"\"","363","            with self._condition:","364","                return self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]","365","","366","        def running(self):","367","            \"\"\"Return True if the future is currently executing.\"\"\"","368","            with self._condition:","369","                return self._state == RUNNING","370","","371","        def done(self):","372","            \"\"\"Return True of the future was cancelled or finished executing.","373","            \"\"\"","374","            with self._condition:","375","                return self._state in [CANCELLED, CANCELLED_AND_NOTIFIED,","376","                                       FINISHED]","377","","378","        def __get_result(self):","379","            if self._exception:","380","                raise self._exception","381","            else:","382","                return self._result","383","","384","        def add_done_callback(self, fn):","385","            \"\"\"Attaches a callable that will be called when the future finishes.","386","","387","            Args:","388","                fn: A callable that will be called with this future as its only","389","                    argument when the future completes or is cancelled. The","390","                    callable will always be called by a thread in the same","391","                    process in which it was added. If the future has already","392","                    completed or been cancelled then the callable will be","393","                    called immediately. These callables are called in the order","394","                    that they were added.","395","            \"\"\"","396","            with self._condition:","397","                if self._state not in [CANCELLED, CANCELLED_AND_NOTIFIED,","398","                                       FINISHED]:","399","                    self._done_callbacks.append(fn)","400","                    return","401","            fn(self)","402","","403","        def result(self, timeout=None):","404","            \"\"\"Return the result of the call that the future represents.","405","","406","            Args:","407","                timeout: The number of seconds to wait for the result if the","408","                    future isn't done. If None, then there is no limit on the","409","                    wait time.","410","","411","            Returns:","412","                The result of the call that the future represents.","413","","414","            Raises:","415","                CancelledError: If the future was cancelled.","416","                TimeoutError: If the future didn't finish executing before the","417","                    given timeout.","418","                Exception: If the call raised then that exception will be","419","                raised.","420","            \"\"\"","421","            with self._condition:","422","                if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","423","                    raise CancelledError()","424","                elif self._state == FINISHED:","425","                    return self.__get_result()","426","","427","                self._condition.wait(timeout)","428","","429","                if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","430","                    raise CancelledError()","431","                elif self._state == FINISHED:","432","                    return self.__get_result()","433","                else:","434","                    raise TimeoutError()","435","","436","        def exception(self, timeout=None):","437","            \"\"\"Return the exception raised by the call that the future","438","            represents.","439","","440","            Args:","441","                timeout: The number of seconds to wait for the exception if the","442","                    future isn't done. If None, then there is no limit on the","443","                    wait time.","444","","445","            Returns:","446","                The exception raised by the call that the future represents or","447","                None if the call completed without raising.","448","","449","            Raises:","450","                CancelledError: If the future was cancelled.","451","                TimeoutError: If the future didn't finish executing before the","452","                    given timeout.","453","            \"\"\"","454","","455","            with self._condition:","456","                if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","457","                    raise CancelledError()","458","                elif self._state == FINISHED:","459","                    return self._exception","460","","461","                self._condition.wait(timeout)","462","","463","                if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","464","                    raise CancelledError()","465","                elif self._state == FINISHED:","466","                    return self._exception","467","                else:","468","                    raise TimeoutError()","469","","470","        # The following methods should only be used by Executors and in tests.","471","        def set_running_or_notify_cancel(self):","472","            \"\"\"Mark the future as running or process any cancel notifications.","473","","474","            Should only be used by Executor implementations and unit tests.","475","","476","            If the future has been cancelled (cancel() was called and returned","477","            True) then any threads waiting on the future completing (though","478","            calls to as_completed() or wait()) are notified and False is","479","            returned.","480","","481","            If the future was not cancelled then it is put in the running state","482","            (future calls to running() will return True) and True is returned.","483","","484","            This method should be called by Executor implementations before","485","            executing the work associated with this future. If this method","486","            returns False then the work should not be executed.","487","","488","            Returns:","489","                False if the Future was cancelled, True otherwise.","490","","491","            Raises:","492","                RuntimeError: if this method was already called or if","493","                    set_result() or set_exception() was called.","494","            \"\"\"","495","            with self._condition:","496","                if self._state == CANCELLED:","497","                    self._state = CANCELLED_AND_NOTIFIED","498","                    for waiter in self._waiters:","499","                        waiter.add_cancelled(self)","500","                    # self._condition.notify_all() is not necessary because","501","                    # self.cancel() triggers a notification.","502","                    return False","503","                elif self._state == PENDING:","504","                    self._state = RUNNING","505","                    return True","506","                else:","507","                    LOGGER.critical('Future %s in unexpected state: %s',","508","                                    id(self),","509","                                    self._state)","510","                    raise RuntimeError('Future in unexpected state')","511","","512","        def set_result(self, result):","513","            \"\"\"Sets the return value of work associated with the future.","514","","515","            Should only be used by Executor implementations and unit tests.","516","            \"\"\"","517","            with self._condition:","518","                self._result = result","519","                self._state = FINISHED","520","                for waiter in self._waiters:","521","                    waiter.add_result(self)","522","                self._condition.notify_all()","523","            self._invoke_callbacks()","524","","525","        def set_exception(self, exception):","526","            \"\"\"Sets the result of the future as being the given exception.","527","","528","            Should only be used by Executor implementations and unit tests.","529","            \"\"\"","530","            with self._condition:","531","                self._exception = exception","532","                self._state = FINISHED","533","                for waiter in self._waiters:","534","                    waiter.add_exception(self)","535","                self._condition.notify_all()","536","            self._invoke_callbacks()","537","","538","    class Executor(object):","539","        \"\"\"This is an abstract base class for concrete asynchronous executors.","540","        \"\"\"","541","","542","        def submit(self, fn, *args, **kwargs):","543","            \"\"\"Submits a callable to be executed with the given arguments.","544","","545","            Schedules the callable to be executed as fn(*args, **kwargs) and","546","            returns a Future instance representing the execution of the","547","            callable.","548","","549","            Returns:","550","                A Future representing the given call.","551","            \"\"\"","552","            raise NotImplementedError()","553","","554","        def map(self, fn, *iterables, **kwargs):","555","            \"\"\"Returns an iterator equivalent to map(fn, iter).","556","","557","            Args:","558","                fn: A callable that will take as many arguments as there are","559","                    passed iterables.","560","                timeout: The maximum number of seconds to wait. If None, then","561","                    there is no limit on the wait time.","562","                chunksize: The size of the chunks the iterable will be broken","563","                    into before being passed to a child process. This argument","564","                    is only used by ProcessPoolExecutor; it is ignored by","565","                    ThreadPoolExecutor.","566","","567","            Returns:","568","                An iterator equivalent to: map(func, *iterables) but the calls","569","                may be evaluated out-of-order.","570","","571","            Raises:","572","                TimeoutError: If the entire result iterator could not be","573","                    generated before the given timeout.","574","                Exception: If fn(*args) raises for any values.","575","            \"\"\"","576","            timeout = kwargs.get('timeout')","577","            if timeout is not None:","578","                end_time = timeout + time.time()","579","","580","            fs = [self.submit(fn, *args) for args in zip(*iterables)]","581","","582","            # Yield must be hidden in closure so that the futures are submitted","583","            # before the first iterator value is required.","584","            def result_iterator():","585","                try:","586","                    for future in fs:","587","                        if timeout is None:","588","                            yield future.result()","589","                        else:","590","                            yield future.result(end_time - time.time())","591","                finally:","592","                    for future in fs:","593","                        future.cancel()","594","            return result_iterator()","595","","596","        def shutdown(self, wait=True):","597","            \"\"\"Clean-up the resources associated with the Executor.","598","","599","            It is safe to call this method several times. Otherwise, no other","600","            methods can be called after this one.","601","","602","            Args:","603","                wait: If True then shutdown will not return until all running","604","                    futures have finished executing and the resources used by","605","                    the executor have been reclaimed.","606","            \"\"\"","607","            pass","608","","609","        def __enter__(self):","610","            return self","611","","612","        def __exit__(self, exc_type, exc_val, exc_tb):","613","            self.shutdown(wait=True)","614","            return False","617","# To make loky._base.Future instances awaitable  by concurrent.futures.wait,","618","# derive our custom Future class from _BaseFuture. _invoke_callback is the only","619","# modification made to this class in loky.","620","class Future(_BaseFuture):"],"delete":["13","import collections","16","import time","17","","18","FIRST_COMPLETED = 'FIRST_COMPLETED'","19","FIRST_EXCEPTION = 'FIRST_EXCEPTION'","20","ALL_COMPLETED = 'ALL_COMPLETED'","21","_AS_COMPLETED = '_AS_COMPLETED'","22","","23","# Possible future states (for internal use by the futures package).","24","PENDING = 'PENDING'","25","RUNNING = 'RUNNING'","26","# The future was cancelled by the user...","27","CANCELLED = 'CANCELLED'","28","# ...and _Waiter.add_cancelled() was called by a worker.","29","CANCELLED_AND_NOTIFIED = 'CANCELLED_AND_NOTIFIED'","30","FINISHED = 'FINISHED'","31","","32","_FUTURE_STATES = [","33","    PENDING,","34","    RUNNING,","35","    CANCELLED,","36","    CANCELLED_AND_NOTIFIED,","37","    FINISHED","38","]","39","","40","_STATE_TO_DESCRIPTION_MAP = {","41","    PENDING: \"pending\",","42","    RUNNING: \"running\",","43","    CANCELLED: \"cancelled\",","44","    CANCELLED_AND_NOTIFIED: \"cancelled\",","45","    FINISHED: \"finished\"","46","}","47","","48","# Logger for internal use by the futures package.","49","LOGGER = logging.getLogger(\"concurrent.futures\")","52","if sys.version_info[:2] < (3, 3):","65","else:","66","    from concurrent.futures import CancelledError, TimeoutError","69","class _Waiter(object):","70","    \"\"\"Provides the event that wait() and as_completed() block on.\"\"\"","71","    def __init__(self):","72","        self.event = threading.Event()","73","        self.finished_futures = []","75","    def add_result(self, future):","76","        self.finished_futures.append(future)","78","    def add_exception(self, future):","79","        self.finished_futures.append(future)","81","    def add_cancelled(self, future):","82","        self.finished_futures.append(future)","85","class _AsCompletedWaiter(_Waiter):","86","    \"\"\"Used by as_completed().\"\"\"","87","","88","    def __init__(self):","89","        super(_AsCompletedWaiter, self).__init__()","90","        self.lock = threading.Lock()","91","","92","    def add_result(self, future):","93","        with self.lock:","94","            super(_AsCompletedWaiter, self).add_result(future)","95","            self.event.set()","96","","97","    def add_exception(self, future):","98","        with self.lock:","99","            super(_AsCompletedWaiter, self).add_exception(future)","100","            self.event.set()","101","","102","    def add_cancelled(self, future):","103","        with self.lock:","104","            super(_AsCompletedWaiter, self).add_cancelled(future)","105","            self.event.set()","106","","107","","108","class _FirstCompletedWaiter(_Waiter):","109","    \"\"\"Used by wait(return_when=FIRST_COMPLETED).\"\"\"","110","","111","    def add_result(self, future):","112","        super(_FirstCompletedWaiter, self).add_result(future)","113","        self.event.set()","114","","115","    def add_exception(self, future):","116","        super(_FirstCompletedWaiter, self).add_exception(future)","117","        self.event.set()","118","","119","    def add_cancelled(self, future):","120","        super(_FirstCompletedWaiter, self).add_cancelled(future)","121","        self.event.set()","122","","123","","124","class _AllCompletedWaiter(_Waiter):","125","    \"\"\"Used by wait(return_when=FIRST_EXCEPTION and ALL_COMPLETED).\"\"\"","126","","127","    def __init__(self, num_pending_calls, stop_on_exception):","128","        self.num_pending_calls = num_pending_calls","129","        self.stop_on_exception = stop_on_exception","130","        self.lock = threading.Lock()","131","        super(_AllCompletedWaiter, self).__init__()","132","","133","    def _decrement_pending_calls(self):","134","        with self.lock:","135","            self.num_pending_calls -= 1","136","            if not self.num_pending_calls:","139","    def add_result(self, future):","140","        super(_AllCompletedWaiter, self).add_result(future)","141","        self._decrement_pending_calls()","143","    def add_exception(self, future):","144","        super(_AllCompletedWaiter, self).add_exception(future)","145","        if self.stop_on_exception:","147","        else:","150","    def add_cancelled(self, future):","151","        super(_AllCompletedWaiter, self).add_cancelled(future)","152","        self._decrement_pending_calls()","153","","154","","155","class _AcquireFutures(object):","156","    \"\"\"A context manager that does an ordered acquire of Future conditions.\"\"\"","157","","158","    def __init__(self, futures):","159","        self.futures = sorted(futures, key=id)","160","","161","    def __enter__(self):","162","        for future in self.futures:","163","            future._condition.acquire()","164","","165","    def __exit__(self, *args):","166","        for future in self.futures:","167","            future._condition.release()","168","","169","","170","def _create_and_install_waiters(fs, return_when):","171","    if return_when == _AS_COMPLETED:","172","        waiter = _AsCompletedWaiter()","173","    elif return_when == FIRST_COMPLETED:","174","        waiter = _FirstCompletedWaiter()","175","    else:","176","        pending_count = sum(","177","                f._state not in [CANCELLED_AND_NOTIFIED, FINISHED] for f in fs)","178","","179","        if return_when == FIRST_EXCEPTION:","180","            waiter = _AllCompletedWaiter(pending_count, stop_on_exception=True)","181","        elif return_when == ALL_COMPLETED:","182","            waiter = _AllCompletedWaiter(pending_count,","183","                                         stop_on_exception=False)","184","        else:","185","            raise ValueError(\"Invalid return condition: %r\" % return_when)","186","","187","    for f in fs:","188","        f._waiters.append(waiter)","189","","190","    return waiter","191","","192","","193","def as_completed(fs, timeout=None):","194","    \"\"\"An iterator over the given futures that yields each as it completes.","195","","196","    Args:","197","        fs: The sequence of Futures (possibly created by different Executors)","198","            to iterate over.","199","        timeout: The maximum number of seconds to wait. If None, then there","200","            is no limit on the wait time.","201","","202","    Returns:","203","        An iterator that yields the given Futures as they complete (finished or","204","        cancelled). If any given Futures are duplicated, they will be returned","205","        once.","206","","207","    Raises:","208","        TimeoutError: If the entire result iterator could not be generated","209","            before the given timeout.","210","    \"\"\"","211","    if timeout is not None:","212","        end_time = timeout + time.time()","213","","214","    fs = set(fs)","215","    with _AcquireFutures(fs):","216","        finished = set(","217","                f for f in fs","218","                if f._state in [CANCELLED_AND_NOTIFIED, FINISHED])","219","        pending = fs - finished","220","        waiter = _create_and_install_waiters(fs, _AS_COMPLETED)","221","","222","    try:","223","        for future in finished:","224","            yield future","225","","226","        while pending:","227","            if timeout is None:","228","                wait_timeout = None","230","                wait_timeout = end_time - time.time()","231","                if wait_timeout < 0:","232","                    raise TimeoutError('%d (of %d) futures unfinished' % (","233","                        len(pending), len(fs)))","235","            waiter.event.wait(wait_timeout)","237","            with waiter.lock:","238","                finished = waiter.finished_futures","239","                waiter.finished_futures = []","240","                waiter.event.clear()","244","                pending.remove(future)","246","    finally:","252","DoneAndNotDoneFutures = collections.namedtuple(","253","        'DoneAndNotDoneFutures', 'done not_done')","256","def wait(fs, timeout=None, return_when=ALL_COMPLETED):","257","    \"\"\"Wait for the futures in the given sequence to complete.","258","","259","    Args:","260","        fs: The sequence of Futures (possibly created by different Executors)","261","            to wait upon.","262","        timeout: The maximum number of seconds to wait. If None, then there","263","            is no limit on the wait time.","264","        return_when: Indicates when this function should return. The options","265","            are:","266","","267","            FIRST_COMPLETED - Return when any future finishes or is","268","                              cancelled.","269","            FIRST_EXCEPTION - Return when any future finishes by raising an","270","                              exception. If no future raises an exception","271","                              then it is equivalent to ALL_COMPLETED.","272","            ALL_COMPLETED -   Return when all futures finish or are cancelled.","273","","274","    Returns:","275","        A named 2-tuple of sets. The first set, named 'done', contains the","276","        futures that completed (is finished or cancelled) before the wait","277","        completed. The second set, named 'not_done', contains uncompleted","278","        futures.","279","    \"\"\"","280","    with _AcquireFutures(fs):","281","        done = set(f for f in fs","282","                   if f._state in [CANCELLED_AND_NOTIFIED, FINISHED])","283","        not_done = set(fs) - done","284","","285","        if (return_when == FIRST_COMPLETED) and done:","286","            return DoneAndNotDoneFutures(done, not_done)","287","        elif (return_when == FIRST_EXCEPTION) and done:","288","            if any(f for f in done","289","                   if not f.cancelled() and f.exception() is not None):","290","                return DoneAndNotDoneFutures(done, not_done)","291","","292","        if len(done) == len(fs):","293","            return DoneAndNotDoneFutures(done, not_done)","294","","295","        waiter = _create_and_install_waiters(fs, return_when)","296","","297","    waiter.event.wait(timeout)","298","    for f in fs:","299","        with f._condition:","300","            f._waiters.remove(waiter)","301","","302","    done.update(waiter.finished_futures)","303","    return DoneAndNotDoneFutures(done, set(fs) - done)","304","","305","","306","class Future(object):","307","    \"\"\"Represents the result of an asynchronous computation.\"\"\"","308","","309","    def __init__(self):","310","        \"\"\"Initializes the future. Should not be called by clients.\"\"\"","311","        self._condition = threading.Condition()","312","        self._state = PENDING","313","        self._result = None","314","        self._exception = None","315","        self._waiters = []","316","        self._done_callbacks = []","317","","324","","325","    def __repr__(self):","326","        with self._condition:","327","            if self._state == FINISHED:","328","                if self._exception:","329","                    return '<%s at %#x state=%s raised %s>' % (","330","                        self.__class__.__name__,","331","                        id(self),","332","                        _STATE_TO_DESCRIPTION_MAP[self._state],","333","                        self._exception.__class__.__name__)","334","                else:","335","                    return '<%s at %#x state=%s returned %s>' % (","336","                        self.__class__.__name__,","337","                        id(self),","338","                        _STATE_TO_DESCRIPTION_MAP[self._state],","339","                        self._result.__class__.__name__)","340","            return '<%s at %#x state=%s>' % (","341","                    self.__class__.__name__,","342","                    id(self),","343","                   _STATE_TO_DESCRIPTION_MAP[self._state])","344","","345","    def cancel(self):","346","        \"\"\"Cancel the future if possible.","347","","348","        Returns True if the future was cancelled, False otherwise. A future","349","        cannot be cancelled if it is running or has already completed.","350","        \"\"\"","351","        with self._condition:","352","            if self._state in [RUNNING, FINISHED]:","353","                return False","354","","355","            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","356","                return True","357","","358","            self._state = CANCELLED","359","            self._condition.notify_all()","360","","361","        self._invoke_callbacks()","362","        return True","363","","364","    def cancelled(self):","365","        \"\"\"Return True if the future was cancelled.\"\"\"","366","        with self._condition:","367","            return self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]","368","","369","    def running(self):","370","        \"\"\"Return True if the future is currently executing.\"\"\"","371","        with self._condition:","372","            return self._state == RUNNING","373","","374","    def done(self):","375","        \"\"\"Return True of the future was cancelled or finished executing.\"\"\"","376","        with self._condition:","377","            return self._state in [CANCELLED, CANCELLED_AND_NOTIFIED, FINISHED]","378","","379","    def __get_result(self):","380","        if self._exception:","381","            raise self._exception","382","        else:","383","            return self._result","384","","385","    def add_done_callback(self, fn):","386","        \"\"\"Attaches a callable that will be called when the future finishes.","387","","388","        Args:","389","            fn: A callable that will be called with this future as its only","390","                argument when the future completes or is cancelled. The","391","                callable will always be called by a thread in the same process","392","                in which it was added. If the future has already completed or","393","                been cancelled then the callable will be called immediately.","394","                These callables are called in the order that they were added.","395","        \"\"\"","396","        with self._condition:","397","            if self._state not in [CANCELLED, CANCELLED_AND_NOTIFIED,","398","                                   FINISHED]:","399","                self._done_callbacks.append(fn)","400","                return","401","        fn(self)","402","","403","    def result(self, timeout=None):","404","        \"\"\"Return the result of the call that the future represents.","405","","406","        Args:","407","            timeout: The number of seconds to wait for the result if the future","408","                isn't done. If None, then there is no limit on the wait time.","409","","410","        Returns:","411","            The result of the call that the future represents.","412","","413","        Raises:","414","            CancelledError: If the future was cancelled.","415","            TimeoutError: If the future didn't finish executing before the","416","                given timeout.","417","            Exception: If the call raised then that exception will be raised.","418","        \"\"\"","419","        with self._condition:","420","            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","421","                raise CancelledError()","422","            elif self._state == FINISHED:","423","                return self.__get_result()","424","","425","            self._condition.wait(timeout)","426","","427","            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","428","                raise CancelledError()","429","            elif self._state == FINISHED:","430","                return self.__get_result()","431","            else:","432","                raise TimeoutError()","433","","434","    def exception(self, timeout=None):","435","        \"\"\"Return the exception raised by the call that the future represents.","436","","437","        Args:","438","            timeout: The number of seconds to wait for the exception if the","439","                future isn't done. If None, then there is no limit on the wait","440","                time.","441","","442","        Returns:","443","            The exception raised by the call that the future represents or None","444","            if the call completed without raising.","445","","446","        Raises:","447","            CancelledError: If the future was cancelled.","448","            TimeoutError: If the future didn't finish executing before the","449","                given timeout.","450","        \"\"\"","451","","452","        with self._condition:","453","            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","454","                raise CancelledError()","455","            elif self._state == FINISHED:","456","                return self._exception","457","","458","            self._condition.wait(timeout)","459","","460","            if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:","461","                raise CancelledError()","462","            elif self._state == FINISHED:","463","                return self._exception","464","            else:","465","                raise TimeoutError()","466","","467","    # The following methods should only be used by Executors and in tests.","468","    def set_running_or_notify_cancel(self):","469","        \"\"\"Mark the future as running or process any cancel notifications.","470","","471","        Should only be used by Executor implementations and unit tests.","472","","473","        If the future has been cancelled (cancel() was called and returned","474","        True) then any threads waiting on the future completing (though calls","475","        to as_completed() or wait()) are notified and False is returned.","476","","477","        If the future was not cancelled then it is put in the running state","478","        (future calls to running() will return True) and True is returned.","479","","480","        This method should be called by Executor implementations before","481","        executing the work associated with this future. If this method returns","482","        False then the work should not be executed.","483","","484","        Returns:","485","            False if the Future was cancelled, True otherwise.","486","","487","        Raises:","488","            RuntimeError: if this method was already called or if set_result()","489","                or set_exception() was called.","490","        \"\"\"","491","        with self._condition:","492","            if self._state == CANCELLED:","493","                self._state = CANCELLED_AND_NOTIFIED","494","                for waiter in self._waiters:","495","                    waiter.add_cancelled(self)","496","                # self._condition.notify_all() is not necessary because","497","                # self.cancel() triggers a notification.","498","                return False","499","            elif self._state == PENDING:","500","                self._state = RUNNING","501","                return True","502","            else:","503","                LOGGER.critical('Future %s in unexpected state: %s',","504","                                id(self),","505","                                self._state)","506","                raise RuntimeError('Future in unexpected state')","507","","508","    def set_result(self, result):","509","        \"\"\"Sets the return value of work associated with the future.","510","","511","        Should only be used by Executor implementations and unit tests.","512","        \"\"\"","513","        with self._condition:","514","            self._result = result","515","            self._state = FINISHED","516","            for waiter in self._waiters:","517","                waiter.add_result(self)","518","            self._condition.notify_all()","519","        self._invoke_callbacks()","520","","521","    def set_exception(self, exception):","522","        \"\"\"Sets the result of the future as being the given exception.","523","","524","        Should only be used by Executor implementations and unit tests.","525","        \"\"\"","526","        with self._condition:","527","            self._exception = exception","528","            self._state = FINISHED","529","            for waiter in self._waiters:","530","                waiter.add_exception(self)","531","            self._condition.notify_all()","532","        self._invoke_callbacks()","533","","534","","535","class Executor(object):","536","    \"\"\"This is an abstract base class for concrete asynchronous executors.\"\"\"","537","","538","    def submit(self, fn, *args, **kwargs):","539","        \"\"\"Submits a callable to be executed with the given arguments.","540","","541","        Schedules the callable to be executed as fn(*args, **kwargs) and","542","        returns a Future instance representing the execution of the callable.","543","","544","        Returns:","545","            A Future representing the given call.","546","        \"\"\"","547","        raise NotImplementedError()","548","","549","    def map(self, fn, *iterables, **kwargs):","550","        \"\"\"Returns an iterator equivalent to map(fn, iter).","551","","552","        Args:","553","            fn: A callable that will take as many arguments as there are","554","                passed iterables.","555","            timeout: The maximum number of seconds to wait. If None, then there","556","                is no limit on the wait time.","557","            chunksize: The size of the chunks the iterable will be broken into","558","                before being passed to a child process. This argument is only","559","                used by ProcessPoolExecutor; it is ignored by","560","                ThreadPoolExecutor.","561","","562","        Returns:","563","            An iterator equivalent to: map(func, *iterables) but the calls may","564","            be evaluated out-of-order.","565","","566","        Raises:","567","            TimeoutError: If the entire result iterator could not be generated","568","                before the given timeout.","569","            Exception: If fn(*args) raises for any values.","570","        \"\"\"","571","        timeout = kwargs.get('timeout')","572","        if timeout is not None:","573","            end_time = timeout + time.time()","574","","575","        fs = [self.submit(fn, *args) for args in zip(*iterables)]","576","","577","        # Yield must be hidden in closure so that the futures are submitted","578","        # before the first iterator value is required.","579","        def result_iterator():","580","            try:","581","                for future in fs:","582","                    if timeout is None:","583","                        yield future.result()","584","                    else:","585","                        yield future.result(end_time - time.time())","586","            finally:","587","                for future in fs:","588","                    future.cancel()","589","        return result_iterator()","590","","591","    def shutdown(self, wait=True):","592","        \"\"\"Clean-up the resources associated with the Executor.","593","","594","        It is safe to call this method several times. Otherwise, no other","595","        methods can be called after this one.","596","","597","        Args:","598","            wait: If True then shutdown will not return until all running","599","                futures have finished executing and the resources used by the","600","                executor have been reclaimed.","601","        \"\"\"","602","        pass","603","","604","    def __enter__(self):","605","        return self","606","","607","    def __exit__(self, exc_type, exc_val, exc_tb):","608","        self.shutdown(wait=True)","609","        return False"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/context.py":[{"add":["108","       ``multiprocessing.cpu_count``;","110","       (available with Python 3.4+ on some Unix systems);","111","     * CFS scheduler CPU bandwidth limit (available on Linux only, typically","112","       set by docker and similar container orchestration systems);","113","     * the value of the LOKY_MAX_CPU_COUNT environment variable if defined.","114","    and is given as the minimum of these constraints.","144","            # Make sure this quantity is an int as math.ceil returns a","145","            # float in python2.7. (See issue #165)","146","            cpu_count_cfs = int(math.ceil(cfs_quota_us \/ cfs_period_us))","148","    # User defined soft-limit passed as an loky specific environment variable.","149","    cpu_count_loky = int(os.environ.get('LOKY_MAX_CPU_COUNT', cpu_count_mp))","150","    aggregate_cpu_count = min(cpu_count_mp, cpu_count_affinity, cpu_count_cfs,","151","                              cpu_count_loky)","152","    return max(aggregate_cpu_count, 1)"],"delete":["108","       ``multiprocessing.cpu_count``","110","       (available with Python 3.4+ on some Unix systems)","111","     * CFS scheduler CPU bandwidth limit","112","       (available on Linux only)","113","    and is given as the minimum of these three constraints.","143","            cpu_count_cfs = math.ceil(cfs_quota_us \/ cfs_period_us)","144","            cpu_count_cfs = max(cpu_count_cfs, 1)","146","    return min(cpu_count_mp, cpu_count_affinity, cpu_count_cfs)"]}],"sklearn\/externals\/joblib\/externals\/loky\/process_executor.py":[{"add":["119","# Minimum time interval between two consecutive memory leak protection checks.","120","_MEMORY_LEAK_CHECK_DELAY = 1.","125","","128","    _USE_PSUTIL = True","137","    _USE_PSUTIL = False","387","    _last_memory_leak_check = None","426","            del r","432","        if _USE_PSUTIL:","436","                _last_memory_leak_check = time()","438","            if time() - _last_memory_leak_check > _MEMORY_LEAK_CHECK_DELAY:","440","                print(mem_usage)","441","                _last_memory_leak_check = time()","450","                _last_memory_leak_check = time()","461","        else:","462","            # if psutil is not installed, trigger gc.collect events","463","            # regularly to limit potential memory leaks due to reference cycles","464","            if ((_last_memory_leak_check is None) or","465","                    (time() - _last_memory_leak_check >","466","                     _MEMORY_LEAK_CHECK_DELAY)):","467","                gc.collect()","468","                _last_memory_leak_check = time()"],"delete":["119","# Minimum time interval between two consecutive memory usage checks.","120","_MEMORY_CHECK_DELAY = 1.","135","    _get_memory_usage = None","385","    _process_last_memory_check = None","429","        if _get_memory_usage is not None:","433","                _process_last_memory_check = time()","435","            if time() - _process_last_memory_check > _MEMORY_CHECK_DELAY:","437","                _process_last_memory_check = time()","446","                _process_last_memory_check = time()"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/reduction.py":[{"add":["183","if not hasattr(sys, \"pypy_version_info\"):","184","    # PyPy uses functions instead of method_descriptors and wrapper_descriptors","185","    def _reduce_method_descriptor(m):","186","        return getattr, (m.__objclass__, m.__name__)","188","    register(type(list.append), _reduce_method_descriptor)","189","    register(type(int.__add__), _reduce_method_descriptor)"],"delete":["183","def _reduce_method_descriptor(m):","184","    return getattr, (m.__objclass__, m.__name__)","186","","187","register(type(list.append), _reduce_method_descriptor)","188","register(type(int.__add__), _reduce_method_descriptor)"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/compat.py":[{"add":["13","","14","from pickle import PicklingError"],"delete":["11","    from _pickle import PicklingError","14","    from pickle import PicklingError"]}],"sklearn\/externals\/joblib\/memory.py":[{"add":["459","","460","        # Wether or not the memorized function must be called","461","        must_call = False","462","","464","        # Compare the function code with the previous to see if the","465","        # function code has changed","475","            must_call = True","504","                must_call = True","505","","506","        if must_call:","507","            out, metadata = self.call(*args, **kwargs)","508","            if self.mmap_mode is not None:","509","                # Memmap the output at the first call to be consistent with","510","                # later calls","511","                if self._verbose:","512","                    msg = _format_load_msg(func_id, args_id,","513","                                           timestamp=self.timestamp,","514","                                           metadata=metadata)","515","                out = self.store_backend.load_item([func_id, args_id], msg=msg,","516","                                                   verbose=self._verbose)"],"delete":["456","        # Compare the function code with the previous to see if the","457","        # function code has changed","471","            out, metadata = self.call(*args, **kwargs)","472","            if self.mmap_mode is not None:","473","                # Memmap the output at the first call to be consistent with","474","                # later calls","475","                if self._verbose:","476","                    msg = _format_load_msg(func_id, args_id,","477","                                           timestamp=self.timestamp,","478","                                           metadata=metadata)","479","                out = self.store_backend.load_item([func_id, args_id], msg=msg,","480","                                                   verbose=self._verbose)","509","                out, metadata = self.call(*args, **kwargs)","510","                args_id = None"]}]}},"3c76b9c425048552a1850582bdc064baa1438185":{"changes":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":"MODIFY","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/linear_model\/coordinate_descent.py":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":[{"add":["820","","821","","822","def test_warm_start_multitask_lasso():","823","    X, y, X_test, y_test = build_dataset()","824","    Y = np.c_[y, y]","825","    clf = MultiTaskLasso(alpha=0.1, max_iter=5, warm_start=True)","826","    ignore_warnings(clf.fit)(X, Y)","827","    ignore_warnings(clf.fit)(X, Y)  # do a second round with 5 iterations","828","","829","    clf2 = MultiTaskLasso(alpha=0.1, max_iter=10)","830","    ignore_warnings(clf2.fit)(X, Y)","831","    assert_array_almost_equal(clf2.coef_, clf.coef_)"],"delete":[]}],"doc\/whats_new\/v0.21.rst":[{"add":["42",":mod:`sklearn.linear_model`","43","...........................","44","- |Fix| Fixed a bug in :class:`linear_model.MultiTaskElasticNet` which was breaking","45","  ``MultiTaskElasticNet`` and ``MultiTaskLasso`` when ``warm_start = True``. :issue:`12360`","46","  by :user:`Aakanksha Joshi <joaak>`.","47",""],"delete":[]}],"sklearn\/linear_model\/coordinate_descent.py":[{"add":["1797","        if not self.warm_start or not hasattr(self, \"coef_\"):"],"delete":["1797","        if not self.warm_start or self.coef_ is None:"]}]}},"40441e86f587e8d7066618b328c43d22f8554f96":{"changes":{"\/dev\/null":"DELETE","doc\/modules\/classes.rst":"MODIFY","sklearn\/cluster\/__init__.py":"MODIFY","examples\/cluster\/plot_cluster_comparison.py":"MODIFY","sklearn\/cluster\/tests\/test_optics.py":"MODIFY","sklearn\/cluster\/optics_.py":"MODIFY"},"diff":{"\/dev\/null":[{"add":[],"delete":[]}],"doc\/modules\/classes.rst":[{"add":["121","   cluster.compute_optics_graph","122","   cluster.cluster_optics_dbscan"],"delete":[]}],"sklearn\/cluster\/__init__.py":[{"add":["13","from .optics_ import OPTICS, cluster_optics_dbscan, compute_optics_graph","22","           'cluster_optics_dbscan',","23","           'compute_optics_graph',"],"delete":["13","from .optics_ import OPTICS"]}],"examples\/cluster\/plot_cluster_comparison.py":[{"add":[],"delete":["118","    optics = cluster.OPTICS(min_samples=30, maxima_ratio=.8,","119","                            rejection_ratio=.4)","137","        ('OPTICS', optics),"]}],"sklearn\/cluster\/tests\/test_optics.py":[{"add":["80","    clust = OPTICS(max_eps=5.0 * 0.03,","81","                   cluster_method='dbscan',","82","                   eps=0.3, min_samples=10)","83","    assert_raise_message(ValueError, msg, clust.fit, X)","92","    with pytest.warns(UserWarning, match=msg):","93","        clust = OPTICS(max_eps=5.0 * 0.003, min_samples=10, eps=0.015)","94","        clust.fit(X)","105","    clust = OPTICS(max_eps=1.0, cluster_method='dbscan',","106","                   eps=0.3, min_samples=10)","108","    assert_warns(RuntimeWarning, clust.fit, X)","110","    assert_equal(max(clust.labels_), 2)","123","    op = OPTICS(min_samples=min_samples, cluster_method='dbscan',","124","                eps=eps).fit(X)","129","    contingency = contingency_matrix(db.labels_, op.labels_)","134","    percent_mismatch = np.round((disagree - 1) \/ X.shape[0], 2)","260","def test_wrong_cluster_method():","261","    clust = OPTICS(cluster_method='superfancy')","262","    with pytest.raises(ValueError, match=\"cluster_method should be one of \"):","263","        clust.fit(X)","264","","265","","266","def test_extract_dbscan():","267","    # testing an easy dbscan case. Not including clusters with different","268","    # densities.","269","    rng = np.random.RandomState(0)","270","    n_points_per_cluster = 20","271","    C1 = [-5, -2] + .2 * rng.randn(n_points_per_cluster, 2)","272","    C2 = [4, -1] + .2 * rng.randn(n_points_per_cluster, 2)","273","    C3 = [1, 2] + .2 * rng.randn(n_points_per_cluster, 2)","274","    C4 = [-2, 3] + .2 * rng.randn(n_points_per_cluster, 2)","275","    X = np.vstack((C1, C2, C3, C4))","276","","277","    clust = OPTICS(cluster_method='dbscan', eps=.5).fit(X)","278","    assert_array_equal(np.sort(np.unique(clust.labels_)), [0, 1, 2, 3])","279","","280",""],"delete":["9","from sklearn.cluster.optics_ import _TreeNode, _cluster_tree","10","from sklearn.cluster.optics_ import _find_local_maxima","47","    assert clust.core_sample_indices_.ndim == 1","48","    assert clust.core_sample_indices_.size > 0","49","    assert clust.core_sample_indices_.dtype.kind == 'i'","50","","78","def test_empty_extract():","79","    # Test extract where fit() has not yet been run.","80","    msg = (\"This OPTICS instance is not fitted yet. Call 'fit' with \"","81","           \"appropriate arguments before using this method.\")","82","    clust = OPTICS(max_eps=5.0 * 0.3, min_samples=10)","83","    assert_raise_message(ValueError, msg, clust.extract_dbscan, 0.01)","84","","85","","94","    clust = OPTICS(max_eps=5.0 * 0.03, min_samples=10)","95","    clust2 = clust.fit(X)","96","    assert_raise_message(ValueError, msg, clust2.extract_dbscan, 0.3)","105","    clust = OPTICS(max_eps=5.0 * 0.003, min_samples=10)","106","    assert_raise_message(ValueError, msg, clust.fit, X)","117","    clust = OPTICS(max_eps=1.0, min_samples=10)","118","    clust3 = clust.fit(X)","120","    assert_warns(RuntimeWarning, clust3.extract_dbscan, .3)","122","    assert_equal(max(clust3.extract_dbscan(.3)[1]), 2)","135","    op = OPTICS(min_samples=min_samples).fit(X)","136","    core_optics, labels_optics = op.extract_dbscan(eps)","141","    contingency = contingency_matrix(db.labels_, labels_optics)","146","    # verify core_labels match","147","    assert_array_equal(core_optics, db.core_sample_indices_)","148","","149","    non_core_count = len(labels_optics) - len(core_optics)","150","    percent_mismatch = np.round((disagree - 1) \/ non_core_count, 2)","184","@pytest.mark.parametrize(\"reach, n_child, members\", [","185","    (np.array([np.inf, 0.9, 0.9, 1.0, 0.89, 0.88, 10, .9, .9, .9, 10, 0.9,","186","               0.9, 0.89, 0.88, 10, .9, .9, .9, .9]), 2, np.r_[0:6]),","187","    (np.array([np.inf, 0.9, 0.9, 0.9, 0.89, 0.88, 10, .9, .9, .9, 10, 0.9,","188","               0.9, 0.89, 0.88, 100, .9, .9, .9, .9]), 1, np.r_[0:15])])","189","def test_cluster_sigmin_pruning(reach, n_child, members):","190","    # Tests pruning left and right, insignificant splitpoints, empty nodelists","191","    # Parameters chosen specifically for this task","192","","193","    # Case 1: Three pseudo clusters, 2 of which are too small","194","    # Case 2: Two pseudo clusters, 1 of which are too small","195","    # Normalize","196","    reach = reach \/ np.max(reach[1:])","197","","198","    ordering = np.r_[0:20]","199","    cluster_boundaries = _find_local_maxima(reach, 5)","200","    root = _TreeNode(ordering, 0, 20, None)","201","","202","    # Build cluster tree inplace on root node","203","    _cluster_tree(root, None, cluster_boundaries, reach, ordering,","204","                  5, .75, .7, .4, .3)","205","    assert_equal(root.split_point, cluster_boundaries[0])","206","    assert_equal(n_child, len(root.children))","207","    assert_array_equal(members, root.children[0].points)","208","","209",""]}],"sklearn\/cluster\/optics_.py":[{"add":["7","         Adrin Jalali <adrinjalali@gmail.com>","25","    OPTICS: Ordering Points To Identify the Clustering Structure Closely","26","    related to DBSCAN, finds core sample of high density and expands clusters","27","    from them [1]_. Unlike DBSCAN, keeps cluster hierarchy for a variable","28","    neighborhood radius. Better suited for usage on large datasets than the","29","    current sklearn implementation of DBSCAN.","30","","31","    Clusters are then extracted using a DBSCAN like method [1]_.","88","    cluster_method : string, optional (default='dbscan')","89","        The extraction method used to extract clusters using the calculated","90","        reachability and ordering. Possible values are \"dbscan\".","92","    eps : float, optional (default=0.5)","93","        The maximum distance between two samples for them to be considered","94","        as in the same neighborhood. Used ony when `cluster_method='dbscan'`.","100","        Used only when `extract_method='xi'`.","157","    .. [1] Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel,","158","       and J?rg Sander. \"OPTICS: ordering points to identify the clustering","159","       structure.\" ACM SIGMOD Record 28, no. 2 (1999): 49-60.","161","    .. [2] Schubert, Erich, Michael Gertz.","162","       \"Improving the Cluster Structure Extracted from OPTICS Plots.\" Proc. of","163","       the Conference \"Lernen, Wissen, Daten, Analysen\" (LWDA) (2018): 318-329.","164","","167","    def __init__(self, min_samples=5, max_eps=np.inf, metric='minkowski', p=2,","168","                 metric_params=None, cluster_method='dbscan', eps=0.5,","169","                 min_cluster_size=.005, algorithm='auto', leaf_size=30,","170","                 n_jobs=None):","180","        self.cluster_method = cluster_method","181","        self.eps = eps","218","        if self.min_samples > n_samples:","219","            raise ValueError(\"Number of training samples (n_samples=%d) must \"","220","                             \"be greater than min_samples (min_samples=%d) \"","221","                             \"used for clustering.\" %","222","                             (n_samples, self.min_samples))","224","        if self.cluster_method not in ['dbscan']:","225","            raise ValueError(\"cluster_method should be one of\"","226","                             \" 'dbscan', but is %s\" %","227","                             self.cluster_method)","229","        if self.cluster_method == 'dbscan':","230","            if self.eps > self.max_eps:","231","                raise ValueError('Specify an epsilon smaller than %s. Got %s.'","232","                                 % (self.max_eps, self.eps))","234","            if self.eps * 5.0 > self.max_eps * 1.05:","235","                warnings.warn(","236","                    \"Warning, max_eps (%s) is close to eps (%s): \"","237","                    \"Output may be unstable.\" % (self.max_eps, self.eps),","238","                    RuntimeWarning, stacklevel=2)","239","                # Stability warning is documented in cluster_optics_dbscan","240","                # method...","241","","242","        (self.ordering_, self.core_distances_, self.reachability_,","243","         self.predecessor_) = compute_optics_graph(","244","             X=X, min_samples=self.min_samples, algorithm=self.algorithm,","245","             leaf_size=self.leaf_size, metric=self.metric,","246","             metric_params=self.metric_params, p=self.p, n_jobs=self.n_jobs,","247","             max_eps=self.max_eps)","248","","249","        # Extract clusters from the calculated orders and reachability","250","        if self.cluster_method == 'dbscan':","251","            labels_ = cluster_optics_dbscan(self.reachability_,","252","                                            self.core_distances_,","253","                                            self.ordering_,","254","                                            self.eps)","255","","256","        self.labels_ = labels_","260","# OPTICS helper functions","261","def _compute_core_distances_(X, neighbors, min_samples, working_memory):","262","    \"\"\"Compute the k-th nearest neighbor of each sample","264","    Equivalent to neighbors.kneighbors(X, self.min_samples)[0][:, -1]","265","    but with more memory efficiency.","269","    X : array, shape (n_samples, n_features)","270","        The data.","271","    neighbors : NearestNeighbors instance","272","        The fitted nearest neighbors estimator.","273","    working_memory : int, optional","274","        The sought maximum memory for temporary distance matrix chunks.","275","        When None (default), the value of","276","        ``sklearn.get_config()['working_memory']`` is used.","280","    core_distances : array, shape (n_samples,)","281","        Distance at which each sample becomes a core point.","282","        Points which will never be core have a distance of inf.","283","    \"\"\"","284","    n_samples = len(X)","285","    core_distances = np.empty(n_samples)","286","    core_distances.fill(np.nan)","288","    chunk_n_rows = get_chunk_n_rows(row_bytes=16 * min_samples,","289","                                    max_n_rows=n_samples,","290","                                    working_memory=working_memory)","291","    slices = gen_batches(n_samples, chunk_n_rows)","292","    for sl in slices:","293","        core_distances[sl] = neighbors.kneighbors(","294","            X[sl], min_samples)[0][:, -1]","295","    return core_distances","296","","297","","298","def compute_optics_graph(X, min_samples, max_eps, metric, p, metric_params,","299","                         algorithm, leaf_size, n_jobs):","300","    \"\"\"Computes the OPTICS reachability graph.","301","","302","    Read more in the :ref:`User Guide <optics>`.","303","","304","    Parameters","305","    ----------","306","    X : array, shape (n_samples, n_features)","307","        The data.","308","","309","    min_samples : int (default=5)","310","        The number of samples in a neighborhood for a point to be considered","311","        as a core point.","312","","313","    max_eps : float, optional (default=np.inf)","314","        The maximum distance between two samples for them to be considered","315","        as in the same neighborhood. Default value of \"np.inf\" will identify","316","        clusters across all scales; reducing `max_eps` will result in","317","        shorter run times.","318","","319","    metric : string or callable, optional (default='minkowski')","320","        metric to use for distance computation. Any metric from scikit-learn","321","        or scipy.spatial.distance can be used.","322","","323","        If metric is a callable function, it is called on each","324","        pair of instances (rows) and the resulting value recorded. The callable","325","        should take two arrays as input and return one value indicating the","326","        distance between them. This works for Scipy's metrics, but is less","327","        efficient than passing the metric name as a string.","328","","329","        Distance matrices are not supported.","330","","331","        Valid values for metric are:","332","","333","        - from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',","334","          'manhattan']","335","","336","        - from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',","337","          'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski',","338","          'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao',","339","          'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',","340","          'yule']","341","","342","        See the documentation for scipy.spatial.distance for details on these","343","        metrics.","344","","345","    p : integer, optional (default=2)","346","        Parameter for the Minkowski metric from","347","        :class:`sklearn.metrics.pairwise_distances`. When p = 1, this is","348","        equivalent to using manhattan_distance (l1), and euclidean_distance","349","        (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.","350","","351","    metric_params : dict, optional (default=None)","352","        Additional keyword arguments for the metric function.","353","","354","    algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional","355","        Algorithm used to compute the nearest neighbors:","356","","357","        - 'ball_tree' will use :class:`BallTree`","358","        - 'kd_tree' will use :class:`KDTree`","359","        - 'brute' will use a brute-force search.","360","        - 'auto' will attempt to decide the most appropriate algorithm","361","          based on the values passed to :meth:`fit` method. (default)","362","","363","        Note: fitting on sparse input will override the setting of","364","        this parameter, using brute force.","365","","366","    leaf_size : int, optional (default=30)","367","        Leaf size passed to :class:`BallTree` or :class:`KDTree`. This can","368","        affect the speed of the construction and query, as well as the memory","369","        required to store the tree. The optimal value depends on the","370","        nature of the problem.","371","","372","    n_jobs : int or None, optional (default=None)","373","        The number of parallel jobs to run for neighbors search.","374","        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.","375","        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`","376","        for more details.","377","","378","    Returns","379","    -------","380","    ordering_ : array, shape (n_samples,)","381","        The cluster ordered list of sample indices.","382","","383","    core_distances_ : array, shape (n_samples,)","384","        Distance at which each sample becomes a core point, indexed by object","385","        order. Points which will never be core have a distance of inf. Use","386","        ``clust.core_distances_[clust.ordering_]`` to access in cluster order.","387","","388","    reachability_ : array, shape (n_samples,)","389","        Reachability distances per sample, indexed by object order. Use","390","        ``clust.reachability_[clust.ordering_]`` to access in cluster order.","391","","392","    predecessor_ : array, shape (n_samples,)","393","        Point that a sample was reached from, indexed by object order.","394","        Seed points have a predecessor of -1.","395","","396","    References","397","    ----------","398","    .. [1] Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel,","399","       and J?rg Sander. \"OPTICS: ordering points to identify the clustering","400","       structure.\" ACM SIGMOD Record 28, no. 2 (1999): 49-60.","401","    \"\"\"","402","    n_samples = len(X)","403","    # Start all points as 'unprocessed' ##","404","    reachability_ = np.empty(n_samples)","405","    reachability_.fill(np.inf)","406","    predecessor_ = np.empty(n_samples, dtype=int)","407","    predecessor_.fill(-1)","408","","409","    nbrs = NearestNeighbors(n_neighbors=min_samples,","410","                            algorithm=algorithm,","411","                            leaf_size=leaf_size,","412","                            metric=metric,","413","                            metric_params=metric_params,","414","                            p=p,","415","                            n_jobs=n_jobs)","416","","417","    nbrs.fit(X)","418","    # Here we first do a kNN query for each point, this differs from","419","    # the original OPTICS that only used epsilon range queries.","420","    # TODO: handle working_memory somehow?","421","    core_distances_ = _compute_core_distances_(X=X, neighbors=nbrs,","422","                                               min_samples=min_samples,","423","                                               working_memory=None)","424","    # OPTICS puts an upper limit on these, use inf for undefined.","425","    core_distances_[core_distances_ > max_eps] = np.inf","426","","427","    # Main OPTICS loop. Not parallelizable. The order that entries are","428","    # written to the 'ordering_' list is important!","429","    # Note that this implementation is O(n^2) theoretically, but","430","    # supposedly with very low constant factors.","431","    processed = np.zeros(X.shape[0], dtype=bool)","432","    ordering = np.zeros(X.shape[0], dtype=int)","433","    for ordering_idx in range(X.shape[0]):","434","        # Choose next based on smallest reachability distance","435","        # (And prefer smaller ids on ties, possibly np.inf!)","436","        index = np.where(processed == 0)[0]","437","        point = index[np.argmin(reachability_[index])]","438","","439","        processed[point] = True","440","        ordering[ordering_idx] = point","441","        if core_distances_[point] != np.inf:","442","            _set_reach_dist(core_distances_=core_distances_,","443","                            reachability_=reachability_,","444","                            predecessor_=predecessor_,","445","                            point_index=point,","446","                            processed=processed, X=X, nbrs=nbrs,","447","                            metric=metric, metric_params=metric_params,","448","                            p=p, max_eps=max_eps)","449","    if np.all(np.isinf(reachability_)):","450","        warnings.warn(\"All reachability values are inf. Set a larger\"","451","                      \" max_eps or all data will be considered outliers.\",","452","                      UserWarning)","453","    return ordering, core_distances_, reachability_, predecessor_","454","","455","","456","def _set_reach_dist(core_distances_, reachability_, predecessor_,","457","                    point_index, processed, X, nbrs, metric, metric_params,","458","                    p, max_eps):","459","    P = X[point_index:point_index + 1]","460","    # Assume that radius_neighbors is faster without distances","461","    # and we don't need all distances, nevertheless, this means","462","    # we may be doing some work twice.","463","    indices = nbrs.radius_neighbors(P, radius=max_eps,","464","                                    return_distance=False)[0]","465","","466","    # Getting indices of neighbors that have not been processed","467","    unproc = np.compress((~np.take(processed, indices)).ravel(),","468","                         indices, axis=0)","469","    # Neighbors of current point are already processed.","470","    if not unproc.size:","471","        return","472","","473","    # Only compute distances to unprocessed neighbors:","474","    if metric == 'precomputed':","475","        dists = X[point_index, unproc]","476","    else:","477","        _params = dict() if metric_params is None else metric_params.copy()","478","        if metric == 'minkowski' and 'p' not in _params:","479","            # the same logic as neighbors, p is ignored if explicitly set","480","            # in the dict params","481","            _params['p'] = p","482","        dists = pairwise_distances(P, np.take(X, unproc, axis=0),","483","                                   metric, n_jobs=None,","484","                                   **_params).ravel()","485","","486","    rdists = np.maximum(dists, core_distances_[point_index])","487","    improved = np.where(rdists < np.take(reachability_, unproc))","488","    reachability_[unproc[improved]] = rdists[improved]","489","    predecessor_[unproc[improved]] = point_index","490","","491","","492","def cluster_optics_dbscan(reachability, core_distances, ordering, eps=0.5):","493","    \"\"\"Performs DBSCAN extraction for an arbitrary epsilon.","494","","495","    Extracting the clusters runs in linear time. Note that if the `max_eps`","496","    OPTICS parameter was set to < inf for extracting reachability and ordering","497","    arrays, DBSCAN extractions will be unstable for `eps` values close to","498","    `max_eps`. Setting `eps` < (`max_eps` \/ 5.0) will guarantee extraction","499","    parity with DBSCAN.","500","","501","    Parameters","502","    ----------","503","    reachability : array, shape (n_samples,)","504","        Reachability distances calculated by OPTICS (`reachability_`)","505","","506","    core_distances : array, shape (n_samples,)","507","        Distances at which points become core (`core_distances_`)","508","","509","    ordering : array, shape (n_samples,)","510","        OPTICS ordered point indices (`ordering_`)","511","","512","    eps : float, optional (default=0.5)","513","        DBSCAN `eps` parameter. Must be set to < `max_eps`. Results","514","        will be close to DBSCAN algorithm if `eps` is < (`max_eps` \/ 5)","515","","516","    Returns","517","    -------","521","    \"\"\"","529","    return labels"],"delete":["7","         Amy X. Zhang <axz@mit.edu>","17","from ..utils.validation import check_is_fitted","26","    OPTICS: Ordering Points To Identify the Clustering Structure","27","    Closely related to DBSCAN, finds core sample of high density and expands","28","    clusters from them. Unlike DBSCAN, keeps cluster hierarchy for a variable","29","    neighborhood radius. Better suited for usage on large point datasets than","30","    the current sklearn implementation of DBSCAN.","87","    maxima_ratio : float, optional (default=.75)","88","        The maximum ratio we allow of average height of clusters on the","89","        right and left to the local maxima in question. The higher the","90","        ratio, the more generous the algorithm is to preserving local","91","        minima, and the more cuts the resulting tree will have.","93","    rejection_ratio : float, optional (default=.7)","94","        Adjusts the fitness of the clustering. When the maxima_ratio is","95","        exceeded, determine which of the clusters to the left and right to","96","        reject based on rejection_ratio. Higher values will result in points","97","        being more readily classified as noise; conversely, lower values will","98","        result in more points being clustered.","99","","100","    similarity_threshold : float, optional (default=.4)","101","        Used to check if nodes can be moved up one level, that is, if the","102","        new cluster created is too \"similar\" to its parent, given the","103","        similarity threshold. Similarity can be determined by 1) the size","104","        of the new cluster relative to the size of the parent node or","105","        2) the average of the reachability values of the new cluster","106","        relative to the average of the reachability values of the parent","107","        node. A lower value for the similarity threshold means less levels","108","        in the tree.","109","","110","    significant_min : float, optional (default=.003)","111","        Sets a lower threshold on how small a significant maxima can be.","117","","118","    min_maxima_ratio : float, optional (default=.001)","119","        Used to determine neighborhood size for minimum cluster membership.","120","        Each local maxima should be a largest value in a neighborhood","121","        of the `size min_maxima_ratio * len(X)` from left and right.","149","    core_sample_indices_ : array, shape (n_core_samples,)","150","        Indices of core samples.","151","","181","    Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel, and J?rg Sander.","182","    \"OPTICS: ordering points to identify the clustering structure.\" ACM SIGMOD","183","    Record 28, no. 2 (1999): 49-60.","185","    Schubert, Erich, Michael Gertz.","186","    \"Improving the Cluster Structure Extracted from OPTICS Plots.\" Proc. of","187","    the Conference \"Lernen, Wissen, Daten, Analysen\" (LWDA) (2018): 318-329.","190","    def __init__(self, min_samples=5, max_eps=np.inf, metric='minkowski',","191","                 p=2, metric_params=None, maxima_ratio=.75,","192","                 rejection_ratio=.7, similarity_threshold=0.4,","193","                 significant_min=.003, min_cluster_size=.005,","194","                 min_maxima_ratio=0.001, algorithm='auto',","195","                 leaf_size=30, n_jobs=None):","199","        self.maxima_ratio = maxima_ratio","200","        self.rejection_ratio = rejection_ratio","201","        self.similarity_threshold = similarity_threshold","202","        self.significant_min = significant_min","204","        self.min_maxima_ratio = min_maxima_ratio","235","        if self.min_samples > n_samples:","236","            raise ValueError(\"Number of training samples (n_samples=%d) must \"","237","                             \"be greater than min_samples (min_samples=%d) \"","238","                             \"used for clustering.\" %","239","                             (n_samples, self.min_samples))","240","","252","        # Start all points as 'unprocessed' ##","253","        self.reachability_ = np.empty(n_samples)","254","        self.reachability_.fill(np.inf)","255","        self.predecessor_ = np.empty(n_samples, dtype=int)","256","        self.predecessor_.fill(-1)","257","        # Start all points as noise ##","258","        self.labels_ = np.full(n_samples, -1, dtype=int)","260","        nbrs = NearestNeighbors(n_neighbors=self.min_samples,","261","                                algorithm=self.algorithm,","262","                                leaf_size=self.leaf_size, metric=self.metric,","263","                                metric_params=self.metric_params, p=self.p,","264","                                n_jobs=self.n_jobs)","266","        nbrs.fit(X)","267","        # Here we first do a kNN query for each point, this differs from","268","        # the original OPTICS that only used epsilon range queries.","269","        self.core_distances_ = self._compute_core_distances_(X, nbrs)","270","        # OPTICS puts an upper limit on these, use inf for undefined.","271","        self.core_distances_[self.core_distances_ > self.max_eps] = np.inf","272","        self.ordering_ = self._calculate_optics_order(X, nbrs)","274","        indices_, self.labels_ = _extract_optics(self.ordering_,","275","                                                 self.reachability_,","276","                                                 self.maxima_ratio,","277","                                                 self.rejection_ratio,","278","                                                 self.similarity_threshold,","279","                                                 self.significant_min,","280","                                                 self.min_cluster_size,","281","                                                 self.min_maxima_ratio)","282","        self.core_sample_indices_ = indices_","285","    # OPTICS helper functions","286","    def _compute_core_distances_(self, X, neighbors, working_memory=None):","287","        \"\"\"Compute the k-th nearest neighbor of each sample","289","        Equivalent to neighbors.kneighbors(X, self.min_samples)[0][:, -1]","290","        but with more memory efficiency.","292","        Parameters","293","        ----------","294","        X : array, shape (n_samples, n_features)","295","            The data.","296","        neighbors : NearestNeighbors instance","297","            The fitted nearest neighbors estimator.","298","        working_memory : int, optional","299","            The sought maximum memory for temporary distance matrix chunks.","300","            When None (default), the value of","301","            ``sklearn.get_config()['working_memory']`` is used.","302","","303","        Returns","304","        -------","305","        core_distances : array, shape (n_samples,)","306","            Distance at which each sample becomes a core point.","307","            Points which will never be core have a distance of inf.","308","        \"\"\"","309","        n_samples = len(X)","310","        core_distances = np.empty(n_samples)","311","        core_distances.fill(np.nan)","312","","313","        chunk_n_rows = get_chunk_n_rows(row_bytes=16 * self.min_samples,","314","                                        max_n_rows=n_samples,","315","                                        working_memory=working_memory)","316","        slices = gen_batches(n_samples, chunk_n_rows)","317","        for sl in slices:","318","            core_distances[sl] = neighbors.kneighbors(","319","                X[sl], self.min_samples)[0][:, -1]","320","        return core_distances","321","","322","    def _calculate_optics_order(self, X, nbrs):","323","        # Main OPTICS loop. Not parallelizable. The order that entries are","324","        # written to the 'ordering_' list is important!","325","        # Note that this implementation is O(n^2) theoretically, but","326","        # supposedly with very low constant factors.","327","        processed = np.zeros(X.shape[0], dtype=bool)","328","        ordering = np.zeros(X.shape[0], dtype=int)","329","        for ordering_idx in range(X.shape[0]):","330","            # Choose next based on smallest reachability distance","331","            # (And prefer smaller ids on ties, possibly np.inf!)","332","            index = np.where(processed == 0)[0]","333","            point = index[np.argmin(self.reachability_[index])]","334","","335","            processed[point] = True","336","            ordering[ordering_idx] = point","337","            if self.core_distances_[point] != np.inf:","338","                self._set_reach_dist(point, processed, X, nbrs)","339","        return ordering","340","","341","    def _set_reach_dist(self, point_index, processed, X, nbrs):","342","        P = X[point_index:point_index + 1]","343","        # Assume that radius_neighbors is faster without distances","344","        # and we don't need all distances, nevertheless, this means","345","        # we may be doing some work twice.","346","        indices = nbrs.radius_neighbors(P, radius=self.max_eps,","347","                                        return_distance=False)[0]","348","","349","        # Getting indices of neighbors that have not been processed","350","        unproc = np.compress((~np.take(processed, indices)).ravel(),","351","                             indices, axis=0)","352","        # Neighbors of current point are already processed.","353","        if not unproc.size:","354","            return","355","","356","        # Only compute distances to unprocessed neighbors:","357","        if self.metric == 'precomputed':","358","            dists = X[point_index, unproc]","359","        else:","360","            dists = pairwise_distances(P, np.take(X, unproc, axis=0),","361","                                       self.metric, n_jobs=None).ravel()","362","","363","        rdists = np.maximum(dists, self.core_distances_[point_index])","364","        improved = np.where(rdists < np.take(self.reachability_, unproc))","365","        self.reachability_[unproc[improved]] = rdists[improved]","366","        self.predecessor_[unproc[improved]] = point_index","367","","368","    def extract_dbscan(self, eps):","369","        \"\"\"Performs DBSCAN extraction for an arbitrary epsilon.","370","","371","        Extraction runs in linear time. Note that if the `max_eps` OPTICS","372","        parameter was set to < inf for extracting reachability and ordering","373","        arrays, DBSCAN extractions will be unstable for `eps` values close to","374","        `max_eps`. Setting `eps` < (`max_eps` \/ 5.0) will guarantee","375","        extraction parity with DBSCAN.","376","","377","        Parameters","378","        ----------","379","        eps : float or int, required","380","            DBSCAN `eps` parameter. Must be set to < `max_eps`. Equivalence","381","            with DBSCAN algorithm is achieved if `eps` is < (`max_eps` \/ 5)","382","","383","        Returns","384","        -------","385","        core_sample_indices_ : array, shape (n_core_samples,)","386","            The indices of the core samples.","387","","388","        labels_ : array, shape (n_samples,)","389","            The estimated labels.","390","        \"\"\"","391","        check_is_fitted(self, 'reachability_')","392","","393","        if eps > self.max_eps:","394","            raise ValueError('Specify an epsilon smaller than %s. Got %s.'","395","                             % (self.max_eps, eps))","396","","397","        if eps * 5.0 > (self.max_eps * 1.05):","398","            warnings.warn(","399","                \"Warning, max_eps (%s) is close to eps (%s): \"","400","                \"Output may be unstable.\" % (self.max_eps, eps),","401","                RuntimeWarning, stacklevel=2)","402","        # Stability warning is documented in _extract_dbscan method...","403","","404","        return _extract_dbscan(self.ordering_, self.core_distances_,","405","                               self.reachability_, eps)","406","","407","","408","def _extract_dbscan(ordering, core_distances, reachability, eps):","409","    \"\"\"Performs DBSCAN extraction for an arbitrary epsilon (`eps`).","413","    ordering : array, shape (n_samples,)","414","        OPTICS ordered point indices (`ordering_`)","415","    core_distances : array, shape (n_samples,)","416","        Distances at which points become core (`core_distances_`)","417","    reachability : array, shape (n_samples,)","418","        Reachability distances calculated by OPTICS (`reachability_`)","419","    eps : float or int","420","        DBSCAN `eps` parameter","424","    core_sample_indices_ : array, shape (n_core_samples,)","425","        The indices of the core samples.","429","    \"\"\"","432","    is_core = np.zeros(n_samples, dtype=bool)","439","    is_core[near_core] = True","440","    return np.arange(n_samples)[is_core], labels","441","","442","","443","def _extract_optics(ordering, reachability, maxima_ratio=.75,","444","                    rejection_ratio=.7, similarity_threshold=0.4,","445","                    significant_min=.003, min_cluster_size=.005,","446","                    min_maxima_ratio=0.001):","447","    \"\"\"Performs automatic cluster extraction for variable density data.","448","","449","    Parameters","450","    ----------","451","    ordering : array, shape (n_samples,)","452","        OPTICS ordered point indices (`ordering_`)","453","","454","    reachability : array, shape (n_samples,)","455","        Reachability distances calculated by OPTICS (`reachability_`)","456","","457","    maxima_ratio : float, optional","458","        The maximum ratio we allow of average height of clusters on the","459","        right and left to the local maxima in question. The higher the","460","        ratio, the more generous the algorithm is to preserving local","461","        minima, and the more cuts the resulting tree will have.","462","","463","    rejection_ratio : float, optional","464","        Adjusts the fitness of the clustering. When the maxima_ratio is","465","        exceeded, determine which of the clusters to the left and right to","466","        reject based on rejection_ratio. Higher values will result in points","467","        being more readily classified as noise; conversely, lower values will","468","        result in more points being clustered.","469","","470","    similarity_threshold : float, optional","471","        Used to check if nodes can be moved up one level, that is, if the","472","        new cluster created is too \"similar\" to its parent, given the","473","        similarity threshold. Similarity can be determined by 1) the size","474","        of the new cluster relative to the size of the parent node or","475","        2) the average of the reachability values of the new cluster","476","        relative to the average of the reachability values of the parent","477","        node. A lower value for the similarity threshold means less levels","478","        in the tree.","479","","480","    significant_min : float, optional","481","        Sets a lower threshold on how small a significant maxima can be.","482","","483","    min_cluster_size : int > 1 or float between 0 and 1","484","        Minimum number of samples in an OPTICS cluster, expressed as an","485","        absolute number or a fraction of the number of samples (rounded","486","        to be at least 2).","487","","488","    min_maxima_ratio : float, optional","489","        Used to determine neighborhood size for minimum cluster membership.","490","","491","    Returns","492","    -------","493","    core_sample_indices_ : array, shape (n_core_samples,)","494","        The indices of the core samples.","495","","496","    labels_ : array, shape (n_samples,)","497","        The estimated labels.","498","    \"\"\"","499","","500","    # Extraction wrapper","501","    # according to Ankerst M. et.al. 1999 (p. 5), for a small enough","502","    # generative distance epsilong, there should be more than one INF.","503","    if np.all(np.isinf(reachability)):","504","        raise ValueError(\"All reachability values are inf. Set a larger\"","505","                         \" max_eps.\")","506","    normalization_factor = np.max(reachability[reachability < np.inf])","507","    reachability = reachability \/ normalization_factor","508","    reachability_plot = reachability[ordering].tolist()","509","    root_node = _automatic_cluster(reachability_plot, ordering,","510","                                   maxima_ratio, rejection_ratio,","511","                                   similarity_threshold, significant_min,","512","                                   min_cluster_size, min_maxima_ratio)","513","    leaves = _get_leaves(root_node, [])","514","    # Start cluster id's at 0","515","    clustid = 0","516","    n_samples = len(reachability)","517","    is_core = np.zeros(n_samples, dtype=bool)","518","    labels = np.full(n_samples, -1, dtype=int)","519","    # Start all points as non-core noise","520","    for leaf in leaves:","521","        index = ordering[leaf.start:leaf.end]","522","        labels[index] = clustid","523","        is_core[index] = 1","524","        clustid += 1","525","    return np.arange(n_samples)[is_core], labels","526","","527","","528","def _automatic_cluster(reachability_plot, ordering,","529","                       maxima_ratio, rejection_ratio,","530","                       similarity_threshold, significant_min,","531","                       min_cluster_size, min_maxima_ratio):","532","    \"\"\"Converts reachability plot to cluster tree and returns root node.","533","","534","    Parameters","535","    ----------","536","","537","    reachability_plot : list, required","538","        Reachability distances ordered by OPTICS ordering index.","539","","540","    \"\"\"","541","","542","    min_neighborhood_size = 2","543","    if min_cluster_size <= 1:","544","        min_cluster_size = max(2, min_cluster_size * len(ordering))","545","    neighborhood_size = int(min_maxima_ratio * len(ordering))","546","","547","    # Again, should this check < min_samples, should the parameter be public?","548","    if neighborhood_size < min_neighborhood_size:","549","        neighborhood_size = min_neighborhood_size","550","","551","    local_maxima_points = _find_local_maxima(reachability_plot,","552","                                             neighborhood_size)","553","    root_node = _TreeNode(ordering, 0, len(ordering), None)","554","    _cluster_tree(root_node, None, local_maxima_points,","555","                  reachability_plot, ordering, min_cluster_size,","556","                  maxima_ratio, rejection_ratio,","557","                  similarity_threshold, significant_min)","558","","559","    return root_node","560","","561","","562","class _TreeNode:","563","    # automatic cluster helper classes and functions","564","    def __init__(self, points, start, end, parent_node):","565","        self.points = points","566","        self.start = start","567","        self.end = end","568","        self.parent_node = parent_node","569","        self.children = []","570","        self.split_point = -1","571","","572","","573","def _is_local_maxima(index, reachability_plot, neighborhood_size):","574","    right_idx = slice(index + 1, index + neighborhood_size + 1)","575","    left_idx = slice(max(1, index - neighborhood_size - 1), index)","576","    return (np.all(reachability_plot[index] >= reachability_plot[left_idx]) and","577","            np.all(reachability_plot[index] >= reachability_plot[right_idx]))","578","","579","","580","def _find_local_maxima(reachability_plot, neighborhood_size):","581","    local_maxima_points = {}","582","    # 1st and last points on Reachability Plot are not taken","583","    # as local maxima points","584","    for i in range(1, len(reachability_plot) - 1):","585","        # if the point is a local maxima on the reachability plot with","586","        # regard to neighborhood_size, insert it into priority queue and","587","        # maxima list","588","        if (reachability_plot[i] > reachability_plot[i - 1] and","589","            reachability_plot[i] >= reachability_plot[i + 1] and","590","            _is_local_maxima(i, np.array(reachability_plot),","591","                             neighborhood_size) == 1):","592","            local_maxima_points[i] = reachability_plot[i]","593","","594","    return sorted(local_maxima_points,","595","                  key=local_maxima_points.__getitem__, reverse=True)","596","","597","","598","def _cluster_tree(node, parent_node, local_maxima_points,","599","                  reachability_plot, reachability_ordering,","600","                  min_cluster_size, maxima_ratio, rejection_ratio,","601","                  similarity_threshold, significant_min):","602","    \"\"\"Recursively builds cluster tree to hold hierarchical cluster structure","603","","604","    node is a node or the root of the tree in the first call","605","    parent_node is parent node of N or None if node is root of the tree","606","    local_maxima_points is list of local maxima points sorted in","607","    descending order of reachability","608","    \"\"\"","609","","610","    if len(local_maxima_points) == 0:","611","        return  # parent_node is a leaf","612","","613","    # take largest local maximum as possible separation between clusters","614","    s = local_maxima_points[0]","615","    node.split_point = s","616","    local_maxima_points = local_maxima_points[1:]","617","","618","    # create two new nodes and add to list of nodes","619","    node_1 = _TreeNode(reachability_ordering[node.start:s],","620","                       node.start, s, node)","621","    node_2 = _TreeNode(reachability_ordering[s + 1:node.end],","622","                       s + 1, node.end, node)","623","    local_max_1 = []","624","    local_max_2 = []","625","","626","    for i in local_maxima_points:","627","        if i < s:","628","            local_max_1.append(i)","629","        if i > s:","630","            local_max_2.append(i)","631","","632","    node_list = []","633","    node_list.append((node_1, local_max_1))","634","    node_list.append((node_2, local_max_2))","635","","636","    if reachability_plot[s] < significant_min:","637","        node.split_point = -1","638","        # if split_point is not significant, ignore this split and continue","639","        return","640","","641","    # only check a certain ratio of points in the child","642","    # nodes formed to the left and right of the maxima","643","    # ...should check_ratio be a user settable parameter?","644","    check_ratio = .8","645","    check_value_1 = int(np.round(check_ratio * len(node_1.points)))","646","    check_value_2 = int(np.round(check_ratio * len(node_2.points)))","647","    avg_reach1 = np.mean(reachability_plot[(node_1.end -","648","                                            check_value_1):node_1.end])","649","    avg_reach2 = np.mean(reachability_plot[node_2.start:(node_2.start","650","                                                         + check_value_2)])","651","","652","    if ((avg_reach1 \/ maxima_ratio) > reachability_plot[s] or","653","            (avg_reach2 \/ maxima_ratio) > reachability_plot[s]):","654","","655","        if (avg_reach1 \/ rejection_ratio) < reachability_plot[s]:","656","            # reject node 2","657","            node_list.remove((node_2, local_max_2))","658","        if (avg_reach2 \/ rejection_ratio) < reachability_plot[s]:","659","            # reject node 1","660","            node_list.remove((node_1, local_max_1))","661","        if ((avg_reach1 \/ rejection_ratio) >= reachability_plot[s] and","662","                (avg_reach2 \/ rejection_ratio) >= reachability_plot[s]):","663","            # since split_point is not significant,","664","            # ignore this split and continue (reject both child nodes)","665","            node.split_point = -1","666","            _cluster_tree(node, parent_node, local_maxima_points,","667","                          reachability_plot, reachability_ordering,","668","                          min_cluster_size, maxima_ratio, rejection_ratio,","669","                          similarity_threshold, significant_min)","670","            return","671","","672","    # remove clusters that are too small","673","    if (len(node_1.points) < min_cluster_size and","674","            node_list.count((node_1, local_max_1)) > 0):","675","        # cluster 1 is too small","676","        node_list.remove((node_1, local_max_1))","677","    if (len(node_2.points) < min_cluster_size and","678","            node_list.count((node_2, local_max_2)) > 0):","679","        # cluster 2 is too small","680","        node_list.remove((node_2, local_max_2))","681","    if not node_list:","682","        # parent_node will be a leaf","683","        node.split_point = -1","684","        return","685","","686","    # Check if nodes can be moved up one level - the new cluster created","687","    # is too \"similar\" to its parent, given the similarity threshold.","688","    bypass_node = 0","689","    if parent_node is not None:","690","        if ((node.end - node.start) \/ (parent_node.end - parent_node.start) >","691","                similarity_threshold):","692","","693","            parent_node.children.remove(node)","694","            bypass_node = 1","695","","696","    for nl in node_list:","697","        if bypass_node == 1:","698","            parent_node.children.append(nl[0])","699","            _cluster_tree(nl[0], parent_node, nl[1],","700","                          reachability_plot, reachability_ordering,","701","                          min_cluster_size, maxima_ratio, rejection_ratio,","702","                          similarity_threshold, significant_min)","703","        else:","704","            node.children.append(nl[0])","705","            _cluster_tree(nl[0], node, nl[1], reachability_plot,","706","                          reachability_ordering, min_cluster_size,","707","                          maxima_ratio, rejection_ratio,","708","                          similarity_threshold, significant_min)","709","","710","","711","def _get_leaves(node, arr):","712","    if node is not None:","713","        if node.split_point == -1:","714","            arr.append(node)","715","        for n in node.children:","716","            _get_leaves(n, arr)","717","    return arr"]}]}},"0d13745d854ae5479425b6845b175b1ab402bd59":{"changes":{"sklearn\/metrics\/classification.py":"MODIFY"},"diff":{"sklearn\/metrics\/classification.py":[{"add":["677","            Calculate metrics for each label, and find their average weighted","780","            Calculate metrics for each label, and find their average weighted","952","            Calculate metrics for each label, and find their average weighted","1226","            Calculate metrics for each label, and find their average weighted","1325","            Calculate metrics for each label, and find their average weighted"],"delete":["677","            Calculate metrics for each label, and find their average, weighted","780","            Calculate metrics for each label, and find their average, weighted","952","            Calculate metrics for each label, and find their average, weighted","1226","            Calculate metrics for each label, and find their average, weighted","1325","            Calculate metrics for each label, and find their average, weighted"]}]}},"14c816e2b864f238b4751f68c7fc5e69741f028a":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/datasets\/tests\/test_openml.py":"MODIFY","sklearn\/datasets\/openml.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["67","- |Fix| :func:`datasets.fetch_openml` to retry downloading when reading","68","  from local cache fails. :issue:`12517` by :user:`Thomas Fan <thomasjpfan>`.","69",""],"delete":[]}],"sklearn\/datasets\/tests\/test_openml.py":[{"add":["15","                                     _get_local_path,","16","                                     _retry_with_clean_cache)","499","@pytest.mark.parametrize('write_to_disk', [True, False])","500","def test_open_openml_url_unlinks_local_path(","501","        monkeypatch, gzip_response, tmpdir, write_to_disk):","502","    data_id = 61","503","    openml_path = sklearn.datasets.openml._DATA_FILE.format(data_id)","504","    cache_directory = str(tmpdir.mkdir('scikit_learn_data'))","505","    location = _get_local_path(openml_path, cache_directory)","506","","507","    def _mock_urlopen(request):","508","        if write_to_disk:","509","            with open(location, \"w\") as f:","510","                f.write(\"\")","511","        raise ValueError(\"Invalid request\")","512","","513","    monkeypatch.setattr(sklearn.datasets.openml, 'urlopen', _mock_urlopen)","514","","515","    with pytest.raises(ValueError, match=\"Invalid request\"):","516","        _open_openml_url(openml_path, cache_directory)","517","","518","    assert not os.path.exists(location)","519","","520","","521","def test_retry_with_clean_cache(tmpdir):","522","    data_id = 61","523","    openml_path = sklearn.datasets.openml._DATA_FILE.format(data_id)","524","    cache_directory = str(tmpdir.mkdir('scikit_learn_data'))","525","    location = _get_local_path(openml_path, cache_directory)","526","    os.makedirs(os.path.dirname(location))","527","","528","    with open(location, 'w') as f:","529","        f.write(\"\")","530","","531","    @_retry_with_clean_cache(openml_path, cache_directory)","532","    def _load_data():","533","        # The first call will raise an error since location exists","534","        if os.path.exists(location):","535","            raise Exception(\"File exist!\")","536","        return 1","537","","538","    warn_msg = \"Invalid cache, redownloading file\"","539","    with pytest.warns(RuntimeWarning, match=warn_msg):","540","        result = _load_data()","541","    assert result == 1","542","","543","","544","def test_retry_with_clean_cache_http_error(tmpdir):","545","    data_id = 61","546","    openml_path = sklearn.datasets.openml._DATA_FILE.format(data_id)","547","    cache_directory = str(tmpdir.mkdir('scikit_learn_data'))","548","","549","    @_retry_with_clean_cache(openml_path, cache_directory)","550","    def _load_data():","551","        raise HTTPError(url=None, code=412,","552","                        msg='Simulated mock error',","553","                        hdrs=None, fp=None)","554","","555","    error_msg = \"Simulated mock error\"","556","    with pytest.raises(HTTPError, match=error_msg):","557","        _load_data()","558","","559","","560","@pytest.mark.parametrize('gzip_response', [True, False])"],"delete":["15","                                     _get_local_path)"]}],"sklearn\/datasets\/openml.py":[{"add":["6","from contextlib import closing","7","from functools import wraps","8","import warnings","40","def _retry_with_clean_cache(openml_path, data_home):","41","    \"\"\"If the first call to the decorated function fails, the local cached","42","    file is removed, and the function is called again. If ``data_home`` is","43","    ``None``, then the function is called once.","44","    \"\"\"","45","    def decorator(f):","46","        @wraps(f)","47","        def wrapper():","48","            if data_home is None:","49","                return f()","50","            try:","51","                return f()","52","            except HTTPError:","53","                raise","54","            except Exception:","55","                warnings.warn(","56","                    \"Invalid cache, redownloading file\",","57","                    RuntimeWarning)","58","                local_path = _get_local_path(openml_path, data_home)","59","                if os.path.exists(local_path):","60","                    os.unlink(local_path)","61","                return f()","62","        return wrapper","63","    return decorator","64","","65","","108","            with closing(urlopen(req)) as fsrc:","109","                if is_gzip(fsrc):","110","                    with open(local_path, 'wb') as fdst:","111","                        shutil.copyfileobj(fsrc, fdst)","112","                else:","113","                    with gzip.GzipFile(local_path, 'wb') as fdst:","114","                        shutil.copyfileobj(fsrc, fdst)","116","            if os.path.exists(local_path):","117","                os.unlink(local_path)","156","","157","    @_retry_with_clean_cache(url, data_home)","158","    def _load_json():","159","        with closing(_open_openml_url(url, data_home)) as response:","160","            return json.loads(response.read().decode(\"utf-8\"))","161","","163","        return _load_json()","167","        if error.code != 412:","169","","170","    # 412 error, not in except for nicer traceback","171","    if raise_if_error:","172","        raise ValueError(error_message)","173","    return None","354","    @_retry_with_clean_cache(url, data_home)","355","    def _arff_load():","356","        with closing(_open_openml_url(url, data_home)) as response:","357","            if sparse is True:","358","                return_type = _arff.COO","359","            else:","360","                return_type = _arff.DENSE","361","","362","            if PY2:","363","                arff_file = _arff.load(","364","                    response.read(),","365","                    encode_nominal=encode_nominal,","366","                    return_type=return_type,","367","                )","368","            else:","369","                arff_file = _arff.loads(response.read().decode('utf-8'),","370","                                        encode_nominal=encode_nominal,","371","                                        return_type=return_type)","372","        return arff_file","373","","374","    return _arff_load()"],"delete":["72","        fsrc = urlopen(req)","80","            if is_gzip(fsrc):","81","                with open(local_path, 'wb') as fdst:","82","                    shutil.copyfileobj(fsrc, fdst)","83","                    fsrc.close()","84","            else:","85","                with gzip.GzipFile(local_path, 'wb') as fdst:","86","                    shutil.copyfileobj(fsrc, fdst)","87","                    fsrc.close()","89","            os.unlink(local_path)","128","    data_found = True","130","        response = _open_openml_url(url, data_home)","134","        if error.code == 412:","135","            data_found = False","136","        else:","138","    if not data_found:","139","        # not in except for nicer traceback","140","        if raise_if_error:","141","            raise ValueError(error_message)","142","        else:","143","            return None","144","    json_data = json.loads(response.read().decode(\"utf-8\"))","145","    response.close()","146","    return json_data","326","    response = _open_openml_url(url, data_home)","327","    if sparse is True:","328","        return_type = _arff.COO","329","    else:","330","        return_type = _arff.DENSE","332","    if PY2:","333","        arff_file = _arff.load(response.read(), encode_nominal=encode_nominal,","334","                               return_type=return_type, )","335","    else:","336","        arff_file = _arff.loads(response.read().decode('utf-8'),","337","                                encode_nominal=encode_nominal,","338","                                return_type=return_type)","339","    response.close()","340","    return arff_file"]}]}},"6b4e00deb02951ff5ab7cd8a70309381db4226f9":{"changes":{"sklearn\/preprocessing\/_discretization.py":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY"},"diff":{"sklearn\/preprocessing\/_discretization.py":[{"add":["194","            # Fit the OneHotEncoder with toy datasets","195","            # so that it's ready for use after the KBinsDiscretizer is fitted","196","            self._encoder.fit(np.zeros((1, len(self.n_bins_)), dtype=int))","272","        return self._encoder.transform(Xt)"],"delete":["269","        return self._encoder.fit_transform(Xt)"]}],"doc\/whats_new\/v0.20.rst":[{"add":["136","- |Fix| Fixed bug in :class:`preprocessing.OrdinalEncoder` when passing","137","  manually specified categories. :issue:`12365` by `Joris Van den Bossche`_.","138","","139","- |Fix| Fixed bug in :class:`preprocessing.KBinsDiscretizer` where the","140","  ``transform`` method mutates the ``_encoder`` attribute. The ``transform``","141","  method is now thread safe. :issue:`12514` by","142","  :user:`Hanmin Qin <qinhanmin2014>`.","143",""],"delete":["142","- |Fix| Fixed bug in :class:`preprocessing.OrdinalEncoder` when passing","143","  manually specified categories. :issue:`12365` by `Joris Van den Bossche`_.","144",""]}]}},"5196657be8c1280b2a8e4149ff78f92d549f22dd":{"changes":{"sklearn\/cluster\/hierarchical.py":"MODIFY"},"diff":{"sklearn\/cluster\/hierarchical.py":[{"add":["232","        X = np.require(X, requirements=\"W\")"],"delete":[]}]}},"8cbb13161dab31780dd18a1d42072e8cd618e1d1":{"changes":{"sklearn\/externals\/joblib\/externals\/loky\/__init__.py":"MODIFY","sklearn\/externals\/joblib\/externals\/cloudpickle\/cloudpickle.py":"MODIFY","sklearn\/externals\/joblib\/__init__.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/spawn.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/cloudpickle_wrapper.py":"ADD","sklearn\/externals\/joblib\/externals\/cloudpickle\/__init__.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/context.py":"MODIFY","sklearn\/externals\/joblib\/numpy_pickle.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/process_executor.py":"MODIFY","sklearn\/externals\/joblib\/_store_backends.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/popen_loky_win32.py":"MODIFY","sklearn\/externals\/joblib\/memory.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/process.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/queues.py":"MODIFY","sklearn\/externals\/joblib\/_parallel_backends.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/popen_loky_posix.py":"MODIFY","sklearn\/externals\/joblib\/_multiprocessing_helpers.py":"MODIFY","sklearn\/externals\/joblib\/externals\/loky\/backend\/utils.py":"MODIFY","sklearn\/externals\/joblib\/parallel.py":"MODIFY","sklearn\/externals\/joblib\/func_inspect.py":"MODIFY"},"diff":{"sklearn\/externals\/joblib\/externals\/loky\/__init__.py":[{"add":["11","__version__ = '2.2.2'"],"delete":["11","__version__ = '2.2.0'"]}],"sklearn\/externals\/joblib\/externals\/cloudpickle\/cloudpickle.py":[{"add":["165","# relevant opcodes","175","    return getattr(func, '__name__') == '<lambda>'","272","            else:","273","                raise","277","","284","        dispatch[buffer] = save_buffer  # noqa: F821 'buffer' was removed in Python 3","306","","327","","336","        try:","337","            should_special_case = obj in _BUILTIN_TYPE_CONSTRUCTORS","338","        except TypeError:","339","            # Methods of builtin types aren't hashable in python 2.","340","            should_special_case = False","341","","342","        if should_special_case:","425","","433","","439","                # A concurrent thread could mutate sys.modules,","440","                # make sure we iterate over a copy to avoid exceptions","441","                for name in list(sys.modules):","448","                            self.save(sys.modules[name])","463","        # For ABCMeta in python3.7+, remove _abc_impl as it is not picklable.","464","        # This is a fix which breaks the cache but this only makes the first","465","        # calls to issubclass slower.","466","        if \"_abc_impl\" in clsdict:","467","            import abc","468","            (registry, _, _, _) = abc._get_dump(obj)","469","            clsdict[\"_abc_impl\"] = [subclass_weakref()","470","                                    for subclass_weakref in registry]","471","","564","            'module': func.__module__,","565","            'name': func.__name__,","566","            'doc': func.__doc__,","568","        if hasattr(func, '__annotations__'):","569","            state['annotations'] = func.__annotations__","594","                out_names = {names[oparg] for _, oparg in _walk_global_ops(co)}","635","        base_globals = self.globals_ref.get(id(func.__globals__), None)","636","        if base_globals is None:","637","            # For functions defined in __main__, use vars(__main__) for","638","            # base_global. This is necessary to share the global variables","639","            # across multiple functions in this module.","640","            if func.__module__ == \"__main__\":","641","                base_globals = \"__main__\"","642","            else:","643","                base_globals = {}","652","","691","                                 obj=obj)","692","","746","","752","","763","            items = (items,)","794","            import StringIO as pystringIO  # we can't use cStringIO as it lacks the name attribute","798","        if not hasattr(obj, 'name') or not hasattr(obj, 'mode'):","801","            return self.save_reduce(getattr, (sys, 'stdout'), obj=obj)","803","            return self.save_reduce(getattr, (sys, 'stderr'), obj=obj)","838","    try:               # Python 2","840","    except NameError:  # Python 3","841","        dispatch[io.TextIOWrapper] = save_file","856","    def save_root_logger(self, obj):","857","        self.save_reduce(logging.getLogger, (), obj=obj)","858","","859","    dispatch[logging.RootLogger] = save_root_logger","860","","966","            except Exception:","975","# object generators:","983","","987","","1048","    # Only set global variables that do not exist.","1049","    for k, v in state['globals'].items():","1050","        if k not in func.__globals__:","1051","            func.__globals__[k] = v","1052","","1055","    if 'annotations' in state:","1056","        func.__annotations__ = state['annotations']","1057","    if 'doc' in state:","1058","        func.__doc__  = state['doc']","1059","    if 'name' in state:","1060","        func.__name__ = state['name']","1091","    elif isinstance(base_globals, str):","1092","        base_globals = vars(sys.modules[base_globals])","1108","    registry = None","1110","        if attrname == \"_abc_impl\":","1111","            registry = attr","1112","        else:","1113","            setattr(skeleton_class, attrname, attr)","1114","    if registry is not None:","1115","        for subclass in registry:","1116","            skeleton_class.register(subclass)","1117","","1124","    This function is able to find submodules (e.g. scikit.tree)","1135","","1139",""],"delete":["165","#relevant opcodes","175","    return getattr(func,'__name__') == '<lambda>'","280","        dispatch[buffer] = save_buffer","282","    def save_unsupported(self, obj):","283","        raise pickle.PicklingError(\"Cannot pickle objects of type %s\" % type(obj))","284","    dispatch[types.GeneratorType] = save_unsupported","285","","286","    # itertools objects do not pickle!","287","    for v in itertools.__dict__.values():","288","        if type(v) is type:","289","            dispatch[v] = save_unsupported","339","        if obj in _BUILTIN_TYPE_CONSTRUCTORS:","434","                for name, module in sys.modules.items():","441","                            self.save(module)","547","            'module': func.__module__,","574","                out_names = set(names[oparg]","575","                                for op, oparg in _walk_global_ops(co))","616","        base_globals = self.globals_ref.get(id(func.__globals__), {})","663","                         obj=obj)","732","            items = (items, )","763","            import StringIO as pystringIO #we can't use cStringIO as it lacks the name attribute","767","        if not hasattr(obj, 'name') or  not hasattr(obj, 'mode'):","770","            return self.save_reduce(getattr, (sys,'stdout'), obj=obj)","772","            return self.save_reduce(getattr, (sys,'stderr'), obj=obj)","807","    if PY3:","808","        dispatch[io.TextIOWrapper] = save_file","809","    else:","930","            except Exception as e:","939","#object generators:","1010","    func.__globals__.update(state['globals'])","1059","        setattr(skeleton_class, attrname, attr)","1066","    This function is able to find submodules (e.g. sickit.tree)"]}],"sklearn\/externals\/joblib\/__init__.py":[{"add":["14","    **Documentation:**       https:\/\/joblib.readthedocs.io","108","__version__ = '0.12.3'"],"delete":["14","    **Documentation:**       http:\/\/pythonhosted.org\/joblib","108","__version__ = '0.12.2'"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/spawn.py":[{"add":["14","from sklearn.externals.joblib.externals.loky.backend import context","15","","96","        except BaseException:"],"delete":["12","import multiprocessing as mp","28","if sys.version_info[:2] < (3, 4):","29","    def get_command_line(pipe_handle, **kwds):","30","        '''","31","        Returns prefix of command line used for spawning a child process","32","        '''","33","        if getattr(sys, 'frozen', False):","34","            return ([sys.executable, '--multiprocessing-fork', pipe_handle])","35","        else:","36","            prog = 'from multiprocessing.forking import main; main()'","37","            opts = util._args_from_interpreter_flags()","38","            return [_python_exe] + opts + [","39","                '-c', prog, '--multiprocessing-fork', pipe_handle]","40","else:","41","    from multiprocessing.spawn import get_command_line","42","","110","        except:","167","    if hasattr(mp, 'set_start_method'):","168","        mp.set_start_method('loky', force=True)","169",""]}],"sklearn\/externals\/joblib\/externals\/loky\/cloudpickle_wrapper.py":[{"add":[],"delete":[]}],"sklearn\/externals\/joblib\/externals\/cloudpickle\/__init__.py":[{"add":["4","__version__ = '0.5.5'"],"delete":["4","__version__ = '0.5.2'"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/context.py":[{"add":["20","from .process import LokyProcess, LokyInitMainProcess","21","","22","START_METHODS = ['loky', 'loky_init_main']","23","_DEFAULT_START_METHOD = None","26","    from multiprocessing import get_context as mp_get_context","30","    START_METHODS += ['spawn']","31","    if sys.platform != 'win32':","32","        START_METHODS += ['fork', 'forkserver']","33","","34","    def get_context(method=None):","35","        # Try to overload the default context","36","        method = method or _DEFAULT_START_METHOD or \"loky\"","38","            # If 'fork' is explicitly requested, warn user about potential","39","            # issues.","40","            warnings.warn(\"`fork` start method should not be used with \"","41","                          \"`loky` as it does not respect POSIX. Try using \"","42","                          \"`spawn` or `loky` instead.\", UserWarning)","43","        try:","44","            context = mp_get_context(method)","45","        except ValueError:","46","            raise ValueError(\"Unknown context '{}'. Value should be in {}.\"","47","                             .format(method, START_METHODS))","48","","49","        return context","54","        # Mechanism to check that the current thread is spawning a process","77","    def get_context(method=None):","78","        method = method or _DEFAULT_START_METHOD or 'loky'","84","            raise ValueError(\"Unknown context '{}'. Value should be in {}.\"","85","                             .format(method, START_METHODS))","86","","87","","88","def set_start_method(method, force=False):","89","    global _DEFAULT_START_METHOD","90","    if _DEFAULT_START_METHOD is not None and not force:","91","        raise RuntimeError('context has already been set')","92","    assert method is None or method in START_METHODS, (","93","        \"'{}' is not a valid start_method. It should be in {}\"","94","        .format(method, START_METHODS))","95","","96","    _DEFAULT_START_METHOD = method","97","","98","","99","def get_start_method():","100","    return _DEFAULT_START_METHOD","172","            return self._name","250","    _name = 'loky_init_main'","251","    Process = LokyInitMainProcess","256","    ctx_loky = LokyContext()","257","    mp.context._concrete_contexts['loky'] = ctx_loky"],"delete":["20","from .process import LokyProcess","23","    from multiprocessing import get_context as get_mp_context","27","    def get_context(method=\"loky\"):","29","            warnings.warn(\"`fork` start method should not be used with `loky` \"","30","                          \"as it does not respect POSIX. Try using `spawn` or \"","31","                          \"`loky` instead.\", UserWarning)","32","        return get_mp_context(method)","35","    METHODS = ['loky', 'loky_init_main']","38","        # Mecanism to check that the current thread is spawning a child process","61","    def get_context(method=\"loky\"):","67","            raise ValueError(\"Method {} is not implemented. The available \"","68","                             \"methods are {}\".format(method, METHODS))","140","            return \"loky\"","218","    def Process(self, *args, **kwargs):","219","        kwargs.pop('init_main_module', True)","220","        return LokyProcess(*args, init_main_module=True, **kwargs)","225","    mp.context._concrete_contexts['loky'] = LokyContext()"]}],"sklearn\/externals\/joblib\/numpy_pickle.py":[{"add":["437","    # LZ4 compression is only supported and installation checked with","438","    # python 3+.","439","    if compress_method == 'lz4' and lz4 is None and PY3_OR_LATER:"],"delete":["437","    if compress_method == 'lz4' and lz4 is None:"]}],"sklearn\/externals\/joblib\/externals\/loky\/process_executor.py":[{"add":["62","import gc","65","import struct","71","from time import time","83","from .cloudpickle_wrapper import _wrap_non_picklable_objects","267","    def __getstate__(self):","268","        return (","269","            self.work_id,","270","            _wrap_non_picklable_objects(self.fn),","271","            [_wrap_non_picklable_objects(a) for a in self.args],","272","            {k: _wrap_non_picklable_objects(a) for k, a in self.kwargs.items()}","273","        )","275","    def __setstate__(self, state):","276","        self.work_id, self.fn, self.args, self.kwargs = state","290","            # format traceback only works on python3","291","            if isinstance(e, struct.error):","292","                raised_error = RuntimeError(","293","                    \"The task could not be sent to the workers as it is too \"","294","                    \"large for `send_bytes`.\")","295","            else:","296","                raised_error = PicklingError(","297","                    \"Could not pickle the task to send it to the workers.\")","300","            raised_error.__cause__ = _RemoteTraceback(","308","                work_item.future.set_exception(raised_error)","384","    _process_reference_size = None","385","    _process_last_memory_check = None","404","            previous_tb = traceback.format_exc()","405","            try:","406","                result_queue.put(_RemoteTraceback(previous_tb))","407","            except BaseException:","408","                # If we cannot format correctly the exception, at least print","409","                # the traceback.","410","                print(previous_tb)","430","            if _process_reference_size is None:","432","                _process_reference_size = _get_memory_usage(pid, force_gc=True)","433","                _process_last_memory_check = time()","435","            if time() - _process_last_memory_check > _MEMORY_CHECK_DELAY:","437","                _process_last_memory_check = time()","438","                if mem_usage - _process_reference_size < _MAX_MEMORY_LEAK_SIZE:","446","                _process_last_memory_check = time()","447","                if mem_usage - _process_reference_size < _MAX_MEMORY_LEAK_SIZE:","613","                if isinstance(result_item, _RemoteTraceback):","614","                    cause = result_item.tb","615","                    broken = (\"A task has failed to un-serialize\", cause)","860","        self._initializer = _wrap_non_picklable_objects(initializer)","861","        self._initargs = [_wrap_non_picklable_objects(a) for a in initargs]"],"delete":["72","from time import time","73","import gc","265","    try:","266","        # If cloudpickle is present on the system, use it to pickle the","267","        # function. This permits to use interactive terminal for loky calls.","268","        # TODO: Add option to deactivate, as it increases pickling time.","269","        from .backend import LOKY_PICKLER","270","        assert LOKY_PICKLER is None or LOKY_PICKLER == \"\"","272","        import cloudpickle  # noqa: F401","273","","274","        def __getstate__(self):","275","            from cloudpickle import dumps","276","            if isinstance(self.fn, (types.FunctionType,","277","                                    types.LambdaType,","278","                                    partial)):","279","                cp = True","280","                fn = dumps(self.fn)","281","            else:","282","                cp = False","283","                fn = self.fn","284","            return (self.work_id, self.args, self.kwargs, fn, cp)","285","","286","        def __setstate__(self, state):","287","            self.work_id, self.args, self.kwargs, self.fn, cp = state","288","            if cp:","289","                from cloudpickle import loads","290","                self.fn = loads(self.fn)","291","","292","    except (ImportError, AssertionError) as e:","293","        pass","307","            # fromat traceback only on python3","308","            pickling_error = PicklingError(","309","                \"Could not pickle the task to send it to the workers.\")","312","            pickling_error.__cause__ = _RemoteTraceback(","320","                work_item.future.set_exception(pickling_error)","396","    _REFERENCE_PROCESS_SIZE = None","397","    _LAST_MEMORY_CHECK = None","416","            traceback.print_exc()","436","            if _REFERENCE_PROCESS_SIZE is None:","438","                _REFERENCE_PROCESS_SIZE = _get_memory_usage(pid, force_gc=True)","439","                _LAST_MEMORY_CHECK = time()","441","            if time() - _LAST_MEMORY_CHECK > _MEMORY_CHECK_DELAY:","443","                _LAST_MEMORY_CHECK = time()","444","                if mem_usage - _REFERENCE_PROCESS_SIZE < _MAX_MEMORY_LEAK_SIZE:","452","                _LAST_MEMORY_CHECK = time()","453","                if mem_usage - _REFERENCE_PROCESS_SIZE < _MAX_MEMORY_LEAK_SIZE:","863","        self._initializer = initializer","864","        self._initargs = initargs"]}],"sklearn\/externals\/joblib\/_store_backends.py":[{"add":["37","    location = None","38","","331","        return '{class_name}(location=\"{location}\")'.format(","332","            class_name=self.__class__.__name__, location=self.location)","389","    def configure(self, location, verbose=1, backend_options=None):","394","        if backend_options is None:","395","            backend_options = {}","403","        self.compress = backend_options.get('compress', False)","407","        mmap_mode = backend_options.get('mmap_mode')","408","        if self.compress and mmap_mode is not None:","409","            warnings.warn('Compressed items cannot be memmapped in a '","410","                          'filesystem store. Option will be ignored.',","411","                          stacklevel=2)"],"delete":["329","        return self.location","386","    def configure(self, location, verbose=1, backend_options={}):","398","        self.compress = backend_options['compress']","402","        mmap_mode = None","403","        if 'mmap_mode' in backend_options:","404","            mmap_mode = backend_options['mmap_mode']","405","            if self.compress and mmap_mode is not None:","406","                warnings.warn('Compressed items cannot be memmapped in a '","407","                              'filesystem store. Option will be ignored.',","408","                              stacklevel=2)"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/popen_loky_win32.py":[{"add":["2","from pickle import load","3","from multiprocessing import process, util","7","from .context import get_spawning_popen, set_spawning_popen","45","            process_obj._name, getattr(process_obj, \"init_main_module\", True))","53","        cmd = get_command_line(parent_pid=os.getpid(), pipe_handle=rhandle)","66","                except BaseException as e:","99","","100","","101","if sys.version_info[:2] >= (3, 4):","102","    from multiprocessing.spawn import get_command_line","103","else:","104","    # compatibility for python2.7. Duplicate here the code from","105","    # multiprocessing.forking.main to call our prepare function and correctly","106","    # set the default start_methods in loky.","107","","108","    def get_command_line(pipe_handle, **kwds):","109","        '''","110","        Returns prefix of command line used for spawning a child process","111","        '''","112","        if getattr(sys, 'frozen', False):","113","            return ([sys.executable, '--multiprocessing-fork', pipe_handle])","114","        else:","115","            prog = 'from sklearn.externals.joblib.externals.loky.backend.popen_loky_win32 import main; main()'","116","            opts = util._args_from_interpreter_flags()","117","            return [spawn.get_executable()] + opts + [","118","                '-c', prog, '--multiprocessing-fork', pipe_handle]","119","","120","    def is_forking(argv):","121","        '''","122","        Return whether commandline indicates we are forking","123","        '''","124","        if len(argv) >= 2 and argv[1] == '--multiprocessing-fork':","125","            assert len(argv) == 3","126","            return True","127","        else:","128","            return False","129","","130","    def main():","131","        '''","132","        Run code specified by data received over pipe","133","        '''","134","        assert is_forking(sys.argv)","135","","136","        handle = int(sys.argv[-1])","137","        fd = msvcrt.open_osfhandle(handle, os.O_RDONLY)","138","        from_parent = os.fdopen(fd, 'rb')","139","","140","        process.current_process()._inheriting = True","141","        preparation_data = load(from_parent)","142","        spawn.prepare(preparation_data)","143","        self = load(from_parent)","144","        process.current_process()._inheriting = False","145","","146","        from_parent.close()","147","","148","        exitcode = self._bootstrap()","149","        exit(exitcode)"],"delete":["3","from .context import get_spawning_popen, set_spawning_popen","6","from multiprocessing import util","44","            process_obj._name, process_obj.init_main_module)","52","        cmd = spawn.get_command_line(parent_pid=os.getpid(),","53","                                     pipe_handle=rhandle)","66","                except:"]}],"sklearn\/externals\/joblib\/memory.py":[{"add":["98","def _store_backend_factory(backend, location, verbose=0, backend_options=None):","100","    if backend_options is None:","101","        backend_options = {}","102","","213","        if isinstance(func, _basestring):","214","            self.func = func","215","        else:","216","            self.func = self.func_id","260","                        location=self.store_backend.location,","264","","265","    def __getstate__(self):","266","        state = self.__dict__.copy()","267","        state['timestamp'] = None","268","        return state","392","","428","    def _cached_call(self, args, kwargs, shelving=False):","433","        Arguments:","434","        ----------","435","","436","        args, kwargs: list and dict","437","            input arguments for wrapped function","438","","439","        shelving: bool","440","            True when called via the call_and_shelve function.","441","","442","","445","        output: value or tuple or None","446","            Output of the wrapped function.","447","            If shelving is True and the call has been already cached,","448","            output is None.","451","            Hash of function arguments.","454","            Some metadata about wrapped function call (see _persist_input()).","488","","489","                if not shelving:","490","                    # When shelving, we do not need to load the output","491","                    out = self.store_backend.load_item(","492","                        [func_id, args_id],","493","                        msg=msg,","494","                        verbose=self._verbose)","495","                else:","496","                    out = None","497","","529","        _, args_id, metadata = self._cached_call(args, kwargs, shelving=True)","537","    def __getstate__(self):","541","        state = self.__dict__.copy()","542","        state['timestamp'] = None","543","        return state","771","        return '{class_name}(func={func}, location={location})'.format(","772","            class_name=self.__class__.__name__,","773","            func=self.func,","774","            location=self.store_backend.location,)","803","        cachedir: str or None, optional","804","","805","            .. deprecated: 0.12","806","                'cachedir' has been deprecated in 0.12 and will be","807","                removed in 0.14. Use the 'location' parameter instead.","808","","835","    def __init__(self, location=None, backend='local', cachedir=None,","836","                 mmap_mode=None, compress=False, verbose=1, bytes_limit=None,","837","                 backend_options=None):","845","        self.compress = compress","846","        if backend_options is None:","847","            backend_options = {}","848","        self.backend_options = backend_options","849","","929","        return MemorizedFunc(func, location=self.store_backend,","930","                             backend=self.backend,","931","                             ignore=ignore, mmap_mode=mmap_mode,","932","                             compress=self.compress,","933","                             verbose=verbose, timestamp=self.timestamp)","966","        return '{class_name}(location={location})'.format(","967","            class_name=self.__class__.__name__,","968","            location=(None if self.store_backend is None","969","                      else self.store_backend.location))","971","    def __getstate__(self):","975","        state = self.__dict__.copy()","976","        state['timestamp'] = None","977","        return state"],"delete":["98","def _store_backend_factory(backend, location, verbose=0, backend_options={}):","209","        self.func = func","254","                        location=self.store_backend,","258","    def __reduce__(self):","259","        return (self.__class__,","260","                (self.store_backend, self.func, self.args_id),","261","                {'mmap_mode': self.mmap_mode})","326","    def __reduce__(self):","327","        return (self.__class__, (self.func,))","328","","423","    def _cached_call(self, args, kwargs):","430","        output: value or tuple","431","            what is returned by wrapped function","434","            hash of function arguments","437","            some metadata about wrapped function call (see _persist_input())","471","                out = self.store_backend.load_item([func_id, args_id], msg=msg,","472","                                                   verbose=self._verbose)","504","        _, args_id, metadata = self._cached_call(args, kwargs)","512","    def __reduce__(self):","515","            In addition, when unpickling, we run the __init__","517","        return (self.__class__, (self.func, None),","518","                {k: v for k, v in vars(self).items()","519","                 if k not in ('timestamp', 'func')})","747","        return (\"{0}(func={1}, location={2})\".format(self.__class__.__name__,","748","                                                     self.func,","749","                                                     self.store_backend,))","799","","800","        cachedir: str or None, optional","801","","802","            .. deprecated: 0.12","803","                'cachedir' has been deprecated in 0.12 and will be","804","                removed in 0.14. Use the 'location' parameter instead.","810","    def __init__(self, location=None, backend='local', mmap_mode=None,","811","                 compress=False, verbose=1, bytes_limit=None,","812","                 backend_options={}, cachedir=None):","899","        return MemorizedFunc(func, self.store_backend, mmap_mode=mmap_mode,","900","                             ignore=ignore, verbose=verbose,","901","                             timestamp=self.timestamp)","934","        return '{0}(location={1})'.format(","935","            self.__class__.__name__, (repr(None) if self.store_backend is None","936","                                      else repr(self.store_backend)))","938","    def __reduce__(self):","941","            In addition, when unpickling, we run the __init__","943","        return (self.__class__, (), {k: v for k, v in vars(self).items()","944","                                     if k != 'timestamp'})"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/process.py":[{"add":["75","        def _bootstrap(self):","76","            from .context import set_start_method","77","            set_start_method(self._start_method)","78","            super(LokyProcess, self)._bootstrap()","79","","80","","81","class LokyInitMainProcess(LokyProcess):","82","    _start_method = 'loky_init_main'","83","","84","    def __init__(self, group=None, target=None, name=None, args=(),","85","                 kwargs={}, daemon=None):","86","        super(LokyInitMainProcess, self).__init__(","87","            group=group, target=target, name=name, args=args, kwargs=kwargs,","88","            daemon=daemon, init_main_module=True)","89",""],"delete":[]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/queues.py":[{"add":["149","                        obj_ = CustomizableLokyPickler.dumps(","152","                            send_bytes(obj_)","156","                                send_bytes(obj_)","159","                        # Remove references early to avoid leaking memory","160","                        del obj, obj_"],"delete":["149","                        obj = CustomizableLokyPickler.dumps(","152","                            send_bytes(obj)","156","                                send_bytes(obj)"]}],"sklearn\/externals\/joblib\/_parallel_backends.py":[{"add":["349","            raise FallbackToBackend(","350","                SequentialBackend(nesting_level=self.nesting_level))","423","            raise FallbackToBackend(","424","                SequentialBackend(nesting_level=self.nesting_level))","465","            raise FallbackToBackend(","466","                SequentialBackend(nesting_level=self.nesting_level))"],"delete":["132","","350","            raise FallbackToBackend(SequentialBackend())","423","            raise FallbackToBackend(SequentialBackend())","464","            raise FallbackToBackend(SequentialBackend())"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/popen_loky_posix.py":[{"add":["129","                    process_obj._name,","130","                    getattr(process_obj, \"init_main_module\", True))","155","                util.debug(\"launched python with pid {} and cmd:\\n{}\"","156","                           .format(pid, cmd_python))"],"delete":["129","                    process_obj._name, process_obj.init_main_module)","152","                util.debug(\"launch python with cmd:\\n%s\" % cmd_python)"]}],"sklearn\/externals\/joblib\/_multiprocessing_helpers.py":[{"add":["6","import sys","24","        # Use the spawn context","25","        if sys.version_info < (3, 3):","26","            Semaphore = mp.Semaphore","27","        else:","28","            # Using mp.Semaphore has a border effect and set the default","29","            # backend for multiprocessing. To avoid that, we use the 'spawn'","30","            # context which is available on all supported platforms.","31","            ctx = mp.get_context('spawn')","32","            Semaphore = ctx.Semaphore","33","        _sem = Semaphore()"],"delete":["23","        _sem = mp.Semaphore()"]}],"sklearn\/externals\/joblib\/externals\/loky\/backend\/utils.py":[{"add":["32","    # Kill the children in reverse order to avoid killing the parents before","33","    # the children in cases where there are more processes nested.","34","    for child in children[::-1]:","36","            child.kill()"],"delete":["32","    for child in children:","34","            child.terminate()","38","    gone, still_alive = psutil.wait_procs(children, timeout=5)","39","    for child_process in still_alive:","40","        child_process.kill()","41",""]}],"sklearn\/externals\/joblib\/parallel.py":[{"add":["198","DEFAULT_MP_CONTEXT = None","201","    if method is not None:","202","        DEFAULT_MP_CONTEXT = mp.get_context(method=method)","681","        elif hasattr(mp, \"get_context\"):","682","            self._backend_args['context'] = mp.get_context()"],"delete":["200","    DEFAULT_MP_CONTEXT = mp.get_context(method=method)","201","else:","202","    DEFAULT_MP_CONTEXT = None"]}],"sklearn\/externals\/joblib\/func_inspect.py":[{"add":["277","                arg_dict[arg_name] = kwargs[arg_name]"],"delete":["277","                arg_dict[arg_name] = kwargs.pop(arg_name)"]}]}},"38e7c8b1170ff906c4fab2992dc4962e1368bd5b":{"changes":{"sklearn\/linear_model\/logistic.py":"MODIFY"},"diff":{"sklearn\/linear_model\/logistic.py":[{"add":["63","    c : float","64","        The intercept."],"delete":["63","    X : {array-like, sparse matrix}, shape (n_samples, n_features)","64","        Training data. Unchanged."]}]}},"c34c5626aa0fa08595e8af1d5e4acbe478149f49":{"changes":{"sklearn\/random_projection.py":"MODIFY"},"diff":{"sklearn\/random_projection.py":[{"add":["152","                         n_features)"],"delete":["152","                         n_components)"]}]}},"4140657700cc55830347c871134c8e982d29fab5":{"changes":{"doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/tests\/test_discriminant_analysis.py":"MODIFY","sklearn\/discriminant_analysis.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.21.rst":[{"add":["19","- :class:`discriminant_analysis.LinearDiscriminantAnalysis` for multiclass","20","  classification. |Fix|","21","- :class:`discriminant_analysis.LinearDiscriminantAnalysis` with 'eigen'","22","  solver. |Fix|","113","- |Fix| Fixed a bug in :class:`discriminant_analysis.LinearDiscriminantAnalysis`","114","  where the predicted probabilities would be incorrectly computed in the","115","  multiclass case. :issue:`6848`, by :user:`Agamemnon Krasoulis","116","  <agamemnonc>` and `Guillaume Lemaitre <glemaitre>`.","117","","118","- |Fix| Fixed a bug in :class:`discriminant_analysis.LinearDiscriminantAnalysis`","119","  where the predicted probabilities would be incorrectly computed with ``eigen``","120","  solver. :issue:`11727`, by :user:`Agamemnon Krasoulis","121","  <agamemnonc>`.","122",""],"delete":[]}],"sklearn\/tests\/test_discriminant_analysis.py":[{"add":["4","from numpy.testing import assert_allclose","5","from scipy import linalg","6","","100","@pytest.mark.parametrize(\"n_classes\", [2, 3])","101","@pytest.mark.parametrize(\"solver\", [\"svd\", \"lsqr\", \"eigen\"])","102","def test_lda_predict_proba(solver, n_classes):","103","    def generate_dataset(n_samples, centers, covariances, random_state=None):","104","        \"\"\"Generate a multivariate normal data given some centers and","105","        covariances\"\"\"","106","        rng = check_random_state(random_state)","107","        X = np.vstack([rng.multivariate_normal(mean, cov,","108","                                               size=n_samples \/\/ len(centers))","109","                       for mean, cov in zip(centers, covariances)])","110","        y = np.hstack([[clazz] * (n_samples \/\/ len(centers))","111","                       for clazz in range(len(centers))])","112","        return X, y","113","","114","    blob_centers = np.array([[0, 0], [-10, 40], [-30, 30]])[:n_classes]","115","    blob_stds = np.array([[[10, 10], [10, 100]]] * len(blob_centers))","116","    X, y = generate_dataset(","117","        n_samples=90000, centers=blob_centers, covariances=blob_stds,","118","        random_state=42","119","    )","120","    lda = LinearDiscriminantAnalysis(solver=solver, store_covariance=True,","121","                                     shrinkage=None).fit(X, y)","122","    # check that the empirical means and covariances are close enough to the","123","    # one used to generate the data","124","    assert_allclose(lda.means_, blob_centers, atol=1e-1)","125","    assert_allclose(lda.covariance_, blob_stds[0], atol=1)","126","","127","    # implement the method to compute the probability given in The Elements","128","    # of Statistical Learning (cf. p.127, Sect. 4.4.5 \"Logistic Regression","129","    # or LDA?\")","130","    precision = linalg.inv(blob_stds[0])","131","    alpha_k = []","132","    alpha_k_0 = []","133","    for clazz in range(len(blob_centers) - 1):","134","        alpha_k.append(","135","            np.dot(precision,","136","                   (blob_centers[clazz] - blob_centers[-1])[:, np.newaxis]))","137","        alpha_k_0.append(","138","            np.dot(- 0.5 * (blob_centers[clazz] +","139","                            blob_centers[-1])[np.newaxis, :], alpha_k[-1]))","140","","141","    sample = np.array([[-22, 22]])","142","","143","    def discriminant_func(sample, coef, intercept, clazz):","144","        return np.exp(intercept[clazz] + np.dot(sample, coef[clazz]))","145","","146","    prob = np.array([float(","147","        discriminant_func(sample, alpha_k, alpha_k_0, clazz) \/","148","        (1 + sum([discriminant_func(sample, alpha_k, alpha_k_0, clazz)","149","                  for clazz in range(n_classes - 1)]))) for clazz in range(","150","                      n_classes - 1)])","151","","152","    prob_ref = 1 - np.sum(prob)","153","","154","    # check the consistency of the computed probability","155","    # all probabilities should sum to one","156","    prob_ref_2 = float(","157","        1 \/ (1 + sum([discriminant_func(sample, alpha_k, alpha_k_0, clazz)","158","                      for clazz in range(n_classes - 1)]))","159","    )","160","","161","    assert prob_ref == pytest.approx(prob_ref_2)","162","    # check that the probability of LDA are close to the theoretical","163","    # probabilties","164","    assert_allclose(lda.predict_proba(sample),","165","                    np.hstack([prob, prob_ref])[np.newaxis],","166","                    atol=1e-2)","167","","168","","303","    # Test for solver 'lsqr' and 'eigen'","319","    # Test for SVD solver, the default is to not set the covariances_ attribute"],"delete":["231","    # Test for slover 'lsqr' and 'eigen'","247","    # Test for SVD slover, the default is to not set the covariances_ attribute"]}],"sklearn\/discriminant_analysis.py":[{"add":["24","from .utils.extmath import softmax","533","        check_is_fitted(self, 'classes_')","534","","535","        decision = self.decision_function(X)","536","        if self.classes_.size == 2:","537","            proba = expit(decision)","538","            return np.vstack([1-proba, proba]).T","540","            return softmax(decision)"],"delete":["340","        evecs \/= np.linalg.norm(evecs, axis=0)","533","        prob = self.decision_function(X)","534","        expit(prob, out=prob)","535","        if len(self.classes_) == 2:  # binary case","536","            return np.column_stack([1 - prob, prob])","538","            # OvR normalization, like LibLinear's predict_probability","539","            prob \/= prob.sum(axis=1).reshape((prob.shape[0], -1))","540","            return prob"]}]}},"94db3d932c393569be97886642049c8920182a77":{"changes":{"sklearn\/metrics\/scorer.py":"MODIFY","sklearn\/metrics\/tests\/test_score_objects.py":"MODIFY"},"diff":{"sklearn\/metrics\/scorer.py":[{"add":["128","            if y_pred.shape[1] == 2:","129","                y_pred = y_pred[:, 1]","130","            else:","131","                raise ValueError('got predict_proba of shape {},'","132","                                 ' but need classifier with two'","133","                                 ' classes for {} scoring'.format(","134","                                     y_pred.shape, self._score_func.__name__))","191","                    if y_pred.shape[1] == 2:","192","                        y_pred = y_pred[:, 1]","193","                    else:","194","                        raise ValueError('got predict_proba of shape {},'","195","                                         ' but need classifier with two'","196","                                         ' classes for {} scoring'.format(","197","                                             y_pred.shape,","198","                                             self._score_func.__name__))"],"delete":["128","            y_pred = y_pred[:, 1]","185","                    y_pred = y_pred[:, 1]"]}],"sklearn\/metrics\/tests\/test_score_objects.py":[{"add":["188","    # This wraps the _check_multimetric_scoring to take in","189","    # single metric scoring parameter so we can run the tests","190","    # that we will run for check_scoring, for check_multimetric_scoring","191","    # too for single-metric usecases","192","","373","    with pytest.raises(ValueError, match=\"multiclass format is not supported\"):","374","        get_scorer('roc_auc')(clf, X_test, y_test)","375","","376","    # test error is raised with a single class present in model","377","    # (predict_proba shape is not suitable for binary auc)","378","    X, y = make_blobs(random_state=0, centers=2)","379","    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","380","    clf = DecisionTreeClassifier()","381","    clf.fit(X_train, np.zeros_like(y_train))","382","    with pytest.raises(ValueError, match=\"need classifier with two classes\"):","383","        get_scorer('roc_auc')(clf, X_test, y_test)","384","","385","    # for proba scorers","386","    with pytest.raises(ValueError, match=\"need classifier with two classes\"):","387","        get_scorer('neg_log_loss')(clf, X_test, y_test)"],"delete":["188","    # This wraps the _check_multimetric_scoring to take in single metric","189","    # scoring parameter so we can run the tests that we will run for","190","    # check_scoring, for check_multimetric_scoring too for single-metric","191","    # usecases","372","    assert_raises(ValueError, get_scorer('roc_auc'), clf, X_test, y_test)"]}]}}}
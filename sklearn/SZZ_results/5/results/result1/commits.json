{"cf9a74059851c91b3b7c5b354b85e1e87ff628bf":{"changes":{"sklearn\/utils\/fixes.py":"MODIFY","sklearn\/feature_extraction\/text.py":"MODIFY","sklearn\/neighbors\/tests\/test_neighbors.py":"MODIFY","sklearn\/naive_bayes.py":"MODIFY","sklearn\/preprocessing\/_encoders.py":"MODIFY","sklearn\/datasets\/kddcup99.py":"MODIFY","sklearn\/metrics\/cluster\/supervised.py":"MODIFY","sklearn\/neighbors\/tests\/test_dist_metrics.py":"MODIFY","sklearn\/preprocessing\/imputation.py":"MODIFY","sklearn\/datasets\/tests\/test_svmlight_format.py":"MODIFY","sklearn\/decomposition\/tests\/test_pca.py":"MODIFY","sklearn\/datasets\/rcv1.py":"MODIFY","sklearn\/metrics\/tests\/test_pairwise.py":"MODIFY","sklearn\/preprocessing\/tests\/test_data.py":"MODIFY","sklearn\/utils\/tests\/test_extmath.py":"MODIFY","sklearn\/tree\/tests\/test_tree.py":"MODIFY","sklearn\/datasets\/base.py":"MODIFY","sklearn\/cluster\/hierarchical.py":"MODIFY","sklearn\/metrics\/tests\/test_classification.py":"MODIFY","sklearn\/manifold\/tests\/test_t_sne.py":"MODIFY","sklearn\/neighbors\/tests\/test_kd_tree.py":"MODIFY","sklearn\/datasets\/samples_generator.py":"MODIFY","sklearn\/preprocessing\/base.py":"MODIFY","sklearn\/datasets\/openml.py":"MODIFY","sklearn\/preprocessing\/data.py":"MODIFY","sklearn\/ensemble\/tests\/test_bagging.py":"MODIFY","doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/datasets\/covtype.py":"MODIFY","sklearn\/feature_selection\/mutual_info_.py":"MODIFY","sklearn\/svm\/base.py":"MODIFY","sklearn\/feature_extraction\/_hashing.pyx":"MODIFY","sklearn\/metrics\/cluster\/expected_mutual_info_fast.pyx":"MODIFY","sklearn\/cluster\/tests\/test_hierarchical.py":"MODIFY","sklearn\/neighbors\/tests\/test_ball_tree.py":"MODIFY","sklearn\/cluster\/k_means_.py":"MODIFY"},"diff":{"sklearn\/utils\/fixes.py":[{"add":["187","# TODO: replace by copy=False, when only scipy > 1.1 is supported.","188","def _astype_copy_false(X):","189","    \"\"\"Returns the copy=False parameter for","190","    {ndarray, csr_matrix, csc_matrix}.astype when possible,","191","    otherwise don't specify","192","    \"\"\"","193","    if sp_version >= (1, 1) or not sp.issparse(X):","194","        return {'copy': False}","195","    else:","196","        return {}","197","","198",""],"delete":[]}],"sklearn\/feature_extraction\/text.py":[{"add":["32","from ..utils.fixes import _astype_copy_false","1242","            df = _document_frequency(X)","1243","            df = df.astype(dtype, **_astype_copy_false(df))"],"delete":["1241","            df = _document_frequency(X).astype(dtype)"]}],"sklearn\/neighbors\/tests\/test_neighbors.py":[{"add":["827","    score_float = clf.fit(X_train.astype(float, copy=False), Y_train).score(","828","        X_test.astype(float, copy=False), Y_test)"],"delete":["827","    score_float = clf.fit(X_train.astype(float), Y_train).score(","828","        X_test.astype(float), Y_test)"]}],"sklearn\/naive_bayes.py":[{"add":["548","        Y = Y.astype(np.float64, copy=False)","599","        Y = Y.astype(np.float64, copy=False)"],"delete":["548","        Y = Y.astype(np.float64)","599","        Y = Y.astype(np.float64)"]}],"sklearn\/preprocessing\/_encoders.py":[{"add":["992","            labels = X[:, i].astype('int64', copy=False)"],"delete":["992","            labels = X[:, i].astype('int64')"]}],"sklearn\/datasets\/kddcup99.py":[{"add":["141","        data[:, 0] = np.log((data[:, 0] + 0.1).astype(float, copy=False))","142","        data[:, 4] = np.log((data[:, 4] + 0.1).astype(float, copy=False))","143","        data[:, 5] = np.log((data[:, 5] + 0.1).astype(float, copy=False))"],"delete":["141","        data[:, 0] = np.log((data[:, 0] + 0.1).astype(float))","142","        data[:, 4] = np.log((data[:, 4] + 0.1).astype(float))","143","        data[:, 5] = np.log((data[:, 5] + 0.1).astype(float))"]}],"sklearn\/metrics\/cluster\/supervised.py":[{"add":["25","from ...utils.fixes import comb, _astype_copy_false","633","    outer = (pi.take(nzx).astype(np.int64, copy=False)","634","             * pj.take(nzy).astype(np.int64, copy=False))","743","    contingency = contingency.astype(np.float64,","744","                                     **_astype_copy_false(contingency))","855","    contingency = contingency.astype(np.float64,","856","                                     **_astype_copy_false(contingency))","939","                           sparse=True)","940","    c = c.astype(np.int64, **_astype_copy_false(c))"],"delete":["25","from ...utils.fixes import comb","633","    outer = pi.take(nzx).astype(np.int64) * pj.take(nzy).astype(np.int64)","742","    contingency = contingency.astype(np.float64)","853","    contingency = contingency.astype(np.float64)","936","                           sparse=True).astype(np.int64)"]}],"sklearn\/neighbors\/tests\/test_dist_metrics.py":[{"add":["25","X1 = rng.random_sample((n1, d)).astype('float64', copy=False)","26","X2 = rng.random_sample((n2, d)).astype('float64', copy=False)"],"delete":["25","X1 = rng.random_sample((n1, d)).astype('float64')","26","X2 = rng.random_sample((n2, d)).astype('float64')"]}],"sklearn\/preprocessing\/imputation.py":[{"add":["287","                row_mask = np.logical_not(row_mask)"],"delete":["287","                row_mask = np.logical_not(row_mask).astype(np.bool)"]}],"sklearn\/datasets\/tests\/test_svmlight_format.py":[{"add":["275","                            y_dense.astype(dtype, copy=False), y2, 4)","281","                            y_dense.astype(dtype, copy=False), y2, 15)"],"delete":["275","                            y_dense.astype(dtype), y2, 4)","281","                            y_dense.astype(dtype), y2, 15)"]}],"sklearn\/decomposition\/tests\/test_pca.py":[{"add":["721","    X_64 = np.random.RandomState(0).rand(1000, 4).astype(np.float64,","722","                                                         copy=False)","743","    X_i64 = X_i64.astype(np.int64, copy=False)","744","    X_i32 = X_i64.astype(np.int32, copy=False)"],"delete":["721","    X_64 = np.random.RandomState(0).rand(1000, 4).astype(np.float64)","742","    X_i64 = X_i64.astype(np.int64)","743","    X_i32 = X_i64.astype(np.int32)"]}],"sklearn\/datasets\/rcv1.py":[{"add":["181","        sample_id = sample_id.astype(np.uint32, copy=False)"],"delete":["181","        sample_id = sample_id.astype(np.uint32)"]}],"sklearn\/metrics\/tests\/test_pairwise.py":[{"add":["205","_wminkowski_kwds = {'w': np.arange(1, 5).astype('double', copy=False), 'p': 1}"],"delete":["205","_wminkowski_kwds = {'w': np.arange(1, 5).astype('double'), 'p': 1}"]}],"sklearn\/preprocessing\/tests\/test_data.py":[{"add":["207","    Xt_dense = est.fit_transform(X.astype(dtype, copy=False))"],"delete":["207","    Xt_dense = est.fit_transform(X.astype(dtype))"]}],"sklearn\/utils\/tests\/test_extmath.py":[{"add":["171","    X = X.astype(dtype, copy=False)","183","            Xcsr.indptr = Xcsr.indptr.astype(csr_index_dtype, copy=False)","184","            Xcsr.indices = Xcsr.indices.astype(csr_index_dtype, copy=False)"],"delete":["171","    X = X.astype(dtype)","183","            Xcsr.indptr = Xcsr.indptr.astype(csr_index_dtype)","184","            Xcsr.indices = Xcsr.indices.astype(csr_index_dtype)"]}],"sklearn\/tree\/tests\/test_tree.py":[{"add":["1581","    X_small32 = X_small.astype(tree._tree.DTYPE, copy=False)","1590","    X_small32 = csr_matrix(X_small.astype(tree._tree.DTYPE, copy=False))"],"delete":["1581","    X_small32 = X_small.astype(tree._tree.DTYPE)","1590","    X_small32 = csr_matrix(X_small.astype(tree._tree.DTYPE))"]}],"sklearn\/datasets\/base.py":[{"add":["547","    target = data[:, -1].astype(np.int, copy=False)"],"delete":["547","    target = data[:, -1].astype(np.int)"]}],"sklearn\/cluster\/hierarchical.py":[{"add":["24","from ..utils.fixes import _astype_copy_false","90","    connectivity = connectivity.astype('float64',","91","                                       **_astype_copy_false(connectivity))","462","        children_ = out[:, :2].astype(np.int, copy=False)","481","        distances = X[connectivity.row, connectivity.col].astype(","482","            'float64', **_astype_copy_false(X))"],"delete":["89","    connectivity = connectivity.astype('float64')","460","        children_ = out[:, :2].astype(np.int)","479","        distances = X[connectivity.row, connectivity.col].astype('float64')"]}],"sklearn\/metrics\/tests\/test_classification.py":[{"add":["858","        cm = confusion_matrix(y, y,","859","                              sample_weight=weight.astype(dtype, copy=False))","862","        cm = confusion_matrix(y, y,","863","                              sample_weight=weight.astype(dtype, copy=False))"],"delete":["858","        cm = confusion_matrix(y, y, sample_weight=weight.astype(dtype))","861","        cm = confusion_matrix(y, y, sample_weight=weight.astype(dtype))"]}],"sklearn\/manifold\/tests\/test_t_sne.py":[{"add":["142","    neighbors_nn = np.argsort(distances, axis=1)[:, 1:k].astype(np.int64,","143","                                                                copy=False)","155","        neighbors_nn = np.argsort(distances, axis=1)[:, :k].astype(np.int64,","156","                                                                   copy=False)","180","    neighbors_nn = np.argsort(distances, axis=1)[:, :k].astype(np.int64,","181","                                                               copy=False)","537","    neighbors = neighbors.astype(np.int64, copy=False)","609","    X = random_state.randn(50, 2).astype(dt, copy=False)"],"delete":["142","    neighbors_nn = np.argsort(distances, axis=1)[:, 1:k].astype(np.int64)","154","        neighbors_nn = np.argsort(distances, axis=1)[:, :k].astype(np.int64)","178","    neighbors_nn = np.argsort(distances, axis=1)[:, :k].astype(np.int64)","534","    neighbors = neighbors.astype(np.int64)","606","    X = random_state.randn(50, 2).astype(dt)"]}],"sklearn\/neighbors\/tests\/test_kd_tree.py":[{"add":["198","        d_in = rng.random_sample(2 * n_nbrs).astype(DTYPE, copy=False)","214","    vals = rng.random_sample(n_nodes).astype(DTYPE, copy=False)","224","    dist = rng.random_sample((n_rows, n_pts)).astype(DTYPE, copy=False)","225","    ind = (np.arange(n_pts) + np.zeros((n_rows, 1))).astype(ITYPE, copy=False)"],"delete":["198","        d_in = rng.random_sample(2 * n_nbrs).astype(DTYPE)","214","    vals = rng.random_sample(n_nodes).astype(DTYPE)","224","    dist = rng.random_sample((n_rows, n_pts)).astype(DTYPE)","225","    ind = (np.arange(n_pts) + np.zeros((n_rows, 1))).astype(ITYPE)"]}],"sklearn\/datasets\/samples_generator.py":[{"add":["192","                                    generator).astype(float, copy=False)","448","    y = ((X ** 2.0).sum(axis=1) > 9.34).astype(np.float64, copy=False)"],"delete":["192","                                    generator).astype(float)","448","    y = ((X ** 2.0).sum(axis=1) > 9.34).astype(np.float64)"]}],"sklearn\/preprocessing\/base.py":[{"add":["6","from ..utils.fixes import _astype_copy_false","74","        X_not_sel = X[:, ind[not_sel]].astype(dtype, **_astype_copy_false(X))"],"delete":["73","        X_not_sel = X[:, ind[not_sel]].astype(dtype)"]}],"sklearn\/datasets\/openml.py":[{"add":["654","                               y[:, i:i+1].astype(int, copy=False))"],"delete":["654","                               y[:, i:i+1].astype(int))"]}],"sklearn\/preprocessing\/data.py":[{"add":["673","            self.n_samples_seen_ = np.repeat(","674","                self.n_samples_seen_, X.shape[1]).astype(np.int64, copy=False)","689","                self.n_samples_seen_ = (","690","                        X.shape[0] - counts_nan).astype(np.int64, copy=False)"],"delete":["673","            self.n_samples_seen_ = np.repeat(self.n_samples_seen_,","674","                                             X.shape[1]).astype(np.int64)","689","                self.n_samples_seen_ = (X.shape[0] -","690","                                        counts_nan).astype(np.int64)"]}],"sklearn\/ensemble\/tests\/test_bagging.py":[{"add":["812","    X = X.astype('float', copy=True)"],"delete":["812","    X = X.copy().astype('float')"]}],"doc\/whats_new\/v0.21.rst":[{"add":["424","- |Efficiency| Memory copies are avoided when casting arrays to a different","425","  dtype in multiple estimators. :issue:`11973` by :user:`Roman Yurchak`_.","426",""],"delete":[]}],"sklearn\/datasets\/covtype.py":[{"add":["117","        y = Xy[:, -1].astype(np.int32, copy=False)"],"delete":["117","        y = Xy[:, -1].astype(np.int32)"]}],"sklearn\/feature_selection\/mutual_info_.py":[{"add":["11","from ..utils.fixes import _astype_copy_false","277","        X = X.astype(float, **_astype_copy_false(X))"],"delete":["276","        X = X.astype(float)"]}],"sklearn\/svm\/base.py":[{"add":["232","        return column_or_1d(y, warn=True).astype(np.float64, copy=False)"],"delete":["232","        return column_or_1d(y, warn=True).astype(np.float64)"]}],"sklearn\/feature_extraction\/_hashing.pyx":[{"add":["97","        indices_a = indices_a.astype(np.int64, copy=False)","99","        indptr_a = indptr_a.astype(np.int32, copy=False)"],"delete":["97","        indices_a = indices_a.astype(np.int64)","99","        indptr_a = indptr_a.astype(np.int32)"]}],"sklearn\/metrics\/cluster\/expected_mutual_info_fast.pyx":[{"add":["31","    a = np.ravel(contingency.sum(axis=1).astype(np.int32, copy=False))","32","    b = np.ravel(contingency.sum(axis=0).astype(np.int32, copy=False))"],"delete":["31","    a = np.ravel(contingency.sum(axis=1).astype(np.int32))","32","    b = np.ravel(contingency.sum(axis=0).astype(np.int32))"]}],"sklearn\/cluster\/tests\/test_hierarchical.py":[{"add":["285","            children_ = out[:, :2].astype(np.int, copy=False)","484","    keys = np.unique(rng.randint(100, size=10).astype(np.intp, copy=False))","491","    other_keys = np.arange(50, dtype=np.intp)[::2]"],"delete":["285","            children_ = out[:, :2].astype(np.int)","484","    keys = np.unique(rng.randint(100, size=10).astype(np.intp))","491","    other_keys = np.arange(50).astype(np.intp)[::2]"]}],"sklearn\/neighbors\/tests\/test_ball_tree.py":[{"add":["240","        d_in = rng.random_sample(2 * n_nbrs).astype(DTYPE, copy=False)","256","    vals = rng.random_sample(n_nodes).astype(DTYPE, copy=False)","266","    dist = rng.random_sample((n_rows, n_pts)).astype(DTYPE, copy=False)","267","    ind = (np.arange(n_pts) + np.zeros((n_rows, 1))).astype(ITYPE, copy=False)"],"delete":["240","        d_in = rng.random_sample(2 * n_nbrs).astype(DTYPE)","256","    vals = rng.random_sample(n_nodes).astype(DTYPE)","266","    dist = rng.random_sample((n_rows, n_pts)).astype(DTYPE)","267","    ind = (np.arange(n_pts) + np.zeros((n_rows, 1))).astype(ITYPE)"]}],"sklearn\/cluster\/k_means_.py":[{"add":["180","        return (sample_weight * scale).astype(X.dtype, copy=False)","620","    labels = labels.astype(np.int32, copy=False)","1196","                assign_rows_csr(","1197","                        X, new_centers.astype(np.intp, copy=False),","1198","                        np.where(to_reassign)[0].astype(np.intp, copy=False),","1199","                        centers)"],"delete":["180","        return (sample_weight * scale).astype(X.dtype)","620","    labels = labels.astype(np.int32)","1196","                assign_rows_csr(X, new_centers.astype(np.intp),","1197","                                np.where(to_reassign)[0].astype(np.intp),","1198","                                centers)"]}]}},"a1565241a42aa949e245b3a966343dd334595fce":{"changes":{"sklearn\/feature_extraction\/image.py":"MODIFY"},"diff":{"sklearn\/feature_extraction\/image.py":[{"add":["288","    slices = tuple(slice(None, None, st) for st in extraction_step)"],"delete":["288","    slices = [slice(None, None, st) for st in extraction_step]"]}]}},"5cef1df11bc7ba337dc9cfc431e21659f4524457":{"changes":{"sklearn\/ensemble\/bagging.py":"MODIFY","sklearn\/ensemble\/tests\/test_bagging.py":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY"},"diff":{"sklearn\/ensemble\/bagging.py":[{"add":["312","        elif isinstance(self.max_features, np.float):","313","            max_features = self.max_features * self.n_features_","314","        else:","315","            raise ValueError(\"max_features must be int or float\")","320","        max_features = max(1, int(max_features))","321",""],"delete":["312","        else:  # float","313","            max_features = int(self.max_features * self.n_features_)"]}],"sklearn\/ensemble\/tests\/test_bagging.py":[{"add":["886","","887","","888","@pytest.mark.filterwarnings('ignore: Default solver will be changed')  # 0.22","889","@pytest.mark.filterwarnings('ignore: Default multi_class will')  # 0.22","890","def test_bagging_small_max_features():","891","    # Check that Bagging estimator can accept low fractional max_features","892","","893","    X = np.array([[1, 2], [3, 4]])","894","    y = np.array([1, 0])","895","","896","    bagging = BaggingClassifier(LogisticRegression(),","897","                                max_features=0.3, random_state=1)","898","    bagging.fit(X, y)"],"delete":[]}],"doc\/whats_new\/v0.20.rst":[{"add":["64","- |Fix| Fixed a bug affecting :class:`ensemble.BaggingClassifier`,","65","  :class:`ensemble.BaggingRegressor` and :class:`ensemble.IsolationForest`,","66","  where ``max_features`` was sometimes rounded down to zero.","67","  :issue:`12388` by :user:`Connor Tann <Connossor>`.","68",""],"delete":[]}]}},"55a98ab7e3b10966f6d00c3562f3a99896797964":{"changes":{"doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/linear_model\/tests\/test_logistic.py":"MODIFY","doc\/modules\/classes.rst":"MODIFY","sklearn\/linear_model\/logistic.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.21.rst":[{"add":["95","- |API| :func:`linear_model.logistic_regression_path` is deprecated","96","  in version 0.21 and will be removed in version 0.23.","97","  :issue:`12821` by :user:`Nicolas Hug <NicolasHug>`.","98",""],"delete":[]}],"sklearn\/linear_model\/tests\/test_logistic.py":[{"add":["37","    logistic_regression_path,","38","    _logistic_regression_path, LogisticRegressionCV,","398","        coefs, Cs, _ = f(_logistic_regression_path)(","413","        coefs, Cs, _ = f(_logistic_regression_path)(","430","    assert_warns(ConvergenceWarning, _logistic_regression_path,","1692","    coefs, _, _ = _logistic_regression_path(X, y, penalty='l1', Cs=Cs,","1693","                                            solver='saga', random_state=0,","1694","                                            multi_class='multinomial')","1749","","1750","","1751","def test_logistic_regression_path_deprecation():","1752","","1753","    assert_warns_message(DeprecationWarning,","1754","                         \"logistic_regression_path was deprecated\",","1755","                         logistic_regression_path, X, Y1)"],"delete":["37","    logistic_regression_path, LogisticRegressionCV,","397","        coefs, Cs, _ = f(logistic_regression_path)(","412","        coefs, Cs, _ = f(logistic_regression_path)(","429","    assert_warns(ConvergenceWarning, logistic_regression_path,","1691","    coefs, _, _ = logistic_regression_path(X, y, penalty='l1', Cs=Cs,","1692","                                           solver='saga', random_state=0,","1693","                                           multi_class='multinomial')"]}],"doc\/modules\/classes.rst":[{"add":["1508","   linear_model.logistic_regression_path"],"delete":["758","   linear_model.logistic_regression_path"]}],"sklearn\/linear_model\/logistic.py":[{"add":["31","from ..utils import deprecated","481","@deprecated('logistic_regression_path was deprecated in version 0.21 and '","482","            'will be removed in version 0.23.0')","500","    .. deprecated:: 0.21","501","        ``logistic_regression_path`` was deprecated in version 0.21 and will","502","        be removed in 0.23.","503","","504","    Read more in the :ref:`User Guide <logistic_regression>`.","505","","506","    Parameters","507","    ----------","508","    X : array-like or sparse matrix, shape (n_samples, n_features)","509","        Input data.","510","","511","    y : array-like, shape (n_samples,) or (n_samples, n_targets)","512","        Input data, target values.","513","","514","    pos_class : int, None","515","        The class with respect to which we perform a one-vs-all fit.","516","        If None, then it is assumed that the given problem is binary.","517","","518","    Cs : int | array-like, shape (n_cs,)","519","        List of values for the regularization parameter or integer specifying","520","        the number of regularization parameters that should be used. In this","521","        case, the parameters will be chosen in a logarithmic scale between","522","        1e-4 and 1e4.","523","","524","    fit_intercept : bool","525","        Whether to fit an intercept for the model. In this case the shape of","526","        the returned array is (n_cs, n_features + 1).","527","","528","    max_iter : int","529","        Maximum number of iterations for the solver.","530","","531","    tol : float","532","        Stopping criterion. For the newton-cg and lbfgs solvers, the iteration","533","        will stop when ``max{|g_i | i = 1, ..., n} <= tol``","534","        where ``g_i`` is the i-th component of the gradient.","535","","536","    verbose : int","537","        For the liblinear and lbfgs solvers set verbose to any positive","538","        number for verbosity.","539","","540","    solver : {'lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'}","541","        Numerical solver to use.","542","","543","    coef : array-like, shape (n_features,), default None","544","        Initialization value for coefficients of logistic regression.","545","        Useless for liblinear solver.","546","","547","    class_weight : dict or 'balanced', optional","548","        Weights associated with classes in the form ``{class_label: weight}``.","549","        If not given, all classes are supposed to have weight one.","550","","551","        The \"balanced\" mode uses the values of y to automatically adjust","552","        weights inversely proportional to class frequencies in the input data","553","        as ``n_samples \/ (n_classes * np.bincount(y))``.","554","","555","        Note that these weights will be multiplied with sample_weight (passed","556","        through the fit method) if sample_weight is specified.","557","","558","    dual : bool","559","        Dual or primal formulation. Dual formulation is only implemented for","560","        l2 penalty with liblinear solver. Prefer dual=False when","561","        n_samples > n_features.","562","","563","    penalty : str, 'l1', 'l2', or 'elasticnet'","564","        Used to specify the norm used in the penalization. The 'newton-cg',","565","        'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is","566","        only supported by the 'saga' solver.","567","","568","    intercept_scaling : float, default 1.","569","        Useful only when the solver 'liblinear' is used","570","        and self.fit_intercept is set to True. In this case, x becomes","571","        [x, self.intercept_scaling],","572","        i.e. a \"synthetic\" feature with constant value equal to","573","        intercept_scaling is appended to the instance vector.","574","        The intercept becomes ``intercept_scaling * synthetic_feature_weight``.","575","","576","        Note! the synthetic feature weight is subject to l1\/l2 regularization","577","        as all other features.","578","        To lessen the effect of regularization on synthetic feature weight","579","        (and therefore on the intercept) intercept_scaling has to be increased.","580","","581","    multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'","582","        If the option chosen is 'ovr', then a binary problem is fit for each","583","        label. For 'multinomial' the loss minimised is the multinomial loss fit","584","        across the entire probability distribution, *even when the data is","585","        binary*. 'multinomial' is unavailable when solver='liblinear'.","586","        'auto' selects 'ovr' if the data is binary, or if solver='liblinear',","587","        and otherwise selects 'multinomial'.","588","","589","        .. versionadded:: 0.18","590","           Stochastic Average Gradient descent solver for 'multinomial' case.","591","        .. versionchanged:: 0.20","592","            Default will change from 'ovr' to 'auto' in 0.22.","593","","594","    random_state : int, RandomState instance or None, optional, default None","595","        The seed of the pseudo random number generator to use when shuffling","596","        the data.  If int, random_state is the seed used by the random number","597","        generator; If RandomState instance, random_state is the random number","598","        generator; If None, the random number generator is the RandomState","599","        instance used by `np.random`. Used when ``solver`` == 'sag' or","600","        'liblinear'.","601","","602","    check_input : bool, default True","603","        If False, the input arrays X and y will not be checked.","604","","605","    max_squared_sum : float, default None","606","        Maximum squared sum of X over samples. Used only in SAG solver.","607","        If None, it will be computed, going through all the samples.","608","        The value should be precomputed to speed up cross validation.","609","","610","    sample_weight : array-like, shape(n_samples,) optional","611","        Array of weights that are assigned to individual samples.","612","        If not provided, then each sample is given unit weight.","613","","614","    l1_ratio : float or None, optional (default=None)","615","        The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only","616","        used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent","617","        to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent","618","        to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a","619","        combination of L1 and L2.","620","","621","    Returns","622","    -------","623","    coefs : ndarray, shape (n_cs, n_features) or (n_cs, n_features + 1)","624","        List of coefficients for the Logistic Regression model. If","625","        fit_intercept is set to True then the second dimension will be","626","        n_features + 1, where the last item represents the intercept. For","627","        ``multiclass='multinomial'``, the shape is (n_classes, n_cs,","628","        n_features) or (n_classes, n_cs, n_features + 1).","629","","630","    Cs : ndarray","631","        Grid of Cs used for cross-validation.","632","","633","    n_iter : array, shape (n_cs,)","634","        Actual number of iteration for each Cs.","635","","636","    Notes","637","    -----","638","    You might get slightly different results with the solver liblinear than","639","    with the others since this uses LIBLINEAR which penalizes the intercept.","640","","641","    .. versionchanged:: 0.19","642","        The \"copy\" parameter was removed.","643","    \"\"\"","644","","645","    return _logistic_regression_path(","646","        X, y, pos_class=None, Cs=10, fit_intercept=True, max_iter=100,","647","        tol=1e-4, verbose=0, solver='lbfgs', coef=None, class_weight=None,","648","        dual=False, penalty='l2', intercept_scaling=1., multi_class='warn',","649","        random_state=None, check_input=True, max_squared_sum=None,","650","        sample_weight=None, l1_ratio=None)","651","","652","","653","def _logistic_regression_path(X, y, pos_class=None, Cs=10, fit_intercept=True,","654","                              max_iter=100, tol=1e-4, verbose=0,","655","                              solver='lbfgs', coef=None,","656","                              class_weight=None, dual=False, penalty='l2',","657","                              intercept_scaling=1., multi_class='warn',","658","                              random_state=None, check_input=True,","659","                              max_squared_sum=None, sample_weight=None,","660","                              l1_ratio=None):","661","    \"\"\"Compute a Logistic Regression model for a list of regularization","662","    parameters.","663","","664","    This is an implementation that uses the result of the previous model","665","    to speed up computations along the set of solutions, making it faster","666","    than sequentially calling LogisticRegression for the different parameters.","667","    Note that there will be no speedup with liblinear solver, since it does","668","    not handle warm-starting.","669","","1150","    coefs, Cs, n_iter = _logistic_regression_path(","1563","        path_func = delayed(_logistic_regression_path)","2140","                w, _, _ = _logistic_regression_path("],"delete":["977","    coefs, Cs, n_iter = logistic_regression_path(","1390","        path_func = delayed(logistic_regression_path)","1967","                w, _, _ = logistic_regression_path("]}]}},"6f5fec9b6a8354f33489465c9f39ee5b4409e2c1":{"changes":{"doc\/glossary.rst":"MODIFY"},"diff":{"doc\/glossary.rst":[{"add":["228","        conventions <https:\/\/numpydoc.readthedocs.io\/en\/latest\/format.html>`_."],"delete":["228","        conventions <numpydoc.readthedocs.io\/en\/latest\/format.html>`_."]}]}},"2e98a9ca8d3549c7bf2a654590f2b9e76807253e":{"changes":{"sklearn\/decomposition\/tests\/test_pca.py":"MODIFY"},"diff":{"sklearn\/decomposition\/tests\/test_pca.py":[{"add":["723","    # decimal=5 fails on mac with scipy = 1.1.0","725","                              decimal=4)"],"delete":["724","                              decimal=5)"]}]}},"774ae893065d6c166d1eb32b8c8ca28b69520742":{"changes":{"sklearn\/feature_extraction\/tests\/test_image.py":"MODIFY","sklearn\/semi_supervised\/tests\/test_label_propagation.py":"MODIFY","sklearn\/cluster\/birch.py":"MODIFY"},"diff":{"sklearn\/feature_extraction\/tests\/test_image.py":[{"add":["306","        last_patch_slices = tuple(slice(i, i + j, None) for i, j in","307","                                  zip(last_patch, patch_size))","308","        assert_true((patches[(-1, None, None) * ndim] =="],"delete":["306","        last_patch_slices = [slice(i, i + j, None) for i, j in","307","                             zip(last_patch, patch_size)]","308","        assert_true((patches[[slice(-1, None, None)] * ndim] =="]}],"sklearn\/semi_supervised\/tests\/test_label_propagation.py":[{"add":["115","    Tuu = T_bar[tuple(np.meshgrid(unlabelled_idx, unlabelled_idx,","116","                      indexing='ij'))]","117","    Tul = T_bar[tuple(np.meshgrid(unlabelled_idx, labelled_idx,","118","                                  indexing='ij'))]"],"delete":["115","    Tuu = T_bar[np.meshgrid(unlabelled_idx, unlabelled_idx, indexing='ij')]","116","    Tul = T_bar[np.meshgrid(unlabelled_idx, labelled_idx, indexing='ij')]"]}],"sklearn\/cluster\/birch.py":[{"add":["76","    node1_dist, node2_dist = dist[(farthest_idx,)]"],"delete":["76","    node1_dist, node2_dist = dist[[farthest_idx]]"]}]}},"1c88b3c9c76c392741692b57fd379c018bc6cedb":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/utils\/__init__.py":"MODIFY","sklearn\/decomposition\/incremental_pca.py":"MODIFY","sklearn\/decomposition\/tests\/test_incremental_pca.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["14","Changed models","15","--------------","16","","17","The following estimators and functions, when fit with the same data and","18","parameters, may produce different models from the previous version. This often","19","occurs due to changes in the modelling logic (bug fixes or enhancements), or in","20","random sampling procedures.","21","","22","- :class:`decomposition.IncrementalPCA` (bug fix)","23","","67",":mod:`sklearn.decomposition`","68","............................","69","","70","- |Fix| Fixed a regression in :class:`decomposition.IncrementalPCA` where","71","  0.20.0 raised an error if the number of samples in the final batch for","72","   fitting IncrementalPCA was smaller than n_components.","73","  :issue:`12234` by :user:`Ming Li <minggli>`.","74",""],"delete":[]}],"sklearn\/utils\/__init__.py":[{"add":["403","def gen_batches(n, batch_size, min_batch_size=0):","414","    min_batch_size : int, default=0","415","        Minimum batch size to produce.","430","    >>> list(gen_batches(7, 3, min_batch_size=0))","431","    [slice(0, 3, None), slice(3, 6, None), slice(6, 7, None)]","432","    >>> list(gen_batches(7, 3, min_batch_size=2))","433","    [slice(0, 3, None), slice(3, 7, None)]","438","        if end + min_batch_size > n:","439","            continue"],"delete":["403","def gen_batches(n, batch_size):"]}],"sklearn\/decomposition\/incremental_pca.py":[{"add":["198","        for batch in gen_batches(n_samples, self.batch_size_,","199","                                 min_batch_size=self.n_components or 0):"],"delete":["198","        for batch in gen_batches(n_samples, self.batch_size_):"]}],"sklearn\/decomposition\/tests\/test_incremental_pca.py":[{"add":["7","from sklearn.utils.testing import assert_allclose_dense_sparse","178","def test_incremental_pca_batch_rank():","179","    # Test sample size in each batch is always larger or equal to n_components","180","    rng = np.random.RandomState(1999)","181","    n_samples = 100","182","    n_features = 20","183","    X = rng.randn(n_samples, n_features)","184","    all_components = []","185","    batch_sizes = np.arange(20, 90, 3)","186","    for batch_size in batch_sizes:","187","        ipca = IncrementalPCA(n_components=20, batch_size=batch_size).fit(X)","188","        all_components.append(ipca.components_)","189","","190","    for components_i, components_j in zip(all_components[:-1],","191","                                          all_components[1:]):","192","        assert_allclose_dense_sparse(components_i, components_j)","193","","194",""],"delete":[]}]}},"bea1eb51b34d5d61a3df217f5b7ed25f6b98eec3":{"changes":{"doc\/developers\/contributing.rst":"MODIFY"},"diff":{"doc\/developers\/contributing.rst":[{"add":["1145","When ``fit`` is called, any previous call to ``fit`` should be ignored. In","1146","general, calling ``estimator.fit(X1)`` and then ``estimator.fit(X2)`` should","1147","be the same as only calling ``estimator.fit(X2)``. However, this may not be","1148","true in practice when ``fit`` depends on some random process, see","1149",":term:`random_state`. Another exception to this rule is when the","1150","hyper-parameter ``warm_start`` is set to ``True`` for estimators that","1151","support it. ``warm_start=True`` means that the previous state of the","1152","trainable parameters of the estimator are reused instead of using the","1153","default initialization strategy.","1154","","1163","The estimated attributes are expected to be overridden when you call ``fit``","1164","a second time."],"delete":["1153","The last-mentioned attributes are expected to be overridden when","1154","you call ``fit`` a second time without taking any previous value into","1155","account: **fit should be idempotent**."]}]}},"0908617f691628d9b94839664bb0e2c20c225645":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["96","  macOS. This appears to be the case on Travis CI servers, but has not been","111","  to set and that scales better, by :user:`Shane <espg>`.","130","- |Enhancement| :class:`cluster.KMeans` now gives a warning if the number of","149","  ``iteration`` was 1 less than the correct value. Also added the missing","150","  ``n_iter_`` attribute in the docstring of :class:`cluster.KMeans`.","193","  `OpenML <http:\/\/openml.org>`_. OpenML is a free, open data sharing platform","198","  ``n_samples`` parameter to indicate the number of samples to generate per","257","  ``n_components=None`` case now selects the minimum of ``n_samples`` and","258","  ``n_features``.","270","  sparse coding in parallel using read-only memory mapped datastructures.","280","  :user:`Nanxin Chen <bobchennan>`.","307","- |Feature| Added ``named_estimators_`` parameter in","472","  multiclass setting, even if ``'multinomial'`` was set.","503","  ``multi_class='multinomial'`` with binary output ``with warm_start=True``","519","  the algorithm before convergence. A parameter ``n_iter_no_change`` was added","804","- |Feature| Add ``sample_weight`` parameter to the fit method of","833","- |Fix| Fixed a bug in :class:`neighbors.KDTree` and :class:`neighbors.BallTree` where","834","  pickled tree objects would change their type to the super class :class:`BinaryTree`.","951","  :class:`preprocessing.StandardScaler` in the rare case when ``with_mean=False``"],"delete":["96","  MacOS. This appears to be the case on Travis CI servers, but has not been","111","  to set and tat scales better, by :user:`Shane <espg>`.","130","- |Enhancement| :class:`cluster.KMeans` now gives a warning, if the number of","149","  `iteration` was 1 less than the correct value. Also added the missing","150","  `n_iter_` attribute in the docstring of :class:`cluster.KMeans`.","193","  `OpenML <http:\/\/openml.org>`. OpenML is a free, open data sharing platform","198","  `n_samples` parameter to indicate the number of samples to generate per","257","  ``n_components=None`` case now selects the minimum of n_samples and","258","  n_features.","270","  sparse coding in parallel using readonly memory mapped datastructures.","280","  :user:`Nanxin Chen <bobchennan>`.`","307","- |Feature| Add `named_estimators_` parameter in","472","  multiclass setting, even if 'multinomial' was set.","503","  multi_class='multinomial' with binary output with warm_start = True","519","  the algorithm before convergence. A parameter `n_iter_no_change` was added","804","- |Feature| Add `sample_weight` parameter to the fit method of","833","- |Fix| Fixed a bug in `neighbors.KDTree` and `neighbors.BallTree` where","834","  pickled tree objects would change their type to the super class `BinaryTree`.","951","  :class:`preprocessing.StandardScaler` in the rare case when `with_mean=False`"]}]}},"4f5dd77d19fc682e5a04f56791e3fd17d1d71e08":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/utils\/validation.py":"MODIFY","sklearn\/utils\/tests\/test_validation.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["48",":mod:`sklearn.utils`","49","....................","50","","51","- |Fix| Calling :func:`utils.check_array` on `pandas.Series` with categorical","52","  data, which raised an error in 0.20.0, now returns the expected output again.","53","  :issue:`12699` by `Joris Van den Bossche`_.","54",""],"delete":[]}],"sklearn\/utils\/validation.py":[{"add":["479","    if hasattr(array, \"dtypes\") and hasattr(array.dtypes, '__array__'):"],"delete":["479","    if hasattr(array, \"dtypes\") and len(array.dtypes):"]}],"sklearn\/utils\/tests\/test_validation.py":[{"add":["703","    # with categorical dtype (not a numpy dtype) (GH12699)","704","    s = pd.Series(['a', 'b', 'c']).astype('category')","705","    res = check_array(s, dtype=None, ensure_2d=False)","706","    assert_array_equal(res, np.array(['a', 'b', 'c'], dtype=object))","707",""],"delete":[]}]}},"88cdeb85a9303a7b580952b720703a4aca9dc1c0":{"changes":{"sklearn\/cluster\/tests\/test_optics.py":"MODIFY","sklearn\/cluster\/optics_.py":"MODIFY"},"diff":{"sklearn\/cluster\/tests\/test_optics.py":[{"add":["24","n_points_per_cluster = 10","160","    redX = X[::2]  # reduce for speed","211","def test_processing_order():","212","    # Ensure that we consider all unprocessed points,","213","    # not only direct neighbors. when picking the next point.","214","    Y = [[0], [10], [-10], [25]]","215","    clust = OPTICS(min_samples=3, max_eps=15).fit(Y)","216","    assert_array_equal(clust.reachability_, [np.inf, 10, 10, 15])","217","    assert_array_equal(clust.core_distances_, [10, 15, np.inf, np.inf])","218","    assert_array_equal(clust.ordering_, [0, 1, 2, 3])","219","","220","","226","    r1 = [np.inf, 1.0574896366427478, 0.7587934993548423, 0.7290174038973836,","227","          0.7290174038973836, 0.7290174038973836, 0.6861627576116127,","228","          0.7587934993548423, 0.9280118450166668, 1.1748022534146194,","229","          3.3355455741292257, 0.49618389254482587, 0.2552805046961355,","230","          0.2552805046961355, 0.24944622248445714, 0.24944622248445714,","231","          0.24944622248445714, 0.2552805046961355, 0.2552805046961355,","232","          0.3086779122185853, 4.163024452756142, 1.623152630340929,","233","          0.45315840475822655, 0.25468325192031926, 0.2254004358159971,","234","          0.18765711877083036, 0.1821471333893275, 0.1821471333893275,","235","          0.18765711877083036, 0.18765711877083036, 0.2240202988740153,","236","          1.154337614548715, 1.342604473837069, 1.323308536402633,","237","          0.8607514948648837, 0.27219111215810565, 0.13260875220533205,","238","          0.13260875220533205, 0.09890587675958984, 0.09890587675958984,","239","          0.13548790801634494, 0.1575483940837384, 0.17515137170530226,","240","          0.17575920159442388, 0.27219111215810565, 0.6101447895405373,","241","          1.3189208094864302, 1.323308536402633, 2.2509184159764577,","242","          2.4517810628594527, 3.675977064404973, 3.8264795626020365,","243","          2.9130735341510614, 2.9130735341510614, 2.9130735341510614,","244","          2.9130735341510614, 2.8459300127258036, 2.8459300127258036,","245","          2.8459300127258036, 3.0321982337972537]","246","    o1 = [0, 3, 6, 4, 7, 8, 2, 9, 5, 1, 31, 30, 32, 34, 33, 38, 39, 35, 37, 36,","247","          44, 21, 23, 24, 22, 25, 27, 29, 26, 28, 20, 40, 45, 46, 10, 15, 11,","248","          13, 17, 19, 18, 12, 16, 14, 47, 49, 43, 48, 42, 41, 53, 57, 51, 52,","249","          56, 59, 54, 55, 58, 50]","250","    p1 = [-1, 0, 3, 6, 6, 6, 8, 3, 7, 5, 1, 31, 30, 30, 34, 34, 34, 32, 32, 37,","251","          36, 44, 21, 23, 24, 22, 25, 25, 22, 22, 22, 21, 40, 45, 46, 10, 15,","252","          15, 13, 13, 15, 11, 19, 15, 10, 47, 12, 45, 14, 43, 42, 53, 57, 57,","253","          57, 57, 59, 59, 59, 58]","258","    clust1 = OPTICS(min_samples=5).fit(X)","260","    assert_array_equal(clust1.ordering_, np.array(o1))","261","    assert_array_equal(clust1.predecessor_[clust1.ordering_], np.array(p1))","262","    assert_allclose(clust1.reachability_[clust1.ordering_], np.array(r1))","265","    for i in clust1.ordering_[1:]:","266","        assert (clust1.reachability_[i] >=","267","                clust1.core_distances_[clust1.predecessor_[i]])","268","","269","    # Expected values, computed with (future) ELKI 0.7.5 using","270","    r2 = [np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf,","271","          np.inf, np.inf, np.inf, 0.27219111215810565, 0.13260875220533205,","272","          0.13260875220533205, 0.09890587675958984, 0.09890587675958984,","273","          0.13548790801634494, 0.1575483940837384, 0.17515137170530226,","274","          0.17575920159442388, 0.27219111215810565, 0.4928068613197889,","275","          np.inf, 0.2666183922512113, 0.18765711877083036, 0.1821471333893275,","276","          0.1821471333893275, 0.1821471333893275, 0.18715928772277457,","277","          0.18765711877083036, 0.18765711877083036, 0.25468325192031926,","278","          np.inf, 0.2552805046961355, 0.2552805046961355, 0.24944622248445714,","279","          0.24944622248445714, 0.24944622248445714, 0.2552805046961355,","280","          0.2552805046961355, 0.3086779122185853, 0.34466409325984865,","281","          np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf,","282","          np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf,","283","          np.inf, np.inf]","284","    o2 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 11, 13, 17, 19, 18, 12, 16, 14,","285","          47, 46, 20, 22, 25, 23, 27, 29, 24, 26, 28, 21, 30, 32, 34, 33, 38,","286","          39, 35, 37, 36, 31, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53,","287","          54, 55, 56, 57, 58, 59]","288","    p2 = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10, 15, 15, 13, 13, 15,","289","          11, 19, 15, 10, 47, -1, 20, 22, 25, 25, 25, 25, 22, 22, 23, -1, 30,","290","          30, 34, 34, 34, 32, 32, 37, 38, -1, -1, -1, -1, -1, -1, -1, -1, -1,","291","          -1, -1, -1, -1, -1, -1, -1, -1, -1]","292","    clust2 = OPTICS(min_samples=5, max_eps=0.5).fit(X)","293","","294","    assert_array_equal(clust2.ordering_, np.array(o2))","295","    assert_array_equal(clust2.predecessor_[clust2.ordering_], np.array(p2))","296","    assert_allclose(clust2.reachability_[clust2.ordering_], np.array(r2))","297","","298","    index = np.where(clust1.core_distances_ <= 0.5)[0]","299","    assert_allclose(clust1.core_distances_[index],","300","                    clust2.core_distances_[index])","304","    redX = X[::2]"],"delete":["24","n_points_per_cluster = 50","157","def test_auto_extract_hier():","158","    # Tests auto extraction gets correct # of clusters with varying density","159","    clust = OPTICS(min_samples=9).fit(X)","160","    assert_equal(len(set(clust.labels_)), 6)","161","","162","","166","    redX = X[::10]  # reduce for speed","222","    r = [np.inf, 0.7865694338710508, 0.4373157299595305, 0.4121908069391695,","223","         0.302907091394212, 0.20815674060999778, 0.20815674060999778,","224","         0.15190193459676368, 0.15190193459676368, 0.28229645104833345,","225","         0.302907091394212, 0.30507239477026865, 0.30820580778767087,","226","         0.3289019667317037, 0.3458462228589966, 0.3458462228589966,","227","         0.2931114364132193, 0.2931114364132193, 0.2562790168458507,","228","         0.23654635530592025, 0.37903448688824876, 0.3920764620583683,","229","         0.4121908069391695, 0.4364542226186831, 0.45523658462146793,","230","         0.458757846268185, 0.458757846268185, 0.4752907412198826,","231","         0.42350366820623375, 0.42350366820623375, 0.42350366820623375,","232","         0.47758738570352993, 0.47758738570352993, 0.4776963110272057,","233","         0.5272079288923731, 0.5591861752070968, 0.5592057084987357,","234","         0.5609913790596295, 0.5909117211348757, 0.5940470220777727,","235","         0.5940470220777727, 0.6861627576116127, 0.687795873252133,","236","         0.7538541412862811, 0.7865694338710508, 0.8038180561910464,","237","         0.8038180561910464, 0.8242451615289921, 0.8548361202185057,","238","         0.8790098789921685, 2.9281214555815764, 1.3256656984284734,","239","         0.19590944671099267, 0.1339924636672767, 0.1137384200258616,","240","         0.061455005237474075, 0.061455005237474075, 0.061455005237474075,","241","         0.045627777293497276, 0.045627777293497276, 0.045627777293497276,","242","         0.04900902556283447, 0.061455005237474075, 0.06225461602815799,","243","         0.06835750467748272, 0.07882900172724974, 0.07882900172724974,","244","         0.07650735397943846, 0.07650735397943846, 0.07650735397943846,","245","         0.07650735397943846, 0.07650735397943846, 0.07113275489288699,","246","         0.07890196345324527, 0.07052683707634783, 0.07052683707634783,","247","         0.07052683707634783, 0.08284027053523288, 0.08725436842020087,","248","         0.08725436842020087, 0.09010229261951723, 0.09128578974358925,","249","         0.09154172670176584, 0.0968576383038391, 0.12007572768323092,","250","         0.12024155806196564, 0.12141990481584404, 0.1339924636672767,","251","         0.13694322786307633, 0.14275793459246572, 0.15093125027309579,","252","         0.17927454395170142, 0.18151803569400365, 0.1906028449191095,","253","         0.1906028449191095, 0.19604486784973194, 0.2096539172540186,","254","         0.2096539172540186, 0.21614333983312325, 0.22036454909290296,","255","         0.23610322103910933, 0.26028003932256766, 0.2607126030060721,","256","         0.2891824876072483, 0.3258089271514364, 0.35968687619960743,","257","         0.4512973330510512, 0.4746141313843085, 0.5958585488429471,","258","         0.6468718886525733, 0.6878453052524358, 0.6911582799500199,","259","         0.7172169499815705, 0.7209874999572031, 0.6326884657912096,","260","         0.5755681293026617, 0.5755681293026617, 0.5755681293026617,","261","         0.6015042225447333, 0.6756244556376542, 0.4722384908959966,","262","         0.08775739179493615, 0.06665303472021758, 0.056308477780164796,","263","         0.056308477780164796, 0.05507767260835565, 0.05368146914586802,","264","         0.05163427719303039, 0.05163427719303039, 0.05163427719303039,","265","         0.04918757627098621, 0.04918757627098621, 0.05368146914586802,","266","         0.05473720349424546, 0.05473720349424546, 0.048442038421760626,","267","         0.048442038421760626, 0.04598840269934622, 0.03984301937835033,","268","         0.04598840269934622, 0.04598840269934622, 0.04303884892957088,","269","         0.04303884892957088, 0.04303884892957088, 0.0431802780806032,","270","         0.0520412490141781, 0.056308477780164796, 0.05080724020124642,","271","         0.05080724020124642, 0.05080724020124642, 0.06385565101399236,","272","         0.05840878369200427, 0.0474472391259039, 0.0474472391259039,","273","         0.04232512684465669, 0.04232512684465669, 0.04232512684465669,","274","         0.0474472391259039, 0.051802632822946656, 0.051802632822946656,","275","         0.05316405104684577, 0.05316405104684577, 0.05840878369200427,","276","         0.06385565101399236, 0.08025248922898705, 0.08775739179493615,","277","         0.08993337040710143, 0.08993337040710143, 0.08993337040710143,","278","         0.08993337040710143, 0.297457175321605, 0.29763608186278934,","279","         0.3415255849656254, 0.34713336941105105, 0.44108940848708167,","280","         0.35942962652965604, 0.35942962652965604, 0.33609522256535296,","281","         0.5008111387107295, 0.5333587622018111, 0.6223243743872802,","282","         0.6793840035409552, 0.7445032492109848, 0.7445032492109848,","283","         0.6556432627279256, 0.6556432627279256, 0.6556432627279256,","284","         0.8196566935960162, 0.8724089149982351, 0.9352758042365477,","285","         0.9352758042365477, 1.0581847953137133, 1.0684332509194163,","286","         1.0887817699873303, 1.2552604310322708, 1.3993856001769436,","287","         1.4869615658197606, 1.6588098267326852, 1.679969559453028,","288","         1.679969559453028, 1.6860509219163458, 1.6860509219163458,","289","         1.1465697826627317, 0.992866533434785, 0.7691908270707519,","290","         0.578131499171622, 0.578131499171622, 0.578131499171622,","291","         0.5754243919945694, 0.8416199360035114, 0.8722493727270406,","292","         0.9156549976203665, 0.9156549976203665, 0.7472322844356064,","293","         0.715219324518981, 0.715219324518981, 0.715219324518981,","294","         0.7472322844356064, 0.820988298336316, 0.908958489674247,","295","         0.9234036745782839, 0.9519521817942455, 0.992866533434785,","296","         0.992866533434785, 0.9995692674695029, 1.0727415198904493,","297","         1.1395519941203158, 1.1395519941203158, 1.1741737271442092,","298","         1.212860115632712, 0.8724097897372123, 0.8724097897372123,","299","         0.8724097897372123, 1.2439272570611581, 1.2439272570611581,","300","         1.3524538390109015, 1.3524538390109015, 1.2982303284415664,","301","         1.3610655849680207, 1.3802783392089437, 1.3802783392089437,","302","         1.4540636953090629, 1.5879329500533819, 1.5909193228826986,","303","         1.72931779186001, 1.9619075944592093, 2.1994355761906257,","304","         2.2508672067362165, 2.274436122235927, 2.417635732260135,","305","         3.014235905390584, 0.30616929141177107, 0.16449675872754976,","306","         0.09071681523805683, 0.09071681523805683, 0.09071681523805683,","307","         0.08727060912039632, 0.09151721189581336, 0.12277953408786725,","308","         0.14285575406641507, 0.16449675872754976, 0.16321992344119793,","309","         0.1330971730344373, 0.11429891993167259, 0.11429891993167259,","310","         0.11429891993167259, 0.11429891993167259, 0.11429891993167259,","311","         0.0945498340011516, 0.11410457435712089, 0.1196414019798306,","312","         0.12925682285016715, 0.12925682285016715, 0.12925682285016715,","313","         0.12864887158869853, 0.12864887158869853, 0.12864887158869853,","314","         0.13369634918690246, 0.14330826543275352, 0.14877705862323184,","315","         0.15203263952428328, 0.15696350160889708, 0.1585326700393211,","316","         0.1585326700393211, 0.16034306786654595, 0.16034306786654595,","317","         0.15053328296567992, 0.16396729418886688, 0.16763548009617293,","318","         0.1732029325454474, 0.21163390061029352, 0.21497664171864372,","319","         0.22125889949299, 0.240251070192081, 0.240251070192081,","320","         0.2413620965310808, 0.26319419022234064, 0.26319419022234064,","321","         0.27989712380504483, 0.2909782800714374]","322","    o = [0, 3, 6, 7, 15, 4, 27, 28, 49, 17, 35, 47, 46, 39, 13, 19,","323","         22, 29, 30, 38, 34, 32, 43, 8, 25, 9, 37, 23, 33, 40, 44, 11, 36, 5,","324","         45, 48, 41, 26, 24, 20, 31, 2, 16, 10, 18, 14, 42, 12, 1, 21, 234,","325","         132, 112, 115, 107, 110, 120, 114, 100, 131, 137, 145, 130, 121, 134,","326","         116, 149, 108, 111, 113, 142, 148, 119, 104, 126, 133, 138, 127, 101,","327","         105, 103, 106, 125, 140, 123, 147, 144, 129, 141, 117, 143, 136, 128,","328","         122, 124, 102, 109, 249, 146, 118, 135, 245, 139, 224, 241, 217, 202,","329","         248, 233, 214, 236, 211, 206, 231, 212, 221, 229, 244, 208, 226, 83,","330","         76, 53, 77, 88, 62, 66, 65, 89, 93, 79, 95, 74, 70, 82, 51, 73, 87,","331","         67, 94, 56, 52, 63, 80, 75, 57, 96, 60, 69, 90, 86, 58, 68, 81, 64,","332","         84, 85, 97, 59, 98, 61, 71, 78, 92, 50, 91, 55, 54, 72, 99, 210, 201,","333","         216, 239, 203, 218, 219, 222, 240, 294, 243, 246, 204, 220, 200, 215,","334","         230, 225, 205, 207, 237, 223, 235, 209, 228, 238, 227, 285, 232, 256,","335","         281, 270, 260, 252, 272, 268, 292, 298, 269, 275, 257, 250, 284, 283,","336","         286, 295, 297, 293, 289, 258, 299, 282, 262, 296, 287, 267, 255, 263,","337","         288, 276, 251, 266, 274, 271, 277, 261, 279, 290, 253, 254, 291, 259,","338","         280, 278, 273, 247, 265, 242, 264, 213, 199, 174, 154, 152, 180, 186,","339","         195, 170, 181, 176, 187, 173, 157, 159, 158, 172, 182, 183, 151, 197,","340","         177, 160, 156, 171, 175, 184, 193, 161, 179, 196, 185, 192, 165, 166,","341","         164, 189, 155, 162, 188, 153, 178, 169, 194, 150, 163, 198, 190, 191,","342","         168, 167]","343","    p = [-1, 0, 3, 6, 7, 15, 15, 27, 27, 4, 7, 49, 47, 4, 39, 39,","344","         19, 19, 29, 30, 30, 13, 6, 43, 34, 32, 32, 25, 23, 23, 23, 3, 11, 46,","345","         46, 45, 9, 38, 33, 26, 26, 8, 20, 33, 0, 18, 18, 2, 18, 44, 0, 234,","346","         132, 112, 115, 107, 107, 120, 114, 114, 114, 114, 107, 100, 100, 134,","347","         134, 149, 149, 108, 108, 108, 148, 113, 104, 104, 104, 142, 127, 127,","348","         126, 138, 126, 148, 127, 148, 127, 112, 147, 116, 117, 101, 145, 128,","349","         128, 122, 136, 136, 249, 102, 102, 118, 143, 146, 245, 123, 139, 241,","350","         241, 217, 248, 202, 248, 224, 231, 212, 212, 212, 229, 229, 226, 83,","351","         76, 53, 53, 88, 62, 66, 66, 66, 93, 93, 79, 93, 70, 82, 82, 73, 87,","352","         73, 94, 56, 56, 56, 63, 67, 53, 96, 96, 96, 69, 86, 58, 58, 81, 81,","353","         81, 58, 64, 64, 59, 59, 86, 69, 78, 83, 84, 55, 55, 55, 72, 50, 201,","354","         210, 216, 203, 203, 219, 54, 240, 239, 240, 236, 236, 220, 220, 220,","355","         217, 139, 243, 243, 204, 211, 246, 215, 223, 294, 209, 227, 227, 209,","356","         281, 270, 260, 252, 272, 272, 272, 298, 269, 298, 275, 275, 284, 283,","357","         283, 283, 284, 286, 283, 298, 299, 260, 260, 250, 299, 258, 258, 296,","358","         250, 276, 276, 276, 289, 289, 267, 267, 279, 261, 277, 277, 258, 266,","359","         290, 209, 207, 290, 228, 278, 228, 290, 199, 174, 154, 154, 154, 186,","360","         186, 180, 170, 174, 187, 173, 157, 159, 157, 157, 159, 183, 183, 172,","361","         197, 160, 160, 171, 171, 171, 151, 173, 184, 151, 196, 185, 185, 179,","362","         179, 189, 177, 165, 175, 162, 164, 181, 169, 169, 181, 178, 178, 178,","363","         168]","368","    clust = OPTICS(min_samples=5).fit(X)","370","    assert_array_equal(clust.ordering_, np.array(o))","371","    assert_array_equal(clust.predecessor_[clust.ordering_], np.array(p))","372","    assert_allclose(clust.reachability_[clust.ordering_], np.array(r))","375","    for i in clust.ordering_[1:]:","376","        assert (clust.reachability_[i] >=","377","                clust.core_distances_[clust.predecessor_[i]])","381","    redX = X[::10]","390","","391","","392","def test_processing_order():","393","    \"\"\"Early dev version of OPTICS would not consider all unprocessed points,","394","    but only direct neighbors. This tests against this mistake.\"\"\"","395","    Y = [[0], [10], [-10], [25]]","396","    clust = OPTICS(min_samples=3, max_eps=15).fit(Y)","397","    assert_array_equal(clust.reachability_, [np.inf, 10, 10, 15])","398","    assert_array_equal(clust.core_distances_, [10, 15, 20, 25])","399","    assert_array_equal(clust.ordering_, [0, 1, 2, 3])"]}],"sklearn\/cluster\/optics_.py":[{"add":["41","    cluster order. Note that we do not employ a heap to manage the expansion","42","    candidates, so the time complexity will be O(n^2).","200","    cluster order. Note that we do not employ a heap to manage the expansion","201","    candidates, so the time complexity will be O(n^2).","432","        # Here we first do a kNN query for each point, this differs from","433","        # the original OPTICS that only used epsilon range queries.","435","        # OPTICS puts an upper limit on these, use inf for undefined.","436","        self.core_distances_[self.core_distances_ > self.max_eps] = np.inf","490","        # Note that this implementation is O(n^2) theoretically, but","491","        # supposedly with very low constant factors.","494","        for ordering_idx in range(X.shape[0]):","495","            # Choose next based on smallest reachability distance","496","            # (And prefer smaller ids on ties, possibly np.inf!)","497","            index = np.where(processed == 0)[0]","498","            point = index[np.argmin(self.reachability_[index])]","499","","500","            processed[point] = True","501","            ordering[ordering_idx] = point","502","            if self.core_distances_[point] != np.inf:","503","                self._set_reach_dist(point, processed, X, nbrs)","508","        # Assume that radius_neighbors is faster without distances","509","        # and we don't need all distances, nevertheless, this means","510","        # we may be doing some work twice.","517","        # Neighbors of current point are already processed.","519","            return","521","        # Only compute distances to unprocessed neighbors:"],"delete":["41","    cluster order. It also does not employ a heap to manage the expansion","42","    candiates, but rather uses numpy masked arrays. This can be potentially","43","    slower with some parameters (at the benefit from using fast numpy code).","201","    cluster order.","447","","489","        ordering_idx = 0","490","        for point in range(X.shape[0]):","491","            if processed[point]:","492","                continue","493","            if self.core_distances_[point] <= self.max_eps:","494","                while not processed[point]:","495","                    processed[point] = True","496","                    ordering[ordering_idx] = point","497","                    ordering_idx += 1","498","                    point = self._set_reach_dist(point, processed, X, nbrs)","499","            else:  # For very noisy points","500","                ordering[ordering_idx] = point","501","                ordering_idx += 1","502","                processed[point] = True","513","        # Keep n_jobs = 1 in the following lines...please","515","            # Everything is already processed. Return to main loop","516","            return point_index","529","        # Choose next based on smallest reachability distance","530","        # (And prefer smaller ids on ties).","531","        # All unprocessed points qualify, not just new neighbors (\"unproc\")","532","        return (np.ma.array(self.reachability_, mask=processed)","533","                .argmin(fill_value=np.inf))","534",""]}]}},"775bef33c06e21a5f6b730f8df80772c7a11e348":{"changes":{"sklearn\/covariance\/graph_lasso_.py":"MODIFY"},"diff":{"sklearn\/covariance\/graph_lasso_.py":[{"add":["245","            if not np.isfinite(precision_.sum()):","246","                raise FloatingPointError('The system is too ill-conditioned '","247","                                         'for this solver')"],"delete":[]}]}},"6e9776329805868462955e8e2d832750ab513ec4":{"changes":{"sklearn\/linear_model\/stochastic_gradient.py":"MODIFY"},"diff":{"sklearn\/linear_model\/stochastic_gradient.py":[{"add":["320","    Returns y, coef, intercept, average_coef, average_intercept."],"delete":["320","    Returns y, coef, intercept."]}]}},"876b14907f96a42e63c3ef576a46755b120c3c01":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/metrics\/pairwise.py":"MODIFY","sklearn\/metrics\/tests\/test_pairwise.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["48",":mod:`sklearn.metrics`","49","......................","50","","51","- |Fix| Fixed a bug in :func:`metrics.pairwise_distances` and","52","  :func:`metrics.pairwise_distances_chunked` where parameters ``V`` of","53","  ``\"seuclidean\"`` and ``VI`` of ``\"mahalanobis\"`` metrics were computed after","54","  the data was split into chunks instead of being pre-computed on whole data.","55","  :issue:`12701` by :user:`Jeremie du Boisberranger <jeremiedbb>`.","56","","57",""],"delete":[]}],"sklearn\/metrics\/pairwise.py":[{"add":["1131","def _precompute_metric_params(X, Y, metric=None, **kwds):","1132","    \"\"\"Precompute data-derived metric parameters if not provided","1133","    \"\"\"","1134","    if metric == \"seuclidean\" and 'V' not in kwds:","1135","        if X is Y:","1136","            V = np.var(X, axis=0, ddof=1)","1137","        else:","1138","            V = np.var(np.vstack([X, Y]), axis=0, ddof=1)","1139","        return {'V': V}","1140","    if metric == \"mahalanobis\" and 'VI' not in kwds:","1141","        if X is Y:","1142","            VI = np.linalg.inv(np.cov(X.T)).T","1143","        else:","1144","            VI = np.linalg.inv(np.cov(np.vstack([X, Y]).T)).T","1145","        return {'VI': VI}","1146","    return {}","1147","","1148","","1284","    # precompute data-derived metric params","1285","    params = _precompute_metric_params(X, Y, metric=metric, **kwds)","1286","    kwds.update(**params)","1287","","1419","        # precompute data-derived metric params","1420","        params = _precompute_metric_params(X, Y, metric=metric, **kwds)","1421","        kwds.update(**params)","1422",""],"delete":[]}],"sklearn\/metrics\/tests\/test_pairwise.py":[{"add":["7","from scipy.spatial.distance import cdist, pdist, squareform","11","from sklearn import config_context","12","","898","","899","","900","@pytest.mark.parametrize(\"n_jobs\", [1, 2])","901","@pytest.mark.parametrize(\"metric\", [\"seuclidean\", \"mahalanobis\"])","902","@pytest.mark.parametrize(\"dist_function\",","903","                         [pairwise_distances, pairwise_distances_chunked])","904","@pytest.mark.parametrize(\"y_is_x\", [True, False], ids=[\"Y is X\", \"Y is not X\"])","905","def test_pairwise_distances_data_derived_params(n_jobs, metric, dist_function,","906","                                                y_is_x):","907","    # check that pairwise_distances give the same result in sequential and","908","    # parallel, when metric has data-derived parameters.","909","    with config_context(working_memory=0.1):  # to have more than 1 chunk","910","        rng = np.random.RandomState(0)","911","        X = rng.random_sample((1000, 10))","912","","913","        if y_is_x:","914","            Y = X","915","            expected_dist_default_params = squareform(pdist(X, metric=metric))","916","            if metric == \"seuclidean\":","917","                params = {'V': np.var(X, axis=0, ddof=1)}","918","            else:","919","                params = {'VI': np.linalg.inv(np.cov(X.T)).T}","920","        else:","921","            Y = rng.random_sample((1000, 10))","922","            expected_dist_default_params = cdist(X, Y, metric=metric)","923","            if metric == \"seuclidean\":","924","                params = {'V': np.var(np.vstack([X, Y]), axis=0, ddof=1)}","925","            else:","926","                params = {'VI': np.linalg.inv(np.cov(np.vstack([X, Y]).T)).T}","927","","928","        expected_dist_explicit_params = cdist(X, Y, metric=metric, **params)","929","        dist = np.vstack(dist_function(X, Y, metric=metric, n_jobs=n_jobs))","930","","931","        assert_allclose(dist, expected_dist_explicit_params)","932","        assert_allclose(dist, expected_dist_default_params)"],"delete":[]}]}},"4223633b0d64c75fef1230f66cfb1d50fb5a8d04":{"changes":{"sklearn\/calibration.py":"MODIFY"},"diff":{"sklearn\/calibration.py":[{"add":["16","from scipy.special import expit","445","        P = expit(-(AB[0] * F + AB[1]))","519","        return expit(-(self.a_ * T + self.b_))"],"delete":["444","        E = np.exp(AB[0] * F + AB[1])","445","        P = 1. \/ (1. + E)","519","        return 1. \/ (1. + np.exp(self.a_ * T + self.b_))"]}]}},"3282d43ccc90b887c7567e28606b516e60221281":{"changes":{"sklearn\/datasets\/tests\/data\/openml\/1\/data-v1-download-1.arff.gz":"ADD","sklearn\/datasets\/tests\/test_openml.py":"MODIFY","sklearn\/datasets\/tests\/data\/openml\/1\/api-v1-json-data-1.json.gz":"ADD","sklearn\/datasets\/tests\/data\/openml\/1\/api-v1-json-data-features-1.json.gz":"ADD","sklearn\/datasets\/openml.py":"MODIFY","sklearn\/datasets\/tests\/data\/openml\/3\/api-v1-json-data-3.json.gz":"ADD","sklearn\/datasets\/tests\/data\/openml\/3\/api-v1-json-data-features-3.json.gz":"ADD","sklearn\/datasets\/tests\/data\/openml\/3\/data-v1-download-3.arff.gz":"ADD"},"diff":{"sklearn\/datasets\/tests\/data\/openml\/1\/data-v1-download-1.arff.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/test_openml.py":[{"add":["610","def test_dataset_with_openml_error(monkeypatch, gzip_response):","611","    data_id = 1","612","    _monkey_patch_webbased_functions(monkeypatch, data_id, gzip_response)","613","    assert_warns_message(","614","        UserWarning,","615","        \"OpenML registered a problem with the dataset. It might be unusable. \"","616","        \"Error:\",","617","        fetch_openml, data_id=data_id, cache=False","618","    )","619","","620","","621","@pytest.mark.parametrize('gzip_response', [True, False])","622","def test_dataset_with_openml_warning(monkeypatch, gzip_response):","623","    data_id = 3","624","    _monkey_patch_webbased_functions(monkeypatch, data_id, gzip_response)","625","    assert_warns_message(","626","        UserWarning,","627","        \"OpenML raised a warning on the dataset. It might be unusable. \"","628","        \"Warning:\",","629","        fetch_openml, data_id=data_id, cache=False","630","    )","631","","632","","633","@pytest.mark.parametrize('gzip_response', [True, False])"],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/1\/api-v1-json-data-1.json.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/1\/api-v1-json-data-features-1.json.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/openml.py":[{"add":["513","    if 'error' in data_description:","514","        warn(\"OpenML registered a problem with the dataset. It might be \"","515","             \"unusable. Error: {}\".format(data_description['error']))","516","    if 'warning' in data_description:","517","        warn(\"OpenML raised a warning on the dataset. It might be \"","518","             \"unusable. Warning: {}\".format(data_description['warning']))"],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/3\/api-v1-json-data-3.json.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/3\/api-v1-json-data-features-3.json.gz":[{"add":[],"delete":[]}],"sklearn\/datasets\/tests\/data\/openml\/3\/data-v1-download-3.arff.gz":[{"add":[],"delete":[]}]}},"da138c5f78e5a4bab0f5a8eea2591e0f25474db0":{"changes":{"doc\/conftest.py":"MODIFY"},"diff":{"doc\/conftest.py":[{"add":["2","import warnings","78","def setup_unsupervised_learning():","79","    # ignore deprecation warnings from scipy.misc.face","80","    warnings.filterwarnings('ignore', 'The binary mode of fromstring',","81","                            DeprecationWarning)","82","","83","","102","    elif fname.endswith('statistical_inference\/unsupervised_learning.rst'):","103","        setup_unsupervised_learning()"],"delete":[]}]}},"fc2503f80f74e788df8f6a2df8cf1abe643c0d59":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","doc\/themes\/scikit-learn\/static\/css\/bootstrap.css":"MODIFY","doc\/whats_new\/_contributors.rst":"MODIFY","doc\/themes\/scikit-learn\/static\/css\/bootstrap.min.css":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["52","Sorry if your contribution didn't make it into the highlights. There's a lot","53","here...","54","","64","- :class:`decomposition.SparsePCA` (bug fix)","65","- :class:`ensemble.gradient_boosting.GradientBoostingClassifier` (bug fix affecting feature importances)","68","- :class:`linear_model.LogisticRegressionCV` (bug fix)","73","- :class:`linear_model.SGDClassifier` (bug fix)","74","- :class:`linear_model.SGDRegressor` (bug fix)","75","- :class:`metrics.roc_auc_score` (bug fix)","76","- :class:`metrics.roc_curve` (bug fix)","77","- :class:`neural_network.BaseMultilayerPerceptron` (bug fix)","78","- :class:`neural_network.MLPClassifier` (bug fix)","79","- :class:`neural_network.MLPRegressor` (bug fix)","94",".. rubric:: :mod:`sklearn.cluster`:","96","- |MajorFeature| A new clustering algorithm: :class:`cluster.OPTICS`: an","97","  algoritm related to :class:`cluster.DBSCAN`, that has hyperparameters easier","98","  to set and tat scales better, by :user:`Shane <espg>`.","100","- |MajorFeature| :class:`cluster.AgglomerativeClustering` now supports Single","101","  Linkage clustering via ``linkage='single'``. :issue:`9372` by :user:`Leland","102","  McInnes <lmcinnes>` and :user:`Steve Astels <sastels>`.","103","","104","- |Feature| :class:`cluster.KMeans` and :class:`cluster.MiniBatchKMeans` now support","105","  sample weights via new parameter ``sample_weight`` in ``fit`` function.","106","  :issue:`10933` by :user:`Johannes Hansen <jnhansen>`.","107","","108","- |Efficiency| :class:`cluster.KMeans`, :class:`cluster.MiniBatchKMeans` and","109","  :func:`cluster.k_means` passed with ``algorithm='full'`` now enforces","110","  row-major ordering, improving runtime.","111","  :issue:`10471` by :user:`Gaurav Dhingra <gxyd>`.","112","","113","- |Efficiency| :class:`cluster.DBSCAN` now is parallelized according to ``n_jobs``","114","  regardless of ``algorithm``.","115","  :issue:`8003` by :user:`Jo?l Billaud <recamshak>`.","116","","117","- |Enhancement| :class:`cluster.KMeans` now gives a warning, if the number of","118","  distinct clusters found is smaller than ``n_clusters``. This may occur when","119","  the number of distinct points in the data set is actually smaller than the","120","  number of cluster one is looking for.","121","  :issue:`10059` by :user:`Christian Braune <christianbraune79>`.","122","","123","- |Fix| Fixed a bug where the ``fit`` method of","124","  :class:`cluster.AffinityPropagation` stored cluster","125","  centers as 3d array instead of 2d array in case of non-convergence. For the","126","  same class, fixed undefined and arbitrary behavior in case of training data","127","  where all samples had equal similarity.","128","  :issue:`9612`. By :user:`Jonatan Samoocha <jsamoocha>`.","129","","130","- |Fix| Fixed a bug in :func:`cluster.spectral_clustering` where the normalization of","131","  the spectrum was using a division instead of a multiplication. :issue:`8129`","132","  by :user:`Jan Margeta <jmargeta>`, :user:`Guillaume Lemaitre <glemaitre>`,","133","  and :user:`Devansh D. <devanshdalal>`.","134","","135","- |Fix| Fixed a bug in :func:`cluster.k_means_elkan` where the returned","136","  `iteration` was 1 less than the correct value. Also added the missing","137","  `n_iter_` attribute in the docstring of :class:`cluster.KMeans`.","138","  :issue:`11353` by :user:`Jeremie du Boisberranger <jeremiedbb>`.","139","","140","- |API| Deprecate ``pooling_func`` unused parameter in","141","  :class:`cluster.AgglomerativeClustering`.","142","  :issue:`9875` by :user:`Kumar Ashutosh <thechargedneutron>`.","143","","144",".. rubric:: :mod:`sklearn.compose`:","145","","146","- New module.","147","","148","- |MajorFeature| Added :class:`compose.ColumnTransformer`, which allows to","149","  apply different transformers to different columns of arrays or pandas","150","  DataFrames. :issue:`9012` by `Andreas Mller`_ and `Joris Van den Bossche`_,","151","  and :issue:`11315` by :user:`Thomas Fan <thomasjpfan>`.","152","","153","- |MajorFeature| Added the :class:`compose.TransformedTargetRegressor` which","154","  transforms the target y before fitting a regression model. The predictions","155","  are mapped back to the original space via an inverse transform. :issue:`9041`","156","  by `Andreas Mller`_ and :user:`Guillaume Lemaitre <glemaitre>`.","157","","158",".. rubric:: :mod:`sklearn.covariance`:","159","","160","- |API| The :func:`covariance.graph_lasso`,","161","  :class:`covariance.GraphLasso` and :class:`covariance.GraphLassoCV` have been","162","  renamed to :func:`covariance.graphical_lasso`,","163","  :class:`covariance.GraphicalLasso` and :class:`covariance.GraphicalLassoCV`","164","  respectively and will be removed in version 0.22.","165","  :issue:`9993` by :user:`Artiem Krinitsyn <artiemq>`","166","","167",".. rubric:: :mod:`sklearn.datasets`:","168","","169","- |Feature| In :func:`datasets.make_blobs`, one can now pass a list to the","170","  `n_samples` parameter to indicate the number of samples to generate per","171","  cluster.  :issue:`8617` by :user:`Maskani Filali Mohamed <maskani-moh>` and","172","  :user:`Konstantinos Katrioplas <kkatrio>`.","173","","174","- |Feature| Add ``filename`` attribute to :mod:`datasets` that have a CSV file.","175","  :issue:`9101` by :user:`alex-33 <alex-33>`","176","  and :user:`Maskani Filali Mohamed <maskani-moh>`.","177","","178","- |Fix| Fixed a bug in :func:`datasets.load_boston` which had a wrong data","179","  point.  :issue:`10801` by :user:`Takeshi Yoshizawa <tarcusx>`.","180","","181","- |Fix| Fixed a bug in :func:`datasets.load_iris` which had two wrong data points.","182","  :issue:`11082` by :user:`Sadhana Srinivasan <rotuna>`","183","  and :user:`Hanmin Qin <qinhanmin2014>`.","184","","185","- |Fix| Fixed a bug in :func:`datasets.fetch_kddcup99`, where data were not","186","  properly shuffled. :issue:`9731` by `Nicolas Goix`_.","187","","188","- |Fix| Fixed a bug in :func:`datasets.make_circles`, where no odd number of","189","  data points could be generated. :issue:`10037` by :user:`Christian Braune","190","  <christianbraune79>`.","191","","192",".. rubric:: :mod:`sklearn.decomposition`:","193","","194","- |Feature| :func:`decomposition.dict_learning` functions and models now","195","  support positivity constraints.  This applies to the dictionary and sparse","196","  code.  :issue:`6374` by :user:`John Kirkham <jakirkham>`.","197","","198","- |Feature| |Fix| :class:`decomposition.SparsePCA` now exposes","199","  ``normalize_components``. When set to True, the train and test data are","200","  centered with the train mean repsectively during the fit phase and the","201","  transform phase. This fixes the behavior of SparsePCA. When set to False,","202","  which is the default, the previous abnormal behaviour still holds. The False","203","  value is for backward compatibility and should not be used.  :issue:`11585`","204","  by :user:`Ivan Panico <FollowKenny>`.","205","","206","- |Fix| Fix for uninformative error in :class:`decomposition.IncrementalPCA`:","207","  now an error is raised if the number of components is larger than the","208","  chosen batch size. The ``n_components=None`` case was adapted accordingly.","209","  :issue:`6452`. By :user:`Wally Gauze <wallygauze>`.","210","","211","- |Fix| Fixed a bug where the ``partial_fit`` method of","212","  :class:`decomposition.IncrementalPCA` used integer division instead of float","213","  division on Python 2.","214","  :issue:`9492` by :user:`James Bourbeau <jrbourbeau>`.","215","","216","- |Fix| In :class:`decomposition.PCA` selecting a n_components parameter greater","217","  than the number of samples now raises an error.  Similarly, the","218","  ``n_components=None`` case now selects the minimum of n_samples and","219","  n_features.","220","  :issue:`8484` by :user:`Wally Gauze <wallygauze>`.","221","","222","- |Fix| Fixed a bug in :class:`decomposition.PCA` where users will get","223","  unexpected error with large datasets when ``n_components='mle'`` on Python 3","224","  versions.","225","  :issue:`9886` by :user:`Hanmin Qin <qinhanmin2014>`.","226","","227","- |Fix| Fixed a bug in :class:`decomposition.SparseCoder` when running OMP","228","  sparse coding in parallel using readonly memory mapped datastructures.","229","  :issue:`5956` by :user:`Vighnesh Birodkar <vighneshbirodkar>` and","230","  :user:`Olivier Grisel <ogrisel>`.","231","","232",".. rubric:: :mod:`sklearn.discriminant_analysis`:","233","","234","- |Efficiency| Memory usage improvement for :func:`_class_means` and","235","  :func:`_class_cov` in :mod:`discriminant_analysis`.  :issue:`10898` by","236","  :user:`Nanxin Chen <bobchennan>`.`","237","","238",".. rubric:: :mod:`sklearn.dummy`:","239","","240","- |Feature| :class:`dummy.DummyRegressor` now has a ``return_std`` option in its","241","  ``predict`` method. The returned standard deviations will be zeros.","242","","243","- |Feature| :class:`dummy.DummyClassifier` and :class:`dummy.DummyRegressor` now","244","  only require X to be an object with finite length or shape.  :issue:`9832` by","245","  :user:`Vrishank Bhardwaj <vrishank97>`.","246","","247",".. rubric:: :mod:`sklearn.ensemble`:","248","","249","- |Feature| :class:`ensemble.BaggingRegressor` and","250","  :class:`ensemble.BaggingClassifier` can now be fit with missing\/non-finite","251","  values in X and\/or multi-output Y to support wrapping pipelines that perform","252","  their own imputation.  :issue:`9707` by :user:`Jimmy Wan <jimmywan>`.","253","","254","- |Feature| :class:`ensemble.GradientBoostingClassifier` and","259","- |Feature| Add `named_estimators_` parameter in","260","  :class:`ensemble.VotingClassifier` to access fitted estimators.","261","  :issue:`9157` by :user:`Herilalaina Rakotoarison <herilalaina>`.","263","- |Fix| Fixed a bug when fitting :class:`ensemble.GradientBoostingClassifier` or","264","  :class:`ensemble.GradientBoostingRegressor` with ``warm_start=True`` which","265","  previously raised a segmentation fault due to a non-conversion of CSC matrix","266","  into CSR format expected by ``decision_function``. Similarly, Fortran-ordered","267","  arrays are converted to C-ordered arrays in the dense case. :issue:`9991` by","270","- |Fix| Fixed a bug in :class:`ensemble.gradient_boosting.GradientBoostingRegressor`","271","  and :class:`ensemble.gradient_boosting.GradientBoostingClassifier` to have","272","  feature importances summed and then normalized, rather than normalizing on a","273","  per-tree basis. The previous behavior over-weighted the Gini importance of","274","  features that appear in later stages. This issue only affected feature","275","  importances. :issue:`11176` by :user:`Gil Forsyth <gforsyth>`.","276","","277","- |API| The default value of the ``n_estimators`` parameter of","278","  :class:`ensemble.RandomForestClassifier`, :class:`ensemble.RandomForestRegressor`,","279","  :class:`ensemble.ExtraTreesClassifier`, :class:`ensemble.ExtraTreesRegressor`,","280","  and :class:`ensemble.RandomTreesEmbedding` will change from 10 in version 0.20","281","  to 100 in 0.22. A FutureWarning is raised when the default value is used.","282","  :issue:`11542` by :user:`Anna Ayzenshtat <annaayzenshtat>`.","283","","284","- |API| Classes derived from :class:`ensemble.BaseBagging`. The attribute","285","  ``estimators_samples_`` will return a list of arrays containing the indices","286","  selected for each bootstrap instead of a list of arrays containing the mask","287","  of the samples selected for each bootstrap. Indices allows to repeat samples","288","  while mask does not allow this functionality.","289","  :issue:`9524` by :user:`Guillaume Lemaitre <glemaitre>`.","290","","291","- |Fix| :class:`ensemble.BaseBagging` where one could not deterministically","292","  reproduce ``fit`` result usinbg the object attributes when ``random_state``","293","  is set.  :issue:`9723` by :user:`Guillaume Lemaitre <glemaitre>`.","294","","295",".. rubric:: :mod:`sklearn.feature_extraction`:","296","","297","- |Feature| Enable the call to :term:`get_feature_names` in unfitted","298","  :class:`feature_extraction.text.CountVectorizer` initialized with a","299","  vocabulary. :issue:`10908` by :user:`Mohamed Maskani <maskani-moh>`.","300","","301","- |Fix| Fixed a bug in :func:`feature_extraction.image.extract_patches_2d` which","302","  would throw an exception if ``max_patches`` was greater than or equal to the","303","  number of all possible patches rather than simply returning the number of","304","  possible patches. :issue:`10100` by :user:`Varun Agrawal <varunagrawal>`","305","","306","- |Fix| Fixed a bug in :class:`feature_extraction.text.CountVectorizer`,","307","  :class:`feature_extraction.text.TfidfVectorizer`,","308","  :class:`feature_extraction.text.HashingVectorizer` to support 64 bit sparse","309","  array indexing necessary to process large datasets with more than 210\u2079 tokens","310","  (words or n-grams). :issue:`9147` by :user:`Claes-Fredrik Mannby <mannby>`","311","  and `Roman Yurchak`_.","312","","313","- |Fix| Fixed bug in :class:`feature_extraction.text.TFIDFVectorizer` which","314","  was ignoring the parameter ``dtype``. In addition,","315","  :class:`feature_extraction.text.TFIDFTransformer` will preserve ``dtype``","316","  for floating and raise a warning if ``dtype`` requested is integer.","317","  :issue:`10441` by :user:`Mayur Kulkarni <maykulkarni>` and","318","  :user:`Guillaume Lemaitre <glemaitre>`.","319","","320",".. rubric:: :mod:`sklearn.feature_selection`:","321","","322","- |Feature| Added select K best features functionality to","323","  :class:`feature_selection.SelectFromModel`.","324","  :issue:`6689` by :user:`Nihar Sheth <nsheth12>` and","325","  :user:`Quazi Rahman <qmaruf>`.","326","","327","- |Fix| Fixed computation of ``n_features_to_compute`` for edge case with tied","328","  CV scores in :class:`feature_selection.RFECV`.","329","  :issue:`9222` by :user:`Nick Hoh <nickypie>`.","330","","331",".. rubric:: :mod:`sklearn.gaussian_process`:","332","","333","- |Efficiency| In :class:`gaussian_process.GaussianProcessRegressor`, method","334","  ``predict`` is faster when using ``return_std=True`` in particular more when","335","  called several times in a row. :issue:`9234` by :user:`andrewww <andrewww>`","336","  and :user:`Minghui Liu <minghui-liu>`.","337","","338",".. rubric:: :mod:`sklearn.impute`:","339","","340","- New module, adopting ``preprocessing.Imputer`` as","341","  :class:`impute.SimpleImputer` with minor changes (see under preprocessing","342","  below).","343","","344","- |MajorFeature| Added :class:`impute.MissingIndicator` which generates a","345","  binary indicator for missing values. :issue:`8075` by :user:`Maniteja Nandana","346","  <maniteja123>` and :user:`Guillaume Lemaitre <glemaitre>`.","347","","348","- |Feature| The :class:`impute.SimpleImputer` has a new strategy,","349","  ``'constant'``, to complete missing values with a fixed one, given by the","350","  ``fill_value`` parameter. This strategy supports numeric and non-numeric","351","  data, and so does the ``'most_frequent'`` strategy now. :issue:`11211` by","352","  :user:`Jeremie du Boisberranger <jeremiedbb>`.","353","","354",".. rubric:: :mod:`sklearn.isotonic`:","355","","356","- |Fix| Fixed a bug in :class:`isotonic.IsotonicRegression` which incorrectly","357","  combined weights when fitting a model to data involving points with","358","  identical X values.","359","  :issue:`9432` by :user:`Dallas Card <dallascard>`","360","","361",".. rubric:: :mod:`sklearn.linear_model`:","362","","363","- |Feature| :class:`linear_model.SGDClassifier`,","364","  :class:`linear_model.SGDRegressor`,","374","- |Feature| Add `sample_weight` parameter to the fit method of","375","  :class:`linear_model.BayesianRidge` for weighted linear regression.","376","  :issue:`10111` by :user:`Peter St. John <pstjohn>`.","378","- |Fix| Fixed a bug in :func:`logistic.logistic_regression_path` to ensure","379","  that the returned coefficients are correct when ``multiclass='multinomial'``.","380","  Previously, some of the coefficients would override each other, leading to","381","  incorrect results in :class:`logistic.LogisticRegressionCV`.","382","  :issue:`11724` by :user:`Nicolas Hug <NicolasHug>`.","384","- |Fix| Fixed a bug in :class:`linear_model.LogisticRegression` where when using","385","  the parameter ``multi_class='multinomial'``, the ``predict_proba`` method was","386","  returning incorrect probabilities in the case of binary outcomes.","387","  :issue:`9939` by :user:`Roger Westover <rwolst>`.","389","- |Fix| Fixed a bug in :class:`linear_model.LogisticRegressionCV` where the","390","  ``score`` method always computes accuracy, not the metric given by","391","  the ``scoring`` parameter.","392","  :issue:`10998` by :user:`Thomas Fan <thomasjpfan>`.","394","- |Fix| Fixed a bug in :class:`linear_model.LogisticRegressionCV` where the","395","  'ovr' strategy was always used to compute cross-validation scores in the","396","  multiclass setting, even if 'multinomial' was set.","397","  :issue:`8720` by :user:`William de Vazelhes <wdevazelhes>`.","399","- |Fix| Fixed a bug in :class:`linear_model.OrthogonalMatchingPursuit` that was","400","  broken when setting ``normalize=False``.","401","  :issue:`10071` by `Alexandre Gramfort`_.","403","- |Fix| Fixed a bug in :class:`linear_model.ARDRegression` which caused","404","  incorrectly updated estimates for the standard deviation and the","405","  coefficients.  :issue:`10153` by :user:`J?rg D?pfert <jdoepfert>`.","407","- |Fix| Fixed a bug in :class:`linear_model.RidgeClassifierCV` where","408","  the parameter ``store_cv_values`` was not implemented though","409","  it was documented in ``cv_values`` as a way to set up the storage","410","  of cross-validation values for different alphas. :issue:`10297` by","411","  :user:`Mabel Villalba-Jimnez <mabelvj>`.","413","- |Fix| Fixed a bug in :class:`linear_model.ElasticNet` which caused the input","414","  to be overridden when using parameter ``copy_X=True`` and","415","  ``check_input=False``.  :issue:`10581` by :user:`Yacine Mazari <ymazari>`.","417","- |Fix| Fixed a bug in :class:`sklearn.linear_model.Lasso`","418","  where the coefficient had wrong shape when ``fit_intercept=False``.","419","  :issue:`10687` by :user:`Martin Hahn <martin-hahn>`.","421","- |Fix| Fixed a bug in :func:`sklearn.linear_model.LogisticRegression` where the","422","  multi_class='multinomial' with binary output with warm_start = True","423","  :issue:`10836` by :user:`Aishwarya Srinivasan <aishgrt1>`.","424","","425","- |Fix| Fixed a bug in :class:`linear_model.RidgeCV` where using integer","426","  ``alphas`` raised an error.","427","  :issue:`10393` by :user:`Mabel Villalba-Jimnez <mabelvj>`.","428","","429","- |Fix| Fixed condition triggering gap computation in","430","  :class:`linear_model.Lasso` and :class:`linear_model.ElasticNet` when working","431","  with sparse matrices.  :issue:`10992` by `Alexandre Gramfort`_.","432","","433","- |Fix| Fixed a bug in :class:`linear_model.SGDClassifier`,","434","  :class:`linear_model.SGDRegressor`,","435","  :class:`linear_model.PassiveAggressiveClassifier`,","436","  :class:`linear_model.PassiveAggressiveRegressor` and","437","  :class:`linear_model.Perceptron`, where the stopping criterion was stopping","438","  the algorithm before convergence. A parameter `n_iter_no_change` was added","439","  and set by default to 5. Previous behavior is equivalent to setting the","440","  parameter to 1. :issue:`9043` by `Tom Dupre la Tour`_.","441","","442","- |Fix| Fixed a bug where liblinear and libsvm-based estimators would segfault","443","  if passed a scipy.sparse matrix with 64-bit indices. They now raise a","444","  ValueError.","445","  :issue:`11327` by :user:`Karan Dhingra <kdhingra307>` and `Joel Nothman`_.","446","","447","- |API| Deprecate ``positive=True`` option in :class:`linear_model.Lars` as","448","  the underlying implementation is broken. Use :class:`linear_model.Lasso`","449","  instead.  :issue:`9837` by `Alexandre Gramfort`_.","450","","451","- |API| ``n_iter_`` may vary from previous releases in","452","  :class:`linear_model.LogisticRegression` with ``solver='lbfgs'`` and","453","  :class:`linear_model.HuberRegressor`.  For Scipy <= 1.0.0, the optimizer could","454","  perform more than the requested maximum number of iterations. Now both","455","  estimators will report at most ``max_iter`` iterations even if more were","456","  performed. :issue:`10723` by `Joel Nothman`_.","457","","458",".. rubric:: :mod:`sklearn.manifold`:","459","","460","- |Efficiency| Speed improvements for both 'exact' and 'barnes_hut' methods in","461","  :class:`manifold.TSNE`. :issue:`10593` and :issue:`10610` by","462","  `Tom Dupre la Tour`_.","463","","464","- |Feature| Support sparse input in :meth:`manifold.Isomap.fit`.","465","  :issue:`8554` by :user:`Leland McInnes <lmcinnes>`.","466","","467","- |Feature| :func:`manifold.t_sne.trustworthiness` accepts metrics other than","468","  Euclidean. :issue:`9775` by :user:`William de Vazelhes <wdevazelhes>`.","469","","470","- |API| |Feature| Deprecate ``precomputed`` parameter in function","471","  :func:`manifold.t_sne.trustworthiness`. Instead, the new parameter ``metric``","472","  should be used with any compatible metric including 'precomputed', in which","473","  case the input matrix ``X`` should be a matrix of pairwise distances or","474","  squared distances.  :issue:`9775` by :user:`William de Vazelhes","475","  <wdevazelhes>`.","476","","477","- |API| Deprecate ``precomputed`` parameter in function","478","  :func:`manifold.t_sne.trustworthiness`. Instead, the new parameter","479","  ``metric`` should be used with any compatible metric including","480","  'precomputed', in which case the input matrix ``X`` should be a matrix of","481","  pairwise distances or squared distances. :issue:`9775` by","482","  :user:`William de Vazelhes <wdevazelhes>`.","483","","484",".. rubric:: :mod:`sklearn.metrics`:","485","","486","- |MajorFeature| Added the :func:`metrics.davies_bouldin_score` metric for","487","  evaluation of clustering models without a ground truth.  :issue:`10827` by","488","  :user:`Luis Osa <logc>`.","489","","490","- |MajorFeature| Added the :func:`metrics.balanced_accuracy_score` metric and","491","  a corresponding ``'balanced_accuracy'`` scorer for binary and multiclass","492","  classification.  :issue:`8066` by :user:`xyguo` and :user:`Aman Dalmia","493","  <dalmia>`, and :issue:`10587` by `Joel Nothman`_.","494","","495","- |Feature| Partial AUC is available via ``max_fpr`` parameter in","499","- |Feature| A scorer based on :func:`metrics.brier_score_loss` is also","500","  available.  :issue:`9521` by :user:`Hanmin Qin <qinhanmin2014>`.","501","","502","- |Feature| Added control over the normalization in","508","","509","- |Feature| Added ``output_dict`` parameter in :func:`metrics.classification_report`","513","- |Feature| :func:`metrics.average_precision_score` now supports binary","514","  ``y_true`` other than ``{0, 1}`` or ``{-1, 1}`` through ``pos_label``","515","  parameter.  :issue:`9980` by :user:`Hanmin Qin <qinhanmin2014>`.","517","- |Feature| :func:`metrics.label_ranking_average_precision_score` now supports","518","  ``sample_weight``.","519","  :issue:`10845` by :user:`Jose Perez-Parras Toledano <jopepato>`.","521","- |Feature| Add ``dense_output`` parameter to :func:`metrics.pairwise.linear_kernel`.","522","  When False and both inputs are sparse, will return a sparse matrix.","523","  :issue:`10999` by :user:`Taylor G Smith <tgsmith61591>`.","525","- |Efficiency| :func:`metrics.cluster.silhouette_score` and","526","  :func:`metrics.cluster.silhouette_samples` are more memory efficient and run","527","  faster. This avoids some reported freezes and MemoryErrors.","528","  :issue:`11135` by `Joel Nothman`_.","530","- |Fix| Fixed a bug in :func:`metrics.precision_recall_fscore_support`","531","  when truncated `range(n_labels)` is passed as value for `labels`.","532","  :issue:`10377` by :user:`Gaurav Dhingra <gxyd>`.","534","- |Fix| Fixed a bug due to floating point error in","535","  :func:`metrics.roc_auc_score` with non-integer sample weights. :issue:`9786`","536","  by :user:`Hanmin Qin <qinhanmin2014>`.","538","- |Fix| Fixed a bug where :func:`metrics.roc_curve` sometimes starts on y-axis","539","  instead of (0, 0), which is inconsistent with the document and other","540","  implementations.  Note that this will not influence the result from","541","  :func:`metrics.roc_auc_score` :issue:`10093` by :user:`alexryndin","542","  <alexryndin>` and :user:`Hanmin Qin <qinhanmin2014>`.","544","- |Fix| Fixed a bug to avoid integer overflow. Casted product to 64 bits integer in","545","  :func:`metrics.mutual_info_score`.","546","  :issue:`9772` by :user:`Kumar Ashutosh <thechargedneutron>`.","548","- |Fix| Fixed a bug where :func:`metrics.average_precision_score` will sometimes return","549","  ``nan`` when ``sample_weight`` contains 0.","550","  :issue:`9980` by :user:`Hanmin Qin <qinhanmin2014>`.","552","- |Fix| Fixed a bug in :func:`metrics.fowlkes_mallows_score` to avoid integer","553","  overflow. Casted return value of `contingency_matrix` to `int64` and computed","554","  product of square roots rather than square root of product.","555","  :issue:`9515` by :user:`Alan Liddell <aliddell>` and","556","  :user:`Manh Dao <manhdao>`.","557","","558","- |API| Deprecate ``reorder`` parameter in :func:`metrics.auc` as it's no","559","  longer required for :func:`metrics.roc_auc_score`. Moreover using","560","  ``reorder=True`` can hide bugs due to floating point error in the input.","561","  :issue:`9851` by :user:`Hanmin Qin <qinhanmin2014>`.","562","","563","- |API| In :func:`metrics.normalized_mutual_information_score` and","564","  :func:`metrics.adjusted_mutual_information_score`, warn that","565","  ``average_method`` will have a new default value. In version 0.22, the","566","  default normalizer for each will become the *arithmetic* mean of the","567","  entropies of each clustering. Currently,","568","  :func:`metrics.normalized_mutual_information_score` uses the default of","569","  ``average_method='geometric'``, and","570","  :func:`metrics.adjusted_mutual_information_score` uses the default of","571","  ``average_method='max'`` to match their behaviors in version 0.19.","572","  :issue:`11124` by :user:`Arya McCarthy <aryamccarthy>`.","573","","574","- |API| The ``batch_size`` parameter to :func:`metrics.pairwise_distances_argmin_min`","575","  and :func:`metrics.pairwise_distances_argmin` is deprecated to be removed in","576","  v0.22.  It no longer has any effect, as batch size is determined by global","577","  ``working_memory`` config. See :ref:`working_memory`. :issue:`10280` by `Joel","578","  Nothman`_ and :user:`Aman Dalmia <dalmia>`.","579","","580",".. rubric:: :mod:`sklearn.mixture`:","581","","582","- |Feature| Added function :term:`fit_predict` to :class:`mixture.GaussianMixture`","583","  and :class:`mixture.GaussianMixture`, which is essentially equivalent to","584","  calling :term:`fit` and :term:`predict`. :issue:`10336` by :user:`Shu Haoran","585","  <haoranShu>` and :user:`Andrew Peng <Andrew-peng>`.","586","","587","- |Fix| Fixed a bug in :class:`mixture.BaseMixture` where the reported `n_iter_` was","588","  missing an iteration. It affected :class:`mixture.GaussianMixture` and","589","  :class:`mixture.BayesianGaussianMixture`. :issue:`10740` by :user:`Erich","590","  Schubert <kno10>` and :user:`Guillaume Lemaitre <glemaitre>`.","591","","592","- |Fix| Fixed a bug in :class:`mixture.BaseMixture` and its subclasses","593","  :class:`mixture.GaussianMixture` and :class:`mixture.BayesianGaussianMixture`","594","  where the ``lower_bound_`` was not the max lower bound across all","595","  initializations (when ``n_init > 1``), but just the lower bound of the last","596","  initialization. :issue:`10869` by :user:`Aurlien Gron <ageron>`.","597","","598",".. rubric:: :mod:`sklearn.model_selection`:","599","","600","- |Feature| Add `return_estimator` parameter in","601","  :func:`model_selection.cross_validate` to return estimators fitted on each","602","  split.  :issue:`9686` by :user:`Aurlien Bellet <bellet>`.","603","","604","- |Feature| New ``refit_time_`` attribute will be stored in","605","  :class:`model_selection.GridSearchCV` and","606","  :class:`model_selection.RandomizedSearchCV` if ``refit`` is set to ``True``.","607","  This will allow measuring the complete time it takes to perform","608","  hyperparameter optimization and refitting the best model on the whole","609","  dataset. :issue:`11310` by :user:`Matthias Feurer <mfeurer>`.","610","","611","- |Feature| Expose `error_score` parameter in","612","  :func:`model_selection.cross_validate`,","613","  :func:`model_selection.cross_val_score`,","614","  :func:`model_selection.learning_curve` and","615","  :func:`model_selection.validation_curve` to control the behavior triggered","616","  when an error occurs in :func:`model_selection._fit_and_score`.","617","  :issue:`11576` by :user:`Samuel O. Ronsin <samronsin>`.","618","","619","- |Feature| `BaseSearchCV` now has an experimental, private interface to","620","  support customized parameter search strategies, through its ``_run_search``","621","  method.  See the implementations in :class:`model_selection.GridSearchCV` and","622","  :class:`model_selection.RandomizedSearchCV` and please provide feedback if","623","  you use this. Note that we do not assure the stability of this API beyond","624","  version 0.20. :issue:`9599` by `Joel Nothman`_","625","","626","- |Enhancement| Add improved error message in","627","  :func:`model_selection.cross_val_score` when multiple metrics are passed in","628","  ``scoring`` keyword.  :issue:`11006` by :user:`Ming Li <minggli>`.","629","","630","- |API| The default number of cross-validation folds ``cv`` and the default","631","  number of splits ``n_splits`` in the :class:`model_selection.KFold`-like","632","  splitters will change from 3 to 5 in 0.22 as 3-fold has a lot of variance.","633","  :issue:`11557` by :user:`Alexandre Boucaud <aboucaud>`.","634","","635","- |API| The default of ``iid`` parameter of :class:`model_selection.GridSearchCV`","636","  and :class:`model_selection.RandomizedSearchCV` will change from ``True`` to","637","  ``False`` in version 0.22 to correspond to the standard definition of","638","  cross-validation, and the parameter will be removed in version 0.24","639","  altogether. This parameter is of greatest practical significance where the","640","  sizes of different test sets in cross-validation were very unequal, i.e. in","641","  group-based CV strategies. :issue:`9085` by :user:`Laurent Direr <ldirer>`","642","  and `Andreas Mller`_.","643","","644","- |API| Changed ValueError exception raised in","645","  :class:`model_selection.ParameterSampler` to a UserWarning for case where the","646","  class is instantiated with a greater value of ``n_iter`` than the total space","647","  of parameters in the parameter grid. ``n_iter`` now acts as an upper bound on","648","  iterations.  :issue:`#10982` by :user:`Juliet Lawton <julietcl>`","649","","650","- |API| Invalid input for :class:`model_selection.ParameterGrid` now","651","  raises TypeError.","652","  :issue:`10928` by :user:`Solutus Immensus <solutusimmensus>`","653","","654",".. rubric:: :mod:`sklearn.multioutput`:","655","","656","- |MajorFeature| Added :class:`multioutput.RegressorChain` for multi-target","657","  regression. :issue:`9257` by :user:`Kumar Ashutosh <thechargedneutron>`.","658","","659",".. rubric:: :mod:`sklearn.naive_bayes`:","660","","661","- |MajorFeature| Added :class:`naive_bayes.ComplementNB`, which implements the","662","  Complement Naive Bayes classifier described in Rennie et al. (2003).","663","  :issue:`8190` by :user:`Michael A. Alcorn <airalcorn2>`.","664","","665","- |Feature| Add `var_smoothing` parameter in :class:`naive_bayes.GaussianNB`","666","  to give a precise control over variances calculation.","667","  :issue:`9681` by :user:`Dmitry Mottl <Mottl>`.","668","","669","- |Fix| Fixed a bug in :class:`naive_bayes.GaussianNB` which incorrectly","670","  raised error for prior list which summed to 1.","671","  :issue:`10005` by :user:`Gaurav Dhingra <gxyd>`.","672","","673","- |Fix| Fixed a bug in :class:`naive_bayes.MultinomialNB` which did not accept","674","  vector valued pseudocounts (alpha).","675","  :issue:`10346` by :user:`Tobias Madsen <TobiasMadsen>`","676","","677",".. rubric:: :mod:`sklearn.neighbors`:","678","","679","- |Efficiency| :class:`neighbors.RadiusNeighborsRegressor` and","680","  :class:`neighbors.RadiusNeighborsClassifier` are now","681","  parallelized according to ``n_jobs`` regardless of ``algorithm``.","682","  :issue:`8003` by :user:`Jo?l Billaud <recamshak>`.","683","","684","- |Efficiency| :mod:`Nearest neighbors <neighbors>` query methods are now more","685","  memory efficient when ``algorithm='brute'``.","686","  :issue:`11136` by `Joel Nothman`_ and :user:`Aman Dalmia <dalmia>`.","687","","688","- |Feature| Add `sample_weight` parameter to the fit method of","689","  :class:`neighbors.KernelDensity` to enable weighting in kernel density","690","  estimation.","691","  :issue:`4394` by :user:`Samuel O. Ronsin <samronsin>`.","692","","693","- |Feature| Novelty detection with :class:`neighbors.LocalOutlierFactor`:","694","  Add a ``novelty`` parameter to :class:`neighbors.LocalOutlierFactor`. When","695","  ``novelty`` is set to True, :class:`neighbors.LocalOutlierFactor` can then ","696","  be used for novelty detection, i.e. predict on new unseen data. Available","697","  prediction methods are ``predict``, ``decision_function`` and","698","  ``score_samples``. By default, ``novelty`` is set to ``False``, and only","699","  the ``fit_predict`` method is avaiable.","700","  By :user:`Albert Thomas <albertcthomas>`.","701","","702","- |Fix| Fixed a bug in :class:`neighbors.NearestNeighbors` where fitting a","703","  NearestNeighbors model fails when a) the distance metric used is a","704","  callable and b) the input to the NearestNeighbors model is sparse.","705","  :issue:`9579` by :user:`Thomas Kober <tttthomasssss>`.","706","","707","- |Fix| Fixed a bug so ``predict`` in","708","  :class:`neighbors.RadiusNeighborsRegressor` can handle empty neighbor set","709","  when using non uniform weights. Also raises a new warning when no neighbors","710","  are found for samples.  :issue:`9655` by :user:`Andreas Bjerre-Nielsen","711","  <abjer>`.","712","","713","- |Fix| |Efficiency| Fixed a bug in ``KDTree`` construction that results in","714","  faster construction and querying times.","715","  :issue:`11556` by :user:`Jake VanderPlas <jakevdp>`","716","","717",".. rubric:: :mod:`sklearn.neural_network`:","718","","719","- |Feature| Add `n_iter_no_change` parameter in","726","- |Fix| Fixed a bug in :class:`neural_network.BaseMultilayerPerceptron`,","727","  :class:`neural_network.MLPRegressor`, and","728","  :class:`neural_network.MLPClassifier` with new ``n_iter_no_change``","729","  parameter now at 10 from previously hardcoded 2.","730","  :issue:`9456` by :user:`Nicholas Nadeau <nnadeau>`.","732","- |Fix| Fixed a bug in :class:`neural_network.MLPRegressor` where fitting","733","  quit unexpectedly early due to local minima or fluctuations.","734","  :issue:`9456` by :user:`Nicholas Nadeau <nnadeau>`","736",".. rubric:: :mod:`sklearn.pipeline`:","738","- |Feature| The ``predict`` method of :class:`pipeline.Pipeline` now passes","739","  keyword arguments on to the pipeline's last estimator, enabling the use of","740","  parameters such as ``return_std`` in a pipeline with caution.","741","  :issue:`9304` by :user:`Breno Freitas <brenolf>`.","743",".. rubric:: :mod:`sklearn.preprocessing`:","745","- |MajorFeature| Expanded :class:`preprocessing.OneHotEncoder` to allow to","746","  encode categorical string features as a numeric array using a one-hot (or","747","  dummy) encoding scheme, and added :class:`preprocessing.OrdinalEncoder` to","748","  convert to ordinal integers.  Those two classes now handle encoding of all","749","  feature types (also handles string-valued features) and derives the","750","  categories based on the unique values in the features instead of the maximum","751","  value in the features. :issue:`9151` and :issue:`10521` by :user:`Vighnesh","752","  Birodkar <vighneshbirodkar>` and `Joris Van den Bossche`_.","754","- |MajorFeature| Added :class:`preprocessing.KBinsDiscretizer` for turning","755","  continuous features into categorical or one-hot encoded","756","  features. :issue:`7668`, :issue:`9647`, :issue:`10195`,","757","  :issue:`10192`, :issue:`11272`, :issue:`11467` and :issue:`11505`.","758","  by :user:`Henry Lin <hlin117>`, `Hanmin Qin`_,","759","  `Tom Dupre la Tour`_ and :user:`Giovanni Giuseppe Costa <ggc87>`.","761","- |MajorFeature| Added :class:`preprocessing.PowerTransformer`, which","762","  implements the Yeo-Johnson and Box-Cox power transformations. Power","763","  transformations try to find a set of feature-wise parametric transformations","764","  to approximately map data to a Gaussian distribution centered at zero and","765","  with unit variance.  This is useful as a variance-stabilizing transformation","766","  in situations where normality and homoscedasticity are desirable.","767","  :issue:`10210` by :user:`Eric Chang <ericchang00>` and :user:`Maniteja","768","  Nandana <maniteja123>`, and :issue:`11520` by :user:`Nicolas Hug","769","  <nicolashug>`.","771","- |MajorFeature| NaN values are ignored and handled in the following","772","  preprocessing methods:","790","- |Feature| :class:`preprocessing.PolynomialFeatures` now supports sparse","791","  input.  :issue:`10452` by :user:`Aman Dalmia <dalmia>` and `Joel Nothman`_.","792","","793","- |Feature| :class:`preprocessing.RobustScaler` and","794","  :func:`preprocessing.robust_scale` can be fitted using sparse matrices.","797","- |Feature| :class:`preprocessing.OneHotEncoder` now supports the","798","  :term:`get_feature_names` method to obtain the transformed feature names.","799","  :issue:`10181` by  :user:`Nirvan Anjirbag <Nirvan101>` and","800","  `Joris Van den Bossche`_.","802","- |Feature| A parameter ``check_inverse`` was added to","803","  :class:`preprocessing.FunctionTransformer` to ensure that ``func`` and","804","  ``inverse_func`` are the inverse of each other.","805","  :issue:`9399` by :user:`Guillaume Lemaitre <glemaitre>`.","807","- |Feature| The ``transform`` method of :class:`sklearn.preprocessing.MultiLabelBinarizer`","808","  now ignores any unknown classes. A warning is raised stating the unknown classes","809","  classes found which are ignored.","810","  :issue:`10913` by :user:`Rodrigo Agundez <rragundez>`.","812","- |Fix| Fixed bugs in :class:`preprocessing.LabelEncoder` which would","813","  sometimes throw errors when ``transform`` or ``inverse_transform`` was called","814","  with empty arrays.  :issue:`10458` by :user:`Mayur Kulkarni <maykulkarni>`.","816","- |Fix| Fix ValueError in :class:`preprocessing.LabelEncoder` when using","820","- |Fix| Fix bug in :class:`preprocessing.OneHotEncoder` which discarded the","821","  ``dtype`` when returning a sparse matrix output.","822","  :issue:`11042` by :user:`Daniel Morales <DanielMorales9>`.","824","- |Fix| Fix ``fit`` and ``partial_fit`` in","825","  :class:`preprocessing.StandardScaler` in the rare case when `with_mean=False`","826","  and `with_std=False` which was crashing by calling ``fit`` more than once and","827","  giving inconsistent results for ``mean_`` whether the input was a sparse or a","828","  dense matrix. ``mean_`` will be set to ``None`` with both sparse and dense","829","  inputs. ``n_samples_seen_`` will be also reported for both input types.","832","- |API| Deprecate ``n_values`` and ``categorical_features`` parameters and","841","- |API| Deprecate :class:`preprocessing.Imputer` and move","842","  the corresponding module to :class:`impute.SimpleImputer`.","843","  :issue:`9726` by :user:`Kumar Ashutosh","846"," - The ``axis`` parameter that was in","847","   :class:`preprocessing.Imputer` is no longer present in","848","   :class:`impute.SimpleImputer`. The behavior is equivalent","849","   to ``axis=0`` (impute along columns).  Row-wise","850","   imputation can be performed with FunctionTransformer","851","   (e.g., ``FunctionTransformer(lambda X:","852","   SimpleImputer().fit_transform(X.T).T)``).  :issue:`10829`","853","   by :user:`Guillaume Lemaitre <glemaitre>` and","854","   :user:`Gilberto Olimpio <gilbertoolimpio>`.","856"," - The NaN marker for the missing values has been changed","857","   between the :class:`preprocessing.Imputer` and the","858","   :class:`impute.SimpleImputer`.","859","   ``missing_values='NaN'``?should now be","860","   ``missing_values=np.nan``.  :issue:`11211` by","861","   :user:`Jeremie du Boisberranger <jeremiedbb>`.","863","- |API| In :class:`preprocessing.FunctionTransformer`, the default of","864","  ``validate`` will be from ``True`` to ``False`` in 0.22.","865","  :issue:`10655` by :user:`Guillaume Lemaitre <glemaitre>`.","867",".. rubric:: :mod:`sklearn.svm`:","869","- |Fix| Fixed a bug in :class:`svm.SVC` where when the argument ``kernel`` is","870","  unicode in Python2, the ``predict_proba`` method was raising an","871","  unexpected TypeError given dense inputs.","872","  :issue:`10412` by :user:`Jiongyan Zhang <qmick>`.","874","- |API| Deprecate ``random_state`` parameter in :class:`svm.OneClassSVM` as","875","  the underlying implementation is not random.","876","  :issue:`9497` by :user:`Albert Thomas <albertcthomas>`.","878","- |API| The default value of ``gamma`` parameter of :class:`svm.SVC`,","879","  :class:`~svm.NuSVC`, :class:`~svm.SVR`, :class:`~svm.NuSVR`,","880","  :class:`~svm.OneClassSVM` will change from ``'auto'`` to ``'scale'`` in","881","  version 0.22 to account better for unscaled features. :issue:`8361` by","882","  :user:`Gaurav Dhingra <gxyd>` and :user:`Ting Neo <neokt>`.","884",".. rubric:: :mod:`sklearn.tree`:","886","- |Fix| Fixed a bug in :class:`tree.BaseDecisionTree` with `splitter=\"best\"`","887","  where split threshold could become infinite when values in X were","888","  near infinite. :issue:`10536` by :user:`Jonathan Ohayon <Johayon>`.","889","","890","- |Fix| Fixed a bug in :class:`tree.MAE` to ensure sample weights are being","891","  used during the calculation of tree MAE impurity. Previous behaviour could","892","  cause suboptimal splits to be chosen since the impurity calculation","893","  considered all samples to be of equal weight importance.","894","  :issue:`11464` by :user:`John Stott <JohnStott>`.","895","","896",".. rubric:: :mod:`sklearn.utils`:","897","","898","- |Feature| :func:`utils.check_array` and :func:`utils.check_X_y` now have","899","  ``accept_large_sparse`` to control whether scipy.sparse matrices with 64-bit","900","  indices should be rejected.","901","  :issue:`11327` by :user:`Karan Dhingra <kdhingra307>` and `Joel Nothman`_.","902","","903","- |Efficiency| |Fix| Avoid copying the data in :func:`utils.check_array` when","904","  the input data is a memmap (and ``copy=False``).  :issue:`10663` by","905","  :user:`Arthur Mensch <arthurmensch>` and :user:`Lo?c Estve <lesteve>`.","906","","907","- |API| :func:`utils.check_array` yield a ``FutureWarning`` indicating","908","  that arrays of bytes\/strings will be interpreted as decimal numbers","909","  beginning in version 0.22. :issue:`10229` by :user:`Ryan Lee <rtlee9>`","910","","911",".. rubric:: Multiple modules","912","","913","- |Feature| |API| More consistent outlier detection API:","940","- |API| Added convergence warning to :class:`svm.LinearSVC` and","941","  :class:`linear_model.LogisticRegression` when ``verbose`` is set to 0.","942","  :issue:`10881` by :user:`Alexandre Sevin <AlexandreSev>`.","944","- |API| Changed warning type from :class:`UserWarning` to","954",".. rubric:: Miscellaneous","956","- |MajorFeature| A new configuration parameter, ``working_memory`` was added","957","  to control memory consumption limits in chunked operations, such as the new","958","  :func:`metrics.pairwise_distances_chunked`.  See :ref:`working_memory`.","959","  :issue:`10280` by `Joel Nothman`_ and :user:`Aman Dalmia <dalmia>`.","961","- |Feature| Add almost complete PyPy 3 support. Known unsupported","962","  functionalities are :func:`datasets.load_svmlight_file`,","963","  :class:`feature_extraction.FeatureHasher` and","964","  :class:`feature_extraction.text.HashingVectorizer`.  For running on PyPy,","965","  PyPy3-v5.10+, Numpy 1.14.0+, and scipy 1.1.0+ are required.","966","  :issue:`11010` by :user:`Ronan Lamy <rlamy>` and `Roman Yurchak`_.","968","- |Feature| An environment variable to use the site joblib instead of the","969","  vendored one was added (:ref:`environment_variable`). The main API of joblib","970","  is now exposed in :mod:`sklearn.utils`.","971","  :issue:`11166`by `Gael Varoquaux`_.","973","- |Feature| A utility method :func:`sklearn.show_versions()` was added to","974","  print out information relevant for debugging. It includes the user system,","975","  the Python executable, the version of the main libraries and BLAS binding","976","  information.  :issue:`11596` by :user:`Alexandre Boucaud <aboucaud>`","978","- |Fix| Fixed a bug when setting parameters on meta-estimator, involving both","979","  a wrapped estimator and its parameter. :issue:`9999` by :user:`Marcus Voss","980","  <marcus-voss>` and `Joel Nothman`_."],"delete":["64","- :class:`metrics.roc_auc_score` (bug fix)","65","- :class:`metrics.roc_curve` (bug fix)","66","- :class:`neural_network.BaseMultilayerPerceptron` (bug fix)","67","- :class:`neural_network.MLPRegressor` (bug fix)","68","- :class:`neural_network.MLPClassifier` (bug fix)","69","- :class:`linear_model.SGDClassifier` (bug fix)","70","- :class:`linear_model.SGDRegressor` (bug fix)","74","- :class:`ensemble.gradient_boosting.GradientBoostingClassifier` (bug fix affecting feature importances)","75","- :class:`linear_model.LogisticRegressionCV` (bug fix)","79","- :class:`decomposition.SparsePCA` (bug fix)","91","New features","92","............","94","Classifiers and regressors","96","- :class:`ensemble.GradientBoostingClassifier` and","101","- :class:`dummy.DummyRegressor` now has a ``return_std`` option in its","102","  ``predict`` method. The returned standard deviations will be zeros.","104","- Added :class:`multioutput.RegressorChain` for multi-target","105","  regression. :issue:`9257` by :user:`Kumar Ashutosh <thechargedneutron>`.","106","","107","- Added :class:`naive_bayes.ComplementNB`, which implements the Complement","108","  Naive Bayes classifier described in Rennie et al. (2003).","109","  :issue:`8190` by :user:`Michael A. Alcorn <airalcorn2>`.","110","","111","- :class:`ensemble.BaggingRegressor` and :class:`ensemble.BaggingClassifier` can now","112","  be fit with missing\/non-finite values in X and\/or multi-output Y to support","113","  wrapping pipelines that perform their own imputation.","114","  :issue:`9707` by :user:`Jimmy Wan <jimmywan>`.","115","","116","Preprocessing","117","","118","- Expanded :class:`preprocessing.OneHotEncoder` to allow to encode","119","  categorical string features as a numeric array using a one-hot (or dummy)","120","  encoding scheme, and added :class:`preprocessing.OrdinalEncoder` to","121","  convert to ordinal integers.  Those two classes now handle","122","  encoding of all feature types (also handles string-valued features) and","123","  derives the categories based on the unique values in the features instead of","124","  the maximum value in the features. :issue:`9151` and :issue:`10521` by","125","  :user:`Vighnesh Birodkar <vighneshbirodkar>` and `Joris Van den Bossche`_.","126","","127","- Added :class:`preprocessing.KBinsDiscretizer` for turning","128","  continuous features into categorical or one-hot encoded","129","  features. :issue:`7668`, :issue:`9647`, :issue:`10195`,","130","  :issue:`10192`, :issue:`11272`, :issue:`11467` and :issue:`11505`.","131","  by :user:`Henry Lin <hlin117>`, `Hanmin Qin`_,","132","  `Tom Dupre la Tour`_ and :user:`Giovanni Giuseppe Costa <ggc87>`.","133","","134","- Added :class:`compose.ColumnTransformer`, which allows to apply","135","  different transformers to different columns of arrays or pandas","136","  DataFrames. :issue:`9012` by `Andreas Mller`_ and `Joris Van den Bossche`_,","137","  and :issue:`11315` by :user:`Thomas Fan <thomasjpfan>`.","138","","139","- Added :class:`preprocessing.PowerTransformer`, which implements the","140","  Yeo-Johnson and Box-Cox power transformations. Power transformations try to","141","  find a set of feature-wise parametric transformations to approximately map","142","  data to a Gaussian distribution centered at zero and with unit variance.","143","  This is useful as a variance-stabilizing transformation in situations where","144","  normality and homoscedasticity are desirable.","145","  :issue:`10210` by :user:`Eric Chang <ericchang00>` and","146","  :user:`Maniteja Nandana <maniteja123>`, and :issue:`11520` by :user:`Nicolas","147","  Hug <nicolashug>`.","148","","149","- Added the :class:`compose.TransformedTargetRegressor` which transforms","150","  the target y before fitting a regression model. The predictions are mapped","151","  back to the original space via an inverse transform. :issue:`9041` by","152","  `Andreas Mller`_ and :user:`Guillaume Lemaitre <glemaitre>`.","153","","154","- Added :class:`MissingIndicator` which generates a binary indicator for","155","  missing values. :issue:`8075` by :user:`Maniteja Nandana <maniteja123>` and","158","- :class:`linear_model.SGDClassifier`, :class:`linear_model.SGDRegressor`,","168","Model evaluation","170","- Added the :func:`metrics.davies_bouldin_score` metric for unsupervised","171","  evaluation of clustering models. :issue:`10827` by :user:`Luis Osa <logc>`.","173","- Added the :func:`metrics.balanced_accuracy_score` metric and a corresponding","174","  ``'balanced_accuracy'`` scorer for binary and multiclass classification.","175","  :issue:`8066` by :user:`xyguo` and :user:`Aman Dalmia <dalmia>`, and","176","  :issue:`10587` by `Joel Nothman`_.","178","Decomposition, manifold learning and clustering","180","- A new clustering algorithm: :class:`cluster.OPTICS`: an algoritm","181","  related to :class:`cluster.DBSCAN`, that has hyperparameters easier to","182","  set and tat scales better, by :user:`Shane <espg>`.","184","- :class:`cluster.AgglomerativeClustering` now supports Single Linkage","185","  clustering via ``linkage='single'``. :issue:`9372` by","186","  :user:`Leland McInnes <lmcinnes>` and :user:`Steve Astels <sastels>`.","188","- :class:`cluster.KMeans` and :class:`cluster.MiniBatchKMeans` now support","189","  sample weights via new parameter ``sample_weight`` in ``fit`` function.","190","  :issue:`10933` by :user:`Johannes Hansen <jnhansen>`.","192","- :mod:`dict_learning` functions and models now support positivity constraints.","193","  This applies to the dictionary and sparse code.","194","  :issue:`6374` by :user:`John Kirkham <jakirkham>`.","196","- :class:`decomposition.SparsePCA` now exposes ``normalize_components``. When","197","  set to True, the train and test data are centered with the train mean ","198","  repsectively during the fit phase and the transform phase. This fixes the","199","  behavior of SparsePCA. When set to False, which is the default, the previous","200","  abnormal behaviour still holds. The False value is for backward","201","  compatibility and should not be used.","202","  :issue:`11585` by :user:`Ivan Panico <FollowKenny>`.","204","Metrics","206","- Partial AUC is available via ``max_fpr`` parameter in","210","- Added control over the normalization in","216","- Added ``output_dict`` parameter in :func:`metrics.classification_report`","220","Misc","222","- A new configuration parameter, ``working_memory`` was added to control memory","223","  consumption limits in chunked operations, such as the new","224","  :func:`metrics.pairwise_distances_chunked`.  See :ref:`working_memory`.","225","  :issue:`10280` by `Joel Nothman`_ and :user:`Aman Dalmia <dalmia>`.","227","- An environment variable to use the site joblib instead of the vendored","228","  one was added (:ref:`environment_variable`). The main API of joblib is now","229","  exposed in :mod:`sklearn.utils`.","230","  :issue:`11166` by `Gael Varoquaux`_","232","- A utility method :func:`sklearn.show_versions()` was added to print out","233","  information relevant for debugging. It includes the user system, the","234","  Python executable, the version of the main libraries and BLAS binding","235","  information.","236","  :issue:`11596` by :user:`Alexandre Boucaud <aboucaud>`","238","Enhancements","239","............","241","Classifiers and regressors","243","- In :class:`gaussian_process.GaussianProcessRegressor`, method ``predict``","244","  is faster when using ``return_std=True`` in particular more when called","245","  several times in a row. :issue:`9234` by :user:`andrewww <andrewww>`","246","  and :user:`Minghui Liu <minghui-liu>`.","248","- Add `named_estimators_` parameter in","249","  :class:`ensemble.VotingClassifier` to access fitted","250","  estimators. :issue:`9157` by :user:`Herilalaina Rakotoarison <herilalaina>`.","252","- Add `var_smoothing` parameter in","253","  :class:`naive_bayes.GaussianNB` to give a precise control over","254","  variances calculation. :issue:`9681` by :user:`Dmitry Mottl <Mottl>`.","256","- Add `n_iter_no_change` parameter in","263","- A parameter ``check_inverse`` was added to","264","  :class:`preprocessing.FunctionTransformer` to ensure that ``func`` and","265","  ``inverse_func`` are the inverse of each other.","266","  :issue:`9399` by :user:`Guillaume Lemaitre <glemaitre>`.","268","- Add `sample_weight` parameter to the fit method of","269","  :class:`linear_model.BayesianRidge` for weighted linear regression.","270","  :issue:`10111` by :user:`Peter St. John <pstjohn>`.","272","- :class:`dummy.DummyClassifier` and :class:`dummy.DummyRegressor` now","273","  only require X to be an object with finite length or shape.","274","  :issue:`9832` by :user:`Vrishank Bhardwaj <vrishank97>`.","276","- Add `sample_weight` parameter to the fit method of","277","  :class:`neighbors.KernelDensity` to enables weighting in kernel density","278","  estimation.","279","  :issue:`4394` by :user:`Samuel O. Ronsin <samronsin>`.","281","- :class:`neighbors.RadiusNeighborsRegressor` and","282","  :class:`neighbors.RadiusNeighborsClassifier` are now","283","  parallelized according to ``n_jobs`` regardless of ``algorithm``.","284","  :issue:`8003` by :user:`Jo?l Billaud <recamshak>`.","286","- Memory usage improvement for :func:`_class_means` and :func:`_class_cov`","287","  in :class:`discriminant_analysis`.","288","  :issue:`10898` by :user:`Nanxin Chen <bobchennan>`.`","290","- :func:`manifold.t_sne.trustworthiness` accepts metrics other than","291","  Euclidean. :issue:`9775` by :user:`William de Vazelhes <wdevazelhes>`.","293","- :mod:`Nearest neighbors <neighbors>` query methods are now more memory","294","  efficient when ``algorithm='brute'``. :issue:`11136` by `Joel Nothman`_","295","  and :user:`Aman Dalmia <dalmia>`.","297","Cluster","298","","299","- :class:`cluster.KMeans`, :class:`cluster.MiniBatchKMeans` and","300","  :func:`cluster.k_means` passed with ``algorithm='full'`` now enforces","301","  row-major ordering, improving runtime.","302","  :issue:`10471` by :user:`Gaurav Dhingra <gxyd>`.","303","","304","- :class:`cluster.DBSCAN` now is parallelized according to ``n_jobs``","305","  regardless of ``algorithm``.","306","  :issue:`8003` by :user:`Jo?l Billaud <recamshak>`.","307","","308","Datasets","309","","310","- In :func:`datasets.make_blobs`, one can now pass a list to the `n_samples`","311","  parameter to indicate the number of samples to generate per cluster.","312","  :issue:`8617` by :user:`Maskani Filali Mohamed <maskani-moh>`","313","  and :user:`Konstantinos Katrioplas <kkatrio>`.","314","","315","Preprocessing","316","","317","- :class:`preprocessing.PolynomialFeatures` now supports sparse input.","318","  :issue:`10452` by :user:`Aman Dalmia <dalmia>` and `Joel Nothman`_.","319","","320","- Enable the call to :meth:`get_feature_names` in unfitted","321","  :class:`feature_extraction.text.CountVectorizer` initialized with a","322","  vocabulary. :issue:`10908` by :user:`Mohamed Maskani <maskani-moh>`.","323","","324","- :class:`preprocessing.OneHotEncoder` now supports the","325","  :meth:`get_feature_names` method to obtain the transformed feature names.","326","  :issue:`10181` by  :user:`Nirvan Anjirbag <Nirvan101>` and","327","  `Joris Van den Bossche`_.","328","","329","- The ``transform`` method of :class:`sklearn.preprocessing.MultiLabelBinarizer`","330","  now ignores any unknown classes. A warning is raised stating the unknown classes","331","  classes found which are ignored.","332","  :issue:`10913` by :user:`Rodrigo Agundez <rragundez>`.","333","","334","- NaN values are ignored and handled in the following preprocessing methods:","352","- :class:`preprocessing.RobustScaler` and :func:`preprocessing.robust_scale`","353","  can be fitted using sparse matrices.","356","Model evaluation and meta-estimators","358","- A scorer based on :func:`metrics.brier_score_loss` is also available.","359","  :issue:`9521` by :user:`Hanmin Qin <qinhanmin2014>`.","361","- The default of ``iid`` parameter of :class:`model_selection.GridSearchCV`","362","  and :class:`model_selection.RandomizedSearchCV` will change from ``True`` to","363","  ``False`` in version 0.22 to correspond to the standard definition of","364","  cross-validation, and the parameter will be removed in version 0.24","365","  altogether. This parameter is of greatest practical significance where the","366","  sizes of different test sets in cross-validation were very unequal, i.e. in","367","  group-based CV strategies. :issue:`9085` by :user:`Laurent Direr <ldirer>`","368","  and `Andreas Mller`_.","370","- The ``predict`` method of :class:`pipeline.Pipeline` now passes keyword","371","  arguments on to the pipeline's last estimator, enabling the use of parameters","372","  such as ``return_std`` in a pipeline with caution.","373","  :issue:`9304` by :user:`Breno Freitas <brenolf>`.","375","- Add `return_estimator` parameter in :func:`model_selection.cross_validate` to","376","  return estimators fitted on each split.","377","  :issue:`9686` by :user:`Aurlien Bellet <bellet>`.","378","","379","- New ``refit_time_`` attribute will be stored in","380","  :class:`model_selection.GridSearchCV` and","381","  :class:`model_selection.RandomizedSearchCV` if ``refit`` is set to ``True``.","382","  This will allow measuring the complete time it takes to perform","383","  hyperparameter optimization and refitting the best model on the whole","384","  dataset. :issue:`11310` by :user:`Matthias Feurer <mfeurer>`.","385","","386","- Expose `error_score` parameter in :func:`model_selection.cross_validate`,","387","  :func:`model_selection.cross_val_score`,","388","  :func:`model_selection.learning_curve` and","389","  :func:`model_selection.validation_curve` to control the behavior triggered","390","  when an error occurs in :func:`model_selection._fit_and_score`.","391","  :issue:`11576` by :user:`Samuel O. Ronsin <samronsin>`.","392","","393","- `BaseSearchCV` now has an experimental, private interface to support","394","  customized parameter search strategies, through its ``_run_search``","395","  method.  See the implementations in :class:`model_selection.GridSearchCV`","396","  and :class:`model_selection.RandomizedSearchCV` and please provide feedback","397","  if you use this. Note that we do not assure the stability of this API","398","  beyond version 0.20. :issue:`9599` by `Joel Nothman`_","399","","400","Decomposition and manifold learning","401","","402","- Speed improvements for both 'exact' and 'barnes_hut' methods in","403","  :class:`manifold.TSNE`. :issue:`10593` and :issue:`10610` by","404","  `Tom Dupre la Tour`_.","405","","406","- Support sparse input in :meth:`manifold.Isomap.fit`. :issue:`8554` by","407","  :user:`Leland McInnes <lmcinnes>`.","408","","409","Metrics","410","","411","- :func:`metrics.roc_auc_score` now supports binary ``y_true`` other than","412","  ``{0, 1}`` or ``{-1, 1}``.","413","  :issue:`9828` by :user:`Hanmin Qin <qinhanmin2014>`.","414","","415","- :func:`metrics.label_ranking_average_precision_score` now supports vector","416","  ``sample_weight``.","417","  :issue:`10845` by :user:`Jose Perez-Parras Toledano <jopepato>`.","418","","419","- Add ``dense_output`` parameter to :func:`metrics.pairwise.linear_kernel`.","420","  When False and both inputs are sparse, will return a sparse matrix.","421","  :issue:`10999` by :user:`Taylor G Smith <tgsmith61591>`.","422","","423","- :func:`metrics.cluster.silhouette_score` and","424","  :func:`metrics.cluster.silhouette_samples` are more memory efficient and run","425","  faster. This avoids some reported freezes and MemoryErrors.","426","  :issue:`11135` by `Joel Nothman`_.","427","","428","- :func:`metrics.average_precision_score` now supports binary ``y_true``","429","  other than ``{0, 1}`` or ``{-1, 1}`` through ``pos_label`` parameter.","430","  :issue:`9980` by :user:`Hanmin Qin <qinhanmin2014>`.","431","","432","Linear, kernelized and related models","433","","434","- Deprecate ``random_state`` parameter in :class:`svm.OneClassSVM` as the","435","  underlying implementation is not random.","436","  :issue:`9497` by :user:`Albert Thomas <albertcthomas>`.","437","","438","Preprocessing and feature selection","439","","440","- Added select K best features functionality to","441","  :class:`feature_selection.SelectFromModel`.","442","  :issue:`6689` by :user:`Nihar Sheth <nsheth12>` and","443","  :user:`Quazi Rahman <qmaruf>`.","444","","445","Decomposition, manifold learning and clustering","446","","447","- Deprecate ``precomputed`` parameter in function","448","  :func:`manifold.t_sne.trustworthiness`. Instead, the new parameter","449","  ``metric`` should be used with any compatible metric including","450","  'precomputed', in which case the input matrix ``X`` should be a matrix of","451","  pairwise distances or squared distances. :issue:`9775` by","452","  :user:`William de Vazelhes <wdevazelhes>`.","453","","454","Utils","455","","456","- Avoid copying the data in :func:`utils.check_array` when the input data is a","457","  memmap (and ``copy=False``). :issue:`10663` by :user:`Arthur Mensch","458","  <arthurmensch>` and :user:`Lo?c Estve <lesteve>`.","459","","460","Miscellaneous","461","","462","- Add ``filename`` attribute to datasets that have a CSV file.","463","  :issue:`9101` by :user:`alex-33 <alex-33>`","464","  and :user:`Maskani Filali Mohamed <maskani-moh>`.","465","","466","- Add almost complete PyPy 3 support. Known unsupported functionalities are","467","  :func:`datasets.load_svmlight_file`, :class:`feature_extraction.FeatureHasher` and","468","  :class:`feature_extraction.text.HashingVectorizer`.  For running on PyPy, PyPy3-v5.10+,","469","  Numpy 1.14.0+, and scipy 1.1.0+ are required.","470","  :issue:`11010` by :user:`Ronan Lamy <rlamy>` and `Roman Yurchak`_.","471","","472","Bug fixes","473",".........","474","","475","Classifiers and regressors","476","","477","- Fixed a bug in :class:`isotonic.IsotonicRegression` which incorrectly","478","  combined weights when fitting a model to data involving points with","479","  identical X values.","480","  :issue:`9432` by :user:`Dallas Card <dallascard>`","481","","482","- Fixed a bug in :class:`neural_network.BaseMultilayerPerceptron`,","483","  :class:`neural_network.MLPRegressor`, and","484","  :class:`neural_network.MLPClassifier` with new ``n_iter_no_change``","485","  parameter now at 10 from previously hardcoded 2.","486","  :issue:`9456` by :user:`Nicholas Nadeau <nnadeau>`.","487","","488","- Fixed a bug in :class:`neural_network.MLPRegressor` where fitting","489","  quit unexpectedly early due to local minima or fluctuations.","490","  :issue:`9456` by :user:`Nicholas Nadeau <nnadeau>`","491","","492","- Fixed a bug in :class:`naive_bayes.GaussianNB` which incorrectly raised","493","  error for prior list which summed to 1.","494","  :issue:`10005` by :user:`Gaurav Dhingra <gxyd>`.","495","","496","- Fixed a bug in :class:`linear_model.LogisticRegression` where when using the","497","  parameter ``multi_class='multinomial'``, the ``predict_proba`` method was","498","  returning incorrect probabilities in the case of binary outcomes.","499","  :issue:`9939` by :user:`Roger Westover <rwolst>`.","500","","501","- Fixed a bug in :class:`linear_model.LogisticRegressionCV` where the","502","  ``score`` method always computes accuracy, not the metric given by","503","  the ``scoring`` parameter.","504","  :issue:`10998` by :user:`Thomas Fan <thomasjpfan>`.","505","","506","- Fixed a bug in :class:`linear_model.LogisticRegressionCV` where the 'ovr'","507","  strategy was always used to compute cross-validation scores in the","508","  multiclass setting, even if 'multinomial' was set.","509","  :issue:`8720` by :user:`William de Vazelhes <wdevazelhes>`.","510","","511","- Fixed a bug in :class:`linear_model.OrthogonalMatchingPursuit` that was","512","  broken when setting ``normalize=False``.","513","  :issue:`10071` by `Alexandre Gramfort`_.","514","","515","- Fixed a bug in :class:`linear_model.ARDRegression` which caused incorrectly","516","  updated estimates for the standard deviation and the coefficients.","517","  :issue:`10153` by :user:`J?rg D?pfert <jdoepfert>`.","518","","519","- Fixed a bug when fitting :class:`ensemble.GradientBoostingClassifier` or","520","  :class:`ensemble.GradientBoostingRegressor` with ``warm_start=True`` which","521","  previously raised a segmentation fault due to a non-conversion of CSC matrix","522","  into CSR format expected by ``decision_function``. Similarly, Fortran-ordered","523","  arrays are converted to C-ordered arrays in the dense case. :issue:`9991` by","524","  :user:`Guillaume Lemaitre <glemaitre>`.","525","","526","- Fixed a bug in :class:`neighbors.NearestNeighbors` where fitting a","527","  NearestNeighbors model fails when a) the distance metric used is a","528","  callable and b) the input to the NearestNeighbors model is sparse.","529","  :issue:`9579` by :user:`Thomas Kober <tttthomasssss>`.","530","","531","- Fixed a bug in :class:`linear_model.RidgeClassifierCV` where","532","  the parameter ``store_cv_values`` was not implemented though","533","  it was documented in ``cv_values`` as a way to set up the storage","534","  of cross-validation values for different alphas. :issue:`10297` by","535","  :user:`Mabel Villalba-Jimnez <mabelvj>`.","536","","537","- Fixed a bug in :class:`naive_bayes.MultinomialNB` which did not accept vector","538","  valued pseudocounts (alpha).","539","  :issue:`10346` by :user:`Tobias Madsen <TobiasMadsen>`","540","","541","- Fixed a bug in :class:`svm.SVC` where when the argument ``kernel`` is","542","  unicode in Python2, the ``predict_proba`` method was raising an","543","  unexpected TypeError given dense inputs.","544","  :issue:`10412` by :user:`Jiongyan Zhang <qmick>`.","545","","546","- Fixed a bug in :class:`tree.BaseDecisionTree` with `splitter=\"best\"`","547","  where split threshold could become infinite when values in X were","548","  near infinite. :issue:`10536` by :user:`Jonathan Ohayon <Johayon>`.","549","","550","- Fixed a bug in :class:`linear_model.ElasticNet` which caused the input to be","551","  overridden when using parameter ``copy_X=True`` and ``check_input=False``.","552","  :issue:`10581` by :user:`Yacine Mazari <ymazari>`.","553","","554","- Fixed a bug in :class:`sklearn.linear_model.Lasso`","555","  where the coefficient had wrong shape when ``fit_intercept=False``.","556","  :issue:`10687` by :user:`Martin Hahn <martin-hahn>`.","557","","558","- Fixed a bug in :func:`sklearn.linear_model.LogisticRegression` where the","559","  multi_class='multinomial' with binary output with warm_start = True","560","  :issue:`10836` by :user:`Aishwarya Srinivasan <aishgrt1>`.","561","","562","- Fixed a bug in :class:`linear_model.RidgeCV` where using integer ``alphas``","563","  raised an error. :issue:`10393` by :user:`Mabel Villalba-Jimnez <mabelvj>`.","564","","565","- Fixed condition triggering gap computation in :class:`linear_model.Lasso`","566","  and :class:`linear_model.ElasticNet` when working with sparse matrices.","567","  :issue:`10992` by `Alexandre Gramfort`_.","568","","569","- Fixed a bug in :class:`linear_model.SGDClassifier`,","570","  :class:`linear_model.SGDRegressor`,","571","  :class:`linear_model.PassiveAggressiveClassifier`,","572","  :class:`linear_model.PassiveAggressiveRegressor` and","573","  :class:`linear_model.Perceptron`, where the stopping criterion was stopping","574","  the algorithm before convergence. A parameter `n_iter_no_change` was added","575","  and set by default to 5. Previous behavior is equivalent to setting the","576","  parameter to 1. :issue:`9043` by `Tom Dupre la Tour`_.","577","","578","- Fixed a bug where liblinear and libsvm-based estimators would segfault if","579","  passed a scipy.sparse matrix with 64-bit indices. They now raise a","580","  ValueError.","581","  :issue:`11327` by :user:`Karan Dhingra <kdhingra307>` and `Joel Nothman`_.","582","","583","- Fixed a bug in :class:`ensemble.gradient_boosting.GradientBoostingRegressor`","584","  and :class:`ensemble.gradient_boosting.GradientBoostingClassifier` to have","585","  feature importances summed and then normalized, rather than normalizing on a","586","  per-tree basis. The previous behavior over-weighted the Gini importance of","587","  features that appear in later stages. This issue only affected feature","588","  importances. :issue:`11176` by :user:`Gil Forsyth <gforsyth>`.","589","","590","- Fixed a bug in :class:`tree.MAE` to ensure sample weights are being used","591","  during the calculation of tree MAE impurity. Previous behaviour could","592","  cause suboptimal splits to be chosen since the impurity calculation","593","  considered all samples to be of equal weight importance.","594","  :issue:`11464` by :user:`John Stott <JohnStott>`.","595","","596","- Fixed a bug in :func:`logistic.logistic_regression_path` to ensure that the","597","  returned coefficients are correct when ``multiclass='multinomial'``.","598","  Previously, some of the coefficients would override each other, leading to","599","  incorrect results in :class:`logistic.LogisticRegressionCV`. :issue:`11724`","600","  by :user:`Nicolas Hug <NicolasHug>`.","601","","602","Decomposition, manifold learning and clustering","603","","604","- Fix for uninformative error in :class:`decomposition.IncrementalPCA`:","605","  now an error is raised if the number of components is larger than the","606","  chosen batch size. The ``n_components=None`` case was adapted accordingly.","607","  :issue:`6452`. By :user:`Wally Gauze <wallygauze>`.","608","","609","- Fixed a bug where the ``partial_fit`` method of","610","  :class:`decomposition.IncrementalPCA` used integer division instead of float","611","  division on Python 2 versions. :issue:`9492` by","612","  :user:`James Bourbeau <jrbourbeau>`.","613","","614","- Fixed a bug where the ``fit`` method of","615","  :class:`cluster.AffinityPropagation` stored cluster","616","  centers as 3d array instead of 2d array in case of non-convergence. For the","617","  same class, fixed undefined and arbitrary behavior in case of training data","618","  where all samples had equal similarity.","619","  :issue:`9612`. By :user:`Jonatan Samoocha <jsamoocha>`.","620","","621","- In :class:`decomposition.PCA` selecting a n_components parameter greater than","622","  the number of samples now raises an error.","623","  Similarly, the ``n_components=None`` case now selects the minimum of","624","  n_samples and n_features. :issue:`8484`. By :user:`Wally Gauze <wallygauze>`.","625","","626","- Fixed a bug in :func:`datasets.fetch_kddcup99`, where data were not properly","627","  shuffled. :issue:`9731` by `Nicolas Goix`_.","628","","629","- Fixed a bug in :class:`decomposition.PCA` where users will get unexpected error","630","  with large datasets when ``n_components='mle'`` on Python 3 versions.","631","  :issue:`9886` by :user:`Hanmin Qin <qinhanmin2014>`.","632","","633","- Fixed a bug when setting parameters on meta-estimator, involving both a","634","  wrapped estimator and its parameter. :issue:`9999` by :user:`Marcus Voss","635","  <marcus-voss>` and `Joel Nothman`_.","636","","637","- ``k_means`` now gives a warning, if the number of distinct clusters found","638","  is smaller than ``n_clusters``. This may occur when the number of distinct","639","  points in the data set is actually smaller than the number of cluster one is","640","  looking for. :issue:`10059` by :user:`Christian Braune <christianbraune79>`.","641","","642","- Fixed a bug in :func:`datasets.make_circles`, where no odd number of data","643","  points could be generated. :issue:`10037`","644","  by :user:`Christian Braune <christianbraune79>`.","645","","646","- Fixed a bug in :func:`cluster.spectral_clustering` where the normalization of","647","  the spectrum was using a division instead of a multiplication. :issue:`8129`","648","  by :user:`Jan Margeta <jmargeta>`, :user:`Guillaume Lemaitre <glemaitre>`,","649","  and :user:`Devansh D. <devanshdalal>`.","650","","651","- Fixed a bug in :class:`mixture.BaseMixture` where the reported `n_iter_` was","652","  missing an iteration. It affected :class:`mixture.GaussianMixture` and","653","  :class:`mixture.BayesianGaussianMixture`. :issue:`10740` by :user:`Erich","654","  Schubert <kno10>` and :user:`Guillaume Lemaitre <glemaitre>`.","655","","656","- Fixed a bug in :class:`mixture.BaseMixture` and its subclasses","657","  :class:`mixture.GaussianMixture` and :class:`mixture.BayesianGaussianMixture`","658","  where the ``lower_bound_`` was not the max lower bound across all","659","  initializations (when ``n_init > 1``), but just the lower bound of the last","660","  initialization. :issue:`10869` by :user:`Aurlien Gron <ageron>`.","661","","662","- Fixed a bug in :class:`decomposition.SparseCoder` when running OMP sparse","663","  coding in parallel using readonly memory mapped datastructures. :issue:`5956`","664","  by :user:`Vighnesh Birodkar <vighneshbirodkar>` and","665","  :user:`Olivier Grisel <ogrisel>`.","666","","667","- Fixed a bug in :func:`cluster.k_means_elkan` where the returned `iteration`","668","  was 1 less than the correct value. Also added the missing `n_iter_` attribute","669","  in the docstring of :class:`cluster.KMeans`. :issue:`11353` by","670","  :user:`Jeremie du Boisberranger <jeremiedbb>`.","671","","672","Metrics","673","","674","- Fixed a bug in :func:`metrics.precision_recall_fscore_support`","675","  when truncated `range(n_labels)` is passed as value for `labels`.","676","  :issue:`10377` by :user:`Gaurav Dhingra <gxyd>`.","677","","678","- Fixed a bug due to floating point error in :func:`metrics.roc_auc_score` with","679","  non-integer sample weights. :issue:`9786` by :user:`Hanmin Qin <qinhanmin2014>`.","680","","681","- Fixed a bug where :func:`metrics.roc_curve` sometimes starts on y-axis instead","682","  of (0, 0), which is inconsistent with the document and other implementations.","683","  Note that this will not influence the result from :func:`metrics.roc_auc_score`","684","  :issue:`10093` by :user:`alexryndin <alexryndin>`","685","  and :user:`Hanmin Qin <qinhanmin2014>`.","686","","687","- Fixed a bug to avoid integer overflow. Casted product to 64 bits integer in","688","  :func:`metrics.mutual_info_score`.","689","  :issue:`9772` by :user:`Kumar Ashutosh <thechargedneutron>`.","690","","691","- Fixed a bug where :func:`metrics.average_precision_score` will sometimes return","692","  ``nan`` when ``sample_weight`` contains 0.","693","  :issue:`9980` by :user:`Hanmin Qin <qinhanmin2014>`.","694","","695","- Fixed a bug in :func:`metrics.fowlkes_mallows_score` to avoid integer","696","  overflow. Casted return value of `contingency_matrix` to `int64` and computed","697","  product of square roots rather than square root of product.","698","  :issue:`9515` by :user:`Alan Liddell <aliddell>` and","699","  :user:`Manh Dao <manhdao>`.","700","","701","Ensemble","702","","703","- Fix allowing to obtain deterministic with :class:`BaseBagging` estimator,","704","  when comparing results generated at fit time with the one using the object","705","  attributes when ``random_state`` is set. :issue:`9723` by :user:`Guillaume","706","  Lemaitre <glemaitre>`.","707","","708","Neighbors","709","","710","- Fixed a bug so ``predict`` in :class:`neighbors.RadiusNeighborsRegressor` can","711","  handle empty neighbor set when using non uniform weights. Also raises a new","712","  warning when no neighbors are found for samples.  :issue:`9655` by","713","  :user:`Andreas Bjerre-Nielsen <abjer>`.","714","","715","- Fixed a bug in ``KDTree`` construction that results in faster construction","716","  and querying times. :issue:`11556` by :user:`Jake VanderPlas <jakevdp>`","717","","718","Feature Extraction","719","","720","- Fixed a bug in :func:`feature_extraction.image.extract_patches_2d` which would","721","  throw an exception if ``max_patches`` was greater than or equal to the number","722","  of all possible patches rather than simply returning the number of possible","723","  patches. :issue:`10100` by :user:`Varun Agrawal <varunagrawal>`","724","","725","- Fixed a bug in :class:`feature_extraction.text.CountVectorizer`,","726","  :class:`feature_extraction.text.TfidfVectorizer`,","727","  :class:`feature_extraction.text.HashingVectorizer` to support 64 bit sparse","728","  array indexing necessary to process large datasets with more than 210\u2079 tokens","729","  (words or n-grams). :issue:`9147` by :user:`Claes-Fredrik Mannby <mannby>`","730","  and `Roman Yurchak`_.","731","","732","- Fixed bug in :class:`feature_extraction.text.TFIDFVectorizer` which","733","  was ignoring the parameter ``dtype``. In addition,","734","  :class:`feature_extraction.text.TFIDFTransformer` will preserve ``dtype``","735","  for floating and raise a warning if ``dtype`` requested is integer.","736","  :issue:`10441` by :user:`Mayur Kulkarni <maykulkarni>` and","737","  :user:`Guillaume Lemaitre <glemaitre>`.","738","","739","Utils","740","","741","- :func:`utils.check_array` yield a ``FutureWarning`` indicating","742","  that arrays of bytes\/strings will be interpreted as decimal numbers","743","  beginning in version 0.22. :issue:`10229` by :user:`Ryan Lee <rtlee9>`","744","","745","Preprocessing","746","","747","- Fixed bugs in :class:`preprocessing.LabelEncoder` which would sometimes throw","748","  errors when ``transform`` or ``inverse_transform`` was called with empty arrays.","749","  :issue:`10458` by :user:`Mayur Kulkarni <maykulkarni>`.","750","","751","- Fix ValueError in :class:`preprocessing.LabelEncoder` when using","755","- Fix bug in :class:`preprocessing.OneHotEncoder` which discarded the ``dtype``","756","  when returning a sparse matrix output. :issue:`11042` by :user:`Daniel","757","  Morales <DanielMorales9>`.","759","- Fix ``fit`` and ``partial_fit`` in :class:`preprocessing.StandardScaler` in","760","  the rare case when `with_mean=False` and `with_std=False` which was crashing","761","  by calling ``fit`` more than once and giving inconsistent results for","762","  ``mean_`` whether the input was a sparse or a dense matrix. ``mean_`` will be","763","  set to ``None`` with both sparse and dense inputs. ``n_samples_seen_`` will","764","  be also reported for both input types.","767","Feature selection","768","","769","- Fixed computation of ``n_features_to_compute`` for edge case with tied CV","770","  scores in :class:`feature_selection.RFECV`. :issue:`9222` by `Nick Hoh","771","  <nickypie>`.","772","","773","Model evaluation and meta-estimators","774","","775","- Add improved error message in :func:`model_selection.cross_val_score` when","776","  multiple metrics are passed in ``scoring`` keyword.","777","  :issue:`11006` by :user:`Ming Li <minggli>`.","778","","779","Datasets","780","","781","- Fixed a bug in :func:`datasets.load_boston` which had a wrong data point.","782","  :issue:`10801` by :user:`Takeshi Yoshizawa <tarcusx>`.","783","","784","- Fixed a bug in :func:`datasets.load_iris` which had two wrong data points.","785","  :issue:`11082` by :user:`Sadhana Srinivasan <rotuna>`","786","  and :user:`Hanmin Qin <qinhanmin2014>`.","787","","788","API changes summary","789","-------------------","790","","791","Classifiers and regressors","792","","793","- The default value of the ``n_estimators`` parameter of","794","  :class:`ensemble.RandomForestClassifier`, :class:`ensemble.RandomForestRegressor`,","795","  :class:`ensemble.ExtraTreesClassifier`, :class:`ensemble.ExtraTreesRegressor`,","796","  and :class:`ensemble.RandomTreesEmbedding` will change from 10 in version 0.20","797","  to 100 in 0.22. A FutureWarning is raised when the default value is used.","798","  :issue:`11542` by :user:`Anna Ayzenshtat <annaayzenshtat>`.","799","","800","Linear, kernelized and related models","801","","802","- Deprecate ``random_state`` parameter in :class:`svm.OneClassSVM` as the","803","  underlying implementation is not random.","804","  :issue:`9497` by :user:`Albert Thomas <albertcthomas>`.","805","","806","- Deprecate ``positive=True`` option in :class:`linear_model.Lars` as the","807","  underlying implementation is broken. Use :class:`linear_model.Lasso` instead.","808","  :issue:`9837` by `Alexandre Gramfort`_.","809","","810","- ``n_iter_`` may vary from previous releases in","811","  :class:`linear_model.LogisticRegression` with ``solver='lbfgs'`` and","812","  :class:`linear_model.HuberRegressor`.  For Scipy <= 1.0.0, the optimizer could","813","  perform more than the requested maximum number of iterations. Now both","814","  estimators will report at most ``max_iter`` iterations even if more were","815","  performed. :issue:`10723` by `Joel Nothman`_.","816","","817","- The default value of ``gamma`` parameter of :class:`svm.SVC`,","818","  :class:`~svm.NuSVC`, :class:`~svm.SVR`, :class:`~svm.NuSVR`,","819","  :class:`~svm.OneClassSVM` will change from ``'auto'`` to ``'scale'`` in","820","  version 0.22 to account better for unscaled features. :issue:`8361` by","821","  :user:`Gaurav Dhingra <gxyd>` and :user:`Ting Neo <neokt>`.","822","","823","- Added convergence warning to :class:`svm.LinearSVC` and","824","  :class:`linear_model.LogisticRegression` when ``verbose`` is set to 0.","825","  :issue:`10881` by :user:`Alexandre Sevin <AlexandreSev>`.","826","","827","Preprocessing","828","","829","- Deprecate ``n_values`` and ``categorical_features`` parameters and","838","Decomposition, manifold learning and clustering","839","","840","- Deprecate ``precomputed`` parameter in function","841","  :func:`manifold.t_sne.trustworthiness`. Instead, the new parameter","842","  ``metric`` should be used with any compatible metric including","843","  'precomputed', in which case the input matrix ``X`` should be a matrix of","844","  pairwise distances or squared distances. :issue:`9775` by","845","  :user:`William de Vazelhes <wdevazelhes>`.","846","","847","- Added function :func:`fit_predict` to :class:`mixture.GaussianMixture` and","848","  :class:`mixture.GaussianMixture`, which is essentially equivalent to calling","849","  :func:`fit` and :func:`predict`. :issue:`10336` by","850","  :user:`Shu Haoran <haoranShu>` and :user:`Andrew Peng <Andrew-peng>`.","851","","852","Metrics","853","","854","- Deprecate ``reorder`` parameter in :func:`metrics.auc` as it's no longer required","855","  for :func:`metrics.roc_auc_score`. Moreover using ``reorder=True`` can hide bugs","856","  due to floating point error in the input.","857","  :issue:`9851` by :user:`Hanmin Qin <qinhanmin2014>`.","858","","859","- In :func:`metrics.normalized_mutual_information_score` and","860","  :func:`metrics.adjusted_mutual_information_score`,","861","  warn that ``average_method``","862","  will have a new default value. In version 0.22, the default normalizer for each","863","  will become the *arithmetic* mean of the entropies of each clustering. Currently,","864","  :func:`metrics.normalized_mutual_information_score` uses the default of","865","  ``average_method='geometric'``, and :func:`metrics.adjusted_mutual_information_score`","866","  uses the default of ``average_method='max'`` to match their behaviors in","867","  version 0.19.","868","  :issue:`11124` by :user:`Arya McCarthy <aryamccarthy>`.","869","","870","- The ``batch_size`` parameter to :func:`metrics.pairwise_distances_argmin_min`","871","  and :func:`metrics.pairwise_distances_argmin` is deprecated to be removed in","872","  v0.22.  It no longer has any effect, as batch size is determined by global","873","  ``working_memory`` config. See :ref:`working_memory`. :issue:`10280` by `Joel","874","  Nothman`_ and :user:`Aman Dalmia <dalmia>`.","875","","876","Cluster","877","","878","- Deprecate ``pooling_func`` unused parameter in","879","  :class:`cluster.AgglomerativeClustering`. :issue:`9875` by :user:`Kumar Ashutosh","882","Ensemble","884","- Classes derived from :class:`ensemble.BaseBagging`. The attribute","885","  ``estimators_samples_`` will return a list of arrays containing the indices","886","  selected for each bootstrap instead of a list of arrays containing the mask","887","  of the samples selected for each bootstrap. Indices allows to repeat samples","888","  while mask does not allow this functionality. :issue:`9524` by","889","  :user:`Guillaume Lemaitre <glemaitre>`.","891","Imputer","893","- Deprecate :class:`preprocessing.Imputer` and move the corresponding module to","894","  :class:`impute.SimpleImputer`. :issue:`9726` by :user:`Kumar Ashutosh","895","  <thechargedneutron>`.","897","- The ``axis`` parameter that was in :class:`preprocessing.Imputer` is no","898","  longer present in :class:`impute.SimpleImputer`. The behavior is equivalent","899","  to ``axis=0`` (impute along columns). Row-wise imputation can be performed","900","  with FunctionTransformer (e.g., ``FunctionTransformer(lambda X:","901","  SimpleImputer().fit_transform(X.T).T)``). :issue:`10829` by :user:`Guillaume","902","  Lemaitre <glemaitre>` and :user:`Gilberto Olimpio <gilbertoolimpio>`.","904","- The :class:`impute.SimpleImputer` has a new strategy, ``'constant'``, to","905","  complete missing values with a fixed one, given by the ``fill_value``","906","  parameter. This strategy supports numeric and non-numeric data, and so does","907","  the ``'most_frequent'`` strategy now. :issue:`11211` by :user:`Jeremie du","908","  Boisberranger <jeremiedbb>`.","910","- The NaN marker for the missing values has been changed between the","911","  :class:`preprocessing.Imputer` and the :class:`impute.SimpleImputer`.","912","  ``missing_values='NaN'``?should now be ``missing_values=np.nan``.","913","  :issue:`11211` by :user:`Jeremie du Boisberranger <jeremiedbb>`.","915","Outlier Detection models","917","- More consistent outlier detection API:","933","- Novelty detection with :class:`neighbors.LocalOutlierFactor`:","934","  Add a ``novelty`` parameter to :class:`neighbors.LocalOutlierFactor`. When","935","  ``novelty`` is set to True, :class:`neighbors.LocalOutlierFactor` can then ","936","  be used for novelty detection, i.e. predict on new unseen data. Available","937","  prediction methods are ``predict``, ``decision_function`` and","938","  ``score_samples``. By default, ``novelty`` is set to ``False``, and only","939","  the ``fit_predict`` method is avaiable.","940","  By :user:`Albert Thomas <albertcthomas>`.","941","","953","Covariance","955","- The :func:`covariance.graph_lasso`, :class:`covariance.GraphLasso` and","956","  :class:`covariance.GraphLassoCV` have been renamed to","957","  :func:`covariance.graphical_lasso`, :class:`covariance.GraphicalLasso` and","958","  :class:`covariance.GraphicalLassoCV` respectively and will be removed in version 0.22.","959","  :issue:`9993` by :user:`Artiem Krinitsyn <artiemq>`","960","","961","Misc","962","","963","- Changed warning type from :class:`UserWarning` to","973","- Changed ValueError exception raised in :class:`model_selection.ParameterSampler`","974","  to a UserWarning for case where the class is instantiated with a greater value of","975","  ``n_iter`` than the total space of parameters in the parameter grid. ``n_iter`` now","976","  acts as an upper bound on iterations.","977","  :issue:`#10982` by :user:`Juliet Lawton <julietcl>`","979","- Invalid input for :class:`model_selection.ParameterGrid` now raises TypeError.","980","  :issue:`10928` by :user:`Solutus Immensus <solutusimmensus>`","982","- :func:`utils.check_array` and :func:`utils.check_X_y` now have","983","  ``accept_large_sparse`` to control whether scipy.sparse matrices with 64-bit","984","  indices should be rejected.","985","  :issue:`11327` by :user:`Karan Dhingra <kdhingra307>` and `Joel Nothman`_.","987","Preprocessing","989","- In :class:`preprocessing.FunctionTransformer`, the default of ``validate``","990","  will be from ``True`` to ``False`` in 0.22.","991","  :issue:`10655` by :user:`Guillaume Lemaitre <glemaitre>`.","993","Model selection","994","","995","- The default number of cross-validation folds ``cv`` and the default number of","996","  splits ``n_splits`` in the :class:`model_selection.KFold`-like splitters will change","997","  from 3 to 5 in 0.22 as 3-fold has a lot of variance.","998","  :issue:`11557` by :user:`Alexandre Boucaud <aboucaud>`."]}],"doc\/themes\/scikit-learn\/static\/css\/bootstrap.css":[{"add":["911",".label-danger,","912",".badge-danger {","913","  \/* XXX: backported from later bootstrap *\/","914","  background-color: #d9534f;","915","}"],"delete":[]}],"doc\/whats_new\/_contributors.rst":[{"add":["6","    It also defines other ReST substitutions.","7","","8",".. role:: raw-html(raw)","9","   :format: html","10","","11",".. role:: raw-latex(raw)","12","   :format: latex","13","","14",".. |MajorFeature| replace:: :raw-html:`<span class=\"label label-success\">Major Feature<\/span>` :raw-latex:`{\\small\\sc [Major Feature]}`","15",".. |Feature| replace:: :raw-html:`<span class=\"label label-success\">Feature<\/span>` :raw-latex:`{\\small\\sc [Feature]}`","16",".. |Efficiency| replace:: :raw-html:`<span class=\"label label-info\">Efficiency<\/span>` :raw-latex:`{\\small\\sc [Efficiency]}`","17",".. |Enhancement| replace:: :raw-html:`<span class=\"label label-info\">Enhancement<\/span>` :raw-latex:`{\\small\\sc [Enhancement]}`","18",".. |Fix| replace:: :raw-html:`<span class=\"label label-danger\">Fix<\/span>` :raw-latex:`{\\small\\sc [Fix]}`","19",".. |API| replace:: :raw-html:`<span class=\"label label-warning\">API Change<\/span>` :raw-latex:`{\\small\\sc [API Change]}`"],"delete":[]}],"doc\/themes\/scikit-learn\/static\/css\/bootstrap.min.css":[{"add":["166",".label-danger,.badge-danger {\/* XXX: backported from later bootstrap *\/background-color: #d9534f;}"],"delete":[]}]}},"419c6cc456f0353d22d701ba6e1110a2bdef219a":{"changes":{".circleci\/config.yml":"MODIFY"},"diff":{".circleci\/config.yml":[{"add":["126","            - doc"],"delete":["126","            - python3"]}]}},"62117f482e39757d3e5f25568e1180dcfa695363":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/preprocessing\/_encoders.py":"MODIFY","sklearn\/preprocessing\/tests\/test_encoders.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["166","- |Fix| Fixed a bug in :class:`preprocessing.OneHotEncoder` where transform","167","  failed when set to ignore unknown numpy strings of different lengths ","168","  :issue:`12471` by :user:`Gabriel Marzinotto<GMarzinotto>`.","169","","170",""],"delete":[]}],"sklearn\/preprocessing\/_encoders.py":[{"add":["112","                    # cast Xi into the largest string type necessary","113","                    # to handle different lengths of numpy strings","114","                    if (self.categories_[i].dtype.kind in ('U', 'S')","115","                            and self.categories_[i].itemsize > Xi.itemsize):","116","                        Xi = Xi.astype(self.categories_[i].dtype)","117","                    else:","118","                        Xi = Xi.copy()","119",""],"delete":["112","                    Xi = Xi.copy()"]}],"sklearn\/preprocessing\/tests\/test_encoders.py":[{"add":["275","def test_one_hot_encoder_handle_unknown_strings():","276","    X = np.array(['11111111', '22', '333', '4444']).reshape((-1, 1))","277","    X2 = np.array(['55555', '22']).reshape((-1, 1))","278","    # Non Regression test for the issue #12470","279","    # Test the ignore option, when categories are numpy string dtype","280","    # particularly when the known category strings are larger","281","    # than the unknown category strings","282","    oh = OneHotEncoder(handle_unknown='ignore')","283","    oh.fit(X)","284","    X2_passed = X2.copy()","285","    assert_array_equal(","286","        oh.transform(X2_passed).toarray(),","287","        np.array([[0.,  0.,  0.,  0.], [0.,  1.,  0.,  0.]]))","288","    # ensure transformed data was not modified in place","289","    assert_array_equal(X2, X2_passed)","290","","291",""],"delete":[]}]}},"2ab2927b2ee4f821fd75050da19a7f1f81aaeca8":{"changes":{"examples\/neural_networks\/plot_mnist_filters.py":"MODIFY"},"diff":{"examples\/neural_networks\/plot_mnist_filters.py":[{"add":["30","X = X \/ 255."],"delete":[]}]}},"c6455fa77f519481f516ded02da66ecaf4b044c9":{"changes":{"sklearn\/tree\/setup.py":"MODIFY"},"diff":{"sklearn\/tree\/setup.py":[{"add":["33","    config.add_data_files(\"_criterion.pxd\")","34","    config.add_data_files(\"_splitter.pxd\")","35","    config.add_data_files(\"_tree.pxd\")","36","    config.add_data_files(\"_utils.pxd\")"],"delete":[]}]}},"2020867b8ffa6325a386591fa8dfcf62ad3128ff":{"changes":{"sklearn\/cluster\/tests\/test_optics.py":"MODIFY","sklearn\/cluster\/optics_.py":"MODIFY"},"diff":{"sklearn\/cluster\/tests\/test_optics.py":[{"add":["90","    msg = \"Specify an epsilon smaller than 0.15. Got 0.3.\"","96","    clust = OPTICS(max_eps=5.0 * 0.03, min_samples=10)","101","def test_bad_reachability():","102","    msg = \"All reachability values are inf. Set a larger max_eps.\"","103","    centers = [[1, 1], [-1, -1], [1, -1]]","104","    X, labels_true = make_blobs(n_samples=750, centers=centers,","105","                                cluster_std=0.4, random_state=0)","106","","107","    clust = OPTICS(max_eps=5.0 * 0.003, min_samples=10)","108","    assert_raise_message(ValueError, msg, clust.fit, X)","109","","110",""],"delete":["90","    msg = \"Specify an epsilon smaller than 0.015. Got 0.3.\"","96","    clust = OPTICS(max_eps=5.0 * 0.003, min_samples=10)"]}],"sklearn\/cluster\/optics_.py":[{"add":["655","    # according to Ankerst M. et.al. 1999 (p. 5), for a small enough","656","    # generative distance epsilong, there should be more than one INF.","657","    if np.all(np.isinf(reachability)):","658","        raise ValueError(\"All reachability values are inf. Set a larger\"","659","                         \" max_eps.\")","660","    normalization_factor = np.max(reachability[reachability < np.inf])","661","    reachability = reachability \/ normalization_factor","806","    if ((avg_reach1 \/ maxima_ratio) > reachability_plot[s] or","807","            (avg_reach2 \/ maxima_ratio) > reachability_plot[s]):","809","        if (avg_reach1 \/ rejection_ratio) < reachability_plot[s]:","812","        if (avg_reach2 \/ rejection_ratio) < reachability_plot[s]:","815","        if ((avg_reach1 \/ rejection_ratio) >= reachability_plot[s] and","816","                (avg_reach2 \/ rejection_ratio) >= reachability_plot[s]):"],"delete":["655","    reachability = reachability \/ np.max(reachability[1:])","800","    if ((avg_reach1 \/ reachability_plot[s]) > maxima_ratio or","801","            (avg_reach2 \/ reachability_plot[s]) > maxima_ratio):","803","        if (avg_reach1 \/ reachability_plot[s]) < rejection_ratio:","806","        if (avg_reach2 \/ reachability_plot[s]) < rejection_ratio:","809","        if ((avg_reach1 \/ reachability_plot[s]) >= rejection_ratio and","810","                (avg_reach2 \/ reachability_plot[s]) >= rejection_ratio):"]}]}},"aae4e337d2c93d9005f5d13c62e80209740dce6a":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/compose\/tests\/test_column_transformer.py":"MODIFY","sklearn\/compose\/_column_transformer.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["27",":mod:`sklearn.compose`","28","......................","29","","30","- |Fix| Fixed an issue in :func:`compose.make_column_transformer` which raises","31","  unexpected error when columns is pandas Index or pandas Series.","32","  :issue:`12704` by :user:`Hanmin Qin <qinhanmin2014>`.","33",""],"delete":[]}],"sklearn\/compose\/tests\/test_column_transformer.py":[{"add":["543","def test_make_column_transformer_pandas():","544","    pd = pytest.importorskip('pandas')","545","    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T","546","    X_df = pd.DataFrame(X_array, columns=['first', 'second'])","547","    norm = Normalizer()","548","    # XXX remove in v0.22","549","    with pytest.warns(DeprecationWarning,","550","                      match='`make_column_transformer` now expects'):","551","        ct1 = make_column_transformer((X_df.columns, norm))","552","    ct2 = make_column_transformer((norm, X_df.columns))","553","    assert_almost_equal(ct1.fit_transform(X_df),","554","                        ct2.fit_transform(X_df))","555","","556",""],"delete":[]}],"sklearn\/compose\/_column_transformer.py":[{"add":["694","        if isinstance(t, six.string_types) and t in ('drop', 'passthrough'):"],"delete":["694","        if t in ('drop', 'passthrough'):"]}]}}}
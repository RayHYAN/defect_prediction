{"2a1408a71d5656f5bfaef7d072b83045cba3b9e6":{"changes":{"sklearn\/linear_model\/least_angle.py":"MODIFY"},"diff":{"sklearn\/linear_model\/least_angle.py":[{"add":["1170","    @deprecated(\"Attribute cv_mse_path_ is deprecated in 0.18 and \"","1171","                \"will be removed in 0.20. Use 'mse_path_' instead\")"],"delete":["1170","    @deprecated(\"Attribute mse_path_ is deprecated in 0.18 and \"","1171","                \"will be removed in 0.20. Use 'cv_mse_path_' instead\")"]}]}},"7978119e037ceaafdbcc2588a8e1f3fa0f36c9c6":{"changes":{"doc\/faq.rst":"MODIFY"},"diff":{"doc\/faq.rst":[{"add":["284","You can find more information about addition of gpu support at","285","`Will you add GPU support?`_.","286",""],"delete":[]}]}},"cc3ce589532681ced6df4fe526b3c0c4cc33c36c":{"changes":{"sklearn\/tree\/tree.py":"MODIFY","sklearn\/ensemble\/gradient_boosting.py":"MODIFY","sklearn\/ensemble\/forest.py":"MODIFY"},"diff":{"sklearn\/tree\/tree.py":[{"add":["631","    Notes","632","    -----","633","    The features are always randomly permuted at each split. Therefore,","634","    the best found split may vary, even with the same training data and","635","    ``max_features=n_features``, if the improvement of the criterion is","636","    identical for several splits enumerated during the search of the best","637","    split. To obtain a deterministic behaviour during fitting,","638","    ``random_state`` has to be fixed.","639","","933","    Notes","934","    -----","935","    The features are always randomly permuted at each split. Therefore,","936","    the best found split may vary, even with the same training data and","937","    ``max_features=n_features``, if the improvement of the criterion is","938","    identical for several splits enumerated during the search of the best","939","    split. To obtain a deterministic behaviour during fitting,","940","    ``random_state`` has to be fixed.","941",""],"delete":[]}],"sklearn\/ensemble\/gradient_boosting.py":[{"add":["1386","    Notes","1387","    -----","1388","    The features are always randomly permuted at each split. Therefore,","1389","    the best found split may vary, even with the same training data and","1390","    ``max_features=n_features``, if the improvement of the criterion is","1391","    identical for several splits enumerated during the search of the best","1392","    split. To obtain a deterministic behaviour during fitting,","1393","    ``random_state`` has to be fixed.","1737","        p","1738","revious solution.","1781","    Notes","1782","    -----","1783","    The features are always randomly permuted at each split. Therefore,","1784","    the best found split may vary, even with the same training data and","1785","    ``max_features=n_features``, if the improvement of the criterion is","1786","    identical for several splits enumerated during the search of the best","1787","    split. To obtain a deterministic behaviour during fitting,","1788","    ``random_state`` has to be fixed.","1789",""],"delete":["1729","        previous solution."]}],"sklearn\/ensemble\/forest.py":[{"add":["891","    Notes","892","    -----","893","    The features are always randomly permuted at each split. Therefore,","894","    the best found split may vary, even with the same training data,","895","    ``max_features=n_features`` and ``bootstrap=False``, if the improvement","896","    of the criterion is identical for several splits enumerated during the","897","    search of the best split. To obtain a deterministic behaviour during","898","    fitting, ``random_state`` has to be fixed.","899","","1081","    Notes","1082","    -----","1083","    The features are always randomly permuted at each split. Therefore,","1084","    the best found split may vary, even with the same training data,","1085","    ``max_features=n_features`` and ``bootstrap=False``, if the improvement","1086","    of the criterion is identical for several splits enumerated during the","1087","    search of the best split. To obtain a deterministic behaviour during","1088","    fitting, ``random_state`` has to be fixed.","1089",""],"delete":[]}]}},"8981b25c1798b52618b730d95a870ec347e31c06":{"changes":{"sklearn\/svm\/classes.py":"MODIFY"},"diff":{"sklearn\/svm\/classes.py":[{"add":[],"delete":["1086",""]}]}},"89962f0c5bb4bea56aaf0e30bd8d2ea3789a4a46":{"changes":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":"MODIFY","sklearn\/linear_model\/coordinate_descent.py":"MODIFY","sklearn\/linear_model\/omp.py":"MODIFY","sklearn\/linear_model\/tests\/test_base.py":"MODIFY","sklearn\/linear_model\/randomized_l1.py":"MODIFY","sklearn\/linear_model\/base.py":"MODIFY","sklearn\/linear_model\/bayes.py":"MODIFY","sklearn\/linear_model\/least_angle.py":"MODIFY","sklearn\/linear_model\/ridge.py":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":[{"add":["663","    # With check_input=False, an exhaustive check is not made on y but its","664","    # dtype is still cast in _preprocess_data to X's dtype. So the test should","665","    # pass anyway","667","    clf.fit(X, y, check_input=False)"],"delete":["664","    clf.fit(X, y, check_input=True)","665","    # Check that an error is raised if data is provided in the wrong dtype,","666","    # because of check bypassing","667","    assert_raises(ValueError, clf.fit, X, y, check_input=False)","668",""]}],"sklearn\/linear_model\/coordinate_descent.py":[{"add":["655","            Target. Will be cast to X's dtype if necessary","1682","            Target. Will be cast to X's dtype if necessary"],"delete":["655","            Target","1682","            Target"]}],"sklearn\/linear_model\/omp.py":[{"add":["619","            Target values. Will be cast to X's dtype if necessary","837","            Target values. Will be cast to X's dtype if necessary"],"delete":["619","            Target values.","837","            Target values."]}],"sklearn\/linear_model\/tests\/test_base.py":[{"add":["326","def test_dtype_preprocess_data():","327","    n_samples = 200","328","    n_features = 2","329","    X = rng.rand(n_samples, n_features)","330","    y = rng.rand(n_samples)","331","","332","    X_32 = np.asarray(X, dtype=np.float32)","333","    y_32 = np.asarray(y, dtype=np.float32)","334","    X_64 = np.asarray(X, dtype=np.float64)","335","    y_64 = np.asarray(y, dtype=np.float64)","336","","337","    for fit_intercept in [True, False]:","338","        for normalize in [True, False]:","339","","340","            Xt_32, yt_32, X_mean_32, y_mean_32, X_norm_32 = _preprocess_data(","341","                X_32, y_32, fit_intercept=fit_intercept, normalize=normalize,","342","                return_mean=True)","343","","344","            Xt_64, yt_64, X_mean_64, y_mean_64, X_norm_64 = _preprocess_data(","345","                X_64, y_64, fit_intercept=fit_intercept, normalize=normalize,","346","                return_mean=True)","347","","348","            Xt_3264, yt_3264, X_mean_3264, y_mean_3264, X_norm_3264 = (","349","                _preprocess_data(X_32, y_64, fit_intercept=fit_intercept,","350","                                 normalize=normalize, return_mean=True))","351","","352","            Xt_6432, yt_6432, X_mean_6432, y_mean_6432, X_norm_6432 = (","353","                _preprocess_data(X_64, y_32, fit_intercept=fit_intercept,","354","                                 normalize=normalize, return_mean=True))","355","","356","            assert_equal(Xt_32.dtype, np.float32)","357","            assert_equal(yt_32.dtype, np.float32)","358","            assert_equal(X_mean_32.dtype, np.float32)","359","            assert_equal(y_mean_32.dtype, np.float32)","360","            assert_equal(X_norm_32.dtype, np.float32)","361","","362","            assert_equal(Xt_64.dtype, np.float64)","363","            assert_equal(yt_64.dtype, np.float64)","364","            assert_equal(X_mean_64.dtype, np.float64)","365","            assert_equal(y_mean_64.dtype, np.float64)","366","            assert_equal(X_norm_64.dtype, np.float64)","367","","368","            assert_equal(Xt_3264.dtype, np.float32)","369","            assert_equal(yt_3264.dtype, np.float32)","370","            assert_equal(X_mean_3264.dtype, np.float32)","371","            assert_equal(y_mean_3264.dtype, np.float32)","372","            assert_equal(X_norm_3264.dtype, np.float32)","373","","374","            assert_equal(Xt_6432.dtype, np.float64)","375","            assert_equal(yt_6432.dtype, np.float64)","376","            assert_equal(X_mean_6432.dtype, np.float64)","377","            assert_equal(y_mean_6432.dtype, np.float64)","378","            assert_equal(X_norm_6432.dtype, np.float64)","379","","380","            assert_equal(X_32.dtype, np.float32)","381","            assert_equal(y_32.dtype, np.float32)","382","            assert_equal(X_64.dtype, np.float64)","383","            assert_equal(y_64.dtype, np.float64)","384","","385","            assert_array_almost_equal(Xt_32, Xt_64)","386","            assert_array_almost_equal(yt_32, yt_64)","387","            assert_array_almost_equal(X_mean_32, X_mean_64)","388","            assert_array_almost_equal(y_mean_32, y_mean_64)","389","            assert_array_almost_equal(X_norm_32, X_norm_64)","390","","391",""],"delete":[]}],"sklearn\/linear_model\/randomized_l1.py":[{"add":["84","            Target values. Will be cast to X's dtype if necessary"],"delete":["84","            Target values."]}],"sklearn\/linear_model\/base.py":[{"add":["160","    centered. This function also systematically makes y consistent with X.dtype","168","    y = np.asarray(y, dtype=X.dtype)","174","                X_offset[:] = X.dtype.type(0)","204","        if y.ndim == 1:","205","            y_offset = X.dtype.type(0)","206","        else:","207","            y_offset = np.zeros(y.shape[1], dtype=X.dtype)","466","            Target values. Will be cast to X's dtype if necessary"],"delete":["160","    centered.","173","                X_offset[:] = 0","203","        y_offset = 0. if y.ndim == 1 else np.zeros(y.shape[1], dtype=X.dtype)","462","            Target values"]}],"sklearn\/linear_model\/bayes.py":[{"add":["150","            Target values. Will be cast to X's dtype if necessary","422","            Target values (integers). Will be cast to X's dtype if necessary"],"delete":["150","            Target values","422","            Target values (integers)"]}],"sklearn\/linear_model\/least_angle.py":[{"add":["1457","            target values. Will be cast to X's dtype if necessary"],"delete":["1457","            target values."]}],"sklearn\/linear_model\/ridge.py":[{"add":["977","            Target values. Will be cast to X's dtype if necessary","1096","            Target values. Will be cast to X's dtype if necessary","1338","            Target values. Will be cast to X's dtype if necessary"],"delete":["977","            Target values","1096","            Target values","1338","            Target values."]}]}},"b429868d07f874b81cafd1228a38f9990fb6ef91":{"changes":{"sklearn\/covariance\/tests\/test_robust_covariance.py":"MODIFY","doc\/whats_new.rst":"MODIFY","sklearn\/covariance\/robust_covariance.py":"MODIFY"},"diff":{"sklearn\/covariance\/tests\/test_robust_covariance.py":[{"add":["6","import itertools","7","","96","def test_mcd_issue3367():","97","    # Check that MCD completes when the covariance matrix is singular","98","    # i.e. one of the rows and columns are all zeros","99","    rand_gen = np.random.RandomState(0)","100","","101","    # Think of these as the values for X and Y -> 10 values between -5 and 5","102","    data_values = np.linspace(-5, 5, 10).tolist()","103","    # Get the cartesian product of all possible coordinate pairs from above set","104","    data = np.array(list(itertools.product(data_values, data_values)))","105","","106","    # Add a third column that's all zeros to make our data a set of point","107","    # within a plane, which means that the covariance matrix will be singular","108","    data = np.hstack((data, np.zeros((data.shape[0], 1))))","109","","110","    # The below line of code should raise an exception if the covariance matrix","111","    # is singular. As a further test, since we have points in XYZ, the","112","    # principle components (Eigenvectors) of these directly relate to the","113","    # geometry of the points. Since it's a plane, we should be able to test","114","    # that the Eigenvector that corresponds to the smallest Eigenvalue is the","115","    # plane normal, specifically [0, 0, 1], since everything is in the XY plane","116","    # (as I've set it up above). To do this one would start by:","117","    #","118","    #     evals, evecs = np.linalg.eigh(mcd_fit.covariance_)","119","    #     normal = evecs[:, np.argmin(evals)]","120","    #","121","    # After which we need to assert that our `normal` is equal to [0, 0, 1].","122","    # Do note that there is floating point error associated with this, so it's","123","    # best to subtract the two and then compare some small tolerance (e.g.","124","    # 1e-12).","125","    MinCovDet(random_state=rand_gen).fit(data)","126","","127",""],"delete":[]}],"doc\/whats_new.rst":[{"add":["189","","190","   - Fixed a bug in :class:`sklearn.covariance.MinCovDet` where inputting data","191","     that produced a singular covariance matrix would cause the helper method","192","     `_c_step` to throw an exception.","193","     :issue:`3367` by :user:`Jeremy Steward <ThatGeoGuy>`","194","","211",""],"delete":[]}],"sklearn\/covariance\/robust_covariance.py":[{"add":["98","    dist = np.inf","122","    # If the data already has singular covariance, calculate the precision,","123","    # as the loop below will not be entered.","124","    if np.isinf(det):","125","        precision = pinvh(covariance)","126","","128","    while (det < previous_det and remaining_iterations > 0","129","            and not np.isinf(det)):","151","    # Check if best fit already found (det => 0, logdet => -inf)","153","        results = location, covariance, det, support, dist"],"delete":["122","    while (det < previous_det) and (remaining_iterations > 0):","144","    # Catch computation errors","146","        raise ValueError(","147","            \"Singular covariance matrix. \"","148","            \"Please check that the covariance matrix corresponding \"","149","            \"to the dataset is full rank and that MinCovDet is used with \"","150","            \"Gaussian-distributed data (or at least data drawn from a \"","151","            \"unimodal, symmetric distribution.\")"]}]}},"aaebee1f6b8b8e821130b1057c8ec1431b0d1da2":{"changes":{"sklearn\/feature_selection\/tests\/test_mutual_info.py":"MODIFY","sklearn\/feature_selection\/mutual_info_.py":"MODIFY"},"diff":{"sklearn\/feature_selection\/tests\/test_mutual_info.py":[{"add":["7","                                   assert_false, assert_raises, assert_equal,","8","                                   assert_allclose, assert_greater)","161","    mi = mutual_info_classif(X, y, discrete_features=[2], n_neighbors=3,","162","                             random_state=0)","164","    for n_neighbors in [5, 7, 9]:","165","        mi_nn = mutual_info_classif(X, y, discrete_features=[2],","166","                                    n_neighbors=n_neighbors, random_state=0)","167","        # Check that the continuous values have an higher MI with greater","168","        # n_neighbors","169","        assert_greater(mi_nn[0], mi[0])","170","        assert_greater(mi_nn[1], mi[1])","171","        # The n_neighbors should not have any effect on the discrete value","172","        # The MI should be the same","173","        assert_equal(mi_nn[2], mi[2])"],"delete":["7","                                   assert_false, assert_raises, assert_equal)","160","    mi = mutual_info_classif(X, y, discrete_features=[2], random_state=0)"]}],"sklearn\/feature_selection\/mutual_info_.py":[{"add":["283","    mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for"],"delete":["283","    mi = [_compute_mi(x, y, discrete_feature, discrete_target) for"]}]}},"511c9a8655c1360189233e788ac2d7c3e74f7b5c":{"changes":{"sklearn\/model_selection\/_split.py":"MODIFY","sklearn\/model_selection\/tests\/test_split.py":"MODIFY","doc\/modules\/cross_validation.rst":"MODIFY"},"diff":{"sklearn\/model_selection\/_split.py":[{"add":["675","    max_train_size : int, optional","676","        Maximum size for a single training set.","677","","685","    TimeSeriesSplit(max_train_size=None, n_splits=3)","701","    def __init__(self, n_splits=3, max_train_size=None):","705","        self.max_train_size = max_train_size","744","            if self.max_train_size and self.max_train_size < test_start:","745","                yield (indices[test_start - self.max_train_size:test_start],","746","                       indices[test_start:test_start + test_size])","747","            else:","748","                yield (indices[:test_start],","749","                       indices[test_start:test_start + test_size])"],"delete":["682","    TimeSeriesSplit(n_splits=3)","698","    def __init__(self, n_splits=3):","740","            yield (indices[:test_start],","741","                   indices[test_start:test_start + test_size])"]}],"sklearn\/model_selection\/tests\/test_split.py":[{"add":["236","    (ValueError, next, KFold(4).split(X1))","1291","def _check_time_series_max_train_size(splits, check_splits, max_train_size):","1292","    for (train, test), (check_train, check_test) in zip(splits, check_splits):","1293","        assert_array_equal(test, check_test)","1294","        assert_true(len(check_train) <= max_train_size)","1295","        suffix_start = max(len(train) - max_train_size, 0)","1296","        assert_array_equal(check_train, train[suffix_start:])","1297","","1298","","1299","def test_time_series_max_train_size():","1300","    X = np.zeros((6, 1))","1301","    splits = TimeSeriesSplit(n_splits=3).split(X)","1302","    check_splits = TimeSeriesSplit(n_splits=3, max_train_size=3).split(X)","1303","    _check_time_series_max_train_size(splits, check_splits, max_train_size=3)","1304","","1305","    # Test for the case where the size of a fold is greater than max_train_size","1306","    check_splits = TimeSeriesSplit(n_splits=3, max_train_size=2).split(X)","1307","    _check_time_series_max_train_size(splits, check_splits, max_train_size=2)","1308","","1309","    # Test for the case where the size of each fold is less than max_train_size","1310","    check_splits = TimeSeriesSplit(n_splits=3, max_train_size=5).split(X)","1311","    _check_time_series_max_train_size(splits, check_splits, max_train_size=2)","1312","","1313",""],"delete":["236","    assert_raises(ValueError, next, KFold(4).split(X1))"]}],"doc\/modules\/cross_validation.rst":[{"add":["466","","603","Time series data is characterised by the correlation between observations","604","that are near in time (*autocorrelation*). However, classical","605","cross-validation techniques such as :class:`KFold` and","606",":class:`ShuffleSplit` assume the samples are independent and","607","identically distributed, and would result in unreasonable correlation","608","between training and testing instances (yielding poor estimates of","609","generalisation error) on time series data. Therefore, it is very important","610","to evaluate our model for time series data on the \"future\" observations","611","least like those that are used to train the model. To achieve this, one","618",":class:`TimeSeriesSplit` is a variation of *k-fold* which","619","returns first :math:`k` folds as train set and the :math:`(k+1)` th","620","fold as test set. Note that unlike standard cross-validation methods,","625","This class can be used to cross-validate time series data samples","636","  TimeSeriesSplit(max_train_size=None, n_splits=3)"],"delete":["466"," ","603","Time series data is characterised by the correlation between observations ","604","that are near in time (*autocorrelation*). However, classical ","605","cross-validation techniques such as :class:`KFold` and ","606",":class:`ShuffleSplit` assume the samples are independent and ","607","identically distributed, and would result in unreasonable correlation ","608","between training and testing instances (yielding poor estimates of ","609","generalisation error) on time series data. Therefore, it is very important ","610","to evaluate our model for time series data on the \"future\" observations ","611","least like those that are used to train the model. To achieve this, one ","618",":class:`TimeSeriesSplit` is a variation of *k-fold* which ","619","returns first :math:`k` folds as train set and the :math:`(k+1)` th ","620","fold as test set. Note that unlike standard cross-validation methods, ","625","This class can be used to cross-validate time series data samples ","636","  TimeSeriesSplit(n_splits=3)"]}]}},"bd0fc236e00c57b9a5212e8802c325c99af7b1b4":{"changes":{"sklearn\/neural_network\/_base.py":"MODIFY","examples\/cluster\/plot_face_ward_segmentation.py":"MODIFY","sklearn\/naive_bayes.py":"MODIFY","sklearn\/covariance\/graph_lasso_.py":"MODIFY","sklearn\/mixture\/base.py":"MODIFY","sklearn\/covariance\/empirical_covariance_.py":"MODIFY","sklearn\/neighbors\/tests\/test_dist_metrics.py":"MODIFY","sklearn\/neural_network\/rbm.py":"MODIFY","sklearn\/utils\/tests\/test_utils.py":"MODIFY","sklearn\/metrics\/ranking.py":"MODIFY","sklearn\/linear_model\/bayes.py":"MODIFY","sklearn\/model_selection\/_search.py":"MODIFY","sklearn\/mixture\/gmm.py":"MODIFY","sklearn\/cluster\/hierarchical.py":"MODIFY","sklearn\/linear_model\/logistic.py":"MODIFY","sklearn\/linear_model\/omp.py":"MODIFY","examples\/cluster\/plot_face_segmentation.py":"MODIFY","examples\/linear_model\/plot_sparse_recovery.py":"MODIFY","sklearn\/feature_selection\/univariate_selection.py":"MODIFY","sklearn\/cluster\/mean_shift_.py":"MODIFY","sklearn\/feature_extraction\/tests\/test_image.py":"MODIFY","sklearn\/utils\/arpack.py":"MODIFY","sklearn\/utils\/sparsetools\/__init__.py":"MODIFY","sklearn\/utils\/fixes.py":"MODIFY","sklearn\/linear_model\/tests\/test_logistic.py":"MODIFY","sklearn\/utils\/tests\/test_fixes.py":"MODIFY","sklearn\/utils\/stats.py":"MODIFY","sklearn\/decomposition\/online_lda.py":"MODIFY","sklearn\/utils\/tests\/test_stats.py":"MODIFY","sklearn\/cluster\/spectral.py":"MODIFY","sklearn\/covariance\/robust_covariance.py":"MODIFY","sklearn\/utils\/graph.py":"MODIFY","sklearn\/cluster\/_k_means.pyx":"MODIFY","doc\/developers\/utilities.rst":"MODIFY","sklearn\/mixture\/dpgmm.py":"MODIFY","sklearn\/manifold\/spectral_embedding_.py":"MODIFY","sklearn\/utils\/extmath.py":"MODIFY","examples\/decomposition\/plot_image_denoising.py":"MODIFY","sklearn\/decomposition\/pca.py":"MODIFY","sklearn\/utils\/tests\/test_extmath.py":"MODIFY","examples\/cluster\/plot_face_compress.py":"MODIFY","sklearn\/decomposition\/truncated_svd.py":"MODIFY","sklearn\/cluster\/bicluster.py":"MODIFY","\/dev\/null":"DELETE","sklearn\/ensemble\/gradient_boosting.py":"MODIFY","sklearn\/utils\/sparsetools\/setup.py":"MODIFY","sklearn\/linear_model\/tests\/test_sag.py":"MODIFY","sklearn\/manifold\/locally_linear.py":"MODIFY","sklearn\/cross_decomposition\/pls_.py":"MODIFY","sklearn\/decomposition\/kernel_pca.py":"MODIFY","sklearn\/linear_model\/least_angle.py":"MODIFY"},"diff":{"sklearn\/neural_network\/_base.py":[{"add":["8","from scipy.special import expit as logistic_sigmoid"],"delete":["8","from ..utils.fixes import expit as logistic_sigmoid"]}],"examples\/cluster\/plot_face_ward_segmentation.py":[{"add":["29","try:  # SciPy >= 0.16 have face in misc","30","    from scipy.misc import face","31","    face = face(gray=True)","32","except ImportError:"],"delete":["25","from sklearn.utils.testing import SkipTest","26","from sklearn.utils.fixes import sp_version","27","","28","if sp_version < (0, 12):","29","    raise SkipTest(\"Skipping because SciPy version earlier than 0.12.0 and \"","30","                   \"thus does not include the scipy.misc.face() image.\")","35","try:","37","except AttributeError:","38","    # Newer versions of scipy have face in misc","39","    from scipy import misc","40","    face = misc.face(gray=True)"]}],"sklearn\/naive_bayes.py":[{"add":["21","from scipy.misc import logsumexp","29","from .utils.extmath import safe_sparse_dot"],"delete":["28","from .utils.extmath import safe_sparse_dot, logsumexp"]}],"sklearn\/covariance\/graph_lasso_.py":[{"add":["192","    precision_ = linalg.pinvh(covariance_)"],"delete":["19","from ..utils.extmath import pinvh","193","    precision_ = pinvh(covariance_)"]}],"sklearn\/mixture\/base.py":[{"add":["13","from scipy.misc import logsumexp"],"delete":["20","from ..utils.extmath import logsumexp"]}],"sklearn\/covariance\/empirical_covariance_.py":[{"add":["19","from ..utils.extmath import fast_logdet","135","            self.precision_ = linalg.pinvh(covariance)","151","            precision = linalg.pinvh(self.covariance_)"],"delete":["19","from ..utils.extmath import fast_logdet, pinvh","135","            self.precision_ = pinvh(covariance)","151","            precision = pinvh(self.covariance_)"]}],"sklearn\/neighbors\/tests\/test_dist_metrics.py":[{"add":["9","from sklearn.utils.testing import assert_raises_regex"],"delete":["6","import scipy","10","from sklearn.utils.testing import SkipTest, assert_raises_regex","17","def cmp_version(version1, version2):","18","    version1 = tuple(map(int, version1.split('.')[:2]))","19","    version2 = tuple(map(int, version2.split('.')[:2]))","20","","21","    if version1 < version2:","22","        return -1","23","    elif version1 > version2:","24","        return 1","25","    else:","26","        return 0","27","","28","","72","        if metric == 'canberra' and cmp_version(scipy.__version__, '0.9') <= 0:","73","            raise SkipTest(\"Canberra distance incorrect in scipy < 0.9\")","96","        if metric == 'canberra' and cmp_version(scipy.__version__, '0.9') <= 0:","97","            raise SkipTest(\"Canberra distance incorrect in scipy < 0.9\")"]}],"sklearn\/neural_network\/rbm.py":[{"add":["13","from scipy.special import expit  # logistic function"],"delete":["23","from ..utils.fixes import expit             # logistic function"]}],"sklearn\/utils\/tests\/test_utils.py":[{"add":["0","from itertools import chain","10","                                   assert_greater_equal, ignore_warnings)","105","@ignore_warnings  # Test deprecated backport to be removed in 0.21","113","@ignore_warnings  # Test deprecated backport to be removed in 0.21","125","@ignore_warnings  # Test deprecated backport to be removed in 0.21","134","@ignore_warnings  # Test deprecated backport to be removed in 0.21","148","    v0 = random_state.uniform(-1, 1, A.shape[0])","263","    joined_range = list(chain(*[some_range[slice] for slice in","264","                                gen_even_slices(10, 3)]))"],"delete":["5","from itertools import chain","10","                                   assert_greater_equal)","11","","145","    v0 = random_state.uniform(-1,1, A.shape[0])","260","    joined_range = list(chain(*[some_range[slice] for slice in gen_even_slices(10, 3)]))"]}],"sklearn\/metrics\/ranking.py":[{"add":["24","from scipy.stats import rankdata"],"delete":["32","from ..utils.stats import rankdata"]}],"sklearn\/linear_model\/bayes.py":[{"add":["11","from scipy.linalg import pinvh","15","from ..utils.extmath import fast_logdet"],"delete":["14","from ..utils.extmath import fast_logdet, pinvh"]}],"sklearn\/model_selection\/_search.py":[{"add":["21","from scipy.stats import rankdata"],"delete":["31","from ..utils.fixes import rankdata"]}],"sklearn\/mixture\/gmm.py":[{"add":["17","from time import time","21","from scipy.misc import logsumexp"],"delete":["20","from time import time","24","from ..utils.extmath import logsumexp"]}],"sklearn\/cluster\/hierarchical.py":[{"add":["14","from scipy.sparse.csgraph import connected_components"],"delete":["20","from ..utils.sparsetools import connected_components"]}],"sklearn\/linear_model\/logistic.py":[{"add":["17","from scipy.misc import logsumexp","18","from scipy.special import expit","26","from ..utils.extmath import (log_logistic, safe_sparse_dot, softmax,","27","                             squared_norm)"],"delete":["24","from ..utils.extmath import (logsumexp, log_logistic, safe_sparse_dot,","25","                             softmax, squared_norm)","30","from ..utils.fixes import expit"]}],"sklearn\/linear_model\/omp.py":[{"add":["19","solve_triangular_args = {'check_finite': False}"],"delete":["8","from distutils.version import LooseVersion","20","import scipy","21","solve_triangular_args = {}","22","if LooseVersion(scipy.__version__) >= LooseVersion('0.12'):","23","    # check_finite=False is an optimization available only in scipy >=0.12","24","    solve_triangular_args = {'check_finite': False}","25",""]}],"examples\/cluster\/plot_face_segmentation.py":[{"add":["35","try:  # SciPy >= 0.16 have face in misc","36","    from scipy.misc import face","37","    face = face(gray=True)","38","except ImportError:"],"delete":["32","from sklearn.utils.testing import SkipTest","33","from sklearn.utils.fixes import sp_version","34","","35","if sp_version < (0, 12):","36","    raise SkipTest(\"Skipping because SciPy version earlier than 0.12.0 and \"","37","                   \"thus does not include the scipy.misc.face() image.\")","41","try:","43","except AttributeError:","44","    # Newer versions of scipy have face in misc","45","    from scipy import misc","46","    face = misc.face(gray=True)"]}],"examples\/linear_model\/plot_sparse_recovery.py":[{"add":["64","                       linalg.pinvh(np.dot(X_relevant.T, X_relevant)))"],"delete":["57","from sklearn.utils.extmath import pinvh","65","                       pinvh(np.dot(X_relevant.T, X_relevant)))"]}],"sklearn\/feature_selection\/univariate_selection.py":[{"add":["17","from ..utils.extmath import safe_sparse_dot, row_norms","298","    corr \/= np.linalg.norm(y)"],"delete":["17","from ..utils.extmath import norm, safe_sparse_dot, row_norms","298","    corr \/= norm(y)"]}],"sklearn\/cluster\/mean_shift_.py":[{"add":["22","from ..utils import check_random_state, gen_batches, check_array","98","        if (np.linalg.norm(my_mean - my_old_mean) < stop_thresh or"],"delete":["22","from ..utils import extmath, check_random_state, gen_batches, check_array","98","        if (extmath.norm(my_mean - my_old_mean) < stop_thresh or"]}],"sklearn\/feature_extraction\/tests\/test_image.py":[{"add":["7","from scipy.sparse.csgraph import connected_components","14","from sklearn.utils.testing import assert_equal, assert_true"],"delete":["13","from sklearn.utils.graph import connected_components","14","from sklearn.utils.testing import SkipTest, assert_equal, assert_true","15","from sklearn.utils.fixes import sp_version","16","","17","if sp_version < (0, 12):","18","    raise SkipTest(\"Skipping because SciPy version earlier than 0.12.0 and \"","19","                   \"thus does not include the scipy.misc.face() image.\")"]}],"sklearn\/utils\/arpack.py":[{"add":["0","# Remove this module in version 0.21","2","from scipy.sparse.linalg import eigs as _eigs, eigsh as _eigsh, svds as _svds","4","from .deprecation import deprecated","7","@deprecated(\"sklearn.utils.arpack.eigs was deprecated in version 0.19 and\"","8","            \"will be removed in 0.21. Use scipy.sparse.linalg.eigs instead.\")","9","def eigs(A, *args, **kwargs):","10","    return _eigs(A, *args, **kwargs)","13","@deprecated(\"sklearn.utils.arpack.eigsh was deprecated in version 0.19 and\"","14","            \"will be removed in 0.21. Use scipy.sparse.linalg.eigsh instead.\")","15","def eigsh(A, *args, **kwargs):","16","    return _eigsh(A, *args, **kwargs)","19","@deprecated(\"sklearn.utils.arpack.svds was deprecated in version 0.19 and\"","20","            \"will be removed in 0.21. Use scipy.sparse.linalg.svds instead.\")","21","def svds(A, *args, **kwargs):","22","    return _svds(A, *args, **kwargs)"],"delete":["0","\"\"\"","1","This contains a copy of the future version of","2","scipy.sparse.linalg.eigen.arpack.eigsh","3","It's an upgraded wrapper of the ARPACK library which","4","allows the use of shift-invert mode for symmetric matrices.","7","Find a few eigenvectors and eigenvalues of a matrix.","10","Uses ARPACK: http:\/\/www.caam.rice.edu\/software\/ARPACK\/","12","\"\"\"","13","# Wrapper implementation notes","14","#","15","# ARPACK Entry Points","16","# -------------------","17","# The entry points to ARPACK are","18","# - (s,d)seupd : single and double precision symmetric matrix","19","# - (s,d,c,z)neupd: single,double,complex,double complex general matrix","20","# This wrapper puts the *neupd (general matrix) interfaces in eigs()","21","# and the *seupd (symmetric matrix) in eigsh().","22","# There is no Hermetian complex\/double complex interface.","23","# To find eigenvalues of a Hermetian matrix you","24","# must use eigs() and not eigsh()","25","# It might be desirable to handle the Hermetian case differently","26","# and, for example, return real eigenvalues.","28","# Number of eigenvalues returned and complex eigenvalues","29","# ------------------------------------------------------","30","# The ARPACK nonsymmetric real and double interface (s,d)naupd return","31","# eigenvalues and eigenvectors in real (float,double) arrays.","32","# Since the eigenvalues and eigenvectors are, in general, complex","33","# ARPACK puts the real and imaginary parts in consecutive entries","34","# in real-valued arrays.   This wrapper puts the real entries","35","# into complex data types and attempts to return the requested eigenvalues","36","# and eigenvectors.","39","# Solver modes","40","# ------------","41","# ARPACK and handle shifted and shift-inverse computations","42","# for eigenvalues by providing a shift (sigma) and a solver.","43","","44","from scipy.sparse.linalg.eigen.arpack import _arpack","45","import numpy as np","46","from scipy.sparse.linalg.interface import aslinearoperator, LinearOperator","47","from scipy.sparse import identity, isspmatrix, isspmatrix_csr","48","from scipy.linalg import lu_factor, lu_solve","49","from scipy.sparse.sputils import isdense","50","from scipy.sparse.linalg import gmres, splu","51","import scipy","52","import functools","53","import operator","54","from distutils.version import LooseVersion","55","","56","__docformat__ = \"restructuredtext en\"","57","","58","__all__ = ['eigs', 'eigsh', 'svds', 'ArpackError', 'ArpackNoConvergence']","59","","60","_type_conv = {'f': 's', 'd': 'd', 'F': 'c', 'D': 'z'}","61","_ndigits = {'f': 5, 'd': 12, 'F': 5, 'D': 12}","62","","63","DNAUPD_ERRORS = {","64","    0: \"Normal exit.\",","65","    1: \"Maximum number of iterations taken. \"","66","       \"All possible eigenvalues of OP has been found. IPARAM(5) \"","67","       \"returns the number of wanted converged Ritz values.\",","68","    2: \"No longer an informational error. Deprecated starting \"","69","       \"with release 2 of ARPACK.\",","70","    3: \"No shifts could be applied during a cycle of the \"","71","       \"Implicitly restarted Arnoldi iteration. One possibility \"","72","       \"is to increase the size of NCV relative to NEV. \",","73","    -1: \"N must be positive.\",","74","    -2: \"NEV must be positive.\",","75","    -3: \"NCV-NEV >= 2 and less than or equal to N.\",","76","    -4: \"The maximum number of Arnoldi update iterations allowed \"","77","        \"must be greater than zero.\",","78","    -5: \" WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\",","79","    -6: \"BMAT must be one of 'I' or 'G'.\",","80","    -7: \"Length of private work array WORKL is not sufficient.\",","81","    -8: \"Error return from LAPACK eigenvalue calculation;\",","82","    -9: \"Starting vector is zero.\",","83","    -10: \"IPARAM(7) must be 1,2,3,4.\",","84","    -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\",","85","    -12: \"IPARAM(1) must be equal to 0 or 1.\",","86","    -13: \"NEV and WHICH = 'BE' are incompatible.\",","87","    -9999: \"Could not build an Arnoldi factorization. \"","88","           \"IPARAM(5) returns the size of the current Arnoldi \"","89","           \"factorization. The user is advised to check that \"","90","           \"enough workspace and array storage has been allocated.\"","91","}","92","","93","SNAUPD_ERRORS = DNAUPD_ERRORS","94","","95","ZNAUPD_ERRORS = DNAUPD_ERRORS.copy()","96","ZNAUPD_ERRORS[-10] = \"IPARAM(7) must be 1,2,3.\"","97","","98","CNAUPD_ERRORS = ZNAUPD_ERRORS","99","","100","DSAUPD_ERRORS = {","101","    0: \"Normal exit.\",","102","    1: \"Maximum number of iterations taken. \"","103","       \"All possible eigenvalues of OP has been found.\",","104","    2: \"No longer an informational error. Deprecated starting with \"","105","       \"release 2 of ARPACK.\",","106","    3: \"No shifts could be applied during a cycle of the Implicitly \"","107","       \"restarted Arnoldi iteration. One possibility is to increase \"","108","       \"the size of NCV relative to NEV. \",","109","    -1: \"N must be positive.\",","110","    -2: \"NEV must be positive.\",","111","    -3: \"NCV must be greater than NEV and less than or equal to N.\",","112","    -4: \"The maximum number of Arnoldi update iterations allowed \"","113","        \"must be greater than zero.\",","114","    -5: \"WHICH must be one of 'LM', 'SM', 'LA', 'SA' or 'BE'.\",","115","    -6: \"BMAT must be one of 'I' or 'G'.\",","116","    -7: \"Length of private work array WORKL is not sufficient.\",","117","    -8: \"Error return from trid. eigenvalue calculation; \"","118","        \"Informational error from LAPACK routine dsteqr .\",","119","    -9: \"Starting vector is zero.\",","120","    -10: \"IPARAM(7) must be 1,2,3,4,5.\",","121","    -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\",","122","    -12: \"IPARAM(1) must be equal to 0 or 1.\",","123","    -13: \"NEV and WHICH = 'BE' are incompatible. \",","124","    -9999: \"Could not build an Arnoldi factorization. \"","125","           \"IPARAM(5) returns the size of the current Arnoldi \"","126","           \"factorization. The user is advised to check that \"","127","           \"enough workspace and array storage has been allocated.\",","128","}","129","","130","SSAUPD_ERRORS = DSAUPD_ERRORS","131","","132","DNEUPD_ERRORS = {","133","    0: \"Normal exit.\",","134","    1: \"The Schur form computed by LAPACK routine dlahqr \"","135","       \"could not be reordered by LAPACK routine dtrsen. \"","136","       \"Re-enter subroutine dneupd  with IPARAM(5)NCV and \"","137","       \"increase the size of the arrays DR and DI to have \"","138","       \"dimension at least dimension NCV and allocate at least NCV \"","139","       \"columns for Z. NOTE: Not necessary if Z and V share \"","140","       \"the same space. Please notify the authors if this error\"","141","       \"occurs.\",","142","    -1: \"N must be positive.\",","143","    -2: \"NEV must be positive.\",","144","    -3: \"NCV-NEV >= 2 and less than or equal to N.\",","145","    -5: \"WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\",","146","    -6: \"BMAT must be one of 'I' or 'G'.\",","147","    -7: \"Length of private work WORKL array is not sufficient.\",","148","    -8: \"Error return from calculation of a real Schur form. \"","149","        \"Informational error from LAPACK routine dlahqr .\",","150","    -9: \"Error return from calculation of eigenvectors. \"","151","        \"Informational error from LAPACK routine dtrevc.\",","152","    -10: \"IPARAM(7) must be 1,2,3,4.\",","153","    -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\",","154","    -12: \"HOWMNY = 'S' not yet implemented\",","155","    -13: \"HOWMNY must be one of 'A' or 'P' if RVEC = .true.\",","156","    -14: \"DNAUPD  did not find any eigenvalues to sufficient \"","157","         \"accuracy.\",","158","    -15: \"DNEUPD got a different count of the number of converged \"","159","         \"Ritz values than DNAUPD got.  This indicates the user \"","160","         \"probably made an error in passing data from DNAUPD to \"","161","         \"DNEUPD or that the data was modified before entering \"","162","         \"DNEUPD\",","163","}","164","","165","SNEUPD_ERRORS = DNEUPD_ERRORS.copy()","166","SNEUPD_ERRORS[1] = (\"The Schur form computed by LAPACK routine slahqr \"","167","                    \"could not be reordered by LAPACK routine strsen . \"","168","                    \"Re-enter subroutine dneupd  with IPARAM(5)=NCV and \"","169","                    \"increase the size of the arrays DR and DI to have \"","170","                    \"dimension at least dimension NCV and allocate at least \"","171","                    \"NCV columns for Z. NOTE: Not necessary if Z and V share \"","172","                    \"the same space. Please notify the authors if this error \"","173","                    \"occurs.\")","174","SNEUPD_ERRORS[-14] = (\"SNAUPD did not find any eigenvalues to sufficient \"","175","                      \"accuracy.\")","176","SNEUPD_ERRORS[-15] = (\"SNEUPD got a different count of the number of \"","177","                      \"converged Ritz values than SNAUPD got.  This indicates \"","178","                      \"the user probably made an error in passing data from \"","179","                      \"SNAUPD to SNEUPD or that the data was modified before \"","180","                      \"entering SNEUPD\")","181","","182","ZNEUPD_ERRORS = {0: \"Normal exit.\",","183","                 1: \"The Schur form computed by LAPACK routine csheqr \"","184","                    \"could not be reordered by LAPACK routine ztrsen. \"","185","                    \"Re-enter subroutine zneupd with IPARAM(5)=NCV and \"","186","                    \"increase the size of the array D to have \"","187","                    \"dimension at least dimension NCV and allocate at least \"","188","                    \"NCV columns for Z. NOTE: Not necessary if Z and V share \"","189","                    \"the same space. Please notify the authors if this error \"","190","                    \"occurs.\",","191","                 -1: \"N must be positive.\",","192","                 -2: \"NEV must be positive.\",","193","                 -3: \"NCV-NEV >= 1 and less than or equal to N.\",","194","                 -5: \"WHICH must be one of 'LM', 'SM', 'LR', 'SR', 'LI', 'SI'\",","195","                 -6: \"BMAT must be one of 'I' or 'G'.\",","196","                 -7: \"Length of private work WORKL array is not sufficient.\",","197","                 -8: \"Error return from LAPACK eigenvalue calculation. \"","198","                     \"This should never happened.\",","199","                 -9: \"Error return from calculation of eigenvectors. \"","200","                     \"Informational error from LAPACK routine ztrevc.\",","201","                 -10: \"IPARAM(7) must be 1,2,3\",","202","                 -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\",","203","                 -12: \"HOWMNY = 'S' not yet implemented\",","204","                 -13: \"HOWMNY must be one of 'A' or 'P' if RVEC = .true.\",","205","                 -14: \"ZNAUPD did not find any eigenvalues to sufficient \"","206","                      \"accuracy.\",","207","                 -15: \"ZNEUPD got a different count of the number of \"","208","                      \"converged Ritz values than ZNAUPD got.  This \"","209","                      \"indicates the user probably made an error in passing \"","210","                      \"data from ZNAUPD to ZNEUPD or that the data was \"","211","                      \"modified before entering ZNEUPD\"","212","                 }","213","","214","CNEUPD_ERRORS = ZNEUPD_ERRORS.copy()","215","CNEUPD_ERRORS[-14] = (\"CNAUPD did not find any eigenvalues to sufficient \"","216","                      \"accuracy.\")","217","CNEUPD_ERRORS[-15] = (\"CNEUPD got a different count of the number of \"","218","                      \"converged Ritz values than CNAUPD got.  This indicates \"","219","                      \"the user probably made an error in passing data from \"","220","                      \"CNAUPD to CNEUPD or that the data was modified before \"","221","                      \"entering CNEUPD\")","222","","223","DSEUPD_ERRORS = {","224","    0: \"Normal exit.\",","225","    -1: \"N must be positive.\",","226","    -2: \"NEV must be positive.\",","227","    -3: \"NCV must be greater than NEV and less than or equal to N.\",","228","    -5: \"WHICH must be one of 'LM', 'SM', 'LA', 'SA' or 'BE'.\",","229","    -6: \"BMAT must be one of 'I' or 'G'.\",","230","    -7: \"Length of private work WORKL array is not sufficient.\",","231","    -8: (\"Error return from trid. eigenvalue calculation; \"","232","         \"Information error from LAPACK routine dsteqr.\"),","233","    -9: \"Starting vector is zero.\",","234","    -10: \"IPARAM(7) must be 1,2,3,4,5.\",","235","    -11: \"IPARAM(7) = 1 and BMAT = 'G' are incompatible.\",","236","    -12: \"NEV and WHICH = 'BE' are incompatible.\",","237","    -14: \"DSAUPD  did not find any eigenvalues to sufficient accuracy.\",","238","    -15: \"HOWMNY must be one of 'A' or 'S' if RVEC = .true.\",","239","    -16: \"HOWMNY = 'S' not yet implemented\",","240","    -17: (\"DSEUPD  got a different count of the number of converged \"","241","          \"Ritz values than DSAUPD  got.  This indicates the user \"","242","          \"probably made an error in passing data from DSAUPD  to \"","243","          \"DSEUPD  or that the data was modified before entering  \"","244","          \"DSEUPD.\")","245","}","246","","247","SSEUPD_ERRORS = DSEUPD_ERRORS.copy()","248","SSEUPD_ERRORS[-14] = (\"SSAUPD  did not find any eigenvalues \"","249","                      \"to sufficient accuracy.\")","250","SSEUPD_ERRORS[-17] = (\"SSEUPD  got a different count of the number of \"","251","                      \"converged \"","252","                      \"Ritz values than SSAUPD  got.  This indicates the user \"","253","                      \"probably made an error in passing data from SSAUPD  to \"","254","                      \"SSEUPD  or that the data was modified before entering  \"","255","                      \"SSEUPD.\")","256","","257","_SAUPD_ERRORS = {'d': DSAUPD_ERRORS,","258","                 's': SSAUPD_ERRORS}","259","_NAUPD_ERRORS = {'d': DNAUPD_ERRORS,","260","                 's': SNAUPD_ERRORS,","261","                 'z': ZNAUPD_ERRORS,","262","                 'c': CNAUPD_ERRORS}","263","_SEUPD_ERRORS = {'d': DSEUPD_ERRORS,","264","                 's': SSEUPD_ERRORS}","265","_NEUPD_ERRORS = {'d': DNEUPD_ERRORS,","266","                 's': SNEUPD_ERRORS,","267","                 'z': ZNEUPD_ERRORS,","268","                 'c': CNEUPD_ERRORS}","269","","270","# accepted values of parameter WHICH in _SEUPD","271","_SEUPD_WHICH = ['LM', 'SM', 'LA', 'SA', 'BE']","272","","273","# accepted values of parameter WHICH in _NAUPD","274","_NEUPD_WHICH = ['LM', 'SM', 'LR', 'SR', 'LI', 'SI']","275","","276","","277","# CHECK IF BACKPORT IS ACTUALLY NEEDED","278","if scipy.version.version >= LooseVersion('0.12'):","279","    BACKPORT_TO = None","280","elif scipy.version.version >= LooseVersion('0.11'):","281","    BACKPORT_TO = '0.10'","282","else:","283","    BACKPORT_TO = '0.09'","284","","285","","286","# redefinition of the function from `scipy._lib._util._aligned_zeros`","287","def _aligned_zeros(shape, dtype=float, order=\"C\", align=None):","288","    \"\"\"Allocate a new ndarray with aligned memory.","289","    Primary use case for this currently is working around a f2py issue","290","    in Numpy 1.9.1, where dtype.alignment is such that np.zeros() does","291","    not necessarily create arrays aligned up to it.","292","    \"\"\"","293","    dtype = np.dtype(dtype)","294","    if align is None:","295","        align = dtype.alignment","296","    if not hasattr(shape, '__len__'):","297","        shape = (shape,)","298","    size = functools.reduce(operator.mul, shape) * dtype.itemsize","299","    buf = np.empty(size + align + 1, np.uint8)","300","    offset = buf.__array_interface__['data'][0] % align","301","    if offset != 0:","302","        offset = align - offset","303","    # Note: slices producing 0-size arrays do not necessarily change","304","    # data pointer --- so we use and allocate size+1","305","    buf = buf[offset:offset+size+1][:-1]","306","    data = np.ndarray(shape, dtype, buf, order=order)","307","    data.fill(0)","308","    return data","309","","310","","311","class ArpackError(RuntimeError):","312","    \"\"\"","313","    ARPACK error","314","    \"\"\"","315","    def __init__(self, info, infodict=_NAUPD_ERRORS):","316","        msg = infodict.get(info, \"Unknown error\")","317","        RuntimeError.__init__(self, \"ARPACK error %d: %s\" % (info, msg))","318","","319","","320","class ArpackNoConvergence(ArpackError):","321","    \"\"\"","322","    ARPACK iteration did not converge","323","","324","    Attributes","325","    ----------","326","    eigenvalues : ndarray","327","        Partial result. Converged eigenvalues.","328","    eigenvectors : ndarray","329","        Partial result. Converged eigenvectors.","330","","331","    \"\"\"","332","    def __init__(self, msg, eigenvalues, eigenvectors):","333","        ArpackError.__init__(self, -1, {-1: msg})","334","        self.eigenvalues = eigenvalues","335","        self.eigenvectors = eigenvectors","336","","337","","338","class _ArpackParams(object):","339","    def __init__(self, n, k, tp, mode=1, sigma=None,","340","                 ncv=None, v0=None, maxiter=None, which=\"LM\", tol=0):","341","        if k <= 0:","342","            raise ValueError(\"k must be positive, k=%d\" % k)","343","","344","        if maxiter is None:","345","            maxiter = n * 10","346","        if maxiter <= 0:","347","            raise ValueError(\"maxiter must be positive, maxiter=%d\" % maxiter)","348","","349","        if tp not in 'fdFD':","350","            raise ValueError(\"matrix type must be 'f', 'd', 'F', or 'D'\")","351","","352","        if v0 is not None:","353","            # ARPACK overwrites its initial resid,  make a copy","354","            self.resid = np.array(v0, copy=True)","355","            info = 1","356","        else:","357","            # ARPACK will use a random initial vector.","358","            self.resid = np.zeros(n, tp)","359","            info = 0","360","","361","        if sigma is None:","362","            # sigma not used","363","            self.sigma = 0","364","        else:","365","            self.sigma = sigma","366","","367","        if ncv is None:","368","            ncv = 2 * k + 1","369","        ncv = min(ncv, n)","370","","371","        self.v = np.zeros((n, ncv), tp)  # holds Ritz vectors","372","        self.iparam = np.zeros(11, \"int\")","373","","374","        # set solver mode and parameters","375","        ishfts = 1","376","        self.mode = mode","377","        self.iparam[0] = ishfts","378","        self.iparam[2] = maxiter","379","        self.iparam[3] = 1","380","        self.iparam[6] = mode","381","","382","        self.n = n","383","        self.tol = tol","384","        self.k = k","385","        self.maxiter = maxiter","386","        self.ncv = ncv","387","        self.which = which","388","        self.tp = tp","389","        self.info = info","390","","391","        self.converged = False","392","        self.ido = 0","393","","394","    def _raise_no_convergence(self):","395","        msg = \"No convergence (%d iterations, %d\/%d eigenvectors converged)\"","396","        k_ok = self.iparam[4]","397","        num_iter = self.iparam[2]","398","        try:","399","            ev, vec = self.extract(True)","400","        except ArpackError as err:","401","            msg = \"%s [%s]\" % (msg, err)","402","            ev = np.zeros((0,))","403","            vec = np.zeros((self.n, 0))","404","            k_ok = 0","405","        raise ArpackNoConvergence(msg % (num_iter, k_ok, self.k), ev, vec)","406","","407","","408","class _SymmetricArpackParams(_ArpackParams):","409","    def __init__(self, n, k, tp, matvec, mode=1, M_matvec=None,","410","                 Minv_matvec=None, sigma=None,","411","                 ncv=None, v0=None, maxiter=None, which=\"LM\", tol=0):","412","        # The following modes are supported:","413","        #  mode = 1:","414","        #    Solve the standard eigenvalue problem:","415","        #      A*x = lambda*x :","416","        #       A - symmetric","417","        #    Arguments should be","418","        #       matvec      = left multiplication by A","419","        #       M_matvec    = None [not used]","420","        #       Minv_matvec = None [not used]","421","        #","422","        #  mode = 2:","423","        #    Solve the general eigenvalue problem:","424","        #      A*x = lambda*M*x","425","        #       A - symmetric","426","        #       M - symmetric positive definite","427","        #    Arguments should be","428","        #       matvec      = left multiplication by A","429","        #       M_matvec    = left multiplication by M","430","        #       Minv_matvec = left multiplication by M^-1","431","        #","432","        #  mode = 3:","433","        #    Solve the general eigenvalue problem in shift-invert mode:","434","        #      A*x = lambda*M*x","435","        #       A - symmetric","436","        #       M - symmetric positive semi-definite","437","        #    Arguments should be","438","        #       matvec      = None [not used]","439","        #       M_matvec    = left multiplication by M","440","        #                     or None, if M is the identity","441","        #       Minv_matvec = left multiplication by [A-sigma*M]^-1","442","        #","443","        #  mode = 4:","444","        #    Solve the general eigenvalue problem in Buckling mode:","445","        #      A*x = lambda*AG*x","446","        #       A  - symmetric positive semi-definite","447","        #       AG - symmetric indefinite","448","        #    Arguments should be","449","        #       matvec      = left multiplication by A","450","        #       M_matvec    = None [not used]","451","        #       Minv_matvec = left multiplication by [A-sigma*AG]^-1","452","        #","453","        #  mode = 5:","454","        #    Solve the general eigenvalue problem in Cayley-transformed mode:","455","        #      A*x = lambda*M*x","456","        #       A - symmetric","457","        #       M - symmetric positive semi-definite","458","        #    Arguments should be","459","        #       matvec      = left multiplication by A","460","        #       M_matvec    = left multiplication by M","461","        #                     or None, if M is the identity","462","        #       Minv_matvec = left multiplication by [A-sigma*M]^-1","463","        if mode == 1:","464","            if matvec is None:","465","                raise ValueError(\"matvec must be specified for mode=1\")","466","            if M_matvec is not None:","467","                raise ValueError(\"M_matvec cannot be specified for mode=1\")","468","            if Minv_matvec is not None:","469","                raise ValueError(\"Minv_matvec cannot be specified for mode=1\")","470","","471","            self.OP = matvec","472","            self.B = lambda x: x","473","            self.bmat = 'I'","474","        elif mode == 2:","475","            if matvec is None:","476","                raise ValueError(\"matvec must be specified for mode=2\")","477","            if M_matvec is None:","478","                raise ValueError(\"M_matvec must be specified for mode=2\")","479","            if Minv_matvec is None:","480","                raise ValueError(\"Minv_matvec must be specified for mode=2\")","481","","482","            self.OP = lambda x: Minv_matvec(matvec(x))","483","            self.OPa = Minv_matvec","484","            self.OPb = matvec","485","            self.B = M_matvec","486","            self.bmat = 'G'","487","        elif mode == 3:","488","            if matvec is not None:","489","                raise ValueError(\"matvec must not be specified for mode=3\")","490","            if Minv_matvec is None:","491","                raise ValueError(\"Minv_matvec must be specified for mode=3\")","492","","493","            if M_matvec is None:","494","                self.OP = Minv_matvec","495","                self.OPa = Minv_matvec","496","                self.B = lambda x: x","497","                self.bmat = 'I'","498","            else:","499","                self.OP = lambda x: Minv_matvec(M_matvec(x))","500","                self.OPa = Minv_matvec","501","                self.B = M_matvec","502","                self.bmat = 'G'","503","        elif mode == 4:","504","            if matvec is None:","505","                raise ValueError(\"matvec must be specified for mode=4\")","506","            if M_matvec is not None:","507","                raise ValueError(\"M_matvec must not be specified for mode=4\")","508","            if Minv_matvec is None:","509","                raise ValueError(\"Minv_matvec must be specified for mode=4\")","510","            self.OPa = Minv_matvec","511","            self.OP = lambda x: self.OPa(matvec(x))","512","            self.B = matvec","513","            self.bmat = 'G'","514","        elif mode == 5:","515","            if matvec is None:","516","                raise ValueError(\"matvec must be specified for mode=5\")","517","            if Minv_matvec is None:","518","                raise ValueError(\"Minv_matvec must be specified for mode=5\")","519","","520","            self.OPa = Minv_matvec","521","            self.A_matvec = matvec","522","","523","            if M_matvec is None:","524","                self.OP = lambda x: Minv_matvec(matvec(x) + sigma * x)","525","                self.B = lambda x: x","526","                self.bmat = 'I'","527","            else:","528","                self.OP = lambda x: Minv_matvec(matvec(x) +","529","                                                sigma * M_matvec(x))","530","                self.B = M_matvec","531","                self.bmat = 'G'","532","        else:","533","            raise ValueError(\"mode=%i not implemented\" % mode)","534","","535","        if which not in _SEUPD_WHICH:","536","            raise ValueError(\"which must be one of %s\"","537","                             % ' '.join(_SEUPD_WHICH))","538","        if k >= n:","539","            raise ValueError(\"k must be less than ndim(A), k=%d\" % k)","540","","541","        _ArpackParams.__init__(self, n, k, tp, mode, sigma,","542","                               ncv, v0, maxiter, which, tol)","543","","544","        if self.ncv > n or self.ncv <= k:","545","            raise ValueError(\"ncv must be k<ncv<=n, ncv=%s\" % self.ncv)","546","","547","        # Use _aligned_zeros to work around a f2py bug in Numpy 1.9.1","548","        self.workd = _aligned_zeros(3 * n, self.tp)","549","        self.workl = _aligned_zeros(self.ncv * (self.ncv + 8), self.tp)","550","","551","        ltr = _type_conv[self.tp]","552","        if ltr not in [\"s\", \"d\"]:","553","            raise ValueError(\"Input matrix is not real-valued.\")","554","","555","        self._arpack_solver = _arpack.__dict__[ltr + 'saupd']","556","        self._arpack_extract = _arpack.__dict__[ltr + 'seupd']","557","","558","        self.iterate_infodict = _SAUPD_ERRORS[ltr]","559","        self.extract_infodict = _SEUPD_ERRORS[ltr]","560","","561","        self.ipntr = np.zeros(11, \"int\")","562","","563","    def iterate(self):","564","        if BACKPORT_TO is None:","565","            return None","566","        if BACKPORT_TO == '0.10':","567","            self.ido, self.tol, self.resid, self.v, self.iparam, self.ipntr, self.info = \\","568","                self._arpack_solver(self.ido, self.bmat, self.which, self.k,","569","                                    self.tol, self.resid, self.v, self.iparam,","570","                                    self.ipntr, self.workd, self.workl, self.info)","571","        elif BACKPORT_TO == '0.09':","572","            self.ido, self.resid, self.v, self.iparam, self.ipntr, self.info = \\","573","                self._arpack_solver(self.ido, self.bmat, self.which, self.k,","574","                                    self.tol, self.resid, self.v, self.iparam,","575","                                    self.ipntr, self.workd, self.workl, self.info)","576","","577","        xslice = slice(self.ipntr[0] - 1, self.ipntr[0] - 1 + self.n)","578","        yslice = slice(self.ipntr[1] - 1, self.ipntr[1] - 1 + self.n)","579","        if self.ido == -1:","580","            # initialization","581","            self.workd[yslice] = self.OP(self.workd[xslice])","582","        elif self.ido == 1:","583","            # compute y = Op*x","584","            if self.mode == 1:","585","                self.workd[yslice] = self.OP(self.workd[xslice])","586","            elif self.mode == 2:","587","                self.workd[xslice] = self.OPb(self.workd[xslice])","588","                self.workd[yslice] = self.OPa(self.workd[xslice])","589","            elif self.mode == 5:","590","                Bxslice = slice(self.ipntr[2] - 1, self.ipntr[2] - 1 + self.n)","591","                Ax = self.A_matvec(self.workd[xslice])","592","                self.workd[yslice] = self.OPa(Ax + (self.sigma *","593","                                                    self.workd[Bxslice]))","594","            else:","595","                Bxslice = slice(self.ipntr[2] - 1, self.ipntr[2] - 1 + self.n)","596","                self.workd[yslice] = self.OPa(self.workd[Bxslice])","597","        elif self.ido == 2:","598","            self.workd[yslice] = self.B(self.workd[xslice])","599","        elif self.ido == 3:","600","            raise ValueError(\"ARPACK requested user shifts.  Assure ISHIFT==0\")","601","        else:","602","            self.converged = True","603","","604","            if self.info == 0:","605","                pass","606","            elif self.info == 1:","607","                self._raise_no_convergence()","608","            else:","609","                raise ArpackError(self.info, infodict=self.iterate_infodict)","610","","611","    def extract(self, return_eigenvectors):","612","        rvec = return_eigenvectors","613","        ierr = 0","614","        howmny = 'A'  # return all eigenvectors","615","        sselect = np.zeros(self.ncv, 'int')  # unused","616","        d, z, ierr = self._arpack_extract(rvec, howmny, sselect, self.sigma,","617","                                          self.bmat, self.which, self.k,","618","                                          self.tol, self.resid, self.v,","619","                                          self.iparam[0:7], self.ipntr,","620","                                          self.workd[0:2 * self.n],","621","                                          self.workl, ierr)","622","        if ierr != 0:","623","            raise ArpackError(ierr, infodict=self.extract_infodict)","624","        k_ok = self.iparam[4]","625","        d = d[:k_ok]","626","        z = z[:, :k_ok]","627","","628","        if return_eigenvectors:","629","            return d, z","630","        else:","631","            return d","632","","633","","634","class _UnsymmetricArpackParams(_ArpackParams):","635","    def __init__(self, n, k, tp, matvec, mode=1, M_matvec=None,","636","                 Minv_matvec=None, sigma=None,","637","                 ncv=None, v0=None, maxiter=None, which=\"LM\", tol=0):","638","        # The following modes are supported:","639","        #  mode = 1:","640","        #    Solve the standard eigenvalue problem:","641","        #      A*x = lambda*x","642","        #       A - square matrix","643","        #    Arguments should be","644","        #       matvec      = left multiplication by A","645","        #       M_matvec    = None [not used]","646","        #       Minv_matvec = None [not used]","647","        #","648","        #  mode = 2:","649","        #    Solve the generalized eigenvalue problem:","650","        #      A*x = lambda*M*x","651","        #       A - square matrix","652","        #       M - symmetric, positive semi-definite","653","        #    Arguments should be","654","        #       matvec      = left multiplication by A","655","        #       M_matvec    = left multiplication by M","656","        #       Minv_matvec = left multiplication by M^-1","657","        #","658","        #  mode = 3,4:","659","        #    Solve the general eigenvalue problem in shift-invert mode:","660","        #      A*x = lambda*M*x","661","        #       A - square matrix","662","        #       M - symmetric, positive semi-definite","663","        #    Arguments should be","664","        #       matvec      = None [not used]","665","        #       M_matvec    = left multiplication by M","666","        #                     or None, if M is the identity","667","        #       Minv_matvec = left multiplication by [A-sigma*M]^-1","668","        #    if A is real and mode==3, use the real part of Minv_matvec","669","        #    if A is real and mode==4, use the imag part of Minv_matvec","670","        #    if A is complex and mode==3,","671","        #       use real and imag parts of Minv_matvec","672","        if mode == 1:","673","            if matvec is None:","674","                raise ValueError(\"matvec must be specified for mode=1\")","675","            if M_matvec is not None:","676","                raise ValueError(\"M_matvec cannot be specified for mode=1\")","677","            if Minv_matvec is not None:","678","                raise ValueError(\"Minv_matvec cannot be specified for mode=1\")","679","","680","            self.OP = matvec","681","            self.B = lambda x: x","682","            self.bmat = 'I'","683","        elif mode == 2:","684","            if matvec is None:","685","                raise ValueError(\"matvec must be specified for mode=2\")","686","            if M_matvec is None:","687","                raise ValueError(\"M_matvec must be specified for mode=2\")","688","            if Minv_matvec is None:","689","                raise ValueError(\"Minv_matvec must be specified for mode=2\")","690","","691","            self.OP = lambda x: Minv_matvec(matvec(x))","692","            self.OPa = Minv_matvec","693","            self.OPb = matvec","694","            self.B = M_matvec","695","            self.bmat = 'G'","696","        elif mode in (3, 4):","697","            if matvec is None:","698","                raise ValueError(\"matvec must be specified \"","699","                                 \"for mode in (3,4)\")","700","            if Minv_matvec is None:","701","                raise ValueError(\"Minv_matvec must be specified \"","702","                                 \"for mode in (3,4)\")","703","","704","            self.matvec = matvec","705","            if tp in 'DF':  # complex type","706","                if mode == 3:","707","                    self.OPa = Minv_matvec","708","                else:","709","                    raise ValueError(\"mode=4 invalid for complex A\")","710","            else:  # real type","711","                if mode == 3:","712","                    self.OPa = lambda x: np.real(Minv_matvec(x))","713","                else:","714","                    self.OPa = lambda x: np.imag(Minv_matvec(x))","715","            if M_matvec is None:","716","                self.B = lambda x: x","717","                self.bmat = 'I'","718","                self.OP = self.OPa","719","            else:","720","                self.B = M_matvec","721","                self.bmat = 'G'","722","                self.OP = lambda x: self.OPa(M_matvec(x))","723","        else:","724","            raise ValueError(\"mode=%i not implemented\" % mode)","725","","726","        if which not in _NEUPD_WHICH:","727","            raise ValueError(\"Parameter which must be one of %s\"","728","                             % ' '.join(_NEUPD_WHICH))","729","        if k >= n - 1:","730","            raise ValueError(\"k must be less than ndim(A)-1, k=%d\" % k)","731","","732","        _ArpackParams.__init__(self, n, k, tp, mode, sigma,","733","                               ncv, v0, maxiter, which, tol)","734","","735","        if self.ncv > n or self.ncv <= k + 1:","736","            raise ValueError(\"ncv must be k+1<ncv<=n, ncv=%s\" % self.ncv)","737","","738","        # Use _aligned_zeros to work around a f2py bug in Numpy 1.9.1","739","        self.workd = _aligned_zeros(3 * n, self.tp)","740","        self.workl = _aligned_zeros(3 * self.ncv * (self.ncv + 2), self.tp)","741","","742","        ltr = _type_conv[self.tp]","743","        self._arpack_solver = _arpack.__dict__[ltr + 'naupd']","744","        self._arpack_extract = _arpack.__dict__[ltr + 'neupd']","745","","746","        self.iterate_infodict = _NAUPD_ERRORS[ltr]","747","        self.extract_infodict = _NEUPD_ERRORS[ltr]","748","","749","        self.ipntr = np.zeros(14, \"int\")","750","","751","        if self.tp in 'FD':","752","            # Use _aligned_zeros to work around a f2py bug in Numpy 1.9.1","753","            self.rwork = _aligned_zeros(self.ncv, self.tp.lower())","754","        else:","755","            self.rwork = None","756","","757","    def iterate(self):","758","        if BACKPORT_TO is None:","759","            return None","760","        if BACKPORT_TO == '0.10':","761","            if self.tp in 'fd':","762","                self.ido, self.tol, self.resid, self.v, self.iparam, self.ipntr, self.info =\\","763","                    self._arpack_solver(self.ido, self.bmat, self.which, self.k,","764","                                        self.tol, self.resid, self.v, self.iparam,","765","                                        self.ipntr, self.workd, self.workl,","766","                                        self.info)","767","            else:","768","                self.ido, self.tol, self.resid, self.v, self.iparam, self.ipntr, self.info =\\","769","                    self._arpack_solver(self.ido, self.bmat, self.which, self.k,","770","                                        self.tol, self.resid, self.v, self.iparam,","771","                                        self.ipntr, self.workd, self.workl,","772","                                        self.rwork, self.info)","773","        elif BACKPORT_TO == '0.09':","774","            if self.tp in 'fd':","775","                self.ido, self.resid, self.v, self.iparam, self.ipntr, self.info =\\","776","                    self._arpack_solver(self.ido, self.bmat, self.which, self.k,","777","                                        self.tol, self.resid, self.v, self.iparam,","778","                                        self.ipntr, self.workd, self.workl,","779","                                        self.info)","780","            else:","781","                self.ido, self.resid, self.v, self.iparam, self.ipntr, self.info =\\","782","                    self._arpack_solver(self.ido, self.bmat, self.which, self.k,","783","                                        self.tol, self.resid, self.v, self.iparam,","784","                                        self.ipntr, self.workd, self.workl,","785","                                        self.rwork, self.info)","786","","787","        xslice = slice(self.ipntr[0] - 1, self.ipntr[0] - 1 + self.n)","788","        yslice = slice(self.ipntr[1] - 1, self.ipntr[1] - 1 + self.n)","789","        if self.ido == -1:","790","            # initialization","791","            self.workd[yslice] = self.OP(self.workd[xslice])","792","        elif self.ido == 1:","793","            # compute y = Op*x","794","            if self.mode in (1, 2):","795","                self.workd[yslice] = self.OP(self.workd[xslice])","796","            else:","797","                Bxslice = slice(self.ipntr[2] - 1, self.ipntr[2] - 1 + self.n)","798","                self.workd[yslice] = self.OPa(self.workd[Bxslice])","799","        elif self.ido == 2:","800","            self.workd[yslice] = self.B(self.workd[xslice])","801","        elif self.ido == 3:","802","            raise ValueError(\"ARPACK requested user shifts.  Assure ISHIFT==0\")","803","        else:","804","            self.converged = True","805","","806","            if self.info == 0:","807","                pass","808","            elif self.info == 1:","809","                self._raise_no_convergence()","810","            else:","811","                raise ArpackError(self.info, infodict=self.iterate_infodict)","812","","813","    def extract(self, return_eigenvectors):","814","        k, n = self.k, self.n","815","","816","        ierr = 0","817","        howmny = 'A'  # return all eigenvectors","818","        sselect = np.zeros(self.ncv, 'int')  # unused","819","        sigmar = np.real(self.sigma)","820","        sigmai = np.imag(self.sigma)","821","        workev = np.zeros(3 * self.ncv, self.tp)","822","","823","        if self.tp in 'fd':","824","            dr = np.zeros(k + 1, self.tp)","825","            di = np.zeros(k + 1, self.tp)","826","            zr = np.zeros((n, k + 1), self.tp)","827","            dr, di, zr, ierr = \\","828","                self._arpack_extract(return_eigenvectors,","829","                       howmny, sselect, sigmar, sigmai, workev,","830","                       self.bmat, self.which, k, self.tol, self.resid,","831","                       self.v, self.iparam, self.ipntr,","832","                       self.workd, self.workl, self.info)","833","            if ierr != 0:","834","                raise ArpackError(ierr, infodict=self.extract_infodict)","835","            nreturned = self.iparam[4]  # number of good eigenvalues returned","836","","837","            # Build complex eigenvalues from real and imaginary parts","838","            d = dr + 1.0j * di","839","","840","            # Arrange the eigenvectors: complex eigenvectors are stored as","841","            # real,imaginary in consecutive columns","842","            z = zr.astype(self.tp.upper())","843","","844","            # The ARPACK nonsymmetric real and double interface (s,d)naupd","845","            # return eigenvalues and eigenvectors in real (float,double)","846","            # arrays.","847","","848","            # Efficiency: this should check that return_eigenvectors == True","849","            #  before going through this construction.","850","            if sigmai == 0:","851","                i = 0","852","                while i <= k:","853","                    # check if complex","854","                    if abs(d[i].imag) != 0:","855","                        # this is a complex conjugate pair with eigenvalues","856","                        # in consecutive columns","857","                        if i < k:","858","                            z[:, i] = zr[:, i] + 1.0j * zr[:, i + 1]","859","                            z[:, i + 1] = z[:, i].conjugate()","860","                            i += 1","861","                        else:","862","                            # last eigenvalue is complex: the imaginary part of","863","                            # the eigenvector has not been returned","864","                            # this can only happen if nreturned > k, so we'll","865","                            # throw out this case.","866","                            nreturned -= 1","867","                    i += 1","868","","869","            else:","870","                # real matrix, mode 3 or 4, imag(sigma) is nonzero:","871","                # see remark 3 in <s,d>neupd.f","872","                # Build complex eigenvalues from real and imaginary parts","873","                i = 0","874","                while i <= k:","875","                    if abs(d[i].imag) == 0:","876","                        d[i] = np.dot(zr[:, i], self.matvec(zr[:, i]))","877","                    else:","878","                        if i < k:","879","                            z[:, i] = zr[:, i] + 1.0j * zr[:, i + 1]","880","                            z[:, i + 1] = z[:, i].conjugate()","881","                            d[i] = ((np.dot(zr[:, i],","882","                                            self.matvec(zr[:, i])) +","883","                                     np.dot(zr[:, i + 1],","884","                                            self.matvec(zr[:, i + 1]))) +","885","                                    1j * (np.dot(zr[:, i],","886","                                          self.matvec(zr[:, i + 1])) -","887","                                          np.dot(zr[:, i + 1],","888","                                          self.matvec(zr[:, i]))))","889","                            d[i + 1] = d[i].conj()","890","                            i += 1","891","                        else:","892","                            # last eigenvalue is complex: the imaginary part of","893","                            # the eigenvector has not been returned","894","                            # this can only happen if nreturned > k, so we'll","895","                            # throw out this case.","896","                            nreturned -= 1","897","                    i += 1","898","","899","            # Now we have k+1 possible eigenvalues and eigenvectors","900","            # Return the ones specified by the keyword \"which\"","901","","902","            if nreturned <= k:","903","                # we got less or equal as many eigenvalues we wanted","904","                d = d[:nreturned]","905","                z = z[:, :nreturned]","906","            else:","907","                # we got one extra eigenvalue (likely a cc pair, but which?)","908","                # cut at approx precision for sorting","909","                rd = np.round(d, decimals=_ndigits[self.tp])","910","                if self.which in ['LR', 'SR']:","911","                    ind = np.argsort(rd.real)","912","                elif self.which in ['LI', 'SI']:","913","                    # for LI,SI ARPACK returns largest,smallest","914","                    # abs(imaginary) why?","915","                    ind = np.argsort(abs(rd.imag))","916","                else:","917","                    ind = np.argsort(abs(rd))","918","                if self.which in ['LR', 'LM', 'LI']:","919","                    d = d[ind[-k:]]","920","                    z = z[:, ind[-k:]]","921","                if self.which in ['SR', 'SM', 'SI']:","922","                    d = d[ind[:k]]","923","                    z = z[:, ind[:k]]","924","        else:","925","            # complex is so much simpler...","926","            d, z, ierr =\\","927","                    self._arpack_extract(return_eigenvectors,","928","                           howmny, sselect, self.sigma, workev,","929","                           self.bmat, self.which, k, self.tol, self.resid,","930","                           self.v, self.iparam, self.ipntr,","931","                           self.workd, self.workl, self.rwork, ierr)","932","","933","            if ierr != 0:","934","                raise ArpackError(ierr, infodict=self.extract_infodict)","935","","936","            k_ok = self.iparam[4]","937","            d = d[:k_ok]","938","            z = z[:, :k_ok]","939","","940","        if return_eigenvectors:","941","            return d, z","942","        else:","943","            return d","944","","945","","946","def _aslinearoperator_with_dtype(m):","947","    m = aslinearoperator(m)","948","    if not hasattr(m, 'dtype'):","949","        x = np.zeros(m.shape[1])","950","        m.dtype = (m * x).dtype","951","    return m","952","","953","","954","class SpLuInv(LinearOperator):","955","    \"\"\"","956","    SpLuInv:","957","       helper class to repeatedly solve M*x=b","958","       using a sparse LU-decopposition of M","959","    \"\"\"","960","    def __init__(self, M):","961","        self.M_lu = splu(M)","962","        self.shape = M.shape","963","        self.dtype = M.dtype","964","        self.isreal = not np.issubdtype(self.dtype, np.complexfloating)","965","","966","    def _matvec(self, x):","967","        # careful here: splu.solve will throw away imaginary","968","        # part of x if M is real","969","        x = np.asarray(x)","970","        if self.isreal and np.issubdtype(x.dtype, np.complexfloating):","971","            return (self.M_lu.solve(np.real(x).astype(self.dtype)) +","972","                    1j * self.M_lu.solve(np.imag(x).astype(self.dtype)))","973","        else:","974","            return self.M_lu.solve(x.astype(self.dtype))","975","","976","","977","class LuInv(LinearOperator):","978","    \"\"\"","979","    LuInv:","980","       helper class to repeatedly solve M*x=b","981","       using an LU-decomposition of M","982","    \"\"\"","983","    def __init__(self, M):","984","        self.M_lu = lu_factor(M)","985","        self.shape = M.shape","986","        self.dtype = M.dtype","987","","988","    def _matvec(self, x):","989","        return lu_solve(self.M_lu, x)","990","","991","","992","class IterInv(LinearOperator):","993","    \"\"\"","994","    IterInv:","995","       helper class to repeatedly solve M*x=b","996","       using an iterative method.","997","    \"\"\"","998","    def __init__(self, M, ifunc=gmres, tol=0):","999","        if tol <= 0:","1000","            # when tol=0, ARPACK uses machine tolerance as calculated","1001","            # by LAPACK's _LAMCH function.  We should match this","1002","            tol = 2 * np.finfo(M.dtype).eps","1003","        self.M = M","1004","        self.ifunc = ifunc","1005","        self.tol = tol","1006","        if hasattr(M, 'dtype'):","1007","            self.dtype = M.dtype","1008","        else:","1009","            x = np.zeros(M.shape[1])","1010","            self.dtype = (M * x).dtype","1011","        self.shape = M.shape","1012","","1013","    def _matvec(self, x):","1014","        b, info = self.ifunc(self.M, x, tol=self.tol)","1015","        if info != 0:","1016","            raise ValueError(\"Error in inverting M: function \"","1017","                             \"%s did not converge (info = %i).\"","1018","                             % (self.ifunc.__name__, info))","1019","        return b","1020","","1021","","1022","class IterOpInv(LinearOperator):","1023","    \"\"\"","1024","    IterOpInv:","1025","       helper class to repeatedly solve [A-sigma*M]*x = b","1026","       using an iterative method","1027","    \"\"\"","1028","    def __init__(self, A, M, sigma, ifunc=gmres, tol=0):","1029","        if tol <= 0:","1030","            # when tol=0, ARPACK uses machine tolerance as calculated","1031","            # by LAPACK's _LAMCH function.  We should match this","1032","            tol = 2 * np.finfo(A.dtype).eps","1033","        self.A = A","1034","        self.M = M","1035","        self.sigma = sigma","1036","        self.ifunc = ifunc","1037","        self.tol = tol","1038","","1039","        def mult_func(x):","1040","            return A.matvec(x) - sigma * M.matvec(x)","1041","","1042","        def mult_func_M_None(x):","1043","            return A.matvec(x) - sigma * x","1044","","1045","        x = np.zeros(A.shape[1])","1046","        if M is None:","1047","            dtype = mult_func_M_None(x).dtype","1048","            self.OP = LinearOperator(self.A.shape,","1049","                                     mult_func_M_None,","1050","                                     dtype=dtype)","1051","        else:","1052","            dtype = mult_func(x).dtype","1053","            self.OP = LinearOperator(self.A.shape,","1054","                                     mult_func,","1055","                                     dtype=dtype)","1056","        self.shape = A.shape","1057","","1058","    def _matvec(self, x):","1059","        b, info = self.ifunc(self.OP, x, tol=self.tol)","1060","        if info != 0:","1061","            raise ValueError(\"Error in inverting [A-sigma*M]: function \"","1062","                             \"%s did not converge (info = %i).\"","1063","                             % (self.ifunc.__name__, info))","1064","        return b","1065","","1066","    @property","1067","    def dtype(self):","1068","        return self.OP.dtype","1069","","1070","","1071","def get_inv_matvec(M, symmetric=False, tol=0):","1072","    if isdense(M):","1073","        return LuInv(M).matvec","1074","    elif isspmatrix(M):","1075","        if isspmatrix_csr(M) and symmetric:","1076","            M = M.T","1077","        return SpLuInv(M).matvec","1078","    else:","1079","        return IterInv(M, tol=tol).matvec","1080","","1081","","1082","def get_OPinv_matvec(A, M, sigma, symmetric=False, tol=0):","1083","    if sigma == 0:","1084","        return get_inv_matvec(A, symmetric=symmetric, tol=tol)","1085","","1086","    if M is None:","1087","        # M is the identity matrix","1088","        if isdense(A):","1089","            if (np.issubdtype(A.dtype, np.complexfloating) or","1090","               np.imag(sigma) == 0):","1091","                A = np.copy(A)","1092","            else:","1093","                A = A + 0j","1094","            A.flat[::A.shape[1] + 1] -= sigma","1095","            return LuInv(A).matvec","1096","        elif isspmatrix(A):","1097","            A = A - sigma * identity(A.shape[0])","1098","            if symmetric and isspmatrix_csr(A):","1099","                A = A.T","1100","            return SpLuInv(A.tocsc()).matvec","1101","        else:","1102","            return IterOpInv(_aslinearoperator_with_dtype(A),","1103","                             M, sigma, tol=tol).matvec","1104","    else:","1105","        if ((not isdense(A) and not isspmatrix(A)) or","1106","                (not isdense(M) and not isspmatrix(M))):","1107","            return IterOpInv(_aslinearoperator_with_dtype(A),","1108","                             _aslinearoperator_with_dtype(M),","1109","                             sigma, tol=tol).matvec","1110","        elif isdense(A) or isdense(M):","1111","            return LuInv(A - sigma * M).matvec","1112","        else:","1113","            OP = A - sigma * M","1114","            if symmetric and isspmatrix_csr(OP):","1115","                OP = OP.T","1116","            return SpLuInv(OP.tocsc()).matvec","1117","","1118","","1119","def _eigs(A, k=6, M=None, sigma=None, which='LM', v0=None,","1120","          ncv=None, maxiter=None, tol=0, return_eigenvectors=True,","1121","          Minv=None, OPinv=None, OPpart=None):","1122","    \"\"\"","1123","    Find k eigenvalues and eigenvectors of the square matrix A.","1124","","1125","    Solves ``A * x[i] = w[i] * x[i]``, the standard eigenvalue problem","1126","    for w[i] eigenvalues with corresponding eigenvectors x[i].","1127","","1128","    If M is specified, solves ``A * x[i] = w[i] * M * x[i]``, the","1129","    generalized eigenvalue problem for w[i] eigenvalues","1130","    with corresponding eigenvectors x[i]","1131","","1132","    Parameters","1133","    ----------","1134","    A : ndarray, sparse matrix or LinearOperator","1135","        An array, sparse matrix, or LinearOperator representing","1136","        the operation ``A * x``, where A is a real or complex square matrix.","1137","    k : int, optional","1138","        The number of eigenvalues and eigenvectors desired.","1139","        `k` must be smaller than N. It is not possible to compute all","1140","        eigenvectors of a matrix.","1141","    M : ndarray, sparse matrix or LinearOperator, optional","1142","        An array, sparse matrix, or LinearOperator representing","1143","        the operation M*x for the generalized eigenvalue problem","1144","","1145","            A * x = w * M * x.","1146","","1147","        M must represent a real, symmetric matrix if A is real, and must","1148","        represent a complex, hermitian matrix if A is complex. For best","1149","        results, the data type of M should be the same as that of A.","1150","        Additionally:","1151","","1152","            If `sigma` is None, M is positive definite","1153","","1154","            If sigma is specified, M is positive semi-definite","1155","","1156","        If sigma is None, eigs requires an operator to compute the solution","1157","        of the linear equation ``M * x = b``.  This is done internally via a","1158","        (sparse) LU decomposition for an explicit matrix M, or via an","1159","        iterative solver for a general linear operator.  Alternatively,","1160","        the user can supply the matrix or operator Minv, which gives","1161","        ``x = Minv * b = M^-1 * b``.","1162","    sigma : real or complex, optional","1163","        Find eigenvalues near sigma using shift-invert mode.  This requires","1164","        an operator to compute the solution of the linear system","1165","        ``[A - sigma * M] * x = b``, where M is the identity matrix if","1166","        unspecified. This is computed internally via a (sparse) LU","1167","        decomposition for explicit matrices A & M, or via an iterative","1168","        solver if either A or M is a general linear operator.","1169","        Alternatively, the user can supply the matrix or operator OPinv,","1170","        which gives ``x = OPinv * b = [A - sigma * M]^-1 * b``.","1171","        For a real matrix A, shift-invert can either be done in imaginary","1172","        mode or real mode, specified by the parameter OPpart ('r' or 'i').","1173","        Note that when sigma is specified, the keyword 'which' (below)","1174","        refers to the shifted eigenvalues ``w'[i]`` where:","1175","","1176","            If A is real and OPpart == 'r' (default),","1177","              ``w'[i] = 1\/2 * [1\/(w[i]-sigma) + 1\/(w[i]-conj(sigma))]``.","1178","","1179","            If A is real and OPpart == 'i',","1180","              ``w'[i] = 1\/2i * [1\/(w[i]-sigma) - 1\/(w[i]-conj(sigma))]``.","1181","","1182","            If A is complex, ``w'[i] = 1\/(w[i]-sigma)``.","1183","","1184","    v0 : ndarray, optional","1185","        Starting vector for iteration.","1186","        Default: random","1187","    ncv : int, optional","1188","        The number of Lanczos vectors generated","1189","        `ncv` must be greater than `k`; it is recommended that ``ncv > 2*k``.","1190","        Default: ``min(n, 2*k + 1)``","1191","    which : str, ['LM' | 'SM' | 'LR' | 'SR' | 'LI' | 'SI'], optional","1192","        Which `k` eigenvectors and eigenvalues to find:","1193","","1194","            'LM' : largest magnitude","1195","","1196","            'SM' : smallest magnitude","1197","","1198","            'LR' : largest real part","1199","","1200","            'SR' : smallest real part","1201","","1202","            'LI' : largest imaginary part","1203","","1204","            'SI' : smallest imaginary part","1205","","1206","        When sigma != None, 'which' refers to the shifted eigenvalues w'[i]","1207","        (see discussion in 'sigma', above).  ARPACK is generally better","1208","        at finding large values than small values.  If small eigenvalues are","1209","        desired, consider using shift-invert mode for better performance.","1210","    maxiter : int, optional","1211","        Maximum number of Arnoldi update iterations allowed","1212","        Default: ``n*10``","1213","    tol : float, optional","1214","        Relative accuracy for eigenvalues (stopping criterion)","1215","        The default value of 0 implies machine precision.","1216","    return_eigenvectors : bool, optional","1217","        Return eigenvectors (True) in addition to eigenvalues","1218","    Minv : ndarray, sparse matrix or LinearOperator, optional","1219","        See notes in M, above.","1220","    OPinv : ndarray, sparse matrix or LinearOperator, optional","1221","        See notes in sigma, above.","1222","    OPpart : {'r' or 'i'}, optional","1223","        See notes in sigma, above","1224","","1225","    Returns","1226","    -------","1227","    w : ndarray","1228","        Array of k eigenvalues.","1229","    v : ndarray","1230","        An array of `k` eigenvectors.","1231","        ``v[:, i]`` is the eigenvector corresponding to the eigenvalue w[i].","1232","","1233","    Raises","1234","    ------","1235","    ArpackNoConvergence","1236","        When the requested convergence is not obtained.","1237","        The currently converged eigenvalues and eigenvectors can be found","1238","        as ``eigenvalues`` and ``eigenvectors`` attributes of the exception","1239","        object.","1240","","1241","    See Also","1242","    --------","1243","    eigsh : eigenvalues and eigenvectors for symmetric matrix A","1244","    svds : singular value decomposition for a matrix A","1245","","1246","    Notes","1247","    -----","1248","    This function is a wrapper to the ARPACK [1]_ SNEUPD, DNEUPD, CNEUPD,","1249","    ZNEUPD, functions which use the Implicitly Restarted Arnoldi Method to","1250","    find the eigenvalues and eigenvectors [2]_.","1251","","1252","    References","1253","    ----------","1254","    .. [1] ARPACK Software, http:\/\/www.caam.rice.edu\/software\/ARPACK\/","1255","    .. [2] R. B. Lehoucq, D. C. Sorensen, and C. Yang,  ARPACK USERS GUIDE:","1256","       Solution of Large Scale Eigenvalue Problems by Implicitly Restarted","1257","       Arnoldi Methods. SIAM, Philadelphia, PA, 1998.","1258","","1259","    Examples","1260","    --------","1261","    Find 6 eigenvectors of the identity matrix:","1262","","1263","    >>> import scipy.sparse as sparse","1264","    >>> id = np.eye(13)","1265","    >>> vals, vecs = sparse.linalg.eigs(id, k=6)","1266","    >>> vals","1267","    array([ 1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j,  1.+0.j])","1268","    >>> vecs.shape","1269","    (13, 6)","1270","","1271","    \"\"\"","1272","    if A.shape[0] != A.shape[1]:","1273","        raise ValueError('expected square matrix (shape=%s)' % (A.shape,))","1274","    if M is not None:","1275","        if M.shape != A.shape:","1276","            raise ValueError('wrong M dimensions %s, should be %s'","1277","                             % (M.shape, A.shape))","1278","        if np.dtype(M.dtype).char.lower() != np.dtype(A.dtype).char.lower():","1279","            import warnings","1280","            warnings.warn('M does not have the same type precision as A. '","1281","                          'This may adversely affect ARPACK convergence')","1282","    n = A.shape[0]","1283","","1284","    if k <= 0 or k >= n:","1285","        raise ValueError(\"k=%d must be between 1 and ndim(A)-1=%d\"","1286","                         % (k, n - 1))","1287","","1288","    if sigma is None:","1289","        matvec = _aslinearoperator_with_dtype(A).matvec","1290","","1291","        if OPinv is not None:","1292","            raise ValueError(\"OPinv should not be specified \"","1293","                             \"with sigma = None.\")","1294","        if OPpart is not None:","1295","            raise ValueError(\"OPpart should not be specified with \"","1296","                             \"sigma = None or complex A\")","1297","","1298","        if M is None:","1299","            # standard eigenvalue problem","1300","            mode = 1","1301","            M_matvec = None","1302","            Minv_matvec = None","1303","            if Minv is not None:","1304","                raise ValueError(\"Minv should not be \"","1305","                                 \"specified with M = None.\")","1306","        else:","1307","            # general eigenvalue problem","1308","            mode = 2","1309","            if Minv is None:","1310","                Minv_matvec = get_inv_matvec(M, symmetric=True, tol=tol)","1311","            else:","1312","                Minv = _aslinearoperator_with_dtype(Minv)","1313","                Minv_matvec = Minv.matvec","1314","            M_matvec = _aslinearoperator_with_dtype(M).matvec","1315","    else:","1316","        # sigma is not None: shift-invert mode","1317","        if np.issubdtype(A.dtype, np.complexfloating):","1318","            if OPpart is not None:","1319","                raise ValueError(\"OPpart should not be specified \"","1320","                                 \"with sigma=None or complex A\")","1321","            mode = 3","1322","        elif OPpart is None or OPpart.lower() == 'r':","1323","            mode = 3","1324","        elif OPpart.lower() == 'i':","1325","            if np.imag(sigma) == 0:","1326","                raise ValueError(\"OPpart cannot be 'i' if sigma is real\")","1327","            mode = 4","1328","        else:","1329","            raise ValueError(\"OPpart must be one of ('r','i')\")","1330","","1331","        matvec = _aslinearoperator_with_dtype(A).matvec","1332","        if Minv is not None:","1333","            raise ValueError(\"Minv should not be specified when sigma is\")","1334","        if OPinv is None:","1335","            Minv_matvec = get_OPinv_matvec(A, M, sigma,","1336","                                           symmetric=False, tol=tol)","1337","        else:","1338","            OPinv = _aslinearoperator_with_dtype(OPinv)","1339","            Minv_matvec = OPinv.matvec","1340","        if M is None:","1341","            M_matvec = None","1342","        else:","1343","            M_matvec = _aslinearoperator_with_dtype(M).matvec","1344","","1345","    params = _UnsymmetricArpackParams(n, k, A.dtype.char, matvec, mode,","1346","                                      M_matvec, Minv_matvec, sigma,","1347","                                      ncv, v0, maxiter, which, tol)","1348","","1349","    while not params.converged:","1350","        params.iterate()","1351","","1352","    return params.extract(return_eigenvectors)","1353","","1354","","1355","def _eigsh(A, k=6, M=None, sigma=None, which='LM', v0=None,","1356","           ncv=None, maxiter=None, tol=0, return_eigenvectors=True,","1357","           Minv=None, OPinv=None, mode='normal'):","1358","    \"\"\"","1359","    Find k eigenvalues and eigenvectors of the real symmetric square matrix","1360","    or complex hermitian matrix A.","1361","","1362","    Solves ``A * x[i] = w[i] * x[i]``, the standard eigenvalue problem for","1363","    w[i] eigenvalues with corresponding eigenvectors x[i].","1364","","1365","    If M is specified, solves ``A * x[i] = w[i] * M * x[i]``, the","1366","    generalized eigenvalue problem for w[i] eigenvalues","1367","    with corresponding eigenvectors x[i]","1368","","1369","    Parameters","1370","    ----------","1371","    A : An N x N matrix, array, sparse matrix, or LinearOperator representing","1372","        the operation A * x, where A is a real symmetric matrix","1373","        For buckling mode (see below) A must additionally be positive-definite","1374","    k : int, optional","1375","        The number of eigenvalues and eigenvectors desired.","1376","        `k` must be smaller than N. It is not possible to compute all","1377","        eigenvectors of a matrix.","1378","","1379","    Returns","1380","    -------","1381","    w : array","1382","        Array of k eigenvalues","1383","    v : array","1384","        An array representing the `k` eigenvectors.  The column ``v[:, i]`` is","1385","        the eigenvector corresponding to the eigenvalue ``w[i]``.","1386","","1387","    Other Parameters","1388","    ----------------","1389","    M : An N x N matrix, array, sparse matrix, or linear operator representing","1390","        the operation M * x for the generalized eigenvalue problem","1391","","1392","            A * x = w * M * x.","1393","","1394","        M must represent a real, symmetric matrix if A is real, and must","1395","        represent a complex, hermitian matrix if A is complex. For best","1396","        results, the data type of M should be the same as that of A.","1397","        Additionally:","1398","","1399","            If sigma is None, M is symmetric positive definite","1400","","1401","            If sigma is specified, M is symmetric positive semi-definite","1402","","1403","            In buckling mode, M is symmetric indefinite.","1404","","1405","        If sigma is None, eigsh requires an operator to compute the solution","1406","        of the linear equation ``M * x = b``. This is done internally via a","1407","        (sparse) LU decomposition for an explicit matrix M, or via an","1408","        iterative solver for a general linear operator.  Alternatively,","1409","        the user can supply the matrix or operator Minv, which gives","1410","        ``x = Minv * b = M^-1 * b``.","1411","    sigma : real","1412","        Find eigenvalues near sigma using shift-invert mode.  This requires","1413","        an operator to compute the solution of the linear system","1414","        `[A - sigma * M] x = b`, where M is the identity matrix if","1415","        unspecified.  This is computed internally via a (sparse) LU","1416","        decomposition for explicit matrices A & M, or via an iterative","1417","        solver if either A or M is a general linear operator.","1418","        Alternatively, the user can supply the matrix or operator OPinv,","1419","        which gives ``x = OPinv * b = [A - sigma * M]^-1 * b``.","1420","        Note that when sigma is specified, the keyword 'which' refers to","1421","        the shifted eigenvalues ``w'[i]`` where:","1422","","1423","            if mode == 'normal', ``w'[i] = 1 \/ (w[i] - sigma)``.","1424","","1425","            if mode == 'cayley', ``w'[i] = (w[i] + sigma) \/ (w[i] - sigma)``.","1426","","1427","            if mode == 'buckling', ``w'[i] = w[i] \/ (w[i] - sigma)``.","1428","","1429","        (see further discussion in 'mode' below)","1430","    v0 : ndarray, optional","1431","        Starting vector for iteration.","1432","        Default: random","1433","    ncv : int, optional","1434","        The number of Lanczos vectors generated ncv must be greater than k and","1435","        smaller than n; it is recommended that ``ncv > 2*k``.","1436","        Default: ``min(n, 2*k + 1)``","1437","    which : str ['LM' | 'SM' | 'LA' | 'SA' | 'BE']","1438","        If A is a complex hermitian matrix, 'BE' is invalid.","1439","        Which `k` eigenvectors and eigenvalues to find:","1440","","1441","            'LM' : Largest (in magnitude) eigenvalues","1442","","1443","            'SM' : Smallest (in magnitude) eigenvalues","1444","","1445","            'LA' : Largest (algebraic) eigenvalues","1446","","1447","            'SA' : Smallest (algebraic) eigenvalues","1448","","1449","            'BE' : Half (k\/2) from each end of the spectrum","1450","","1451","        When k is odd, return one more (k\/2+1) from the high end.","1452","        When sigma != None, 'which' refers to the shifted eigenvalues ``w'[i]``","1453","        (see discussion in 'sigma', above).  ARPACK is generally better","1454","        at finding large values than small values.  If small eigenvalues are","1455","        desired, consider using shift-invert mode for better performance.","1456","    maxiter : int, optional","1457","        Maximum number of Arnoldi update iterations allowed","1458","        Default: ``n*10``","1459","    tol : float","1460","        Relative accuracy for eigenvalues (stopping criterion).","1461","        The default value of 0 implies machine precision.","1462","    Minv : N x N matrix, array, sparse matrix, or LinearOperator","1463","        See notes in M, above","1464","    OPinv : N x N matrix, array, sparse matrix, or LinearOperator","1465","        See notes in sigma, above.","1466","    return_eigenvectors : bool","1467","        Return eigenvectors (True) in addition to eigenvalues","1468","    mode : string ['normal' | 'buckling' | 'cayley']","1469","        Specify strategy to use for shift-invert mode.  This argument applies","1470","        only for real-valued A and sigma != None.  For shift-invert mode,","1471","        ARPACK internally solves the eigenvalue problem","1472","        ``OP * x'[i] = w'[i] * B * x'[i]``","1473","        and transforms the resulting Ritz vectors x'[i] and Ritz values w'[i]","1474","        into the desired eigenvectors and eigenvalues of the problem","1475","        ``A * x[i] = w[i] * M * x[i]``.","1476","        The modes are as follows:","1477","","1478","            'normal' :","1479","                OP = [A - sigma * M]^-1 * M,","1480","                B = M,","1481","                w'[i] = 1 \/ (w[i] - sigma)","1482","","1483","            'buckling' :","1484","                OP = [A - sigma * M]^-1 * A,","1485","                B = A,","1486","                w'[i] = w[i] \/ (w[i] - sigma)","1487","","1488","            'cayley' :","1489","                OP = [A - sigma * M]^-1 * [A + sigma * M],","1490","                B = M,","1491","                w'[i] = (w[i] + sigma) \/ (w[i] - sigma)","1492","","1493","        The choice of mode will affect which eigenvalues are selected by","1494","        the keyword 'which', and can also impact the stability of","1495","        convergence (see [2] for a discussion)","1496","","1497","    Raises","1498","    ------","1499","    ArpackNoConvergence","1500","        When the requested convergence is not obtained.","1501","","1502","        The currently converged eigenvalues and eigenvectors can be found","1503","        as ``eigenvalues`` and ``eigenvectors`` attributes of the exception","1504","        object.","1505","","1506","    See Also","1507","    --------","1508","    eigs : eigenvalues and eigenvectors for a general (nonsymmetric) matrix A","1509","    svds : singular value decomposition for a matrix A","1510","","1511","    Notes","1512","    -----","1513","    This function is a wrapper to the ARPACK [1]_ SSEUPD and DSEUPD","1514","    functions which use the Implicitly Restarted Lanczos Method to","1515","    find the eigenvalues and eigenvectors [2]_.","1516","","1517","    References","1518","    ----------","1519","    .. [1] ARPACK Software, http:\/\/www.caam.rice.edu\/software\/ARPACK\/","1520","    .. [2] R. B. Lehoucq, D. C. Sorensen, and C. Yang,  ARPACK USERS GUIDE:","1521","       Solution of Large Scale Eigenvalue Problems by Implicitly Restarted","1522","       Arnoldi Methods. SIAM, Philadelphia, PA, 1998.","1523","","1524","    Examples","1525","    --------","1526","    >>> import scipy.sparse as sparse","1527","    >>> id = np.eye(13)","1528","    >>> vals, vecs = sparse.linalg.eigsh(id, k=6)","1529","    >>> vals","1530","    array([ 1.,  1.,  1.,  1.,  1.,  1.])","1531","    >>> vecs.shape","1532","    (13, 6)","1533","","1534","    \"\"\"","1535","    # complex hermitian matrices should be solved with eigs","1536","    if np.issubdtype(A.dtype, np.complexfloating):","1537","        if mode != 'normal':","1538","            raise ValueError(\"mode=%s cannot be used with \"","1539","                             \"complex matrix A\" % mode)","1540","        if which == 'BE':","1541","            raise ValueError(\"which='BE' cannot be used with complex matrix A\")","1542","        elif which == 'LA':","1543","            which = 'LR'","1544","        elif which == 'SA':","1545","            which = 'SR'","1546","        ret = eigs(A, k, M=M, sigma=sigma, which=which, v0=v0,","1547","                   ncv=ncv, maxiter=maxiter, tol=tol,","1548","                   return_eigenvectors=return_eigenvectors, Minv=Minv,","1549","                   OPinv=OPinv)","1550","","1551","        if return_eigenvectors:","1552","            return ret[0].real, ret[1]","1553","        else:","1554","            return ret.real","1555","","1556","    if A.shape[0] != A.shape[1]:","1557","        raise ValueError('expected square matrix (shape=%s)' % (A.shape,))","1558","    if M is not None:","1559","        if M.shape != A.shape:","1560","            raise ValueError('wrong M dimensions %s, should be %s'","1561","                             % (M.shape, A.shape))","1562","        if np.dtype(M.dtype).char.lower() != np.dtype(A.dtype).char.lower():","1563","            import warnings","1564","            warnings.warn('M does not have the same type precision as A. '","1565","                          'This may adversely affect ARPACK convergence')","1566","    n = A.shape[0]","1567","","1568","    if k <= 0 or k >= n:","1569","        raise ValueError(\"k must be between 1 and the order of the \"","1570","                         \"square input matrix.\")","1571","","1572","    if sigma is None:","1573","        A = _aslinearoperator_with_dtype(A)","1574","        matvec = A.matvec","1575","","1576","        if OPinv is not None:","1577","            raise ValueError(\"OPinv should not be specified \"","1578","                             \"with sigma = None.\")","1579","        if M is None:","1580","            # standard eigenvalue problem","1581","            mode = 1","1582","            M_matvec = None","1583","            Minv_matvec = None","1584","            if Minv is not None:","1585","                raise ValueError(\"Minv should not be \"","1586","                                 \"specified with M = None.\")","1587","        else:","1588","            # general eigenvalue problem","1589","            mode = 2","1590","            if Minv is None:","1591","                Minv_matvec = get_inv_matvec(M, symmetric=True, tol=tol)","1592","            else:","1593","                Minv = _aslinearoperator_with_dtype(Minv)","1594","                Minv_matvec = Minv.matvec","1595","            M_matvec = _aslinearoperator_with_dtype(M).matvec","1596","    else:","1597","        # sigma is not None: shift-invert mode","1598","        if Minv is not None:","1599","            raise ValueError(\"Minv should not be specified when sigma is\")","1600","","1601","        # normal mode","1602","        if mode == 'normal':","1603","            mode = 3","1604","            matvec = None","1605","            if OPinv is None:","1606","                Minv_matvec = get_OPinv_matvec(A, M, sigma,","1607","                                               symmetric=True, tol=tol)","1608","            else:","1609","                OPinv = _aslinearoperator_with_dtype(OPinv)","1610","                Minv_matvec = OPinv.matvec","1611","            if M is None:","1612","                M_matvec = None","1613","            else:","1614","                M = _aslinearoperator_with_dtype(M)","1615","                M_matvec = M.matvec","1616","","1617","        # buckling mode","1618","        elif mode == 'buckling':","1619","            mode = 4","1620","            if OPinv is None:","1621","                Minv_matvec = get_OPinv_matvec(A, M, sigma,","1622","                                               symmetric=True, tol=tol)","1623","            else:","1624","                Minv_matvec = _aslinearoperator_with_dtype(OPinv).matvec","1625","            matvec = _aslinearoperator_with_dtype(A).matvec","1626","            M_matvec = None","1627","","1628","        # cayley-transform mode","1629","        elif mode == 'cayley':","1630","            mode = 5","1631","            matvec = _aslinearoperator_with_dtype(A).matvec","1632","            if OPinv is None:","1633","                Minv_matvec = get_OPinv_matvec(A, M, sigma,","1634","                                               symmetric=True, tol=tol)","1635","            else:","1636","                Minv_matvec = _aslinearoperator_with_dtype(OPinv).matvec","1637","            if M is None:","1638","                M_matvec = None","1639","            else:","1640","                M_matvec = _aslinearoperator_with_dtype(M).matvec","1641","","1642","        # unrecognized mode","1643","        else:","1644","            raise ValueError(\"unrecognized mode '%s'\" % mode)","1645","","1646","    params = _SymmetricArpackParams(n, k, A.dtype.char, matvec, mode,","1647","                                    M_matvec, Minv_matvec, sigma,","1648","                                    ncv, v0, maxiter, which, tol)","1649","","1650","    while not params.converged:","1651","        params.iterate()","1652","","1653","    return params.extract(return_eigenvectors)","1654","","1655","","1656","def _augmented_orthonormal_cols(x, k):","1657","    # extract the shape of the x array","1658","    n, m = x.shape","1659","    # create the expanded array and copy x into it","1660","    y = np.empty((n, m+k), dtype=x.dtype)","1661","    y[:, :m] = x","1662","    # do some modified gram schmidt to add k random orthonormal vectors","1663","    for i in range(k):","1664","        # sample a random initial vector","1665","        v = np.random.randn(n)","1666","        if np.iscomplexobj(x):","1667","            v = v + 1j*np.random.randn(n)","1668","        # subtract projections onto the existing unit length vectors","1669","        for j in range(m+i):","1670","            u = y[:, j]","1671","            v -= (np.dot(v, u.conj()) \/ np.dot(u, u.conj())) * u","1672","        # normalize v","1673","        v \/= np.sqrt(np.dot(v, v.conj()))","1674","        # add v into the output array","1675","        y[:, m+i] = v","1676","    # return the expanded array","1677","    return y","1678","","1679","","1680","def _augmented_orthonormal_rows(x, k):","1681","    return _augmented_orthonormal_cols(x.T, k).T","1682","","1683","","1684","def _herm(x):","1685","    return x.T.conj()","1686","","1687","","1688","def _svds(A, k=6, ncv=None, tol=0, which='LM', v0=None,","1689","          maxiter=None, return_singular_vectors=True):","1690","    \"\"\"Compute the largest k singular values\/vectors for a sparse matrix.","1691","","1692","    Parameters","1693","    ----------","1694","    A : {sparse matrix, LinearOperator}","1695","        Array to compute the SVD on, of shape (M, N)","1696","    k : int, optional","1697","        Number of singular values and vectors to compute.","1698","    ncv : int, optional","1699","        The number of Lanczos vectors generated","1700","        ncv must be greater than k+1 and smaller than n;","1701","        it is recommended that ncv > 2*k","1702","        Default: ``min(n, 2*k + 1)``","1703","    tol : float, optional","1704","        Tolerance for singular values. Zero (default) means machine precision.","1705","    which : str, ['LM' | 'SM'], optional","1706","        Which `k` singular values to find:","1707","","1708","            - 'LM' : largest singular values","1709","            - 'SM' : smallest singular values","1710","","1711","        .. versionadded:: 0.12.0","1712","    v0 : ndarray, optional","1713","        Starting vector for iteration, of length min(A.shape). Should be an","1714","        (approximate) left singular vector if N > M and a right singular","1715","        vector otherwise.","1716","        Default: random","1717","","1718","        .. versionadded:: 0.12.0","1719","    maxiter : int, optional","1720","        Maximum number of iterations.","1721","","1722","        .. versionadded:: 0.12.0","1723","    return_singular_vectors : bool or str, optional","1724","        - True: return singular vectors (True) in addition to singular values.","1725","","1726","        .. versionadded:: 0.12.0","1727","","1728","        - \"u\": only return the u matrix, without computing vh (if N > M).","1729","        - \"vh\": only return the vh matrix, without computing u (if N <= M).","1730","","1731","        .. versionadded:: 0.16.0","1732","","1733","    Returns","1734","    -------","1735","    u : ndarray, shape=(M, k)","1736","        Unitary matrix having left singular vectors as columns.","1737","        If `return_singular_vectors` is \"vh\", this variable is not computed,","1738","        and None is returned instead.","1739","    s : ndarray, shape=(k,)","1740","        The singular values.","1741","    vt : ndarray, shape=(k, N)","1742","        Unitary matrix having right singular vectors as rows.","1743","        If `return_singular_vectors` is \"u\", this variable is not computed,","1744","        and None is returned instead.","1745","","1746","","1747","    Notes","1748","    -----","1749","    This is a naive implementation using ARPACK as an eigensolver","1750","    on A.H * A or A * A.H, depending on which one is more efficient.","1751","","1752","    \"\"\"","1753","    if not (isinstance(A, LinearOperator) or isspmatrix(A)):","1754","        A = np.asarray(A)","1755","","1756","    n, m = A.shape","1757","","1758","    if isinstance(A, LinearOperator):","1759","        if n > m:","1760","            X_dot = A.matvec","1761","            X_matmat = A.matmat","1762","            XH_dot = A.rmatvec","1763","        else:","1764","            X_dot = A.rmatvec","1765","            XH_dot = A.matvec","1766","","1767","            dtype = getattr(A, 'dtype', None)","1768","            if dtype is None:","1769","                dtype = A.dot(np.zeros([m, 1])).dtype","1770","","1771","            # A^H * V; works around lack of LinearOperator.adjoint.","1772","            # XXX This can be slow!","1773","            def X_matmat(V):","1774","                out = np.empty((V.shape[1], m), dtype=dtype)","1775","                for i, col in enumerate(V.T):","1776","                    out[i, :] = A.rmatvec(col.reshape(-1, 1)).T","1777","                return out.T","1778","","1779","    else:","1780","        if n > m:","1781","            X_dot = X_matmat = A.dot","1782","            XH_dot = _herm(A).dot","1783","        else:","1784","            XH_dot = A.dot","1785","            X_dot = X_matmat = _herm(A).dot","1786","","1787","    def matvec_XH_X(x):","1788","        return XH_dot(X_dot(x))","1789","","1790","    XH_X = LinearOperator(matvec=matvec_XH_X, dtype=A.dtype,","1791","                          shape=(min(A.shape), min(A.shape)))","1792","","1793","    # Get a low rank approximation of the implicitly defined gramian matrix.","1794","    # This is not a stable way to approach the problem.","1795","    eigvals, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,","1796","                            ncv=ncv, which=which, v0=v0)","1797","","1798","    # In 'LM' mode try to be clever about small eigenvalues.","1799","    # Otherwise in 'SM' mode do not try to be clever.","1800","    if which == 'LM':","1801","","1802","        # Gramian matrices have real non-negative eigenvalues.","1803","        eigvals = np.maximum(eigvals.real, 0)","1804","","1805","        # Use the sophisticated detection of small eigenvalues from pinvh.","1806","        t = eigvec.dtype.char.lower()","1807","        factor = {'f': 1E3, 'd': 1E6}","1808","        cond = factor[t] * np.finfo(t).eps","1809","        cutoff = cond * np.max(eigvals)","1810","","1811","        # Get a mask indicating which eigenpairs are not degenerately tiny,","1812","        # and create the re-ordered array of thresholded singular values.","1813","        above_cutoff = (eigvals > cutoff)","1814","        nlarge = above_cutoff.sum()","1815","        nsmall = k - nlarge","1816","        slarge = np.sqrt(eigvals[above_cutoff])","1817","        s = np.zeros_like(eigvals)","1818","        s[:nlarge] = slarge","1819","        if not return_singular_vectors:","1820","            return s","1821","","1822","        if n > m:","1823","            vlarge = eigvec[:, above_cutoff]","1824","            ularge = X_matmat(vlarge) \/ slarge if return_singular_vectors != 'vh' else None","1825","            vhlarge = _herm(vlarge)","1826","        else:","1827","            ularge = eigvec[:, above_cutoff]","1828","            vhlarge = _herm(X_matmat(ularge) \/ slarge) if return_singular_vectors != 'u' else None","1829","","1830","        u = _augmented_orthonormal_cols(ularge, nsmall) if ularge is not None else None","1831","        vh = _augmented_orthonormal_rows(vhlarge, nsmall) if vhlarge is not None else None","1832","","1833","    elif which == 'SM':","1834","","1835","        s = np.sqrt(eigvals)","1836","        if not return_singular_vectors:","1837","            return s","1838","","1839","        if n > m:","1840","            v = eigvec","1841","            u = X_matmat(v) \/ s if return_singular_vectors != 'vh' else None","1842","            vh = _herm(v)","1843","        else:","1844","            u = eigvec","1845","            vh = _herm(X_matmat(u) \/ s) if return_singular_vectors != 'u' else None","1846","","1847","    else:","1848","","1849","        raise ValueError(\"which must be either 'LM' or 'SM'.\")","1850","","1851","    return u, s, vh","1852","","1853","","1854","# Redefine the backported function","1855","if scipy.version.version >= LooseVersion('0.12'):","1856","    from scipy.sparse.linalg import eigs, eigsh, svds","1857","else:","1858","    eigs, eigsh, svds = _eigs, _eigsh, _svds"]}],"sklearn\/utils\/sparsetools\/__init__.py":[{"add":["0","# Remove in version 0.21","2","from scipy.sparse.csgraph import connected_components as \\","3","     scipy_connected_components","5","from sklearn.utils.deprecation import deprecated","6","","7","","8","@deprecated(\"sklearn.utils.sparsetools.connected_components was deprecated in\"","9","            \"version 0.19 and will be removed in 0.21. Use\"","10","            \"scipy.sparse.csgraph.connected_components instead.\")","11","def connected_components(*args, **kwargs):","12","    return scipy_connected_components(*args, **kwargs)"],"delete":["0","\"\"\"sparsetools - a collection of routines for sparse matrix operations\"\"\"","2","from ._traversal import connected_components","4","__all__ = [\"connected_components\"]"]}],"sklearn\/utils\/fixes.py":[{"add":[],"delete":["45","try:","46","    from scipy.special import expit     # SciPy >= 0.10","47","    with np.errstate(invalid='ignore', over='ignore'):","48","        if np.isnan(expit(1000)):       # SciPy < 0.14","49","            raise ImportError(\"no stable expit in scipy.special\")","50","except ImportError:","51","    def expit(x, out=None):","52","        \"\"\"Logistic sigmoid function, ``1 \/ (1 + exp(-x))``.","53","","54","        See sklearn.utils.extmath.log_logistic for the log of this function.","55","        \"\"\"","56","        if out is None:","57","            out = np.empty(np.atleast_1d(x).shape, dtype=np.float64)","58","        out[:] = x","59","","60","        # 1 \/ (1 + exp(-x)) = (1 + tanh(x \/ 2)) \/ 2","61","        # This way of computing the logistic is both fast and stable.","62","        out *= .5","63","        np.tanh(out, out)","64","        out += 1","65","        out *= .5","66","","67","        return out.reshape(np.shape(x))","68","","69","","327","if sp_version < (0, 13, 0):","328","    def rankdata(a, method='average'):","329","        if method not in ('average', 'min', 'max', 'dense', 'ordinal'):","330","            raise ValueError('unknown method \"{0}\"'.format(method))","331","","332","        arr = np.ravel(np.asarray(a))","333","        algo = 'mergesort' if method == 'ordinal' else 'quicksort'","334","        sorter = np.argsort(arr, kind=algo)","335","","336","        inv = np.empty(sorter.size, dtype=np.intp)","337","        inv[sorter] = np.arange(sorter.size, dtype=np.intp)","338","","339","        if method == 'ordinal':","340","            return inv + 1","341","","342","        arr = arr[sorter]","343","        obs = np.r_[True, arr[1:] != arr[:-1]]","344","        dense = obs.cumsum()[inv]","345","","346","        if method == 'dense':","347","            return dense","348","","349","        # cumulative counts of each unique value","350","        count = np.r_[np.nonzero(obs)[0], len(obs)]","351","","352","        if method == 'max':","353","            return count[dense]","354","","355","        if method == 'min':","356","            return count[dense - 1] + 1","357","","358","        # average method","359","        return .5 * (count[dense] + count[dense - 1] + 1)","360","else:","361","    from scipy.stats import rankdata","362",""]}],"sklearn\/linear_model\/tests\/test_logistic.py":[{"add":["998","    solvers = ['newton-cg', 'liblinear', 'sag', 'saga', 'lbfgs']","1065","    solvers = ['newton-cg', 'sag', 'saga', 'lbfgs']"],"delete":["8","from sklearn.utils.fixes import sp_version","999","    solvers = ['newton-cg', 'liblinear', 'sag', 'saga']","1000","    # old scipy doesn't have maxiter","1001","    if sp_version >= (0, 12):","1002","        solvers.append('lbfgs')","1069","    solvers = ['newton-cg', 'sag', 'saga']","1070","    # old scipy doesn't have maxiter","1071","    if sp_version >= (0, 12):","1072","        solvers.append('lbfgs')"]}],"sklearn\/utils\/tests\/test_fixes.py":[{"add":["14","from sklearn.utils.fixes import divide"],"delete":["12","from sklearn.utils.testing import assert_almost_equal","14","from sklearn.utils.testing import assert_array_almost_equal","16","from sklearn.utils.fixes import divide, expit","22","def test_expit():","23","    # Check numerical stability of expit (logistic function).","24","","25","    # Simulate our previous Cython implementation, based on","26","    #http:\/\/fa.bianp.net\/blog\/2013\/numerical-optimizers-for-logistic-regression","27","    assert_almost_equal(expit(1000.), 1. \/ (1. + np.exp(-1000.)), decimal=16)","28","    assert_almost_equal(expit(-1000.), np.exp(-1000.) \/ (1. + np.exp(-1000.)),","29","                        decimal=16)","30","","31","    x = np.arange(10)","32","    out = np.zeros_like(x, dtype=np.float32)","33","    assert_array_almost_equal(expit(x), expit(x, out=out))","34","","35",""]}],"sklearn\/utils\/stats.py":[{"add":["1","from scipy.stats import rankdata as scipy_rankdata","2","","3","from sklearn.utils.extmath import stable_cumsum","4","from sklearn.utils.deprecation import deprecated","7","# Remove in sklearn 0.21","8","@deprecated(\"sklearn.utils.stats.rankdata was deprecated in version 0.19 and\"","9","            \"will be removed in 0.21. Use scipy.stats.rankdata instead.\")","10","def rankdata(*args, **kwargs):","11","    return scipy_rankdata(*args, **kwargs)","15","    \"\"\"","16","    Compute the weighted ``percentile`` of ``array`` with ``sample_weight``.","17","    \"\"\""],"delete":["1","from scipy.stats import rankdata as _sp_rankdata","2","from .fixes import bincount","3","from ..utils.extmath import stable_cumsum","6","# To remove when we support scipy 0.13","7","def _rankdata(a, method=\"average\"):","8","    \"\"\"Assign ranks to data, dealing with ties appropriately.","9","","10","    Ranks begin at 1. The method argument controls how ranks are assigned","11","    to equal values.","12","","13","    Parameters","14","    ----------","15","    a : array_like","16","        The array of values to be ranked. The array is first flattened.","17","","18","    method : str, optional","19","        The method used to assign ranks to tied elements.","20","        The options are 'max'.","21","        'max': The maximum of the ranks that would have been assigned","22","              to all the tied values is assigned to each value.","23","","24","    Returns","25","    -------","26","    ranks : ndarray","27","        An array of length equal to the size of a, containing rank scores.","28","","29","    Notes","30","    -----","31","    We only backport the 'max' method","32","","33","    \"\"\"","34","    if method != \"max\":","35","        raise NotImplementedError()","36","","37","    unique_all, inverse = np.unique(a, return_inverse=True)","38","    count = bincount(inverse, minlength=unique_all.size)","39","    cum_count = count.cumsum()","40","    rank = cum_count[inverse]","41","    return rank","42","","43","try:","44","    _sp_rankdata([1.], 'max')","45","    rankdata = _sp_rankdata","46","","47","except TypeError as e:","48","    rankdata = _rankdata","52","    \"\"\"Compute the weighted ``percentile`` of ``array`` with ``sample_weight``. \"\"\""]}],"sklearn\/decomposition\/online_lda.py":[{"add":["15","from scipy.misc import logsumexp","687","            norm_phi = logsumexp(temp, axis=0)"],"delete":["22","from ..utils.extmath import logsumexp","687","            norm_phi = logsumexp(temp)"]}],"sklearn\/utils\/tests\/test_stats.py":[{"add":["0","from sklearn.utils.testing import assert_array_equal, ignore_warnings","15","@ignore_warnings  # Test deprecated backport to be removed in 0.21"],"delete":["0","from sklearn.utils.testing import assert_array_equal"]}],"sklearn\/cluster\/spectral.py":[{"add":["91","        vectors[:, i] = (vectors[:, i] \/ np.linalg.norm(vectors[:, i])) \\"],"delete":["14","from ..utils.extmath import norm","92","        vectors[:, i] = (vectors[:, i] \/ norm(vectors[:, i])) \\"]}],"sklearn\/covariance\/robust_covariance.py":[{"add":["16","from ..utils.extmath import fast_logdet","109","        precision = linalg.pinvh(covariance)","129","        precision = linalg.pinvh(covariance)","395","            precision = linalg.pinvh(covariance)","403","            precision = linalg.pinvh(covariance)","631","            precision = linalg.pinvh(raw_covariance)"],"delete":["16","from ..utils.extmath import fast_logdet, pinvh","109","        precision = pinvh(covariance)","129","        precision = pinvh(covariance)","395","            precision = pinvh(covariance)","403","            precision = pinvh(covariance)","631","            precision = pinvh(raw_covariance)"]}],"sklearn\/utils\/graph.py":[{"add":["17","from .deprecation import deprecated","73","@deprecated(\"sklearn.utils.graph.connected_components was deprecated in\"","74","            \"version 0.19 and will be removed in 0.21. Use\"","75","            \"scipy.sparse.csgraph.connected_components instead.\")","76","def connected_components(*args, **kwargs):","77","    return sparse.csgraph.connected_components(*args, **kwargs)"],"delete":["72","if hasattr(sparse, 'connected_components'):","73","    connected_components = sparse.connected_components","74","else:","75","    from .sparsetools import connected_components"]}],"sklearn\/cluster\/_k_means.pyx":[{"add":[],"delete":["17","from ..utils.extmath import norm"]}],"doc\/developers\/utilities.rst":[{"add":[],"delete":["91","- :func:`extmath.norm`: computes Euclidean (L2) vector norm","92","  by directly calling the BLAS","93","  ``nrm2`` function.  This is more stable than ``scipy.linalg.norm``.  See","94","  `Fabian's blog post","95","  <http:\/\/fa.bianp.net\/blog\/2011\/computing-the-vector-norm>`_ for a discussion.","106","- :func:`extmath.logsumexp`: compute the sum of X assuming X is in the log","107","  domain. This is equivalent to calling ``np.log(np.sum(np.exp(X)))``, but is","108","  robust to overflow\/underflow errors.  Note that there is similar","109","  functionality in ``np.logaddexp.reduce``, but because of the pairwise nature","110","  of this routine, it is slower for large arrays.","111","  Scipy has a similar routine in ``scipy.misc.logsumexp`` (In scipy versions","112","  < 0.10, this is found in ``scipy.maxentropy.logsumexp``),","113","  but the scipy version does not accept an ``axis`` keyword.","114","","179","Backports","180","=========","181","","182","- :func:`fixes.expit`: Logistic sigmoid function. Replacement for SciPy 0.10's","183","  ``scipy.special.expit``.","184","","185","- :func:`sparsetools.connected_components`","186","  (backported from ``scipy.sparse.connected_components`` in scipy 0.12).","187","  Used in ``sklearn.cluster.hierarchical``, as well as in tests for","188","  :mod:`sklearn.feature_extraction`.","189","","190","","191","ARPACK","192","------","193","","194","- :func:`arpack.eigs`","195","  (backported from ``scipy.sparse.linalg.eigs`` in scipy 0.10)","196","  Sparse non-symmetric eigenvalue decomposition using the Arnoldi","197","  method.  A limited version of ``eigs`` is available in earlier","198","  scipy versions.","199","","200","- :func:`arpack.eigsh`","201","  (backported from ``scipy.sparse.linalg.eigsh`` in scipy 0.10)","202","  Sparse non-symmetric eigenvalue decomposition using the Arnoldi","203","  method.  A limited version of ``eigsh`` is available in earlier","204","  scipy versions.","205","","206","- :func:`arpack.svds`","207","  (backported from ``scipy.sparse.linalg.svds`` in scipy 0.10)","208","  Sparse non-symmetric eigenvalue decomposition using the Arnoldi","209","  method.  A limited version of ``svds`` is available in earlier","210","  scipy versions.","211","","212",""]}],"sklearn\/mixture\/dpgmm.py":[{"add":["22","from scipy.linalg import pinvh","23","from scipy.misc import logsumexp","28","from ..utils.extmath import squared_norm, stable_cumsum"],"delete":["26","from ..utils.extmath import logsumexp, pinvh, squared_norm, stable_cumsum"]}],"sklearn\/manifold\/spectral_embedding_.py":[{"add":["7","","11","from scipy.sparse.linalg import eigsh, lobpcg","12","from scipy.sparse.csgraph import connected_components","13",""],"delete":["10","from scipy.sparse.linalg import lobpcg","16","from ..utils.sparsetools import connected_components","17","from ..utils.arpack import eigsh"]}],"sklearn\/utils\/extmath.py":[{"add":["20","from scipy.misc import logsumexp as scipy_logsumexp","22","from . import check_random_state, deprecated","31","@deprecated(\"sklearn.utils.extmath.norm was deprecated in version 0.19\"","32","            \"and will be removed in 0.21. Use scipy.linalg.norm instead.\")","39","    return linalg.norm(x)","401","@deprecated(\"sklearn.utils.extmath.logsumexp was deprecated in version 0.19\"","402","            \"and will be removed in 0.21. Use scipy.misc.logsumexp instead.\")","417","    return scipy_logsumexp(arr, axis)","494","@deprecated(\"sklearn.utils.extmath.pinvh was deprecated in version 0.19\"","495","            \"and will be removed in 0.21. Use scipy.linalg.pinvh instead.\")","497","    return linalg.pinvh(a, cond, rcond, lower)","597","    For the ordinary logistic function, use ``scipy.special.expit``."],"delete":["21","from . import check_random_state","36","    x = np.asarray(x)","37","    nrm2, = linalg.get_blas_funcs(['nrm2'], [x])","38","    return nrm2(x)","402","","405","","408","","417","    arr = np.rollaxis(arr, axis)","418","    # Use the max to normalize, as with the log this is what accumulates","419","    # the less errors","420","    vmax = arr.max(axis=0)","421","    out = np.log(np.sum(np.exp(arr - vmax), axis=0))","422","    out += vmax","423","    return out","501","    \"\"\"Compute the (Moore-Penrose) pseudo-inverse of a hermetian matrix.","502","","503","    Calculate a generalized inverse of a symmetric matrix using its","504","    eigenvalue decomposition and including all 'large' eigenvalues.","505","","506","    Parameters","507","    ----------","508","    a : array, shape (N, N)","509","        Real symmetric or complex hermetian matrix to be pseudo-inverted","510","","511","    cond : float or None, default None","512","        Cutoff for 'small' eigenvalues.","513","        Singular values smaller than rcond * largest_eigenvalue are considered","514","        zero.","515","","516","        If None or -1, suitable machine precision is used.","517","","518","    rcond : float or None, default None (deprecated)","519","        Cutoff for 'small' eigenvalues.","520","        Singular values smaller than rcond * largest_eigenvalue are considered","521","        zero.","522","","523","        If None or -1, suitable machine precision is used.","524","","525","    lower : boolean","526","        Whether the pertinent array data is taken from the lower or upper","527","        triangle of a. (Default: lower)","528","","529","    Returns","530","    -------","531","    B : array, shape (N, N)","532","","533","    Raises","534","    ------","535","    LinAlgError","536","        If eigenvalue does not converge","537","","538","    Examples","539","    --------","540","    >>> import numpy as np","541","    >>> a = np.random.randn(9, 6)","542","    >>> a = np.dot(a, a.T)","543","    >>> B = pinvh(a)","544","    >>> np.allclose(a, np.dot(a, np.dot(B, a)))","545","    True","546","    >>> np.allclose(B, np.dot(B, np.dot(a, B)))","547","    True","548","","549","    \"\"\"","550","    a = np.asarray_chkfinite(a)","551","    s, u = linalg.eigh(a, lower=lower)","552","","553","    if rcond is not None:","554","        cond = rcond","555","    if cond in [None, -1]:","556","        t = u.dtype.char.lower()","557","        factor = {'f': 1E3, 'd': 1E6}","558","        cond = factor[t] * np.finfo(t).eps","559","","560","    # unlike svd case, eigh can lead to negative eigenvalues","561","    above_cutoff = (abs(s) > cond * np.max(abs(s)))","562","    psigma_diag = np.zeros_like(s)","563","    psigma_diag[above_cutoff] = 1.0 \/ s[above_cutoff]","564","","565","    return np.dot(u * psigma_diag, np.conjugate(u).T)","665","    For the ordinary logistic function, use ``sklearn.utils.fixes.expit``."]}],"examples\/decomposition\/plot_image_denoising.py":[{"add":["47","try:  # SciPy >= 0.16 have face in misc","48","    from scipy.misc import face","49","    face = face(gray=True)","50","except ImportError:"],"delete":["44","from sklearn.utils.testing import SkipTest","45","from sklearn.utils.fixes import sp_version","47","if sp_version < (0, 12):","48","    raise SkipTest(\"Skipping because SciPy version earlier than 0.12.0 and \"","49","                   \"thus does not include the scipy.misc.face() image.\")","52","try:","53","    from scipy import misc","54","    face = misc.face(gray=True)","55","except AttributeError:","56","    # Old versions of scipy have face in the top level package"]}],"sklearn\/decomposition\/pca.py":[{"add":["18","from scipy.sparse.linalg import svds"],"delete":["29","from ..utils.arpack import svds"]}],"sklearn\/utils\/tests\/test_extmath.py":[{"add":["23","from sklearn.utils.testing import ignore_warnings","89","@ignore_warnings  # Test deprecated backport to be removed in 0.21","145","@ignore_warnings  # extmath.norm is deprecated to be removed in 0.21"],"delete":[]}],"examples\/cluster\/plot_face_compress.py":[{"add":["27","try:  # SciPy >= 0.16 have face in misc","28","    from scipy.misc import face","29","    face = face(gray=True)","30","except ImportError:","35",""],"delete":["25","from sklearn.utils.testing import SkipTest","26","from sklearn.utils.fixes import sp_version","28","if sp_version < (0, 12):","29","    raise SkipTest(\"Skipping because SciPy version earlier than 0.12.0 and \"","30","                   \"thus does not include the scipy.misc.face() image.\")","32","try:","34","except AttributeError:","35","    # Newer versions of scipy have face in misc","36","    from scipy import misc","37","    face = misc.face(gray=True)","41","    "]}],"sklearn\/decomposition\/truncated_svd.py":[{"add":["10","from scipy.sparse.linalg import svds"],"delete":["10","","11","try:","12","    from scipy.sparse.linalg import svds","13","except ImportError:","14","    from ..utils.arpack import svds"]}],"sklearn\/cluster\/bicluster.py":[{"add":["10","from scipy.linalg import norm","11","from scipy.sparse import dia_matrix, issparse","12","from scipy.sparse.linalg import eigsh, svds","19","from ..utils.extmath import (make_nonnegative, randomized_svd,","204","        :func:`scipy.sparse.linalg.svds`, which is more accurate, but","336","        `scipy.sparse.linalg.svds`, which is more accurate, but"],"delete":["10","from scipy.sparse import dia_matrix","11","from scipy.sparse import issparse","17","from ..utils.arpack import eigsh, svds","19","from ..utils.extmath import (make_nonnegative, norm, randomized_svd,","204","        :func:`sklearn.utils.arpack.svds`, which is more accurate, but","336","        `sklearn.utils.arpack.svds`, which is more accurate, but"]}],"\/dev\/null":[{"add":[],"delete":[]}],"sklearn\/ensemble\/gradient_boosting.py":[{"add":["42","from scipy.misc import logsumexp","46","from scipy.special import expit"],"delete":["56","from ..utils.extmath import logsumexp","57","from ..utils.fixes import expit"]}],"sklearn\/utils\/sparsetools\/setup.py":[{"add":["0","# Remove in version 0.21","11",""],"delete":["0","import numpy","7","","8","    config.add_extension('_traversal',","9","                         sources=['_traversal.pyx'],","10","                         include_dirs=[numpy.get_include()])","11","    config.add_extension('_graph_tools',","12","                         sources=['_graph_tools.pyx'],","13","                         include_dirs=[numpy.get_include()])","14",""]}],"sklearn\/linear_model\/tests\/test_sag.py":[{"add":["8","from scipy.misc import logsumexp"],"delete":["15","from sklearn.utils.extmath import logsumexp"]}],"sklearn\/manifold\/locally_linear.py":[{"add":["9","from scipy.sparse.linalg import eigsh","10",""],"delete":["11","from ..utils.arpack import eigsh"]}],"sklearn\/cross_decomposition\/pls_.py":[{"add":["9","","11","from scipy.linalg import pinv2, svd","12","from scipy.sparse.linalg import svds","13","","14","from ..base import BaseEstimator, RegressorMixin, TransformerMixin","15","from ..utils import check_array, check_consistent_length","16","from ..utils.extmath import svd_flip","18","from ..externals import six","44","                X_pinv = pinv2(X, check_finite=False)","61","                Y_pinv = pinv2(Y, check_finite=False)  # compute once pinv(Y)","85","    U, s, Vh = svd(C, full_matrices=False)","349","            pinv2(np.dot(self.x_loadings_.T, self.x_weights_),","350","                  check_finite=False))","354","                pinv2(np.dot(self.y_loadings_.T, self.y_weights_),","355","                      check_finite=False))","810","            U, s, V = svd(C, full_matrices=False)","812","            U, s, V = svds(C, k=self.n_components)"],"delete":["6","from distutils.version import LooseVersion","7","from sklearn.utils.extmath import svd_flip","8","","9","from ..base import BaseEstimator, RegressorMixin, TransformerMixin","10","from ..utils import check_array, check_consistent_length","11","from ..externals import six","16","from scipy import linalg","17","from ..utils import arpack","22","import scipy","23","pinv2_args = {}","24","if LooseVersion(scipy.__version__) >= LooseVersion('0.12'):","25","    # check_finite=False is an optimization available only in scipy >=0.12","26","    pinv2_args = {'check_finite': False}","27","","50","                X_pinv = linalg.pinv2(X, **pinv2_args)","67","                Y_pinv = linalg.pinv2(Y, **pinv2_args)  # compute once pinv(Y)","91","    U, s, Vh = linalg.svd(C, full_matrices=False)","355","            linalg.pinv2(np.dot(self.x_loadings_.T, self.x_weights_),","356","                         **pinv2_args))","360","                linalg.pinv2(np.dot(self.y_loadings_.T, self.y_weights_),","361","                             **pinv2_args))","816","            U, s, V = linalg.svd(C, full_matrices=False)","818","            U, s, V = arpack.svds(C, k=self.n_components)"]}],"sklearn\/decomposition\/kernel_pca.py":[{"add":["7","from scipy.sparse.linalg import eigsh"],"delete":["9","from ..utils.arpack import eigsh"]}],"sklearn\/linear_model\/least_angle.py":[{"add":["29","solve_triangular_args = {'check_finite': False}"],"delete":["15","from distutils.version import LooseVersion","30","import scipy","31","solve_triangular_args = {}","32","if LooseVersion(scipy.__version__) >= LooseVersion('0.12'):","33","    solve_triangular_args = {'check_finite': False}"]}]}},"6413febf8d2967a9f704f3e90cdb8160f98adce7":{"changes":{"sklearn\/tests\/test_grid_search.py":"MODIFY","doc\/whats_new.rst":"MODIFY","sklearn\/grid_search.py":"MODIFY"},"diff":{"sklearn\/tests\/test_grid_search.py":[{"add":["73","    def transform(self, X):","74","        return X - self.foo_param","75","","76","    def inverse_transform(self, X):","77","        return X + self.foo_param","78","","173","def test_transform_inverse_transform_round_trip():","174","    clf = MockClassifier()","175","    grid_search = GridSearchCV(clf, {'foo_param': [1, 2, 3]}, verbose=3)","176","    grid_search.fit(X, y)","177","    X_round_trip = grid_search.inverse_transform(grid_search.transform(X))","178","    assert_array_equal(X, X_round_trip)","179","","180",""],"delete":["75","    transform = predict"]}],"doc\/whats_new.rst":[{"add":["191","   - Fixed same issue in :func:`sklearn.grid_search.BaseSearchCV.inverse_transform`","192","     :issue:`8846` by :user:`Rasmus Eriksson <MrMjauh>`"],"delete":[]}],"sklearn\/grid_search.py":[{"add":["542","        return self.best_estimator_.inverse_transform(Xt)"],"delete":["542","        return self.best_estimator_.transform(Xt)"]}]}},"a0db45db0e86243757b53294db2483228c917ce0":{"changes":{"sklearn\/utils\/class_weight.py":"MODIFY","sklearn\/utils\/tests\/test_class_weight.py":"MODIFY"},"diff":{"sklearn\/utils\/class_weight.py":[{"add":["68","                raise ValueError(\"Class label {} not present.\".format(c))"],"delete":["68","                raise ValueError(\"Class label %d not present.\" % c)"]}],"sklearn\/utils\/tests\/test_class_weight.py":[{"add":["33","    # Fix exception in error message formatting when missing label is a string","34","    # https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/8312","35","    assert_raise_message(ValueError,","36","                         'Class label label_not_present not present',","37","                         compute_class_weight,","38","                         {'label_not_present': 1.}, classes, y)"],"delete":[]}]}},"719afba518e6c8f71a0d98faf2263a7312ac22a1":{"changes":{"examples\/model_selection\/plot_grid_search_digits.py":"ADD","\/dev\/null":"DELETE","examples\/exercises\/plot_digits_classification_exercise.py":"ADD","examples\/plot_missing_values.py":"ADD","examples\/applications\/plot_topics_extraction_with_nmf_lda.py":"ADD","examples\/applications\/plot_face_recognition.py":"ADD","examples\/feature_selection\/plot_feature_selection_pipeline.py":"ADD","examples\/bicluster\/plot_bicluster_newsgroups.py":"ADD","examples\/linear_model\/plot_lasso_dense_vs_sparse_data.py":"ADD","examples\/model_selection\/plot_randomized_search.py":"ADD","examples\/plot_feature_stacker.py":"ADD"},"diff":{"examples\/model_selection\/plot_grid_search_digits.py":[{"add":[],"delete":[]}],"\/dev\/null":[{"add":[],"delete":[]}],"examples\/exercises\/plot_digits_classification_exercise.py":[{"add":[],"delete":[]}],"examples\/plot_missing_values.py":[{"add":[],"delete":[]}],"examples\/applications\/plot_topics_extraction_with_nmf_lda.py":[{"add":[],"delete":[]}],"examples\/applications\/plot_face_recognition.py":[{"add":[],"delete":[]}],"examples\/feature_selection\/plot_feature_selection_pipeline.py":[{"add":[],"delete":[]}],"examples\/bicluster\/plot_bicluster_newsgroups.py":[{"add":[],"delete":[]}],"examples\/linear_model\/plot_lasso_dense_vs_sparse_data.py":[{"add":[],"delete":[]}],"examples\/model_selection\/plot_randomized_search.py":[{"add":[],"delete":[]}],"examples\/plot_feature_stacker.py":[{"add":[],"delete":[]}]}},"0eb33adb789052029eddc72135027e490d510375":{"changes":{"build_tools\/travis\/flake8_diff.sh":"MODIFY"},"diff":{"build_tools\/travis\/flake8_diff.sh":[{"add":["127","    shift","128","    options=\"$*\"","129","    if [ -n \"$files\" ]; then","130","        # Conservative approach: diff without context (--unified=0) so that code","131","        # that was not changed does not create failures","132","        git diff --unified=0 $COMMIT_RANGE -- $files | flake8 --diff --show-source $options","133","    fi"],"delete":["127","    options=\"$2\"","128","    # Conservative approach: diff without context (--unified=0) so that code","129","    # that was not changed does not create failures","130","    git diff --unified=0 $COMMIT_RANGE -- $files | flake8 --diff --show-source $options"]}]}},"fb5a498d0bd00fc2b42fbd19b6ef18e1dfeee47e":{"changes":{"sklearn\/datasets\/base.py":"MODIFY","sklearn\/datasets\/lfw.py":"MODIFY","sklearn\/datasets\/species_distributions.py":"MODIFY","sklearn\/datasets\/california_housing.py":"MODIFY","sklearn\/datasets\/olivetti_faces.py":"MODIFY","sklearn\/datasets\/twenty_newsgroups.py":"MODIFY","sklearn\/datasets\/kddcup99.py":"MODIFY","doc\/modules\/pipeline.rst":"MODIFY","sklearn\/utils\/__init__.py":"MODIFY","sklearn\/datasets\/rcv1.py":"MODIFY","sklearn\/tests\/test_pipeline.py":"MODIFY","sklearn\/datasets\/covtype.py":"MODIFY","sklearn\/datasets\/mldata.py":"MODIFY","doc\/whats_new.rst":"MODIFY","sklearn\/pipeline.py":"MODIFY"},"diff":{"sklearn\/datasets\/base.py":[{"add":["22","from ..utils import Bunch"],"delete":["28","class Bunch(dict):","29","    \"\"\"Container object for datasets","30","","31","    Dictionary-like object that exposes its keys as attributes.","32","","33","    >>> b = Bunch(a=1, b=2)","34","    >>> b['b']","35","    2","36","    >>> b.b","37","    2","38","    >>> b.a = 3","39","    >>> b['a']","40","    3","41","    >>> b.c = 6","42","    >>> b['c']","43","    6","44","","45","    \"\"\"","46","","47","    def __init__(self, **kwargs):","48","        super(Bunch, self).__init__(kwargs)","49","","50","    def __setattr__(self, key, value):","51","        self[key] = value","52","","53","    def __dir__(self):","54","        return self.keys()","55","","56","    def __getattr__(self, key):","57","        try:","58","            return self[key]","59","        except KeyError:","60","            raise AttributeError(key)","61","","62","    def __setstate__(self, state):","63","        # Bunch pickles generated with scikit-learn 0.16.* have an non","64","        # empty __dict__. This causes a surprising behaviour when","65","        # loading these pickles scikit-learn 0.17: reading bunch.key","66","        # uses __dict__ but assigning to bunch.key use __setattr__ and","67","        # only changes bunch['key']. More details can be found at:","68","        # https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/6196.","69","        # Overriding __setstate__ to be a noop has the effect of","70","        # ignoring the pickled __dict__","71","        pass","72","","73",""]}],"sklearn\/datasets\/lfw.py":[{"add":["36","from .base import get_data_home","37","from ..utils import Bunch"],"delete":["36","from .base import get_data_home, Bunch"]}],"sklearn\/datasets\/species_distributions.py":[{"add":["52","from sklearn.datasets.base import get_data_home","53","from ..utils import Bunch"],"delete":["52","from sklearn.datasets.base import get_data_home, Bunch"]}],"sklearn\/datasets\/california_housing.py":[{"add":["37","from .base import get_data_home","38","from ..utils import Bunch"],"delete":["37","from .base import get_data_home, Bunch"]}],"sklearn\/datasets\/olivetti_faces.py":[{"add":["39","from .base import get_data_home","41","from ..utils import check_random_state, Bunch","82","        Each row corresponds to a ravelled face image of original size","83","        64 x 64 pixels.","86","        Each row is a face image corresponding to one of the 40 subjects","87","        of the dataset."],"delete":["39","from .base import get_data_home, Bunch","41","from ..utils import check_random_state","82","        Each row corresponds to a ravelled face image of original size 64 x 64 pixels.","85","        Each row is a face image corresponding to one of the 40 subjects of the dataset."]}],"sklearn\/datasets\/twenty_newsgroups.py":[{"add":["51","from ..utils import check_random_state, Bunch"],"delete":["49","from .base import Bunch","52","from ..utils import check_random_state"]}],"sklearn\/datasets\/kddcup99.py":[{"add":["25","from ..utils import Bunch"],"delete":["25","from .base import Bunch"]}],"doc\/modules\/pipeline.rst":[{"add":["81","Attributes of named_steps map to keys, enabling tab completion in interactive environments::","82","","83","    >>> pipe.named_steps.reduce_dim is pipe.named_steps['reduce_dim']","84","    True","85",""],"delete":[]}],"sklearn\/utils\/__init__.py":[{"add":["30","class Bunch(dict):","31","    \"\"\"Container object for datasets","32","","33","    Dictionary-like object that exposes its keys as attributes.","34","","35","    >>> b = Bunch(a=1, b=2)","36","    >>> b['b']","37","    2","38","    >>> b.b","39","    2","40","    >>> b.a = 3","41","    >>> b['a']","42","    3","43","    >>> b.c = 6","44","    >>> b['c']","45","    6","46","","47","    \"\"\"","48","","49","    def __init__(self, **kwargs):","50","        super(Bunch, self).__init__(kwargs)","51","","52","    def __setattr__(self, key, value):","53","        self[key] = value","54","","55","    def __dir__(self):","56","        return self.keys()","57","","58","    def __getattr__(self, key):","59","        try:","60","            return self[key]","61","        except KeyError:","62","            raise AttributeError(key)","63","","64","    def __setstate__(self, state):","65","        # Bunch pickles generated with scikit-learn 0.16.* have an non","66","        # empty __dict__. This causes a surprising behaviour when","67","        # loading these pickles scikit-learn 0.17: reading bunch.key","68","        # uses __dict__ but assigning to bunch.key use __setattr__ and","69","        # only changes bunch['key']. More details can be found at:","70","        # https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/6196.","71","        # Overriding __setstate__ to be a noop has the effect of","72","        # ignoring the pickled __dict__","73","        pass","74","","75",""],"delete":[]}],"sklearn\/datasets\/rcv1.py":[{"add":["27","from ..utils import Bunch"],"delete":["22","from .base import Bunch"]}],"sklearn\/tests\/test_pipeline.py":[{"add":["511","def test_pipeline_named_steps():","512","    transf = Transf()","513","    mult2 = Mult(mult=2)","514","    pipeline = Pipeline([('mock', transf), (\"mult\", mult2)])","515","","516","    # Test access via named_steps bunch object","517","    assert_true('mock' in pipeline.named_steps)","518","    assert_true('mock2' not in pipeline.named_steps)","519","    assert_true(pipeline.named_steps.mock is transf)","520","    assert_true(pipeline.named_steps.mult is mult2)","521","","522","    # Test bunch with conflict attribute of dict","523","    pipeline = Pipeline([('values', transf), (\"mult\", mult2)])","524","    assert_true(pipeline.named_steps.values is not transf)","525","    assert_true(pipeline.named_steps.mult is mult2)","526","","527",""],"delete":[]}],"sklearn\/datasets\/covtype.py":[{"add":["28","from ..utils import Bunch"],"delete":["28","from .base import Bunch"]}],"sklearn\/datasets\/mldata.py":[{"add":["25","from .base import get_data_home","26","from ..utils import Bunch"],"delete":["25","from .base import get_data_home, Bunch"]}],"doc\/whats_new.rst":[{"add":["279","   - Replace attribute ``named_steps`` ``dict`` to :class:`sklearn.utils.Bunch`","280","     in :class:`sklearn.pipeline.Pipeline` to enable tab completion in interactive","281","     environment. In the case conflict value on ``named_steps`` and ``dict``","282","     attribute, ``dict`` behavior will be prioritized.","283","     :issue:`8481` by :user:`Herilalaina Rakotoarison <herilalaina>`.","284",""],"delete":[]}],"sklearn\/pipeline.py":[{"add":["22","from .utils import Bunch","125","    named_steps : bunch object, a dictionary with attribute access","160","    >>> # Another way to get selected features chosen by anova_filter","161","    >>> anova_svm.named_steps.anova.get_support()","162","    ... # doctest: +NORMALIZE_WHITESPACE","163","    array([False, False,  True,  True, False, False, True,  True, False,","164","           True,  False,  True,  True, False, True,  False, True, True,","165","           False, False], dtype=bool)","235","        # Use Bunch object to improve autocomplete","236","        return Bunch(**dict(self.steps))"],"delete":["124","    named_steps : dict","159","","229","        return dict(self.steps)"]}]}},"05b5b371743300dc8bba36f43c46a1b8f7ee984c":{"changes":{"sklearn\/linear_model\/coordinate_descent.py":"MODIFY"},"diff":{"sklearn\/linear_model\/coordinate_descent.py":[{"add":["1560","        For l1_ratio = 1 the penalty is an L1\/L2 penalty. For l1_ratio = 0 it","1561","        is an L2 penalty.","1875","        For l1_ratio = 1 the penalty is an L1\/L2 penalty. For l1_ratio = 0 it","1876","        is an L2 penalty."],"delete":["1560","        For l1_ratio = 0 the penalty is an L1\/L2 penalty. For l1_ratio = 1 it","1561","        is an L1 penalty.","1875","        For l1_ratio = 0 the penalty is an L1\/L2 penalty. For l1_ratio = 1 it","1876","        is an L1 penalty."]}]}},"08772c42e7be84ba89c0c7a9d8280fd79ab53397":{"changes":{"sklearn\/linear_model\/tests\/test_least_angle.py":"MODIFY","doc\/whats_new.rst":"MODIFY","sklearn\/linear_model\/least_angle.py":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_least_angle.py":[{"add":["368","    estimators = [","369","        linear_model.LassoLars(),","370","        linear_model.Lars(),","371","        # regression test for gh-1615","372","        linear_model.LassoLars(fit_intercept=False),","373","        linear_model.Lars(fit_intercept=False),","374","    ]","376","    for estimator in estimators:"],"delete":["369","    for estimator in (linear_model.LassoLars(), linear_model.Lars()):"]}],"doc\/whats_new.rst":[{"add":["196","   - Fix a bug where :func:`sklearn.linear_model.LassoLars.fit` sometimes","197","     left `coef_` as a list, rather than an ndarray.","198","     :issue:`8160` by :user:`CJ Carey <perimosocordiae>`.","199",""],"delete":[]}],"sklearn\/linear_model\/least_angle.py":[{"add":["667","        self.coef_ = np.empty((n_targets, n_features))","684","                self.coef_[k] = coef_path[:, -1]"],"delete":["669","            self.coef_ = []","684","                self.coef_.append(coef_path[:, -1])","692","            self.coef_ = np.empty((n_targets, n_features))"]}]}},"eaebfe05353afce37605162597485c494cdd68b2":{"changes":{"sklearn\/model_selection\/_split.py":"MODIFY","sklearn\/model_selection\/tests\/test_split.py":"MODIFY"},"diff":{"sklearn\/model_selection\/_split.py":[{"add":["1861","    shuffle : boolean, optional (default=True)","1862","        Whether or not to shuffle the data before splitting. If shuffle=False","1863","        then stratify must be None.","1864","","1908","    >>> train_test_split(y, shuffle=False)","1909","    [[0, 1, 2], [3, 4]]","1910","","1919","    shuffle = options.pop('shuffle', True)","1929","    if shuffle is False:","1930","        if stratify is not None:","1931","            raise NotImplementedError(","1932","                \"Stratified train\/test split is not implemented for \"","1933","                \"shuffle=False\")","1934","","1935","        n_samples = _num_samples(arrays[0])","1936","        n_train, n_test = _validate_shuffle_split(n_samples, test_size,","1937","                                                  train_size)","1938","","1939","        train = np.arange(n_train)","1940","        test = np.arange(n_train, n_train + n_test)","1941","","1943","        if stratify is not None:","1944","            CVClass = StratifiedShuffleSplit","1945","        else:","1946","            CVClass = ShuffleSplit","1948","        cv = CVClass(test_size=test_size,","1949","                     train_size=train_size,","1950","                     random_state=random_state)","1952","        train, test = next(cv.split(X=arrays[0], y=stratify))","1953","","1960",""],"delete":["1452","","1922","    if stratify is not None:","1923","        CVClass = StratifiedShuffleSplit","1925","        CVClass = ShuffleSplit","1927","    cv = CVClass(test_size=test_size,","1928","                 train_size=train_size,","1929","                 random_state=random_state)","1931","    train, test = next(cv.split(X=arrays[0], y=stratify))"]}],"sklearn\/model_selection\/tests\/test_split.py":[{"add":["933","    assert_raises(NotImplementedError, train_test_split, range(10),","934","                  shuffle=False, stratify=True)","977","    # test unshuffled split","978","    y = np.arange(10)","979","    for test_size in [2, 0.2]:","980","        train, test = train_test_split(y, shuffle=False, test_size=test_size)","981","        assert_array_equal(test, [8, 9])","982","        assert_array_equal(train, [0, 1, 2, 3, 4, 5, 6, 7])","983",""],"delete":[]}]}},"b4a12b18a8f9c274c637bf8f5a26282aa4249d85":{"changes":{"examples\/cross_decomposition\/plot_compare_cross_decomposition.py":"MODIFY"},"diff":{"examples\/cross_decomposition\/plot_compare_cross_decomposition.py":[{"add":["146","X_train_r, Y_train_r = cca.transform(X_train, Y_train)","147","X_test_r, Y_test_r = cca.transform(X_test, Y_test)"],"delete":["146","X_train_r, Y_train_r = plsca.transform(X_train, Y_train)","147","X_test_r, Y_test_r = plsca.transform(X_test, Y_test)"]}]}},"2d0bce7bc83b4da51ef1d309e9d587012920edcb":{"changes":{"doc\/tutorial\/statistical_inference\/model_selection.rst":"MODIFY"},"diff":{"doc\/tutorial\/statistical_inference\/model_selection.rst":[{"add":["109","    - :class:`StratifiedKFold` **(n_splits, shuffle, random_state)**","111","    - :class:`GroupKFold` **(n_splits)**","127","    - :class:`ShuffleSplit` **(n_splits, test_size, train_size, random_state)**","148","    - :class:`LeavePGroupsOut`  **(n_groups)**"],"delete":["109","    - :class:`StratifiedKFold` **(n_iter, test_size, train_size, random_state)**","111","    - :class:`GroupKFold` **(n_splits, shuffle, random_state)**","127","    - :class:`ShuffleSplit` **(n_iter, test_size, train_size, random_state)**","148","    - :class:`LeavePGroupsOut`  **(p)**"]}]}},"4ab99c75b4486f5e1a67be730b7afa6d9551ed7e":{"changes":{"sklearn\/utils\/fixes.py":"MODIFY","sklearn\/ensemble\/iforest.py":"MODIFY","doc\/whats_new.rst":"MODIFY","sklearn\/ensemble\/tests\/test_iforest.py":"MODIFY"},"diff":{"sklearn\/utils\/fixes.py":[{"add":["38","euler_gamma = getattr(np, 'euler_gamma',","39","                      0.577215664901532860606512090082402431)"],"delete":[]}],"sklearn\/ensemble\/iforest.py":[{"add":["9","from sklearn.utils.fixes import euler_gamma","303","            return 2. * (np.log(n_samples_leaf - 1.) + euler_gamma) - 2. * (","317","            np.log(n_samples_leaf[not_mask] - 1.) + euler_gamma) - 2. * ("],"delete":["302","            return 2. * (np.log(n_samples_leaf) + 0.5772156649) - 2. * (","316","            np.log(n_samples_leaf[not_mask]) + 0.5772156649) - 2. * ("]}],"doc\/whats_new.rst":[{"add":["20","   * :class:`sklearn.ensemble.IsolationForest` (bug fix)","158","   - Fixed a bug where :class:`sklearn.ensemble.IsolationForest` uses an","159","     an incorrect formula for the average path length","160","     :issue:`8549` by `Peter Wang <https:\/\/github.com\/PTRWang>`_.","161","","162","   - Fixed a bug where :class:`sklearn.cluster.DBSCAN` gives incorrect","173","     :issue:`8344` by :user:`Akshay Gupta <Akshay0724>`","280","","281","   - Estimators with both methods ``decision_function`` and ``predict_proba``","282","     are now required to have a monotonic relation between them. The","283","     method ``check_decision_proba_consistency`` has been added in","284","     **sklearn.utils.estimator_checks** to check their consistency.","286",""],"delete":["20","* *to be listed*","158","   - Fixed a bug where :class:`sklearn.cluster.DBSCAN` gives incorrect ","169","     :issue:`8344` by :user:`Akshay Gupta <Akshay0724>` ","276","      ","277","   - Estimators with both methods ``decision_function`` and ``predict_proba`` ","278","     are now required to have a monotonic relation between them. The ","279","     method ``check_decision_proba_consistency`` has been added in ","280","     **sklearn.utils.estimator_checks** to check their consistency. ","282","      "]}],"sklearn\/ensemble\/tests\/test_iforest.py":[{"add":["10","from sklearn.utils.fixes import euler_gamma","11","from sklearn.utils.testing import assert_almost_equal","23","from sklearn.ensemble.iforest import _average_path_length","216","","217","","218","def test_iforest_average_path_length():","219","    # It tests non-regression for #8549 which used the wrong formula","220","    # for average path length, strictly for the integer case","221","","222","    result_one = 2. * (np.log(4.) + euler_gamma) - 2. * 4. \/ 5.","223","    result_two = 2. * (np.log(998.) + euler_gamma) - 2. * 998. \/ 999.","224","    assert_almost_equal(_average_path_length(1), 1., decimal=10)","225","    assert_almost_equal(_average_path_length(5), result_one, decimal=10)","226","    assert_almost_equal(_average_path_length(999), result_two, decimal=10)","227","    assert_array_almost_equal(_average_path_length(np.array([1, 5, 999])),","228","                              [1., result_one, result_two], decimal=10)"],"delete":[]}]}},"fc2f24927fc37d7e42917369f17de045b14c59b5":{"changes":{"sklearn\/tree\/_tree.pxd":"MODIFY","sklearn\/tree\/tree.py":"MODIFY","sklearn\/ensemble\/gradient_boosting.py":"MODIFY","sklearn\/ensemble\/tests\/test_forest.py":"MODIFY","doc\/whats_new.rst":"MODIFY","sklearn\/tree\/_tree.pyx":"MODIFY","sklearn\/ensemble\/tests\/test_gradient_boosting.py":"MODIFY","sklearn\/ensemble\/forest.py":"MODIFY","sklearn\/tree\/tests\/test_tree.py":"MODIFY"},"diff":{"sklearn\/tree\/_tree.pxd":[{"add":["92","    cdef Splitter splitter              # Splitting algorithm","94","    cdef SIZE_t min_samples_split       # Minimum number of samples in an internal node","95","    cdef SIZE_t min_samples_leaf        # Minimum number of samples in a leaf","96","    cdef double min_weight_leaf         # Minimum weight in a leaf","97","    cdef SIZE_t max_depth               # Maximal tree depth","98","    cdef double min_impurity_split","99","    cdef double min_impurity_decrease   # Impurity threshold for early stopping"],"delete":["92","    cdef Splitter splitter          # Splitting algorithm","94","    cdef SIZE_t min_samples_split   # Minimum number of samples in an internal node","95","    cdef SIZE_t min_samples_leaf    # Minimum number of samples in a leaf","96","    cdef double min_weight_leaf     # Minimum weight in a leaf","97","    cdef SIZE_t max_depth           # Maximal tree depth","98","    cdef double min_impurity_split  # Impurity threshold for early stopping"]}],"sklearn\/tree\/tree.py":[{"add":["20","import warnings","92","                 min_impurity_decrease,","105","        self.min_impurity_decrease = min_impurity_decrease","277","        if self.min_impurity_split is not None:","278","            warnings.warn(\"The min_impurity_split parameter is deprecated and\"","279","                          \" will be removed in version 0.21. \"","280","                          \"Use the min_impurity_decrease parameter instead.\",","281","                          DeprecationWarning)","282","            min_impurity_split = self.min_impurity_split","283","        else:","284","            min_impurity_split = 1e-7","285","","286","        if min_impurity_split < 0.:","290","        if self.min_impurity_decrease < 0.:","291","            raise ValueError(\"min_impurity_decrease must be greater than \"","292","                             \"or equal to 0\")","293","","349","                                            max_depth,","350","                                            self.min_impurity_decrease,","351","                                            min_impurity_split)","358","                                           self.min_impurity_decrease,","359","                                           min_impurity_split)","608","    min_impurity_decrease : float, optional (default=0.)","609","        A node will be split if this split induces a decrease of the impurity","610","        greater than or equal to this value.","612","        The weighted impurity decrease equation is the following::","613","","614","            N_t \/ N * (impurity - N_t_R \/ N_t * right_impurity","615","                                - N_t_L \/ N_t * left_impurity)","616","","617","        where ``N`` is the total number of samples, ``N_t`` is the number of","618","        samples at the current node, ``N_t_L`` is the number of samples in the","619","        left child, and ``N_t_R`` is the number of samples in the right child.","620","","621","        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,","622","        if ``sample_weight`` is passed.","623","","624","        .. versionadded:: 0.19","712","                 min_impurity_decrease=0.,","713","                 min_impurity_split=None,","727","            min_impurity_decrease=min_impurity_decrease,","932","    min_impurity_decrease : float, optional (default=0.)","933","        A node will be split if this split induces a decrease of the impurity","934","        greater than or equal to this value.","936","        The weighted impurity decrease equation is the following::","937","","938","            N_t \/ N * (impurity - N_t_R \/ N_t * right_impurity","939","                                - N_t_L \/ N_t * left_impurity)","940","","941","        where ``N`` is the total number of samples, ``N_t`` is the number of","942","        samples at the current node, ``N_t_L`` is the number of samples in the","943","        left child, and ``N_t_R`` is the number of samples in the right child.","944","","945","        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,","946","        if ``sample_weight`` is passed.","947","","948","        .. versionadded:: 0.19","1028","                 min_impurity_decrease=0.,","1029","                 min_impurity_split=None,","1041","            min_impurity_decrease=min_impurity_decrease,","1123","                 min_impurity_decrease=0.,","1124","                 min_impurity_split=None,","1136","            min_impurity_decrease=min_impurity_decrease,","1174","                 min_impurity_decrease=0.,","1175","                 min_impurity_split=None,","1186","            min_impurity_decrease=min_impurity_decrease,"],"delete":["274","        if self.min_impurity_split < 0.:","333","                                            max_depth, self.min_impurity_split)","340","                                           self.min_impurity_split)","589","    min_impurity_split : float, optional (default=1e-7)","590","        Threshold for early stopping in tree growth. A node will split","591","        if its impurity is above the threshold, otherwise it is a leaf.","593","        .. versionadded:: 0.18","681","                 min_impurity_split=1e-7,","899","    min_impurity_split : float, optional (default=1e-7)","900","        Threshold for early stopping in tree growth. If the impurity","901","        of a node is below the threshold, the node is a leaf.","903","        .. versionadded:: 0.18","983","                 min_impurity_split=1e-7,","1076","                 min_impurity_split=1e-7,","1125","                 min_impurity_split=1e-7,"]}],"sklearn\/ensemble\/gradient_boosting.py":[{"add":["725","                 max_depth, min_impurity_decrease, min_impurity_split,","726","                 init, subsample, max_features,","740","        self.min_impurity_decrease = min_impurity_decrease","773","                min_impurity_decrease=self.min_impurity_decrease,","1329","    min_impurity_decrease : float, optional (default=0.)","1330","        A node will be split if this split induces a decrease of the impurity","1331","        greater than or equal to this value.","1333","        The weighted impurity decrease equation is the following::","1334","","1335","            N_t \/ N * (impurity - N_t_R \/ N_t * right_impurity","1336","                                - N_t_L \/ N_t * left_impurity)","1337","","1338","        where ``N`` is the total number of samples, ``N_t`` is the number of","1339","        samples at the current node, ``N_t_L`` is the number of samples in the","1340","        left child, and ``N_t_R`` is the number of samples in the right child.","1341","","1342","        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,","1343","        if ``sample_weight`` is passed.","1344","","1345","        .. versionadded:: 0.19","1434","                 max_depth=3, min_impurity_decrease=0.,","1435","                 min_impurity_split=1e-7, init=None,","1449","            min_impurity_decrease=min_impurity_decrease,","1734","    min_impurity_decrease : float, optional (default=0.)","1735","        A node will be split if this split induces a decrease of the impurity","1736","        greater than or equal to this value.","1738","        The weighted impurity decrease equation is the following::","1739","","1740","            N_t \/ N * (impurity - N_t_R \/ N_t * right_impurity","1741","                                - N_t_L \/ N_t * left_impurity)","1742","","1743","        where ``N`` is the total number of samples, ``N_t`` is the number of","1744","        samples at the current node, ``N_t_L`` is the number of samples in the","1745","        left child, and ``N_t_R`` is the number of samples in the right child.","1746","","1747","        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,","1748","        if ``sample_weight`` is passed.","1749","","1750","        .. versionadded:: 0.19","1842","                 max_depth=3, min_impurity_decrease=0.,","1843","                 min_impurity_split=1e-7, init=None, random_state=None,","1853","            max_features=max_features,","1854","            min_impurity_decrease=min_impurity_decrease,","1855","            min_impurity_split=min_impurity_split,"],"delete":["725","                 max_depth, min_impurity_split, init, subsample, max_features,","1326","    min_impurity_split : float, optional (default=1e-7)","1327","        Threshold for early stopping in tree growth. A node will split","1328","        if its impurity is above the threshold, otherwise it is a leaf.","1330","        .. versionadded:: 0.18","1419","                 max_depth=3, min_impurity_split=1e-7, init=None,","1717","    min_impurity_split : float, optional (default=1e-7)","1718","        Threshold for early stopping in tree growth. A node will split","1719","        if its impurity is above the threshold, otherwise it is a leaf.","1721","        .. versionadded:: 0.18","1813","                 max_depth=3, min_impurity_split=1e-7, init=None, random_state=None,","1823","            max_features=max_features, min_impurity_split=min_impurity_split,"]}],"sklearn\/ensemble\/tests\/test_forest.py":[{"add":["30","from sklearn.utils.testing import assert_warns_message","1183","","1184","","1185","def test_min_impurity_split():","1186","    # Test if min_impurity_split of base estimators is set","1187","    # Regression test for #8006","1188","    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)","1189","    all_estimators = [RandomForestClassifier, RandomForestRegressor,","1190","                      ExtraTreesClassifier, ExtraTreesRegressor]","1191","","1192","    for Estimator in all_estimators:","1193","        est = Estimator(min_impurity_split=0.1)","1194","        est = assert_warns_message(DeprecationWarning, \"min_impurity_decrease\",","1195","                                   est.fit, X, y)","1196","        for tree in est.estimators_:","1197","            assert_equal(tree.min_impurity_split, 0.1)","1198","","1199","","1200","def test_min_impurity_decrease():","1201","    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)","1202","    all_estimators = [RandomForestClassifier, RandomForestRegressor,","1203","                      ExtraTreesClassifier, ExtraTreesRegressor]","1204","","1205","    for Estimator in all_estimators:","1206","        est = Estimator(min_impurity_decrease=0.1)","1207","        est.fit(X, y)","1208","        for tree in est.estimators_:","1209","            # Simply check if the parameter is passed on correctly. Tree tests","1210","            # will suffice for the actual working of this param","1211","            assert_equal(tree.min_impurity_decrease, 0.1)"],"delete":[]}],"doc\/whats_new.rst":[{"add":["311","   - All tree based estimators now accept a ``min_impurity_decrease``","312","     parameter in lieu of the ``min_impurity_split``, which is now deprecated.","313","     The ``min_impurity_decrease`` helps stop splitting the nodes in which","314","     the weighted impurity decrease from splitting is no longer alteast","315","     ``min_impurity_decrease``.  :issue:`8449` by `Raghav RV_`","316",""],"delete":[]}],"sklearn\/tree\/_tree.pyx":[{"add":["21","from libc.math cimport fabs","54","cdef double EPSILON = np.finfo('double').eps","134","                  SIZE_t max_depth, double min_impurity_decrease,","135","                  double min_impurity_split):","141","        self.min_impurity_decrease = min_impurity_decrease","172","        cdef double min_impurity_decrease = self.min_impurity_decrease","236","                    # If EPSILON=0 in the below comparison, float precision","237","                    # issues stop splitting, producing trees that are","238","                    # dissimilar to v0.18","239","                    is_leaf = (is_leaf or split.pos >= end or","240","                               (split.improvement + EPSILON <","241","                                min_impurity_decrease))","305","                  double min_impurity_decrease, double min_impurity_split):","312","        self.min_impurity_decrease = min_impurity_decrease","439","        cdef double min_impurity_decrease = self.min_impurity_decrease","460","            # If EPSILON=0 in the below comparison, float precision issues stop","461","            # splitting early, producing trees that are dissimilar to v0.18","462","            is_leaf = (is_leaf or split.pos >= end or","463","                       split.improvement + EPSILON < min_impurity_decrease)"],"delete":["132","                  SIZE_t max_depth, double min_impurity_split):","231","                    is_leaf = is_leaf or (split.pos >= end)","295","                  double min_impurity_split):","448","            is_leaf = is_leaf or (split.pos >= end)"]}],"sklearn\/ensemble\/tests\/test_gradient_boosting.py":[{"add":["28","from sklearn.utils.testing import assert_warns_message","968","    all_estimators = [GradientBoostingRegressor, GradientBoostingClassifier]","971","        est = GBEstimator(min_impurity_split=0.1)","972","        est = assert_warns_message(DeprecationWarning, \"min_impurity_decrease\",","973","                                   est.fit, X, y)","978","def test_min_impurity_decrease():","979","    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)","980","    all_estimators = [GradientBoostingRegressor, GradientBoostingClassifier]","981","","982","    for GBEstimator in all_estimators:","983","        est = GBEstimator(min_impurity_decrease=0.1)","984","        est.fit(X, y)","985","        for tree in est.estimators_.flat:","986","            # Simply check if the parameter is passed on correctly. Tree tests","987","            # will suffice for the actual working of this param","988","            assert_equal(tree.min_impurity_decrease, 0.1)","989","","990",""],"delete":["967","    all_estimators = [GradientBoostingRegressor,","968","                      GradientBoostingClassifier]","971","        est = GBEstimator(min_impurity_split=0.1).fit(X, y)"]}],"sklearn\/ensemble\/forest.py":[{"add":["815","    min_impurity_decrease : float, optional (default=0.)","816","        A node will be split if this split induces a decrease of the impurity","817","        greater than or equal to this value.","819","        The weighted impurity decrease equation is the following::","820","","821","            N_t \/ N * (impurity - N_t_R \/ N_t * right_impurity","822","                                - N_t_L \/ N_t * left_impurity)","823","","824","        where ``N`` is the total number of samples, ``N_t`` is the number of","825","        samples at the current node, ``N_t_L`` is the number of samples in the","826","        left child, and ``N_t_R`` is the number of samples in the right child.","827","","828","        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,","829","        if ``sample_weight`` is passed.","830","","831","        .. versionadded:: 0.19","936","                 min_impurity_decrease=0.,","937","                 min_impurity_split=None,","950","                              \"max_features\", \"max_leaf_nodes\",","951","                              \"min_impurity_decrease\", \"min_impurity_split\",","968","        self.min_impurity_decrease = min_impurity_decrease","1051","    min_impurity_decrease : float, optional (default=0.)","1052","        A node will be split if this split induces a decrease of the impurity","1053","        greater than or equal to this value.","1055","        The weighted impurity decrease equation is the following::","1056","","1057","            N_t \/ N * (impurity - N_t_R \/ N_t * right_impurity","1058","                                - N_t_L \/ N_t * left_impurity)","1059","","1060","        where ``N`` is the total number of samples, ``N_t`` is the number of","1061","        samples at the current node, ``N_t_L`` is the number of samples in the","1062","        left child, and ``N_t_R`` is the number of samples in the right child.","1063","","1064","        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,","1065","        if ``sample_weight`` is passed.","1066","","1067","        .. versionadded:: 0.19","1141","                 min_impurity_decrease=0.,","1142","                 min_impurity_split=None,","1154","                              \"max_features\", \"max_leaf_nodes\",","1155","                              \"min_impurity_decrease\", \"min_impurity_split\",","1171","        self.min_impurity_decrease = min_impurity_decrease","1247","    min_impurity_decrease : float, optional (default=0.)","1248","        A node will be split if this split induces a decrease of the impurity","1249","        greater than or equal to this value.","1251","        The weighted impurity decrease equation is the following::","1252","","1253","            N_t \/ N * (impurity - N_t_R \/ N_t * right_impurity","1254","                                - N_t_L \/ N_t * left_impurity)","1255","","1256","        where ``N`` is the total number of samples, ``N_t`` is the number of","1257","        samples at the current node, ``N_t_L`` is the number of samples in the","1258","        left child, and ``N_t_R`` is the number of samples in the right child.","1259","","1260","        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,","1261","        if ``sample_weight`` is passed.","1262","","1263","        .. versionadded:: 0.19","1360","                 min_impurity_decrease=0.,","1361","                 min_impurity_split=None,","1374","                              \"max_features\", \"max_leaf_nodes\",","1375","                              \"min_impurity_decrease\", \"min_impurity_split\",","1392","        self.min_impurity_decrease = min_impurity_decrease","1473","    min_impurity_decrease : float, optional (default=0.)","1474","        A node will be split if this split induces a decrease of the impurity","1475","        greater than or equal to this value.","1477","        The weighted impurity decrease equation is the following::","1478","","1479","            N_t \/ N * (impurity - N_t_R \/ N_t * right_impurity","1480","                                - N_t_L \/ N_t * left_impurity)","1481","","1482","        where ``N`` is the total number of samples, ``N_t`` is the number of","1483","        samples at the current node, ``N_t_L`` is the number of samples in the","1484","        left child, and ``N_t_R`` is the number of samples in the right child.","1485","","1486","        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,","1487","        if ``sample_weight`` is passed.","1488","","1489","        .. versionadded:: 0.19","1555","                 min_impurity_decrease=0.,","1556","                 min_impurity_split=None,","1568","                              \"max_features\", \"max_leaf_nodes\",","1569","                              \"min_impurity_decrease\", \"min_impurity_split\",","1585","        self.min_impurity_decrease = min_impurity_decrease","1646","    min_impurity_decrease : float, optional (default=0.)","1647","        A node will be split if this split induces a decrease of the impurity","1648","        greater than or equal to this value.","1650","        The weighted impurity decrease equation is the following::","1651","","1652","            N_t \/ N * (impurity - N_t_R \/ N_t * right_impurity","1653","                                - N_t_L \/ N_t * left_impurity)","1654","","1655","        where ``N`` is the total number of samples, ``N_t`` is the number of","1656","        samples at the current node, ``N_t_L`` is the number of samples in the","1657","        left child, and ``N_t_R`` is the number of samples in the right child.","1658","","1659","        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,","1660","        if ``sample_weight`` is passed.","1661","","1662","        .. versionadded:: 0.19","1663","","1664","    bootstrap : boolean, optional (default=True)","1665","        Whether bootstrap samples are used when building trees.","1711","                 min_impurity_decrease=0.,","1712","                 min_impurity_split=None,","1723","                              \"max_features\", \"max_leaf_nodes\",","1724","                              \"min_impurity_decrease\", \"min_impurity_split\",","1740","        self.min_impurity_decrease = min_impurity_decrease"],"delete":["815","    min_impurity_split : float, optional (default=1e-7)","816","        Threshold for early stopping in tree growth. A node will split","817","        if its impurity is above the threshold, otherwise it is a leaf.","819","        .. versionadded:: 0.18","924","                 min_impurity_split=1e-7,","937","                              \"max_features\", \"max_leaf_nodes\", \"min_impurity_split\",","1036","    min_impurity_split : float, optional (default=1e-7)","1037","        Threshold for early stopping in tree growth. A node will split","1038","        if its impurity is above the threshold, otherwise it is a leaf.","1040","        .. versionadded:: 0.18","1114","                 min_impurity_split=1e-7,","1126","                              \"max_features\", \"max_leaf_nodes\", \"min_impurity_split\",","1217","    min_impurity_split : float, optional (default=1e-7)","1218","        Threshold for early stopping in tree growth. A node will split","1219","        if its impurity is above the threshold, otherwise it is a leaf.","1221","        .. versionadded:: 0.18","1318","                 min_impurity_split=1e-7,","1331","                              \"max_features\", \"max_leaf_nodes\", \"min_impurity_split\",","1428","    min_impurity_split : float, optional (default=1e-7)","1429","        Threshold for early stopping in tree growth. A node will split","1430","        if its impurity is above the threshold, otherwise it is a leaf.","1432","        .. versionadded:: 0.18","1498","                 min_impurity_split=1e-7,","1510","                              \"max_features\", \"max_leaf_nodes\", \"min_impurity_split\",","1586","    min_impurity_split : float, optional (default=1e-7)","1587","        Threshold for early stopping in tree growth. A node will split","1588","        if its impurity is above the threshold, otherwise it is a leaf.","1590","        .. versionadded:: 0.18","1636","                 min_impurity_split=1e-7,","1647","                              \"max_features\", \"max_leaf_nodes\", \"min_impurity_split\","]}],"sklearn\/tree\/tests\/test_tree.py":[{"add":["30","from sklearn.utils.testing import assert_warns","31","from sklearn.utils.testing import assert_warns_message","529","        assert_raises(ValueError,","530","                      TreeEstimator(min_impurity_decrease=-1.0).fit, X, y)","804","        assert_true(est.min_impurity_split is None,","805","                    \"Failed, min_impurity_split = {0} > 1e-7\".format(","806","                        est.min_impurity_split))","807","        try:","808","            assert_warns(DeprecationWarning, est.fit, X, y)","809","        except AssertionError:","810","            pass","813","                    est.tree_.children_right[node] == TREE_LEAF):","820","        # verify leaf nodes have impurity [0,min_impurity_split] when using","821","        # min_impurity_split","825","        assert_warns_message(DeprecationWarning,","826","                             \"Use the min_impurity_decrease\",","827","                             est.fit, X, y)","830","                    est.tree_.children_right[node] == TREE_LEAF):","843","def test_min_impurity_decrease():","844","    # test if min_impurity_decrease ensure that a split is made only if","845","    # if the impurity decrease is atleast that value","846","    X, y = datasets.make_classification(n_samples=10000, random_state=42)","847","","848","    # test both DepthFirstTreeBuilder and BestFirstTreeBuilder","849","    # by setting max_leaf_nodes","850","    for max_leaf_nodes, name in product((None, 1000), ALL_TREES.keys()):","851","        TreeEstimator = ALL_TREES[name]","852","","853","        # Check default value of min_impurity_decrease, 1e-7","854","        est1 = TreeEstimator(max_leaf_nodes=max_leaf_nodes, random_state=0)","855","        # Check with explicit value of 0.05","856","        est2 = TreeEstimator(max_leaf_nodes=max_leaf_nodes,","857","                             min_impurity_decrease=0.05, random_state=0)","858","        # Check with a much lower value of 0.0001","859","        est3 = TreeEstimator(max_leaf_nodes=max_leaf_nodes,","860","                             min_impurity_decrease=0.0001, random_state=0)","861","        # Check with a much lower value of 0.1","862","        est4 = TreeEstimator(max_leaf_nodes=max_leaf_nodes,","863","                             min_impurity_decrease=0.1, random_state=0)","864","","865","        for est, expected_decrease in ((est1, 1e-7), (est2, 0.05),","866","                                       (est3, 0.0001), (est4, 0.1)):","867","            assert_less_equal(est.min_impurity_decrease, expected_decrease,","868","                              \"Failed, min_impurity_decrease = {0} > {1}\"","869","                              .format(est.min_impurity_decrease,","870","                                      expected_decrease))","871","            est.fit(X, y)","872","            for node in range(est.tree_.node_count):","873","                # If current node is a not leaf node, check if the split was","874","                # justified w.r.t the min_impurity_decrease","875","                if est.tree_.children_left[node] != TREE_LEAF:","876","                    imp_parent = est.tree_.impurity[node]","877","                    wtd_n_node = est.tree_.weighted_n_node_samples[node]","878","","879","                    left = est.tree_.children_left[node]","880","                    wtd_n_left = est.tree_.weighted_n_node_samples[left]","881","                    imp_left = est.tree_.impurity[left]","882","                    wtd_imp_left = wtd_n_left * imp_left","883","","884","                    right = est.tree_.children_right[node]","885","                    wtd_n_right = est.tree_.weighted_n_node_samples[right]","886","                    imp_right = est.tree_.impurity[right]","887","                    wtd_imp_right = wtd_n_right * imp_right","888","","889","                    wtd_avg_left_right_imp = wtd_imp_right + wtd_imp_left","890","                    wtd_avg_left_right_imp \/= wtd_n_node","891","","892","                    fractional_node_weight = (","893","                        est.tree_.weighted_n_node_samples[node] \/ X.shape[0])","894","","895","                    actual_decrease = fractional_node_weight * (","896","                        imp_parent - wtd_avg_left_right_imp)","897","","898","                    assert_greater_equal(actual_decrease, expected_decrease,","899","                                         \"Failed with {0} \"","900","                                         \"expected min_impurity_decrease={1}\"","901","                                         .format(actual_decrease,","902","                                                 expected_decrease))","1684","    dt_mae.fit([[3], [5], [3], [8], [5]], [6, 7, 3, 4, 3])","1688","    dt_mae.fit([[3], [5], [3], [8], [5]], [6, 7, 3, 4, 3],","1689","               [0.6, 0.3, 0.1, 1.0, 0.3])"],"delete":["800","        assert_less_equal(est.min_impurity_split, 1e-7,","801","                     \"Failed, min_impurity_split = {0} > 1e-7\".format(","802","                         est.min_impurity_split))","803","        est.fit(X, y)","806","                est.tree_.children_right[node] == TREE_LEAF):","813","        # verify leaf nodes have impurity [0,min_impurity_split] when using min_impurity_split","817","        est.fit(X, y)","820","                est.tree_.children_right[node] == TREE_LEAF):","833","def test_pickle():","1615","    dt_mae.fit([[3],[5],[3],[8],[5]],[6,7,3,4,3])","1619","    dt_mae.fit([[3],[5],[3],[8],[5]],[6,7,3,4,3], [0.6,0.3,0.1,1.0,0.3])"]}]}},"cb5c1620c39352f58813b3988302c2a302fc526d":{"changes":{"doc\/whats_new.rst":"MODIFY"},"diff":{"doc\/whats_new.rst":[{"add":["46","     :issue:`5295` by `Tom Dupre la Tour`_.","48","   - Added the :class:`model_selection.RepeatedKFold` and","49","     :class:`model_selection.RepeatedStratifiedKFold`.","62","     :issue:`8446` by `Arthur Mensch`_.","75","     documentation build with Sphinx>1.5 :issue:`8010`, :issue:`7986` by","83","     :issue:`7990` by :user:`Guillaume Lemaitre <glemaitre>`.","101","   - Relax assumption on the data for the","102","     :class:`kernel_approximation.SkewedChi2Sampler`. Since the Skewed-Chi2","103","     kernel is defined on the open interval :math:`(-skewedness; +\\infty)^d`,","104","     the transform function should not check whether ``X < 0`` but whether ``X <","105","     -self.skewedness``. :issue:`7573` by `Romain Brault`_.","131","     to enable selection of the norm order when ``coef_`` is more than 1D.","132","     :issue:`6181` by :user:`Antoine Wendlinger <antoinewdg>`.","146","   - :class:`linear_model.RANSACRegressor` no longer throws an error","156","   - Fix a bug where :class:`feature_selection.SelectFdr` did not","178","   - Add ``sample_weight`` parameter to :func:`metrics.cohen_kappa_score`.","179","     :issue:`8335` by :user:`Victor Poughon <vpoughon>`.","182","     is a lot faster with ``return_std=True``. :issue:`8591` by","183","     :user:`Hadrien Bertrand <hbertrand>`.","194","     :class:`linear_model.LogisticRegression` when using newton-cg","195","     solver. :issue:`8835` by :user:`Joan Massich <massich>`.","212","     ``_c_step`` to throw an exception.","215","   - Fixed a bug where :class:`ensemble.IsolationForest` uses an","219","   - Fixed a bug where :class:`cluster.DBSCAN` gives incorrect","221","     rows all zero. :issue:`8306` by :user:`Akshay Gupta <Akshay0724>`","223","   - Fixed a bug where :class:`ensemble.AdaBoostClassifier` throws","227","   - Fixed a bug when :func:`datasets.make_classification` fails","229","     :user:`Herilalaina Rakotoarison <herilalaina>`.","231","   - Fixed a bug where :func:`model_selection.BaseSearchCV.inverse_transform`","232","     returns ``self.best_estimator_.transform()`` instead of","233","     ``self.best_estimator_.inverse_transform()``.","234","     :issue:`8344` by :user:`Akshay Gupta <Akshay0724>`.","236","   - Fixed same issue in :func:`grid_search.BaseSearchCV.inverse_transform`","239","   - Fixed a bug where :class:`linear_model.RandomizedLasso` and","240","     :class:`linear_model.RandomizedLogisticRegression` breaks for","241","     sparse input. :issue:`8259` by :user:`Aman Dalmia <dalmia>`.","243","   - Fixed a bug where :func:`linear_model.RANSACRegressor.fit` may run until","246","   - Fixed a bug where :func:`datasets.make_moons` gives an","250","   - Fixed a bug where :class:`linear_model.LassoLars` does not give","254","   - Some ``fetch_`` functions in :mod:`sklearn.datasets` were ignoring the","255","     ``download_if_missing`` keyword. :issue:`7944` by :user:`Ralf Gommers <rgommers>`.","257","   - Fixed a bug in :class:`ensemble.GradientBoostingClassifier`","258","     and :class:`ensemble.GradientBoostingRegressor`","260","     error. issue:`7970` by :user:`He Chen <chenhe95>`.","262","   - Fix a bug regarding fitting :class:`cluster.KMeans` with a sparse","270","   - Fixed a bug where :class:`ensemble.IsolationForest` fails when","274","   - Fix a bug where :class:`ensemble.VotingClassifier` raises an error","278","   - Fix a bug in :class:`decomposition.LatentDirichletAllocation`","283","   - Fix a bug where :class:`ensemble.GradientBoostingClassifier` and","284","     :class:`ensemble.GradientBoostingRegressor` ignored the","288","   - Fixes to the input validation in :class:`covariance.EllipticEnvelope`.","291","   - Fix output shape and bugs with n_jobs > 1 in","292","     :class:`decomposition.SparseCoder` transform and","293","     :func:`decomposition.sparse_encode`","295","     This also impacts the output shape of :class:`decomposition.DictionaryLearning`.","303","     :class:`ensemble.gradient_boosting.QuantileLossFunction` computed","308","   - Fix :func:`multioutput.MultiOutputClassifier.predict_proba` to","314","   - Fix a bug where :func:`linear_model.LassoLars.fit` sometimes","318","   - Fix a bug where :class:`feature_extraction.FeatureHasher`","320","     preventing the use of","321","     :class:`feature_extraction.text.HashingVectorizer` in a","322","     pipeline with  :class:`feature_extraction.text.TfidfTransformer`.","324","","325","   - Fix a bug in cases where ``numpy.cumsum`` may be numerically unstable,","326","     raising an exception if instability is identified. :issue:`7376` and","328","","329","   - Fix a bug where :meth:`base.BaseEstimator.__getstate__`","333","","334","   - Fix a bug in :func:`metrics.classification._check_targets`","339","","340","   - Fix :func:`linear_model.BayesianRidge.fit` to return","351","   - Fixed a bug where :func:`tree.export_graphviz` raised an error","353","     tree. :issue:`8512` by :user:`Li Li <aikinogard>`.","360","   - Fixed improper scaling in :class:`cross_decomposition.PLSRegression`","366","   - Add ``shuffle`` parameter to :func:`model_selection.train_test_split`.","384","     in :class:`decomposition.LatentDirichletAllocation` because the","389","   - Replace attribute ``named_steps`` ``dict`` to :class:`utils.Bunch`","390","     in :class:`pipeline.Pipeline` to enable tab completion in interactive","395","   - The :func:`multioutput.MultiOutputClassifier.predict_proba`","405","     :class:`model_selection.GridSearchCV` and","406","     :class:`model_selection.RandomizedSearchCV` in favor","412","     :func:`model_selection.cross_val_predict`.","426","     only if the underlying estimator does.  By `Andreas Mller`_.","438","     ``min_impurity_decrease``.  :issue:`8449` by `Raghav RV`_.","440","   - The ``n_topics`` parameter of :class:`decomposition.LatentDirichletAllocation`","442","     :issue:`8922` by :user:`Attractadore`","444","   - :class:`cluster.bicluster.SpectralCoclustering` and","449","     for scikit-learn. The following backported functions in","450","     :mod:`sklearn.utils` have been removed or deprecated accordingly."],"delete":["46","     By `Tom Dupre la Tour`_.","48","   - Added the :class:`sklearn.model_selection.RepeatedKFold` and","49","     :class:`sklearn.model_selection.RepeatedStratifiedKFold`.","62","     By `Arthur Mensch`_.","75","     documentation build with Sphinx>1.5 :issue:`8010`, :issue:`7986`","83","     By :issue:`7990` by :user:`Guillaume Lemaitre <glemaitre>`.","101","   - Relax assumption on the data for the ``SkewedChi2Sampler``. Since the","102","     Skewed-Chi2 kernel is defined on the open interval :math: `(-skewedness;","103","     +\\infty)^d`, the transform function should not check whether X < 0 but","104","     whether ``X < -self.skewedness``. (`#7573","105","     <https:\/\/github.com\/scikit-learn\/scikit-learn\/pull\/7573>`_) by `Romain","106","     Brault`_.","132","     to enable selection of the norm order when ``coef_`` is more than 1D","146","   - :class:`sklearn.linear_model.RANSACRegressor` no longer throws an error","156","   - Fix a bug where :class:`sklearn.feature_selection.SelectFdr` did not","178","   - Add ``sample_weight`` parameter to :func:`metrics.cohen_kappa_score` by","179","     Victor Poughon.","182","     is a lot faster with ``return_std=True`` by :user:`Hadrien Bertrand <hbertrand>`.","193","     :class:`sklearn.linear_model.LogisticRegression` when using newton-cg solver","194","     by :user:`Joan Massich <massich>`","211","     `_c_step` to throw an exception.","214","   - Fixed a bug where :class:`sklearn.ensemble.IsolationForest` uses an","218","   - Fixed a bug where :class:`sklearn.cluster.DBSCAN` gives incorrect","220","     rows all zero.","221","     :issue:`8306` by :user:`Akshay Gupta <Akshay0724>`","223","   - Fixed a bug where :class:`sklearn.ensemble.AdaBoostClassifier` throws","227","   - Fixed a bug when :func:`sklearn.datasets.make_classification` fails ","229","     :user:`Herilalaina Rakotoarison <herilalaina>`","231","   - Fixed a bug where :func:`sklearn.model_selection.BaseSearchCV.inverse_transform`","232","     returns self.best_estimator_.transform() instead of self.best_estimator_.inverse_transform()","233","     :issue:`8344` by :user:`Akshay Gupta <Akshay0724>`","235","   - Fixed same issue in :func:`sklearn.grid_search.BaseSearchCV.inverse_transform`","238","   - Fixed a bug where :class:`sklearn.linear_model.RandomizedLasso` and","239","     :class:`sklearn.linear_model.RandomizedLogisticRegression` breaks for","240","     sparse input.","241","     :issue:`8259` by :user:`Aman Dalmia <dalmia>`.","243","   - Fixed a bug where :func:`sklearn.linear_model.RANSACRegressor.fit` may run until","246","   - Fixed a bug where :func:`sklearn.datasets.make_moons` gives an","250","   - Fixed a bug where :class:`sklearn.linear_model.LassoLars` does not give","254","   - Some ``fetch_`` functions in `sklearn.datasets` were ignoring the","255","     ``download_if_missing`` keyword.  This was fixed in :issue:`7944` by","256","     :user:`Ralf Gommers <rgommers>`.","258","   - Fixed a bug in :class:`sklearn.ensemble.GradientBoostingClassifier`","259","     and :class:`sklearn.ensemble.GradientBoostingRegressor`","261","     error. This was fixed in :issue:`7970` by :user:`He Chen <chenhe95>`.","263","   - Fix a bug regarding fitting :class:`sklearn.cluster.KMeans` with a sparse","271","   - Fixed a bug where :class:`sklearn.ensemble.IsolationForest` fails when","275","   - Fix a bug where :class:`sklearn.ensemble.VotingClassifier` raises an error","279","   - Fix a bug in :class:`sklearn.decomposition.LatentDirichletAllocation`","284","   - Fix a bug where :class:`sklearn.ensemble.GradientBoostingClassifier` and","285","     :class:`sklearn.ensemble.GradientBoostingRegressor` ignored the","289","   - Fixes to the input validation in","290","     :class:`sklearn.covariance.EllipticEnvelope`.","293","   - Fix output shape and bugs with n_jobs > 1 in  ","294","     :class:`sklearn.decomposition.SparseCoder` transform and :func:`sklarn.decomposition.sparse_encode`","296","     This also impacts the output shape of :class:`sklearn.decomposition.DictionaryLearning`.","304","     :class:`sklearn.ensemble.gradient_boosting.QuantileLossFunction` computed","309","   - Fix :func:`sklearn.multioutput.MultiOutputClassifier.predict_proba` to","315","   - Fix a bug where :func:`sklearn.linear_model.LassoLars.fit` sometimes","319","","320","   - Fix a bug where :class:`sklearn.feature_extraction.FeatureHasher`","322","     preventing the use of ","323","     :class:`sklearn.feature_extraction.text.HashingVectorizer` in a","324","     pipeline with  :class:`sklearn.feature_extraction.text.TfidfTransformer`.","326","     ","327","   - Fix a bug in cases where `numpy.cumsum` may be numerically unstable,","328","     raising an exception if instability is identified.  :issue:`7376` and","330","     ","331","   - Fix a bug where :meth:`sklearn.base.BaseEstimator.__getstate__`","335","   - Fix a bug in :func:`sklearn.metrics.classification._check_targets`","340","   - Fix :func:`sklearn.linear_model.BayesianRidge.fit` to return","351","   - Fixed a bug where :func:`sklearn.tree.export_graphviz` raised an error","353","     tree.","354","     :issue:`8512` by :user:`Li Li <aikinogard>`.","361","   - Fixed improper scaling in :class:`sklearn.cross_decomposition.PLSRegression`","367","   - Add ``shuffle`` parameter to :func:`sklearn.model_selection.train_test_split`.","385","     in :class:`sklearn.decomposition.LatentDirichletAllocation` because the","390","   - Replace attribute ``named_steps`` ``dict`` to :class:`sklearn.utils.Bunch`","391","     in :class:`sklearn.pipeline.Pipeline` to enable tab completion in interactive","396","   - The :func:`sklearn.multioutput.MultiOutputClassifier.predict_proba`","406","     :class:`sklearn.model_selection.GridSearchCV` and","407","     :class:`sklearn.model_selection.RandomizedSearchCV` in favor","413","     :func:`sklearn.model_selection.cross_val_predict`.","416","","428","     only if the underlying estimator does.  By `Andreas Mller`_. ","440","     ``min_impurity_decrease``.  :issue:`8449` by `Raghav RV_`","442","   - The ``n_topics`` parameter of :class:`decomposition.LatentDirichletAllocation` ","444","     :issue:`8922` by :user:Attractadore","446","   - :class:`cluster.bicluster.SpectralCoClustering` and","451","     for scikit-learn. The following backported functions in ``sklearn.utils``","452","     have been removed or deprecated accordingly."]}]}},"6d604d1d9342397b90e5e59e1ec1932da3374e7a":{"changes":{"examples\/model_selection\/randomized_search.py":"MODIFY"},"diff":{"examples\/model_selection\/randomized_search.py":[{"add":["56","              \"min_samples_split\": sp_randint(2, 11),","75","              \"min_samples_split\": [2, 3, 10],"],"delete":["56","              \"min_samples_split\": sp_randint(1, 11),","75","              \"min_samples_split\": [1, 3, 10],"]}]}},"00da9cc5341e59e52d52c3278b7c81d4af3c05ce":{"changes":{"sklearn\/tree\/tests\/test_export.py":"MODIFY","sklearn\/tree\/export.py":"MODIFY"},"diff":{"sklearn\/tree\/tests\/test_export.py":[{"add":["4","from re import finditer, search","6","from numpy.random import RandomState","7","","8","from sklearn.base import ClassifierMixin","13","from sklearn.utils.testing import (assert_in, assert_equal, assert_raises,","14","                                   assert_less_equal, assert_raises_regex,","15","                                   assert_raise_message)","241","    # Check precision error","242","    out = StringIO()","243","    assert_raises_regex(ValueError, \"should be greater or equal\",","244","                        export_graphviz, clf, out, precision=-1)","245","    assert_raises_regex(ValueError, \"should be an integer\",","246","                        export_graphviz, clf, out, precision=\"1\")","247","","262","","263","","264","def test_precision():","265","","266","    rng_reg = RandomState(2)","267","    rng_clf = RandomState(8)","268","    for X, y, clf in zip(","269","            (rng_reg.random_sample((5, 2)),","270","             rng_clf.random_sample((1000, 4))),","271","            (rng_reg.random_sample((5, )),","272","             rng_clf.randint(2, size=(1000, ))),","273","            (DecisionTreeRegressor(criterion=\"friedman_mse\", random_state=0,","274","                                   max_depth=1),","275","             DecisionTreeClassifier(max_depth=1, random_state=0))):","276","","277","        clf.fit(X, y)","278","        for precision in (4, 3):","279","            dot_data = export_graphviz(clf, out_file=None, precision=precision,","280","                                       proportion=True)","281","","282","            # With the current random state, the impurity and the threshold","283","            # will have the number of precision set in the export_graphviz","284","            # function. We will check the number of precision with a strict","285","            # equality. The value reported will have only 2 precision and","286","            # therefore, only a less equal comparison will be done.","287","","288","            # check value","289","            for finding in finditer(\"value = \\d+\\.\\d+\", dot_data):","290","                assert_less_equal(","291","                    len(search(\"\\.\\d+\", finding.group()).group()),","292","                    precision + 1)","293","            # check impurity","294","            if isinstance(clf, ClassifierMixin):","295","                pattern = \"gini = \\d+\\.\\d+\"","296","            else:","297","                pattern = \"friedman_mse = \\d+\\.\\d+\"","298","","299","            # check impurity","300","            for finding in finditer(pattern, dot_data):","301","                assert_equal(len(search(\"\\.\\d+\", finding.group()).group()),","302","                             precision + 1)","303","            # check threshold","304","            for finding in finditer(\"<= \\d+\\.\\d+\", dot_data):","305","                assert_equal(len(search(\"\\.\\d+\", finding.group()).group()),","306","                             precision + 1)"],"delete":["4","from re import finditer","10","from sklearn.utils.testing import assert_in, assert_equal, assert_raises","11","from sklearn.utils.testing import assert_raise_message"]}],"sklearn\/tree\/export.py":[{"add":["13","from numbers import Integral","14","","77","                    rounded=False, special_characters=False, precision=3):","147","    precision : int, optional (default=3)","148","        Number of digits of precision for floating point in the values of","149","        impurity, threshold and value attributes of each node.","150","","170","","235","                                           round(tree.threshold[node_id],","236","                                                 precision),","247","            node_string += (str(round(tree.impurity[node_id], precision)) +","270","            value_text = np.around(value, precision)","273","            value_text = np.around(value, precision)","279","            value_text = np.around(value, precision)","412","        if isinstance(precision, Integral):","413","            if precision < 0:","414","                raise ValueError(\"'precision' should be greater or equal to 0.\"","415","                                 \" Got {} instead.\".format(precision))","416","        else:","417","            raise ValueError(\"'precision' should be an integer. Got {}\"","418","                             \" instead.\".format(type(precision)))","419",""],"delete":["75","                    rounded=False, special_characters=False):","228","                                           round(tree.threshold[node_id], 4),","239","            node_string += (str(round(tree.impurity[node_id], 4)) +","262","            value_text = np.around(value, 4)","265","            value_text = np.around(value, 2)","271","            value_text = np.around(value, 4)"]}]}},"676e8630243b894aa2976ef6fb6048f9880b8a23":{"changes":{"sklearn\/model_selection\/tests\/test_search.py":"MODIFY","doc\/whats_new.rst":"MODIFY","sklearn\/model_selection\/_search.py":"MODIFY"},"diff":{"sklearn\/model_selection\/tests\/test_search.py":[{"add":["81","    def transform(self, X):","82","        return X + self.foo_param","83","","84","    def inverse_transform(self, X):","85","        return X - self.foo_param","86","","1311","","1312","","1313","def test_transform_inverse_transform_round_trip():","1314","    clf = MockClassifier()","1315","    grid_search = GridSearchCV(clf, {'foo_param': [1, 2, 3]}, verbose=3)","1316","","1317","    grid_search.fit(X, y)","1318","    X_round_trip = grid_search.inverse_transform(grid_search.transform(X))","1319","    assert_array_equal(X, X_round_trip)"],"delete":["84","    transform = predict","85","    inverse_transform = predict"]}],"doc\/whats_new.rst":[{"add":["155","   - Fixed a bug where :func:`sklearn.model_selection.BaseSearchCV.inverse_transform`","156","     returns self.best_estimator_.transform() instead of self.best_estimator_.inverse_transform()","157","     :issue:`8344` by :user:`Akshay Gupta <Akshay0724>` ","158","","159",""],"delete":[]}],"sklearn\/model_selection\/_search.py":[{"add":["532","        return self.best_estimator_.inverse_transform(Xt)"],"delete":["532","        return self.best_estimator_.transform(Xt)"]}]}}}
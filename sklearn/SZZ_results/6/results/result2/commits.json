{"e070611bdb4884c222b40e4f59b65e8c6ca35380":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/model_selection\/tests\/test_search.py":"MODIFY","sklearn\/model_selection\/_search.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["55","- :class:`dummy.DummyRegressor` now has a ``return_std`` option in its","149","- :class:`neighbors.RadiusNeighborsRegressor` and","278","  of cross-validation values for different alphas. :issue:`10297` by","280","","491","- The :func:`covariance.graph_lasso`, :class:`covariance.GraphLasso` and","492","  :class:`covariance.GraphLassoCV` have been renamed to","508","- Changed ValueError exception raised in :class:`model_selection.ParameterSampler`","509","  to a UserWarning for case where the class is instantiated with a greater value of","510","  ``n_iter`` than the total space of parameters in the parameter grid. ``n_iter`` now","511","  acts as an upper bound on iterations.","512","  :issue:`#10982` by :user:`Juliet Lawton <julietcl>`","513",""],"delete":["55","- :class:`dummy.DummyRegressor` now has a ``return_std`` option in its ","149","- :class:`neighbors.RadiusNeighborsRegressor` and ","278","  of cross-validation values for different alphas. :issue:`10297` by ","280","  ","491","- The :func:`covariance.graph_lasso`, :class:`covariance.GraphLasso` and ","492","  :class:`covariance.GraphLassoCV` have been renamed to "]}],"sklearn\/model_selection\/tests\/test_search.py":[{"add":["1387","    # raise warning if n_iter is bigger than total parameter space","1390","    n_iter = 7","1391","    grid_size = 6","1392","    expected_warning = ('The total space of parameters %d is smaller '","1393","                        'than n_iter=%d. Running %d iterations. For '","1394","                        'exhaustive searches, use GridSearchCV.'","1395","                        % (grid_size, n_iter, grid_size))","1396","    assert_warns_message(UserWarning, expected_warning,","1397","                         list, sampler)","1398",""],"delete":["1387","    # raise error if n_iter too large","1390","    assert_raises(ValueError, list, sampler)"]}],"sklearn\/model_selection\/_search.py":[{"add":["244","            n_iter = self.n_iter","246","            if grid_size < n_iter:","247","                warnings.warn(","248","                    'The total space of parameters %d is smaller '","249","                    'than n_iter=%d. Running %d iterations. For exhaustive '","250","                    'searches, use GridSearchCV.'","251","                    % (grid_size, self.n_iter, grid_size), UserWarning)","252","                n_iter = grid_size","253","            for i in sample_without_replacement(grid_size, n_iter,"],"delete":["245","            if grid_size < self.n_iter:","246","                raise ValueError(","247","                    \"The total space of parameters %d is smaller \"","248","                    \"than n_iter=%d. For exhaustive searches, use \"","249","                    \"GridSearchCV.\" % (grid_size, self.n_iter))","250","            for i in sample_without_replacement(grid_size, self.n_iter,"]}]}},"97a15dbad3ef1ae8fd35a9ff4cb33b3a522b7341":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/linear_model\/tests\/test_logistic.py":"MODIFY","sklearn\/linear_model\/logistic.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["439","  ","440","- Fixed a bug in :func:`sklearn.linear_model.LogisticRegression` where the ","441","  multi_class='multinomial' with binary output with warm_start = True","442","  :issue:`10836` by :user:`Aishwarya Srinivasan <aishgrt1>`."],"delete":[]}],"sklearn\/linear_model\/tests\/test_logistic.py":[{"add":["12","from sklearn.utils.testing import assert_allclose","1241","","1242","","1243","def test_warm_start_converge_LR():","1244","    # Test to see that the logistic regression converges on warm start,","1245","    # with multi_class='multinomial'. Non-regressive test for #10836","1246","","1247","    rng = np.random.RandomState(0)","1248","    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))","1249","    y = np.array([1] * 100 + [-1] * 100)","1250","    lr_no_ws = LogisticRegression(multi_class='multinomial',","1251","                                  solver='sag', warm_start=False)","1252","    lr_ws = LogisticRegression(multi_class='multinomial',","1253","                               solver='sag', warm_start=True)","1254","","1255","    lr_no_ws_loss = log_loss(y, lr_no_ws.fit(X, y).predict_proba(X))","1256","    lr_ws_loss = [log_loss(y, lr_ws.fit(X, y).predict_proba(X)) ","1257","                 for _ in range(5)]","1258","","1259","    for i in range(5):","1260","        assert_allclose(lr_no_ws_loss, lr_ws_loss[i], rtol=1e-5)"],"delete":[]}],"sklearn\/linear_model\/logistic.py":[{"add":["678","","679","            if n_classes == 1:","680","                w0[0, :coef.shape[1]] = -coef","681","                w0[1, :coef.shape[1]] = coef","682","            else:","683","                w0[:, :coef.shape[1]] = coef","684",""],"delete":["678","            w0[:, :coef.shape[1]] = coef"]}]}},"02c7f986eb0fdca086f35343a922a239e4835017":{"changes":{"sklearn\/model_selection\/_split.py":"MODIFY","sklearn\/externals\/joblib\/parallel.py":"MODIFY"},"diff":{"sklearn\/model_selection\/_split.py":[{"add":["1255","        complement of the train size. By default (the parameter is"],"delete":["1255","        complement of the train size. By default (the is parameter"]}],"sklearn\/externals\/joblib\/parallel.py":[{"add":["247","    n_jobs is the number of workers requested by the callers."],"delete":["247","    n_jobs is the is the number of workers requested by the callers."]}]}},"2e0b27483a842e115e6f8e388fca98accef00735":{"changes":{"doc\/install.rst":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY","README.rst":"MODIFY","doc\/index.rst":"MODIFY"},"diff":{"doc\/install.rst":[{"add":["23","","24",".. warning::","25","","26","    Scikit-learn 0.20 is the last version to support Python 2.7 and Python 3.4.","27","    Scikit-learn 0.21 will require Python 3.5 or newer.","28",""],"delete":[]}],"doc\/whats_new\/v0.20.rst":[{"add":["13",".. warning::","14","","15","    Version 0.20 is the last version of scikit-learn to support Python 2.7 and Python 3.4.","16","    Scikit-learn 0.21 will require Python 3.5 or higher.","17",""],"delete":[]}],"README.rst":[{"add":["55","**Scikit-learn 0.20 is the last version to support Python2.7.**","56","Scikit-learn 0.21 and later will require Python 3.5 or newer.","57",""],"delete":[]}],"doc\/index.rst":[{"add":["209","                    <li><strong>Scikit-learn 0.21 will drop support for Python 2.7 and Python 3.4.<\/strong>","210","                    <\/li>","211","                    <li><em>July 2018.<\/em> scikit-learn 0.20 is available for download (<a href=\"whats_new.html#version-0-20\">Changelog<\/a>).","212","                    <\/li>"],"delete":["217","                    <li><em>September 2016.<\/em> scikit-learn 0.18.0 is available for download (<a href=\"whats_new\/v0.18.html#version-0-18\">Changelog<\/a>).","218","                    <\/li>","219","                    <li><em>November 2015.<\/em> scikit-learn 0.17.0 is available for download (<a href=\"whats_new\/v0.17.html\">Changelog<\/a>).","220","                    <\/li>","221","                    <li><em>March 2015.<\/em> scikit-learn 0.16.0 is available for download (<a href=\"whats_new\/v0.16.html\">Changelog<\/a>).","222","                    <\/li>"]}]}},"3b037b0e281cb42e5bc58e29813f4ee54d39899e":{"changes":{"sklearn\/datasets\/base.py":"MODIFY","sklearn\/datasets\/covtype.py":"MODIFY","sklearn\/datasets\/olivetti_faces.py":"MODIFY","sklearn\/datasets\/twenty_newsgroups.py":"MODIFY","sklearn\/datasets\/kddcup99.py":"MODIFY","sklearn\/datasets\/samples_generator.py":"MODIFY","sklearn\/datasets\/rcv1.py":"MODIFY"},"diff":{"sklearn\/datasets\/base.py":[{"add":["146","    random_state : int, RandomState instance or None (default=0)","147","        Determines random number generation for dataset shuffling. Pass an int","148","        for reproducible output across multiple function calls.","149","        See :term:`Glossary <random_state>`."],"delete":["146","    random_state : int, RandomState instance or None, optional (default=0)","147","        If int, random_state is the seed used by the random number generator;","148","        If RandomState instance, random_state is the random number generator;","149","        If None, the random number generator is the RandomState instance used","150","        by `np.random`."]}],"sklearn\/datasets\/covtype.py":[{"add":["59","    random_state : int, RandomState instance or None (default)","60","        Determines random number generation for dataset shuffling. Pass an int","61","        for reproducible output across multiple function calls.","62","        See :term:`Glossary <random_state>`."],"delete":["59","    random_state : int, RandomState instance or None, optional (default=None)","60","        Random state for shuffling the dataset.","61","        If int, random_state is the seed used by the random number generator;","62","        If RandomState instance, random_state is the random number generator;","63","        If None, the random number generator is the RandomState instance used","64","        by `np.random`."]}],"sklearn\/datasets\/olivetti_faces.py":[{"add":["66","    random_state : int, RandomState instance or None (default=0)","67","        Determines random number generation for dataset shuffling. Pass an int","68","        for reproducible output across multiple function calls.","69","        See :term:`Glossary <random_state>`."],"delete":["66","    random_state : int, RandomState instance or None, optional (default=0)","67","        If int, random_state is the seed used by the random number generator;","68","        If RandomState instance, random_state is the random number generator;","69","        If None, the random number generator is the RandomState instance used","70","        by `np.random`."]}],"sklearn\/datasets\/twenty_newsgroups.py":[{"add":["171","    random_state : int, RandomState instance or None (default)","172","        Determines random number generation for dataset shuffling. Pass an int","173","        for reproducible output across multiple function calls.","174","        See :term:`Glossary <random_state>`."],"delete":["171","    random_state : numpy random number generator or seed integer","172","        Used to shuffle the dataset."]}],"sklearn\/datasets\/kddcup99.py":[{"add":["141","    random_state : int, RandomState instance or None (default)","142","        Determines random number generation for dataset shuffling and for","143","        selection of abnormal samples if `subset='SA'`. Pass an int for","144","        reproducible output across multiple function calls.","145","        See :term:`Glossary <random_state>`."],"delete":["141","    random_state : int, RandomState instance or None, optional (default=None)","142","        Random state for shuffling the dataset. If subset='SA', this random","143","        state is also used to randomly select the small proportion of abnormal","144","        samples.","145","        If int, random_state is the seed used by the random number generator;","146","        If RandomState instance, random_state is the random number generator;","147","        If None, the random number generator is the RandomState instance used","148","        by `np.random`."]}],"sklearn\/datasets\/samples_generator.py":[{"add":["127","    random_state : int, RandomState instance or None (default)","128","        Determines random number generation for dataset creation. Pass an int","129","        for reproducible output across multiple function calls.","130","        See :term:`Glossary <random_state>`.","317","    random_state : int, RandomState instance or None (default)","318","        Determines random number generation for dataset creation. Pass an int","319","        for reproducible output across multiple function calls.","320","        See :term:`Glossary <random_state>`.","423","    random_state : int, RandomState instance or None (default)","424","        Determines random number generation for dataset creation. Pass an int","425","        for reproducible output across multiple function calls.","426","        See :term:`Glossary <random_state>`.","514","    random_state : int, RandomState instance or None (default)","515","        Determines random number generation for dataset creation. Pass an int","516","        for reproducible output across multiple function calls.","517","        See :term:`Glossary <random_state>`.","598","    random_state : int, RandomState instance or None (default)","599","        Determines random number generation for dataset shuffling and noise.","600","        Pass an int for reproducible output across multiple function calls.","601","        See :term:`Glossary <random_state>`.","660","    random_state : int, RandomState instance or None (default)","661","        Determines random number generation for dataset shuffling and noise.","662","        Pass an int for reproducible output across multiple function calls.","663","        See :term:`Glossary <random_state>`.","732","    random_state : int, RandomState instance or None (default)","733","        Determines random number generation for dataset creation. Pass an int","734","        for reproducible output across multiple function calls.","735","        See :term:`Glossary <random_state>`.","869","    random_state : int, RandomState instance or None (default)","870","        Determines random number generation for dataset noise. Pass an int","871","        for reproducible output across multiple function calls.","872","        See :term:`Glossary <random_state>`.","930","    random_state : int, RandomState instance or None (default)","931","        Determines random number generation for dataset noise. Pass an int","932","        for reproducible output across multiple function calls.","933","        See :term:`Glossary <random_state>`.","995","    random_state : int, RandomState instance or None (default)","996","        Determines random number generation for dataset noise. Pass an int","997","        for reproducible output across multiple function calls.","998","        See :term:`Glossary <random_state>`.","1071","    random_state : int, RandomState instance or None (default)","1072","        Determines random number generation for dataset creation. Pass an int","1073","        for reproducible output across multiple function calls.","1074","        See :term:`Glossary <random_state>`.","1124","    random_state : int, RandomState instance or None (default)","1125","        Determines random number generation for dataset creation. Pass an int","1126","        for reproducible output across multiple function calls.","1127","        See :term:`Glossary <random_state>`.","1183","    random_state : int, RandomState instance or None (default)","1184","        Determines random number generation for dataset creation. Pass an int","1185","        for reproducible output across multiple function calls.","1186","        See :term:`Glossary <random_state>`.","1223","    random_state : int, RandomState instance or None (default)","1224","        Determines random number generation for dataset creation. Pass an int","1225","        for reproducible output across multiple function calls.","1226","        See :term:`Glossary <random_state>`.","1272","    random_state : int, RandomState instance or None (default)","1273","        Determines random number generation for dataset creation. Pass an int","1274","        for reproducible output across multiple function calls.","1275","        See :term:`Glossary <random_state>`.","1333","    random_state : int, RandomState instance or None (default)","1334","        Determines random number generation for dataset creation. Pass an int","1335","        for reproducible output across multiple function calls.","1336","        See :term:`Glossary <random_state>`.","1385","    random_state : int, RandomState instance or None (default)","1386","        Determines random number generation for dataset creation. Pass an int","1387","        for reproducible output across multiple function calls.","1388","        See :term:`Glossary <random_state>`.","1448","    random_state : int, RandomState instance or None (default)","1449","        Determines random number generation for dataset creation. Pass an int","1450","        for reproducible output across multiple function calls.","1451","        See :term:`Glossary <random_state>`.","1536","    random_state : int, RandomState instance or None (default)","1537","        Determines random number generation for dataset creation. Pass an int","1538","        for reproducible output across multiple function calls.","1539","        See :term:`Glossary <random_state>`.","1627","    random_state : int, RandomState instance or None (default)","1628","        Determines random number generation for dataset creation. Pass an int","1629","        for reproducible output across multiple function calls.","1630","        See :term:`Glossary <random_state>`."],"delete":["127","    random_state : int, RandomState instance or None, optional (default=None)","128","        If int, random_state is the seed used by the random number generator;","129","        If RandomState instance, random_state is the random number generator;","130","        If None, the random number generator is the RandomState instance used","131","        by ``np.random``.","318","    random_state : int, RandomState instance or None, optional (default=None)","319","        If int, random_state is the seed used by the random number generator;","320","        If RandomState instance, random_state is the random number generator;","321","        If None, the random number generator is the RandomState instance used","322","        by `np.random`.","425","    random_state : int, RandomState instance or None, optional (default=None)","426","        If int, random_state is the seed used by the random number generator;","427","        If RandomState instance, random_state is the random number generator;","428","        If None, the random number generator is the RandomState instance used","429","        by `np.random`.","517","    random_state : int, RandomState instance or None, optional (default=None)","518","        If int, random_state is the seed used by the random number generator;","519","        If RandomState instance, random_state is the random number generator;","520","        If None, the random number generator is the RandomState instance used","521","        by `np.random`.","602","    random_state : int, RandomState instance or None, optional (default=None)","603","        If int, random_state is the seed used by the random number generator;","604","        If RandomState instance, random_state is the random number generator;","605","        If None, the random number generator is the RandomState instance used","606","        by `np.random`.","665","    random_state : int, RandomState instance or None, optional (default=None)","666","        If int, random_state is the seed used by the random number generator;","667","        If RandomState instance, random_state is the random number generator;","668","        If None, the random number generator is the RandomState instance used","669","        by `np.random`.","738","    random_state : int, RandomState instance or None, optional (default=None)","739","        If int, random_state is the seed used by the random number generator;","740","        If RandomState instance, random_state is the random number generator;","741","        If None, the random number generator is the RandomState instance used","742","        by `np.random`.","876","    random_state : int, RandomState instance or None, optional (default=None)","877","        If int, random_state is the seed used by the random number generator;","878","        If RandomState instance, random_state is the random number generator;","879","        If None, the random number generator is the RandomState instance used","880","        by `np.random`.","938","    random_state : int, RandomState instance or None, optional (default=None)","939","        If int, random_state is the seed used by the random number generator;","940","        If RandomState instance, random_state is the random number generator;","941","        If None, the random number generator is the RandomState instance used","942","        by `np.random`.","1004","    random_state : int, RandomState instance or None, optional (default=None)","1005","        If int, random_state is the seed used by the random number generator;","1006","        If RandomState instance, random_state is the random number generator;","1007","        If None, the random number generator is the RandomState instance used","1008","        by `np.random`.","1081","    random_state : int, RandomState instance or None, optional (default=None)","1082","        If int, random_state is the seed used by the random number generator;","1083","        If RandomState instance, random_state is the random number generator;","1084","        If None, the random number generator is the RandomState instance used","1085","        by `np.random`.","1135","    random_state : int, RandomState instance or None, optional (default=None)","1136","        If int, random_state is the seed used by the random number generator;","1137","        If RandomState instance, random_state is the random number generator;","1138","        If None, the random number generator is the RandomState instance used","1139","        by `np.random`.","1195","    random_state : int, RandomState instance or None, optional (default=None)","1196","        If int, random_state is the seed used by the random number generator;","1197","        If RandomState instance, random_state is the random number generator;","1198","        If None, the random number generator is the RandomState instance used","1199","        by `np.random`.","1236","    random_state : int, RandomState instance or None, optional (default=None)","1237","        If int, random_state is the seed used by the random number generator;","1238","        If RandomState instance, random_state is the random number generator;","1239","        If None, the random number generator is the RandomState instance used","1240","        by `np.random`.","1286","    random_state : int, RandomState instance or None, optional (default=None)","1287","        If int, random_state is the seed used by the random number generator;","1288","        If RandomState instance, random_state is the random number generator;","1289","        If None, the random number generator is the RandomState instance used","1290","        by `np.random`.","1348","    random_state : int, RandomState instance or None, optional (default=None)","1349","        If int, random_state is the seed used by the random number generator;","1350","        If RandomState instance, random_state is the random number generator;","1351","        If None, the random number generator is the RandomState instance used","1352","        by `np.random`.","1401","    random_state : int, RandomState instance or None, optional (default=None)","1402","        If int, random_state is the seed used by the random number generator;","1403","        If RandomState instance, random_state is the random number generator;","1404","        If None, the random number generator is the RandomState instance used","1405","        by `np.random`.","1465","    random_state : int, RandomState instance or None, optional (default=None)","1466","        If int, random_state is the seed used by the random number generator;","1467","        If RandomState instance, random_state is the random number generator;","1468","        If None, the random number generator is the RandomState instance used","1469","        by `np.random`.","1554","    random_state : int, RandomState instance or None, optional (default=None)","1555","        If int, random_state is the seed used by the random number generator;","1556","        If RandomState instance, random_state is the random number generator;","1557","        If None, the random number generator is the RandomState instance used","1558","        by `np.random`.","1621","","1647","    random_state : int, RandomState instance or None, optional (default=None)","1648","        If int, random_state is the seed used by the random number generator;","1649","        If RandomState instance, random_state is the random number generator;","1650","        If None, the random number generator is the RandomState instance used","1651","        by `np.random`."]}],"sklearn\/datasets\/rcv1.py":[{"add":["104","    random_state : int, RandomState instance or None (default)","105","        Determines random number generation for dataset shuffling. Pass an int","106","        for reproducible output across multiple function calls.","107","        See :term:`Glossary <random_state>`."],"delete":["104","    random_state : int, RandomState instance or None, optional (default=None)","105","        Random state for shuffling the dataset.","106","        If int, random_state is the seed used by the random number generator;","107","        If RandomState instance, random_state is the random number generator;","108","        If None, the random number generator is the RandomState instance used","109","        by `np.random`.","184",""]}]}},"6b1d8e5e1404853eece7bf56bde00d3683840a29":{"changes":{"doc\/whats_new\/v0.21.rst":"MODIFY","sklearn\/tests\/test_discriminant_analysis.py":"MODIFY","sklearn\/discriminant_analysis.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.21.rst":[{"add":["56","  ","57",":mod:`sklearn.discriminant_analysis`","58","....................................","60","- |Fix| A ``ChangedBehaviourWarning`` is now raised when","61","  :class:`discriminant_analysis.LinearDiscriminantAnalysis` is given as","62","  parameter ``n_components > min(n_features, n_classes - 1)``, and","63","  ``n_components`` is changed to ``min(n_features, n_classes - 1)`` if so.","64","  Previously the change was made, but silently. :issue:`11526` by","65","  :user:`William de Vazelhes<wdevazelhes>`.","76",":mod:`sklearn.linear_model`","77","...........................","78","","79","- |Feature| :class:`linear_model.LogisticRegression` and","80","  :class:`linear_model.LogisticRegressionCV` now support Elastic-Net penalty,","81","  with the 'saga' solver. :issue:`11646` by :user:`Nicolas Hug <NicolasHug>`.","82","","83","- |Fix| Fixed a bug in the 'saga' solver where the weights would not be","84","  correctly updated in some cases. :issue:`11646` by `Tom Dupre la Tour`_.","85","","86","- |Fix| Fixed a bug in :class:`linear_model.MultiTaskElasticNet` and","87","  :class:`linear_model.MultiTaskLasso` which were breaking when","88","  ``warm_start = True``. :issue:`12360` by :user:`Aakanksha Joshi <joaak>`.","89",""],"delete":["57",":mod:`sklearn.linear_model`","58","...........................","59","","60","- |Fix| Fixed a bug in :class:`linear_model.MultiTaskElasticNet` and","61","  :class:`linear_model.MultiTaskLasso` which were breaking when","62","  ``warm_start = True``. :issue:`12360` by :user:`Aakanksha Joshi <joaak>`.","154",":mod:`sklearn.linear_model`","155","...........................","156","","157","- |Feature| :class:`linear_model.LogisticRegression` and","158","  :class:`linear_model.LogisticRegressionCV` now support Elastic-Net penalty,","159","  with the 'saga' solver. :issue:`11646` by :user:`Nicolas Hug <NicolasHug>`.","160","","161","- |Fix| Fixed a bug in the 'saga' solver where the weights would not be","162","  correctly updated in some cases. :issue:`11646` by `Tom Dupre la Tour`_."]}],"sklearn\/tests\/test_discriminant_analysis.py":[{"add":["4","from sklearn.exceptions import ChangedBehaviorWarning","5","from sklearn.utils import check_random_state","6","from sklearn.utils.testing import (assert_array_equal, assert_no_warnings,","7","                                   assert_warns_message)","262","@pytest.mark.parametrize('n_features', [3, 5])","263","@pytest.mark.parametrize('n_classes', [5, 3])","264","def test_lda_dimension_warning(n_classes, n_features):","265","    # FIXME: Future warning to be removed in 0.23","266","    rng = check_random_state(0)","267","    n_samples = 10","268","    X = rng.randn(n_samples, n_features)","269","    # we create n_classes labels by repeating and truncating a","270","    # range(n_classes) until n_samples","271","    y = np.tile(range(n_classes), n_samples \/\/ n_classes + 1)[:n_samples]","272","    max_components = min(n_features, n_classes - 1)","273","","274","    for n_components in [max_components - 1, None, max_components]:","275","        # if n_components <= min(n_classes - 1, n_features), no warning","276","        lda = LinearDiscriminantAnalysis(n_components=n_components)","277","        assert_no_warnings(lda.fit, X, y)","278","","279","    for n_components in [max_components + 1,","280","                         max(n_features, n_classes - 1) + 1]:","281","        # if n_components > min(n_classes - 1, n_features), raise warning","282","        # We test one unit higher than max_components, and then something","283","        # larger than both n_features and n_classes - 1 to ensure the test","284","        # works for any value of n_component","285","        lda = LinearDiscriminantAnalysis(n_components=n_components)","286","        msg = (\"n_components cannot be larger than min(n_features, \"","287","               \"n_classes - 1). Using min(n_features, \"","288","               \"n_classes - 1) = min(%d, %d - 1) = %d components.\" %","289","               (n_features, n_classes, max_components))","290","        assert_warns_message(ChangedBehaviorWarning, msg, lda.fit, X, y)","291","        future_msg = (\"In version 0.23, setting n_components > min(\"","292","                      \"n_features, n_classes - 1) will raise a \"","293","                      \"ValueError. You should set n_components to None\"","294","                      \" (default), or a value smaller or equal to \"","295","                      \"min(n_features, n_classes - 1).\")","296","        assert_warns_message(FutureWarning, future_msg, lda.fit, X, y)","297","","298",""],"delete":[]}],"sklearn\/discriminant_analysis.py":[{"add":["14","from .exceptions import ChangedBehaviorWarning","168","    n_components : int, optional (default=None)","169","        Number of components (<= min(n_classes - 1, n_features)) for","170","        dimensionality reduction. If None, will be set to","171","        min(n_classes - 1, n_features).","430","        # FIXME: Future warning to be removed in 0.23","453","        # Maximum number of components no matter what n_components is","454","        # specified:","455","        max_components = min(len(self.classes_) - 1, X.shape[1])","456","","458","            self._max_components = max_components","460","            if self.n_components > max_components:","461","                warnings.warn(","462","                    \"n_components cannot be larger than min(n_features, \"","463","                    \"n_classes - 1). Using min(n_features, \"","464","                    \"n_classes - 1) = min(%d, %d - 1) = %d components.\"","465","                    % (X.shape[1], len(self.classes_), max_components),","466","                    ChangedBehaviorWarning)","467","                future_msg = (\"In version 0.23, setting n_components > min(\"","468","                              \"n_features, n_classes - 1) will raise a \"","469","                              \"ValueError. You should set n_components to None\"","470","                              \" (default), or a value smaller or equal to \"","471","                              \"min(n_features, n_classes - 1).\")","472","                warnings.warn(future_msg, FutureWarning)","473","                self._max_components = max_components","474","            else:","475","                self._max_components = self.n_components"],"delete":["167","    n_components : int, optional","168","        Number of components (< n_classes - 1) for dimensionality reduction.","449","        # Get the maximum number of components","451","            self._max_components = len(self.classes_) - 1","453","            self._max_components = min(len(self.classes_) - 1,","454","                                       self.n_components)"]}]}},"8616a0863c4e27dc70164345e0de12a5fc649861":{"changes":{"sklearn\/ensemble\/_gradient_boosting.pyx":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/ensemble\/gradient_boosting.py":"MODIFY","sklearn\/ensemble\/tests\/test_gradient_boosting.py":"MODIFY"},"diff":{"sklearn\/ensemble\/_gradient_boosting.pyx":[{"add":["205","        if X.format != 'csr':","206","            raise ValueError(\"When X is a sparse matrix, a CSR format is\"","207","                             \" expected, got {!r}\".format(type(X)))","210","        if not isinstance(X, np.ndarray) or np.isfortran(X):","211","            raise ValueError(\"X should be C-ordered np.ndarray,\"","212","                             \" got {}\".format(type(X)))"],"delete":["207","        if not isinstance(X, np.ndarray):","208","            raise ValueError(\"X should be in np.ndarray or csr_matrix format,\"","209","                             \"got %s\" % type(X))"]}],"doc\/whats_new\/v0.20.rst":[{"add":["150","- Fixed a bug when fitting :class:`ensemble.GradientBoostingClassifier` or","151","  :class:`ensemble.GradientBoostingRegressor` with ``warm_start=True`` which","152","  previously raised a segmentation fault due to a non-conversion of CSC matrix","153","  into CSR format expected by ``decision_function``. Similarly, Fortran-ordered","154","  arrays are converted to C-ordered arrays in the dense case. :issue:`9991` by","155","  :user:`Guillaume Lemaitre <glemaitre>`.","156",""],"delete":[]}],"sklearn\/ensemble\/gradient_boosting.py":[{"add":["1041","            # The requirements of _decision_function (called in two lines","1042","            # below) are more constrained than fit. It accepts only CSR","1043","            # matrices.","1044","            X = check_array(X, dtype=DTYPE, order=\"C\", accept_sparse='csr')"],"delete":[]}],"sklearn\/ensemble\/tests\/test_gradient_boosting.py":[{"add":["18","from sklearn.ensemble._gradient_boosting import predict_stages","394","def test_check_inputs_predict_stages():","395","    # check that predict_stages through an error if the type of X is not","396","    # supported","397","    x, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)","398","    x_sparse_csc = csc_matrix(x)","399","    clf = GradientBoostingClassifier(n_estimators=100, random_state=1)","400","    clf.fit(x, y)","401","    score = np.zeros((y.shape)).reshape(-1, 1)","402","    assert_raise_message(ValueError,","403","                         \"When X is a sparse matrix, a CSR format is expected\",","404","                         predict_stages, clf.estimators_, x_sparse_csc,","405","                         clf.learning_rate, score)","406","    x_fortran = np.asfortranarray(x)","407","    assert_raise_message(ValueError,","408","                         \"X should be C-ordered np.ndarray\",","409","                         predict_stages, clf.estimators_, x_fortran,","410","                         clf.learning_rate, score)","411","","412","","883","def test_warm_start_sparse():","884","    # Test that all sparse matrix types are supported","885","    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)","886","    sparse_matrix_type = [csr_matrix, csc_matrix, coo_matrix]","887","    for Cls in [GradientBoostingRegressor, GradientBoostingClassifier]:","888","        est_dense = Cls(n_estimators=100, max_depth=1, subsample=0.5,","889","                        random_state=1, warm_start=True)","890","        est_dense.fit(X, y)","891","        est_dense.predict(X)","892","        est_dense.set_params(n_estimators=200)","893","        est_dense.fit(X, y)","894","        y_pred_dense = est_dense.predict(X)","895","","896","        for sparse_constructor in sparse_matrix_type:","897","            X_sparse = sparse_constructor(X)","898","","899","            est_sparse = Cls(n_estimators=100, max_depth=1, subsample=0.5,","900","                             random_state=1, warm_start=True)","901","            est_sparse.fit(X_sparse, y)","902","            est_sparse.predict(X)","903","            est_sparse.set_params(n_estimators=200)","904","            est_sparse.fit(X_sparse, y)","905","            y_pred_sparse = est_sparse.predict(X)","906","","907","            assert_array_almost_equal(est_dense.oob_improvement_[:100],","908","                                      est_sparse.oob_improvement_[:100])","909","            assert_array_almost_equal(y_pred_dense, y_pred_sparse)","910","","911","","912","def test_warm_start_fortran():","913","    # Test that feeding a X in Fortran-ordered is giving the same results as","914","    # in C-ordered","915","    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)","916","    for Cls in [GradientBoostingRegressor, GradientBoostingClassifier]:","917","        est_c = Cls(n_estimators=1, random_state=1, warm_start=True)","918","        est_fortran = Cls(n_estimators=1, random_state=1, warm_start=True)","919","","920","        est_c.fit(X, y)","921","        est_c.set_params(n_estimators=11)","922","        est_c.fit(X, y)","923","","924","        X_fortran = np.asfortranarray(X)","925","        est_fortran.fit(X_fortran, y)","926","        est_fortran.set_params(n_estimators=11)","927","        est_fortran.fit(X_fortran, y)","928","","929","        assert_array_almost_equal(est_c.predict(X),","930","                                  est_fortran.predict(X))","931","","932",""],"delete":[]}]}},"3a704b1ad3e73a492c46271b98464a71ba46c190":{"changes":{"doc\/modules\/clustering.rst":"MODIFY","doc\/modules\/classes.rst":"MODIFY"},"diff":{"doc\/modules\/clustering.rst":[{"add":["1584","","1585",".. _contingency_matrix:","1586","","1587","Contingency Matrix","1588","------------------","1589","","1590","Contingency matrix (:func:`sklearn.metrics.cluster.contingency_matrix`)","1591","reports the intersection cardinality for every true\/predicted cluster pair.","1592","The contingency matrix provides sufficient statistics for all clustering","1593","metrics where the samples are independent and identically distributed and","1594","one doesn't need to account for some instances not being clustered.","1595","","1596","Here is an example::","1597","","1598","   >>> from sklearn.metrics.cluster import contingency_matrix","1599","   >>> x = [\"a\", \"a\", \"a\", \"b\", \"b\", \"b\"]","1600","   >>> y = [0, 0, 1, 1, 2, 2]","1601","   >>> contingency_matrix(x, y)","1602","   array([[2, 1, 0],","1603","          [0, 1, 2]])","1604","","1605","The first row of output array indicates that there are three samples whose","1606","true cluster is \"a\". Of them, two are in predicted cluster 0, one is in 1,","1607","and none is in 2. And the second row indicates that there are three samples","1608","whose true cluster is \"b\". Of them, none is in predicted cluster 0, one is in","1609","1 and two are in 2.","1610","","1611","A :ref:`confusion matrix <confusion_matrix>` for classification is a square","1612","contingency matrix where the order of rows and columns correspond to a list","1613","of classes.","1614","","1615","","1616","Advantages","1617","~~~~~~~~~~","1618","","1619","- Allows to examine the spread of each true cluster across predicted","1620","  clusters and vice versa.","1621","","1622","- The contingency table calculated is typically utilized in the calculation","1623","  of a similarity statistic (like the others listed in this document) between","1624","  the two clusterings.","1625","","1626","Drawbacks","1627","~~~~~~~~~","1628","","1629","- Contingency matrix is easy to interpret for a small number of clusters, but","1630","  becomes very hard to interpret for a large number of clusters.","1631","","1632","- It doesn't give a single metric to use as an objective for clustering","1633","  optimisation.","1634","","1635","","1636",".. topic:: References","1637","","1638"," * `Wikipedia entry for contingency matrix","1639","   <https:\/\/en.wikipedia.org\/wiki\/Contingency_table>`_"],"delete":[]}],"doc\/modules\/classes.rst":[{"add":["856","   metrics.cluster.contingency_matrix"],"delete":[]}]}},"d9863547875abfe7ab690b5b70058d4f4daa65c8":{"changes":{"sklearn\/tests\/test_impute.py":"MODIFY","sklearn\/impute.py":"MODIFY"},"diff":{"sklearn\/tests\/test_impute.py":[{"add":["707","","708","","709","@pytest.mark.parametrize(\"imputer_constructor\",","710","                         [SimpleImputer, ChainedImputer])","711","@pytest.mark.parametrize(","712","    \"imputer_missing_values, missing_value, err_msg\",","713","    [(\"NaN\", np.nan, \"Input contains NaN\"),","714","     (\"-1\", -1, \"types are expected to be both numerical.\")])","715","def test_inconsistent_dtype_X_missing_values(imputer_constructor,","716","                                             imputer_missing_values,","717","                                             missing_value,","718","                                             err_msg):","719","    # regression test for issue #11390. Comparison between incoherent dtype","720","    # for X and missing_values was not raising a proper error.","721","    rng = np.random.RandomState(42)","722","    X = rng.randn(10, 10)","723","    X[0, 0] = missing_value","724","","725","    imputer = imputer_constructor(missing_values=imputer_missing_values)","726","","727","    with pytest.raises(ValueError, match=err_msg):","728","        imputer.fit_transform(X)"],"delete":[]}],"sklearn\/impute.py":[{"add":["42","def _check_inputs_dtype(X, missing_values):","43","    if (X.dtype.kind in (\"f\", \"i\", \"u\") and","44","            not isinstance(missing_values, numbers.Real)):","45","        raise ValueError(\"'X' and 'missing_values' types are expected to be\"","46","                         \" both numerical. Got X.dtype={} and \"","47","                         \" type(missing_values)={}.\"","48","                         .format(X.dtype, type(missing_values)))","49","","50","","193","        _check_inputs_dtype(X, self.missing_values)","799","        _check_inputs_dtype(X, self.missing_values)"],"delete":["53",""]}]}},"c09352c2419217588c5f49c9258fd9722722f12b":{"changes":{"sklearn\/metrics\/scorer.py":"MODIFY","sklearn\/model_selection\/_split.py":"MODIFY","sklearn\/utils\/fixes.py":"MODIFY","sklearn\/model_selection\/tests\/test_search.py":"MODIFY","sklearn\/covariance\/graph_lasso_.py":"MODIFY","sklearn\/utils\/multiclass.py":"MODIFY","sklearn\/datasets\/samples_generator.py":"MODIFY","sklearn\/tests\/test_init.py":"MODIFY","sklearn\/utils\/__init__.py":"MODIFY","sklearn\/feature_extraction\/dict_vectorizer.py":"MODIFY","sklearn\/feature_extraction\/tests\/test_text.py":"MODIFY","sklearn\/model_selection\/_search.py":"MODIFY"},"diff":{"sklearn\/metrics\/scorer.py":[{"add":["41","from ..utils.fixes import _Iterable as Iterable"],"delete":["21","from collections import Iterable"]}],"sklearn\/model_selection\/_split.py":[{"add":["30","from ..utils.fixes import _Iterable as Iterable"],"delete":["17","from collections import Iterable"]}],"sklearn\/utils\/fixes.py":[{"add":["312","","313","","314","# To be removed once this fix is included in six","315","try:","316","    from collections.abc import Sequence as _Sequence  # noqa","317","    from collections.abc import Iterable as _Iterable  # noqa","318","    from collections.abc import Mapping as _Mapping  # noqa","319","    from collections.abc import Sized as _Sized  # noqa","320","except ImportError:  # python <3.3","321","    from collections import Sequence as _Sequence  # noqa","322","    from collections import Iterable as _Iterable  # noqa","323","    from collections import Mapping as _Mapping  # noqa","324","    from collections import Sized as _Sized  # noqa"],"delete":[]}],"sklearn\/model_selection\/tests\/test_search.py":[{"add":["16","from sklearn.utils.fixes import _Iterable as Iterable, _Sized as Sized"],"delete":["2","from collections import Iterable, Sized"]}],"sklearn\/covariance\/graph_lasso_.py":[{"add":["21","from ..utils.fixes import _Sequence as Sequence","610","        if isinstance(n_alphas, Sequence):","686","            if not isinstance(n_alphas, Sequence):"],"delete":["25","import collections","610","        if isinstance(n_alphas, collections.Sequence):","686","            if not isinstance(n_alphas, collections.Sequence):"]}],"sklearn\/utils\/multiclass.py":[{"add":["19","from ..utils.fixes import _Sequence as Sequence"],"delete":["9","from collections import Sequence","23",""]}],"sklearn\/datasets\/samples_generator.py":[{"add":["17","from ..utils.fixes import _Iterable as Iterable"],"delete":["13","from collections import Iterable"]}],"sklearn\/tests\/test_init.py":[{"add":["2","import subprocess","3","","4","import pkgutil","5","","6","import pytest","7","","8","import sklearn","9","from sklearn.utils.testing import assert_equal","10","","27","","28","","29","def test_import_sklearn_no_warnings():","30","    # Test that importing scikit-learn main modules doesn't raise any warnings.","31","","32","    try:","33","        pkgs = pkgutil.iter_modules(path=sklearn.__path__, prefix='sklearn.')","34","        import_modules = '; '.join(['import ' + modname","35","                                    for _, modname, _ in pkgs","36","                                    if (not modname.startswith('_') and","37","                                        # add deprecated top level modules","38","                                        # below to ignore them","39","                                        modname not in [])])","40","","41","        message = subprocess.check_output(['python', '-Wdefault',","42","                                           '-c', import_modules],","43","                                          stderr=subprocess.STDOUT)","44","        message = message.decode(\"utf-8\")","45","        message = '\\n'.join([line for line in message.splitlines()","46","                             if not (","47","                                     # ignore ImportWarning due to Cython","48","                                     \"ImportWarning\" in line or","49","                                     # ignore DeprecationWarning due to pytest","50","                                     \"pytest\" in line or","51","                                     # ignore DeprecationWarnings due to","52","                                     # numpy.oldnumeric","53","                                     \"oldnumeric\" in line","54","                                     )])","55","        assert 'Warning' not in message","56","        assert 'Error' not in message","57","","58","    except Exception as e:","59","        pytest.skip('soft-failed test_import_sklearn_no_warnings.\\n'","60","                    ' %s, \\n %s' % (e, message))"],"delete":["6","from sklearn.utils.testing import assert_equal","7",""]}],"sklearn\/utils\/__init__.py":[{"add":["3","","19","from ..utils.fixes import _Sequence as Sequence"],"delete":["3","from collections import Sequence"]}],"sklearn\/feature_extraction\/dict_vectorizer.py":[{"add":["14","from ..utils.fixes import _Mapping as Mapping"],"delete":["5","from collections import Mapping"]}],"sklearn\/feature_extraction\/tests\/test_text.py":[{"add":["35","from sklearn.utils.fixes import _Mapping as Mapping","36","from collections import defaultdict"],"delete":["35","","36","from collections import defaultdict, Mapping"]}],"sklearn\/model_selection\/_search.py":[{"add":["15","from collections import namedtuple, defaultdict","36","from ..utils.fixes import _Mapping as Mapping, _Sequence as Sequence","37","from ..utils.fixes import _Iterable as Iterable"],"delete":["15","from collections import Mapping, namedtuple, defaultdict, Sequence, Iterable"]}]}},"727314b2feda7e9c4c7de460eff8a360def0e440":{"changes":{"sklearn\/preprocessing\/tests\/test_data.py":"MODIFY","sklearn\/preprocessing\/data.py":"MODIFY"},"diff":{"sklearn\/preprocessing\/tests\/test_data.py":[{"add":["2113","    assert np.issubdtype(enc.categories_[0].dtype, np.str_)","2127","    assert np.issubdtype(enc.categories_[0].dtype, np.str_)","2229","def test_categorical_encoder_warning():","2230","    enc = CategoricalEncoder()","2231","    X = [['Male', 1], ['Female', 3]]","2232","    np.testing.assert_no_warnings(enc.fit_transform, X)","2233","","2234",""],"delete":["2113","    assert np.issubdtype(enc.categories_[0].dtype, str)","2127","    assert np.issubdtype(enc.categories_[0].dtype, str)"]}],"sklearn\/preprocessing\/data.py":[{"add":["2998","        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):","3041","        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):"],"delete":["2998","        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, str):","3041","        if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, str):"]}]}},"34ad7d4d160af281827425fcd88fe744ffe850f1":{"changes":{"sklearn\/model_selection\/_search.py":"MODIFY"},"diff":{"sklearn\/model_selection\/_search.py":[{"add":["970","        |  'poly'    |     --    |      2     |       0.80      |...|    2    |","972","        |  'poly'    |     --    |      3     |       0.70      |...|    4    |","974","        |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |","976","        |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |","988","            'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],","989","            'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],","990","            'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],","991","            'std_test_score'     : [0.01, 0.10, 0.05, 0.08],","993","            'split0_train_score' : [0.80, 0.92, 0.70, 0.93],","994","            'split1_train_score' : [0.82, 0.55, 0.70, 0.87],","995","            'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],","996","            'std_train_score'    : [0.01, 0.19, 0.00, 0.03],","999","            'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],","1000","            'std_score_time'     : [0.00, 0.00, 0.00, 0.01],","1276","        |    'rbf'     |     0.1     |       0.80        |...|       2       |","1278","        |    'rbf'     |     0.2     |       0.90        |...|       1       |","1280","        |    'rbf'     |     0.3     |       0.70        |...|       1       |","1289","            'split0_test_score'  : [0.80, 0.90, 0.70],","1290","            'split1_test_score'  : [0.82, 0.50, 0.70],","1291","            'mean_test_score'    : [0.81, 0.70, 0.70],","1292","            'std_test_score'     : [0.01, 0.20, 0.00],","1294","            'split0_train_score' : [0.80, 0.92, 0.70],","1295","            'split1_train_score' : [0.82, 0.55, 0.70],","1296","            'mean_train_score'   : [0.81, 0.74, 0.70],","1297","            'std_train_score'    : [0.01, 0.19, 0.00],","1298","            'mean_fit_time'      : [0.73, 0.63, 0.43],","1299","            'std_fit_time'       : [0.01, 0.02, 0.01],","1300","            'mean_score_time'    : [0.01, 0.06, 0.04],","1301","            'std_score_time'     : [0.00, 0.00, 0.00],"],"delete":["970","        |  'poly'    |     --    |      2     |        0.8      |...|    2    |","972","        |  'poly'    |     --    |      3     |        0.7      |...|    4    |","974","        |  'rbf'     |     0.1   |     --     |        0.8      |...|    3    |","976","        |  'rbf'     |     0.2   |     --     |        0.9      |...|    1    |","988","            'split0_test_score'  : [0.8, 0.7, 0.8, 0.9],","989","            'split1_test_score'  : [0.82, 0.5, 0.7, 0.78],","990","            'mean_test_score'    : [0.81, 0.60, 0.75, 0.82],","991","            'std_test_score'     : [0.02, 0.01, 0.03, 0.03],","993","            'split0_train_score' : [0.8, 0.9, 0.7],","994","            'split1_train_score' : [0.82, 0.5, 0.7],","995","            'mean_train_score'   : [0.81, 0.7, 0.7],","996","            'std_train_score'    : [0.03, 0.03, 0.04],","999","            'mean_score_time'    : [0.007, 0.06, 0.04, 0.04],","1000","            'std_score_time'     : [0.001, 0.002, 0.003, 0.005],","1276","        |    'rbf'     |     0.1     |        0.8        |...|       2       |","1278","        |    'rbf'     |     0.2     |        0.9        |...|       1       |","1280","        |    'rbf'     |     0.3     |        0.7        |...|       1       |","1289","            'split0_test_score'  : [0.8, 0.9, 0.7],","1290","            'split1_test_score'  : [0.82, 0.5, 0.7],","1291","            'mean_test_score'    : [0.81, 0.7, 0.7],","1292","            'std_test_score'     : [0.02, 0.2, 0.],","1294","            'split0_train_score' : [0.8, 0.9, 0.7],","1295","            'split1_train_score' : [0.82, 0.5, 0.7],","1296","            'mean_train_score'   : [0.81, 0.7, 0.7],","1297","            'std_train_score'    : [0.03, 0.03, 0.04],","1298","            'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],","1299","            'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],","1300","            'mean_score_time'    : [0.007, 0.06, 0.04, 0.04],","1301","            'std_score_time'     : [0.001, 0.002, 0.003, 0.005],"]}]}},"73fc2e4618dbdeb6e71f8a63de2a5bc673c80629":{"changes":{"doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/neighbors\/kd_tree.pyx":"MODIFY"},"diff":{"doc\/whats_new\/v0.20.rst":[{"add":["663","- Fixed a bug in ``KDTree`` construction that results in faster construction","664","  and querying times. :issue:`11556` by :user:`Jake VanderPlas <jakevdp>`","665",""],"delete":[]}],"sklearn\/neighbors\/kd_tree.pyx":[{"add":["71","","72","    for j in range(n_features):"],"delete":[]}]}},"9cc59e70907e3646ae09ecefefb71a7352674e80":{"changes":{"sklearn\/utils\/metaestimators.py":"MODIFY"},"diff":{"sklearn\/utils\/metaestimators.py":[{"add":["47","        # 3. Step parameters and other initialisation arguments"],"delete":["47","        # 3. Step parameters and other initilisation arguments"]}]}},"2dc226154769841d07601c19b089086f4aa31cf9":{"changes":{"\/dev\/null":"DELETE","build_tools\/circle\/build_doc.sh":"MODIFY","examples\/applications\/plot_stock_market.py":"ADD",".circleci\/config.yml":"MODIFY","README.rst":"MODIFY"},"diff":{"\/dev\/null":[{"add":[],"delete":[]}],"build_tools\/circle\/build_doc.sh":[{"add":["120","  scikit-image=\"${SCIKIT_IMAGE_VERSION:-*}\" pandas=\"${PANDAS_VERSION:-*}\""],"delete":["120","  scikit-image=\"${SCIKIT_IMAGE_VERSION:-*}\""]}],"examples\/applications\/plot_stock_market.py":[{"add":[],"delete":[]}],".circleci\/config.yml":[{"add":["49","      - PANDAS_VERSION: 0.13.1"],"delete":[]}],"README.rst":[{"add":["56","require scikit-image >= 0.9.3 and a few examples require pandas >= 0.13.1."],"delete":["56","require scikit-image >= 0.9.3 as well."]}]}},"bcd6ff387e3b273fb5edf2fb0a12497655eb2df9":{"changes":{"sklearn\/utils\/estimator_checks.py":"MODIFY"},"diff":{"sklearn\/utils\/estimator_checks.py":[{"add":["90","    yield check_sample_weights_invariance","557","@ignore_warnings(category=(DeprecationWarning, FutureWarning))","558","def check_sample_weights_invariance(name, estimator_orig):","559","    # check that the estimators yield same results for","560","    # unit weights and no weights","561","    if (has_fit_parameter(estimator_orig, \"sample_weight\") and","562","            not (hasattr(estimator_orig, \"_pairwise\")","563","                 and estimator_orig._pairwise)):","564","        # We skip pairwise because the data is not pairwise","565","","566","        estimator1 = clone(estimator_orig)","567","        estimator2 = clone(estimator_orig)","568","        set_random_state(estimator1, random_state=0)","569","        set_random_state(estimator2, random_state=0)","570","","571","        X = np.array([[1, 3], [1, 3], [1, 3], [1, 3],","572","                      [2, 1], [2, 1], [2, 1], [2, 1],","573","                      [3, 3], [3, 3], [3, 3], [3, 3],","574","                      [4, 1], [4, 1], [4, 1], [4, 1]], dtype=np.dtype('float'))","575","        y = np.array([1, 1, 1, 1, 2, 2, 2, 2,","576","                      1, 1, 1, 1, 2, 2, 2, 2], dtype=np.dtype('int'))","577","","578","        estimator1.fit(X, y=y, sample_weight=np.ones(shape=len(y)))","579","        estimator2.fit(X, y=y, sample_weight=None)","580","","581","        for method in [\"predict\", \"transform\"]:","582","            if hasattr(estimator_orig, method):","583","                X_pred1 = getattr(estimator1, method)(X)","584","                X_pred2 = getattr(estimator2, method)(X)","585","                assert_allclose(X_pred1, X_pred2, rtol=0.5,","586","                                err_msg=\"For %s sample_weight=None is not\"","587","                                        \" equivalent to sample_weight=ones\"","588","                                        % name)","589","","590",""],"delete":[]}]}},"f158e2dfe2af1b23ae3f9d86c598013b2c155c3f":{"changes":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":"MODIFY","sklearn\/tests\/test_impute.py":"MODIFY","sklearn\/linear_model\/tests\/test_logistic.py":"MODIFY","sklearn\/neighbors\/tests\/test_neighbors.py":"MODIFY","examples\/compose\/plot_compare_reduction.py":"MODIFY","sklearn\/model_selection\/tests\/test_search.py":"MODIFY","sklearn\/tests\/test_multiclass.py":"MODIFY","sklearn\/covariance\/graph_lasso_.py":"MODIFY","sklearn\/linear_model\/coordinate_descent.py":"MODIFY","sklearn\/model_selection\/tests\/test_split.py":"MODIFY","doc\/modules\/cross_validation.rst":"MODIFY","sklearn\/linear_model\/tests\/test_ridge.py":"MODIFY","doc\/modules\/ensemble.rst":"MODIFY","sklearn\/tests\/test_calibration.py":"MODIFY","sklearn\/feature_selection\/tests\/test_rfe.py":"MODIFY","sklearn\/feature_extraction\/tests\/test_text.py":"MODIFY","sklearn\/tests\/test_metaestimators.py":"MODIFY","sklearn\/calibration.py":"MODIFY","examples\/ensemble\/plot_gradient_boosting_oob.py":"MODIFY","doc\/modules\/learning_curve.rst":"MODIFY","doc\/modules\/model_evaluation.rst":"MODIFY","doc\/glossary.rst":"MODIFY","sklearn\/model_selection\/_search.py":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/feature_selection\/rfe.py":"MODIFY","sklearn\/linear_model\/logistic.py":"MODIFY","sklearn\/ensemble\/tests\/test_forest.py":"MODIFY","doc\/tutorial\/statistical_inference\/model_selection.rst":"MODIFY","sklearn\/covariance\/tests\/test_graph_lasso.py":"MODIFY","sklearn\/covariance\/tests\/test_graphical_lasso.py":"MODIFY","sklearn\/linear_model\/omp.py":"MODIFY","sklearn\/ensemble\/tests\/test_weight_boosting.py":"MODIFY","doc\/modules\/linear_model.rst":"MODIFY","sklearn\/metrics\/tests\/test_score_objects.py":"MODIFY","sklearn\/model_selection\/_split.py":"MODIFY","sklearn\/ensemble\/tests\/test_bagging.py":"MODIFY","sklearn\/model_selection\/_validation.py":"MODIFY","sklearn\/linear_model\/tests\/test_least_angle.py":"MODIFY","sklearn\/model_selection\/tests\/test_validation.py":"MODIFY","sklearn\/linear_model\/least_angle.py":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":[{"add":["148","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","235","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","293","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","365","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","460","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","487","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","501","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","514","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","532","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"sklearn\/tests\/test_impute.py":[{"add":["436","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"sklearn\/linear_model\/tests\/test_logistic.py":[{"add":["469","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","496","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","530","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","570","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","734","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","774","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","890","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","984","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","993","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1086","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"sklearn\/neighbors\/tests\/test_neighbors.py":[{"add":["183","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"examples\/compose\/plot_compare_reduction.py":[{"add":["65","grid = GridSearchCV(pipe, cv=5, n_jobs=1, param_grid=param_grid)","116","grid = GridSearchCV(cached_pipe, cv=5, n_jobs=1, param_grid=param_grid)"],"delete":["65","grid = GridSearchCV(pipe, cv=3, n_jobs=1, param_grid=param_grid)","116","grid = GridSearchCV(cached_pipe, cv=3, n_jobs=1, param_grid=param_grid)"]}],"sklearn\/model_selection\/tests\/test_search.py":[{"add":["181","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","182","","253","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","316","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","347","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","382","    estimators = [GridSearchCV(LinearSVC(random_state=0), grid,","383","                               iid=False, cv=3),","385","                                     n_iter=2, iid=False, cv=3)]","414","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","443","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","457","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","489","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","500","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","516","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","530","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","561","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","584","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","621","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","651","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","690","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","761","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","789","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1143","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1176","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1254","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1284","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1303","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1437","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1490","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1522","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1616","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":["377","    estimators = [GridSearchCV(LinearSVC(random_state=0), grid, iid=False),","379","                                     n_iter=2, iid=False)]"]}],"sklearn\/tests\/test_multiclass.py":[{"add":["334","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","428","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","606","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","702","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","753","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"sklearn\/covariance\/graph_lasso_.py":[{"add":["499","        .. versionchanged:: 0.20","500","            ``cv`` default value if None will change from 3-fold to 5-fold","501","            in v0.22.","502","","572","    def __init__(self, alphas=4, n_refinements=4, cv='warn', tol=1e-4,","906","        .. versionchanged:: 0.20","907","            ``cv`` default value if None will change from 3-fold to 5-fold","908","            in v0.22.","909",""],"delete":["568","    def __init__(self, alphas=4, n_refinements=4, cv=None, tol=1e-4,"]}],"sklearn\/linear_model\/coordinate_descent.py":[{"add":["1054","                 copy_X=True, cv='warn', verbose=False, n_jobs=1,","1313","        .. versionchanged:: 0.20","1314","            ``cv`` default value if None will change from 3-fold to 5-fold","1315","            in v0.22.","1316","","1387","                 copy_X=True, cv='warn', verbose=False, n_jobs=1,","1470","        .. versionchanged:: 0.20","1471","            ``cv`` default value if None will change from 3-fold to 5-fold","1472","            in v0.22.","1473","","1583","                 max_iter=1000, tol=1e-4, cv='warn', copy_X=True,","2004","        .. versionchanged:: 0.20","2005","            ``cv`` default value if None will change from 3-fold to 5-fold","2006","            in v0.22.","2007","","2062","    >>> clf = linear_model.MultiTaskElasticNetCV(cv=3)","2066","    MultiTaskElasticNetCV(alphas=None, copy_X=True, cv=3, eps=0.001,","2093","                 max_iter=1000, tol=1e-4, cv='warn', copy_X=True,","2178","        .. versionchanged:: 0.20","2179","            ``cv`` default value if None will change from 3-fold to 5-fold","2180","            in v0.22.","2181","","2243","                 cv='warn', verbose=False, n_jobs=1, random_state=None,"],"delete":["1054","                 copy_X=True, cv=None, verbose=False, n_jobs=1,","1383","                 copy_X=True, cv=None, verbose=False, n_jobs=1,","1575","                 max_iter=1000, tol=1e-4, cv=None, copy_X=True,","2050","    >>> clf = linear_model.MultiTaskElasticNetCV()","2054","    MultiTaskElasticNetCV(alphas=None, copy_X=True, cv=None, eps=0.001,","2081","                 max_iter=1000, tol=1e-4, cv=None, copy_X=True,","2227","                 cv=None, verbose=False, n_jobs=1, random_state=None,"]}],"sklearn\/model_selection\/tests\/test_split.py":[{"add":["3","import pytest","25","from sklearn.utils.testing import assert_no_warnings","53","from sklearn.model_selection._split import CV_WARNING","54","from sklearn.model_selection._split import NSPLIT_WARNING","204","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1404","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1430","def test_nsplit_default_warn():","1431","    # Test that warnings are raised. Will be removed in 0.22","1432","    assert_warns_message(FutureWarning, NSPLIT_WARNING, KFold)","1433","    assert_warns_message(FutureWarning, NSPLIT_WARNING, GroupKFold)","1434","    assert_warns_message(FutureWarning, NSPLIT_WARNING, StratifiedKFold)","1435","    assert_warns_message(FutureWarning, NSPLIT_WARNING, TimeSeriesSplit)","1436","","1437","    assert_no_warnings(KFold, n_splits=5)","1438","    assert_no_warnings(GroupKFold, n_splits=5)","1439","    assert_no_warnings(StratifiedKFold, n_splits=5)","1440","    assert_no_warnings(TimeSeriesSplit, n_splits=5)","1441","","1442","","1443","def test_check_cv_default_warn():","1444","    # Test that warnings are raised. Will be removed in 0.22","1445","    assert_warns_message(FutureWarning, CV_WARNING, check_cv)","1446","","1447","    assert_no_warnings(check_cv, cv=5)","1448","","1449",""],"delete":["3",""]}],"doc\/modules\/cross_validation.rst":[{"add":["140","  >>> cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)","141","  >>> cross_val_score(clf, iris.data, iris.target, cv=cv)  # doctest: +ELLIPSIS","142","  array([0.977..., 0.977..., 1.  ..., 0.955..., 1.        ])","168","      array([0.977..., 0.933..., 0.955..., 0.933..., 0.977...])","230","    ...                         scoring='precision_macro', cv=5,","462","  >>> X = np.arange(10)","463","  >>> ss = ShuffleSplit(n_splits=5, test_size=0.25,","467","  [9 1 6 7 3 0 5] [2 8 4]","468","  [2 9 8 0 6 7 4] [3 5 1]","469","  [4 5 1 0 6 9 7] [2 3 8]","470","  [2 7 5 8 0 3 4] [6 1 9]","471","  [4 1 0 6 8 9 3] [5 2 7]"],"delete":["140","  >>> cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=0)","141","  >>> cross_val_score(clf, iris.data, iris.target, cv=cv)","142","  ...                                                     # doctest: +ELLIPSIS","143","  array([0.97..., 0.97..., 1.        ])","144","","170","      array([0.97..., 0.93..., 0.95...])","232","    ...                         scoring='precision_macro',","464","  >>> X = np.arange(5)","465","  >>> ss = ShuffleSplit(n_splits=3, test_size=0.25,","469","  ...","470","  [1 3 4] [2 0]","471","  [1 4 3] [0 2]","472","  [4 0 2] [1 3]"]}],"sklearn\/linear_model\/tests\/test_ridge.py":[{"add":["492","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","551","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","581","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","598","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","608","    r = RidgeCV(alphas=alphas, cv=None, store_cv_values=True)","622","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","632","    r = RidgeClassifierCV(alphas=alphas, cv=None, store_cv_values=True)","743","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","754","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":["604","    r = RidgeCV(alphas=alphas, store_cv_values=True)","627","    r = RidgeClassifierCV(alphas=alphas, store_cv_values=True)"]}],"doc\/modules\/ensemble.rst":[{"add":["169","    >>> scores = cross_val_score(clf, X, y, cv=5)","170","    >>> scores.mean()                               # doctest: +ELLIPSIS","171","    0.98...","175","    >>> scores = cross_val_score(clf, X, y, cv=5)","176","    >>> scores.mean()                               # doctest: +ELLIPSIS","181","    >>> scores = cross_val_score(clf, X, y, cv=5)","259","the top of the tree contribute to the final prediction decision of a","260","larger fraction of the input samples. The **expected fraction of the","375","    >>> scores = cross_val_score(clf, iris.data, iris.target, cv=5)"],"delete":["169","    >>> scores = cross_val_score(clf, X, y)","170","    >>> scores.mean()                             # doctest: +ELLIPSIS","171","    0.97...","175","    >>> scores = cross_val_score(clf, X, y)","176","    >>> scores.mean()                             # doctest: +ELLIPSIS","181","    >>> scores = cross_val_score(clf, X, y)","259","the top of the tree contribute to the final prediction decision of a ","260","larger fraction of the input samples. The **expected fraction of the ","375","    >>> scores = cross_val_score(clf, iris.data, iris.target)"]}],"sklearn\/tests\/test_calibration.py":[{"add":["28","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","104","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"sklearn\/feature_selection\/tests\/test_rfe.py":[{"add":["231","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","323","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"sklearn\/feature_extraction\/tests\/test_text.py":[{"add":["734","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","772","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"sklearn\/tests\/test_metaestimators.py":[{"add":["1","import pytest","49","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":["1",""]}],"sklearn\/calibration.py":[{"add":["77","        .. versionchanged:: 0.20","78","            ``cv`` default value if None will change from 3-fold to 5-fold","79","            in v0.22.","80","","105","    def __init__(self, base_estimator=None, method='sigmoid', cv='warn'):"],"delete":["101","    def __init__(self, base_estimator=None, method='sigmoid', cv=3):"]}],"examples\/ensemble\/plot_gradient_boosting_oob.py":[{"add":["76","def cv_estimate(n_splits=None):"],"delete":["76","def cv_estimate(n_splits=3):"]}],"doc\/modules\/learning_curve.rst":[{"add":["83","  ...                                               np.logspace(-7, 3, 3),","84","  ...                                               cv=5)","85","  >>> train_scores            # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE","86","  array([[0.93..., 0.94..., 0.92..., 0.91..., 0.92...],","87","         [0.93..., 0.94..., 0.92..., 0.91..., 0.92...],","88","         [0.51..., 0.52..., 0.49..., 0.47..., 0.49...]])","90","  array([[0.90..., 0.84..., 0.94..., 0.96..., 0.93...],","91","         [0.90..., 0.84..., 0.94..., 0.96..., 0.93...],","92","         [0.46..., 0.25..., 0.50..., 0.49..., 0.52...]])"],"delete":["83","  ...                                               np.logspace(-7, 3, 3))","84","  >>> train_scores           # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE","85","  array([[0.94..., 0.92..., 0.92...],","86","         [0.94..., 0.92..., 0.92...],","87","         [0.47..., 0.45..., 0.42...]])","89","  array([[0.90..., 0.92..., 0.94...],","90","         [0.90..., 0.92..., 0.94...],","91","         [0.44..., 0.39..., 0.45...]])"]}],"doc\/modules\/model_evaluation.rst":[{"add":["101","    >>> cross_val_score(clf, X, y, scoring='recall_macro',","102","    ...                 cv=5)  # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE","103","    array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])","105","    >>> cross_val_score(model, X, y, cv=5, scoring='wrong_choice')","153","    >>> grid = GridSearchCV(LinearSVC(), param_grid={'C': [1, 10]},","154","    ...                     scoring=ftwo_scorer, cv=5)","254","    >>> cv_results = cross_validate(svm.fit(X, y), X, y,","255","    ...                             scoring=scoring, cv=5)","257","    >>> print(cv_results['test_tp'])  # doctest: +NORMALIZE_WHITESPACE","258","    [10  9  8  7  8]","260","    >>> print(cv_results['test_fn'])  # doctest: +NORMALIZE_WHITESPACE","261","    [0 1 2 3 2]"],"delete":["101","    >>> cross_val_score(clf, X, y, scoring='recall_macro') # doctest: +ELLIPSIS","102","    array([0.980..., 0.960..., 0.979...])","104","    >>> cross_val_score(model, X, y, scoring='wrong_choice')","152","    >>> grid = GridSearchCV(LinearSVC(), param_grid={'C': [1, 10]}, scoring=ftwo_scorer)","252","    >>> cv_results = cross_validate(svm.fit(X, y), X, y, scoring=scoring)","254","    >>> print(cv_results['test_tp'])          # doctest: +NORMALIZE_WHITESPACE","255","    [16 14  9]","257","    >>> print(cv_results['test_fn'])          # doctest: +NORMALIZE_WHITESPACE","258","    [1 3 7]"]}],"doc\/glossary.rst":[{"add":["1416","        all is an option), the default is 3-fold and will change to 5-fold","1417","        in version 0.22."],"delete":["1416","        all is an option), the default is 3-fold."]}],"sklearn\/model_selection\/_search.py":[{"add":["415","                 refit=True, cv='warn', verbose=0, pre_dispatch='2*n_jobs',","889","        .. versionchanged:: 0.20","890","            ``cv`` default value if None will change from 3-fold to 5-fold","891","            in v0.22.","892","","944","    >>> clf = GridSearchCV(svc, parameters, cv=5)","945","    >>> clf.fit(iris.data, iris.target)","947","    GridSearchCV(cv=5, error_score=...,","956","    >>> sorted(clf.cv_results_.keys())","1097","                 n_jobs=1, iid='warn', refit=True, cv='warn', verbose=0,","1233","        .. versionchanged:: 0.20","1234","            ``cv`` default value if None will change from 3-fold to 5-fold","1235","            in v0.22.","1236","","1414","                 fit_params=None, n_jobs=1, iid='warn', refit=True, cv='warn',"],"delete":["415","                 refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs',","940","    >>> clf = GridSearchCV(svc, parameters) # doctest: +SKIP","941","    >>> clf.fit(iris.data, iris.target) # doctest: +SKIP","943","    GridSearchCV(cv=None, error_score=...,","952","    >>> sorted(clf.cv_results_.keys()) # doctest: +SKIP","1093","                 n_jobs=1, iid='warn', refit=True, cv=None, verbose=0,","1406","                 fit_params=None, n_jobs=1, iid='warn', refit=True, cv=None,"]}],"doc\/whats_new\/v0.20.rst":[{"add":["197","- Added control over the normalization in","336","","550","","551","- Fixed a bug in :class:`tree.MAE` to ensure sample weights are being used","552","  during the calculation of tree MAE impurity. Previous behaviour could","553","  cause suboptimal splits to be chosen since the impurity calculation","555","  :issue:`11464` by :user:`John Stott <JohnStott>`.","741","- The default value of the ``n_estimators`` parameter of","742","  :class:`ensemble.RandomForestClassifier`, :class:`ensemble.RandomForestRegressor`,","743","  :class:`ensemble.ExtraTreesClassifier`, :class:`ensemble.ExtraTreesRegressor`,","744","  and :class:`ensemble.RandomTreesEmbedding` will change from 10 in version 0.20","808","  :func:`metrics.adjusted_mutual_information_score`,","810","  will have a new default value. In version 0.22, the default normalizer for each","912","Model selection","913","","914","- The default number of cross-validation folds ``cv`` and the default number of","915","  splits ``n_splits`` in the :class:`model_selection.KFold`-like splitters will change","916","  from 3 to 5 in 0.22 as 3-fold has a lot of variance.","917","  :issue:`11557` by :user:`Alexandre Boucaud <aboucaud>`.","918","","936",""],"delete":["197","- Added control over the normalization in ","336","  ","550","  ","551","- Fixed a bug in :class:`tree.MAE` to ensure sample weights are being used ","552","  during the calculation of tree MAE impurity. Previous behaviour could ","553","  cause suboptimal splits to be chosen since the impurity calculation ","555","  :issue:`11464` by :user:`John Stott <JohnStott>`.  ","741","- The default value of the ``n_estimators`` parameter of ","742","  :class:`ensemble.RandomForestClassifier`, :class:`ensemble.RandomForestRegressor`, ","743","  :class:`ensemble.ExtraTreesClassifier`, :class:`ensemble.ExtraTreesRegressor`, ","744","  and :class:`ensemble.RandomTreesEmbedding` will change from 10 in version 0.20 ","808","  :func:`metrics.adjusted_mutual_information_score`, ","810","  will have a new default value. In version 0.22, the default normalizer for each ","929","  "]}],"sklearn\/feature_selection\/rfe.py":[{"add":["314","        .. versionchanged:: 0.20","315","            ``cv`` default value if None will change from 3-fold to 5-fold","316","            in v0.22.","317","","388","    def __init__(self, estimator, step=1, cv='warn', scoring=None, verbose=0,"],"delete":["384","    def __init__(self, estimator, step=1, cv=None, scoring=None, verbose=0,"]}],"sklearn\/linear_model\/logistic.py":[{"add":["1410","    cv : integer or cross-validation generator, default: None","1416","        .. versionchanged:: 0.20","1417","            ``cv`` default value if None will change from 3-fold to 5-fold","1418","            in v0.22.","1419","","1576","    def __init__(self, Cs=10, fit_intercept=True, cv='warn', dual=False,"],"delete":["1410","    cv : integer or cross-validation generator","1572","    def __init__(self, Cs=10, fit_intercept=True, cv=None, dual=False,"]}],"sklearn\/ensemble\/tests\/test_forest.py":[{"add":["448","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"doc\/tutorial\/statistical_inference\/model_selection.rst":[{"add":["62","    >>> X = [\"a\", \"a\", \"a\", \"b\", \"b\", \"c\", \"c\", \"c\", \"c\", \"c\"]","63","    >>> k_fold = KFold(n_splits=5)","66","    Train: [2 3 4 5 6 7 8 9] | test: [0 1]","67","    Train: [0 1 4 5 6 7 8 9] | test: [2 3]","68","    Train: [0 1 2 3 6 7 8 9] | test: [4 5]","69","    Train: [0 1 2 3 4 5 8 9] | test: [6 7]","70","    Train: [0 1 2 3 4 5 6 7] | test: [8 9]","76","    [0.963..., 0.922..., 0.963..., 0.963..., 0.930...]","90","    array([0.96388889, 0.92222222, 0.9637883 , 0.9637883 , 0.93036212])","100","    array([0.96578289, 0.92708922, 0.96681476, 0.96362897, 0.93192644])","233","a stratified 3-fold. The default will change to a 5-fold cross-validation in","234","version 0.22.","265","    >>> lasso = linear_model.LassoCV(cv=3)","270","    LassoCV(alphas=None, copy_X=True, cv=3, eps=0.001, fit_intercept=True,"],"delete":["62","    >>> X = [\"a\", \"a\", \"b\", \"c\", \"c\", \"c\"]","63","    >>> k_fold = KFold(n_splits=3)","66","    Train: [2 3 4 5] | test: [0 1]","67","    Train: [0 1 4 5] | test: [2 3]","68","    Train: [0 1 2 3] | test: [4 5]","74","    [0.934..., 0.956..., 0.939...]","88","    array([0.93489149, 0.95659432, 0.93989983])","98","    array([0.93969761, 0.95911415, 0.94041254])","231","a stratified 3-fold.","262","    >>> lasso = linear_model.LassoCV()","267","    LassoCV(alphas=None, copy_X=True, cv=None, eps=0.001, fit_intercept=True,"]}],"sklearn\/covariance\/tests\/test_graph_lasso.py":[{"add":["4","import pytest","5","","122","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","146","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"sklearn\/covariance\/tests\/test_graphical_lasso.py":[{"add":["118","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","141","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"sklearn\/linear_model\/omp.py":[{"add":["787","        .. versionchanged:: 0.20","788","            ``cv`` default value if None will change from 3-fold to 5-fold","789","            in v0.22.","790","","828","                 max_iter=None, cv='warn', n_jobs=1, verbose=False):"],"delete":["824","                 max_iter=None, cv=None, n_jobs=1, verbose=False):"]}],"sklearn\/ensemble\/tests\/test_weight_boosting.py":[{"add":["199","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"doc\/modules\/linear_model.rst":[{"add":["140","    >>> reg = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0], cv=3)","142","    RidgeCV(alphas=[0.1, 1.0, 10.0], cv=3, fit_intercept=True, scoring=None,"],"delete":["140","    >>> reg = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])","142","    RidgeCV(alphas=[0.1, 1.0, 10.0], cv=None, fit_intercept=True, scoring=None,"]}],"sklearn\/metrics\/tests\/test_score_objects.py":[{"add":["252","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"sklearn\/model_selection\/_split.py":[{"add":["51","NSPLIT_WARNING = (","52","    \"You should specify a value for 'n_splits' instead of relying on the \"","53","    \"default value. The default value will change from 3 to 5 \"","54","    \"in version 0.22.\")","55","","56","CV_WARNING = (","57","    \"You should specify a value for 'cv' instead of relying on the \"","58","    \"default value. The default value will change from 3 to 5 \"","59","    \"in version 0.22.\")","60","","61","","371","        .. versionchanged:: 0.20","372","            ``n_splits`` default value will change from 3 to 5 in v0.22.","373","","422","    def __init__(self, n_splits='warn', shuffle=False,","424","        if n_splits is 'warn':","425","            warnings.warn(NSPLIT_WARNING, FutureWarning)","426","            n_splits = 3","459","        .. versionchanged:: 0.20","460","            ``n_splits`` default value will change from 3 to 5 in v0.22.","461","","494","    def __init__(self, n_splits='warn'):","495","        if n_splits is 'warn':","496","            warnings.warn(NSPLIT_WARNING, FutureWarning)","497","            n_splits = 3","555","        .. versionchanged:: 0.20","556","            ``n_splits`` default value will change from 3 to 5 in v0.22.","557","","595","    def __init__(self, n_splits='warn', shuffle=False, random_state=None):","596","        if n_splits is 'warn':","597","            warnings.warn(NSPLIT_WARNING, FutureWarning)","598","            n_splits = 3","718","        .. versionchanged:: 0.20","719","            ``n_splits`` default value will change from 3 to 5 in v0.22.","720","","727","    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])","728","    >>> y = np.array([1, 2, 3, 4, 5, 6])","729","    >>> tscv = TimeSeriesSplit(n_splits=5)","731","    TimeSeriesSplit(max_train_size=None, n_splits=5)","739","    TRAIN: [0 1 2 3] TEST: [4]","740","    TRAIN: [0 1 2 3 4] TEST: [5]","749","    def __init__(self, n_splits='warn', max_train_size=None):","750","        if n_splits is 'warn':","751","            warnings.warn(NSPLIT_WARNING, FutureWarning)","752","            n_splits = 3","1309","    >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [3, 4], [5, 6]])","1310","    >>> y = np.array([1, 2, 1, 2, 1, 2])","1311","    >>> rs = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)","1313","    5","1315","    ShuffleSplit(n_splits=5, random_state=0, test_size=0.25, train_size=None)","1319","    TRAIN: [1 3 0 4] TEST: [5 2]","1320","    TRAIN: [4 0 2 5] TEST: [1 3]","1321","    TRAIN: [1 2 4 0] TEST: [3 5]","1322","    TRAIN: [3 4 1 0] TEST: [5 2]","1323","    TRAIN: [3 5 1 0] TEST: [2 4]","1324","    >>> rs = ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,","1329","    TRAIN: [1 3 0] TEST: [5 2]","1330","    TRAIN: [4 0 2] TEST: [1 3]","1331","    TRAIN: [1 2 4] TEST: [3 5]","1332","    TRAIN: [3 4 1] TEST: [5 2]","1333","    TRAIN: [3 5 1] TEST: [2 4]","1545","    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])","1546","    >>> y = np.array([0, 0, 0, 1, 1, 1])","1547","    >>> sss = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)","1549","    5","1551","    StratifiedShuffleSplit(n_splits=5, random_state=0, ...)","1556","    TRAIN: [5 2 3] TEST: [4 1 0]","1557","    TRAIN: [5 1 4] TEST: [0 2 3]","1558","    TRAIN: [5 0 2] TEST: [4 3 1]","1559","    TRAIN: [4 1 0] TEST: [2 3 5]","1560","    TRAIN: [0 5 1] TEST: [3 4 2]","1904","def check_cv(cv='warn', y=None, classifier=False):","1925","        .. versionchanged:: 0.20","1926","            ``cv`` default value will change from 3-fold to 5-fold in v0.22.","1927","","1941","    if cv is 'warn':","1942","        warnings.warn(CV_WARNING, FutureWarning)"],"delete":["408","    def __init__(self, n_splits=3, shuffle=False,","474","    def __init__(self, n_splits=3):","569","    def __init__(self, n_splits=3, shuffle=False, random_state=None):","695","    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])","696","    >>> y = np.array([1, 2, 3, 4])","697","    >>> tscv = TimeSeriesSplit(n_splits=3)","699","    TimeSeriesSplit(max_train_size=None, n_splits=3)","715","    def __init__(self, n_splits=3, max_train_size=None):","1272","    >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])","1273","    >>> y = np.array([1, 2, 1, 2])","1274","    >>> rs = ShuffleSplit(n_splits=3, test_size=.25, random_state=0)","1276","    3","1278","    ShuffleSplit(n_splits=3, random_state=0, test_size=0.25, train_size=None)","1282","    TRAIN: [3 1 0] TEST: [2]","1283","    TRAIN: [2 1 3] TEST: [0]","1284","    TRAIN: [0 2 1] TEST: [3]","1285","    >>> rs = ShuffleSplit(n_splits=3, train_size=0.5, test_size=.25,","1290","    TRAIN: [3 1] TEST: [2]","1291","    TRAIN: [2 1] TEST: [0]","1292","    TRAIN: [0 2] TEST: [3]","1504","    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])","1505","    >>> y = np.array([0, 0, 1, 1])","1506","    >>> sss = StratifiedShuffleSplit(n_splits=3, test_size=0.5, random_state=0)","1508","    3","1510","    StratifiedShuffleSplit(n_splits=3, random_state=0, ...)","1515","    TRAIN: [1 2] TEST: [3 0]","1516","    TRAIN: [0 2] TEST: [1 3]","1517","    TRAIN: [0 2] TEST: [3 1]","1861","def check_cv(cv=3, y=None, classifier=False):","1895","    if cv is None:"]}],"sklearn\/ensemble\/tests\/test_bagging.py":[{"add":["500","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"sklearn\/model_selection\/_validation.py":[{"add":["40","def cross_validate(estimator, X, y=None, groups=None, scoring=None, cv='warn',","95","        .. versionchanged:: 0.20","96","            ``cv`` default value if None will change from 3-fold to 5-fold","97","            in v0.22.","98","","181","    >>> cv_results = cross_validate(lasso, X, y, cv=3,","182","    ...                             return_train_score=False)","191","    >>> scores = cross_validate(lasso, X, y, cv=3,","262","def cross_val_score(estimator, X, y=None, groups=None, scoring=None, cv='warn',","306","        .. versionchanged:: 0.20","307","            ``cv`` default value if None will change from 3-fold to 5-fold","308","            in v0.22.","309","","350","    >>> print(cross_val_score(lasso, X, y, cv=3))  # doctest: +ELLIPSIS","623","def cross_val_predict(estimator, X, y=None, groups=None, cv='warn', n_jobs=1,","665","        .. versionchanged:: 0.20","666","            ``cv`` default value if None will change from 3-fold to 5-fold","667","            in v0.22.","668","","729","    >>> y_pred = cross_val_predict(lasso, X, y, cv=3)","903","def permutation_test_score(estimator, X, y, groups=None, cv='warn',","954","        .. versionchanged:: 0.20","955","            ``cv`` default value if None will change from 3-fold to 5-fold","956","            in v0.22.","957","","1044","                   train_sizes=np.linspace(0.1, 1.0, 5), cv='warn',","1045","                   scoring=None, exploit_incremental_learning=False, n_jobs=1,","1104","        .. versionchanged:: 0.20","1105","            ``cv`` default value if None will change from 3-fold to 5-fold","1106","            in v0.22.","1107","","1289","                     cv='warn', scoring=None, n_jobs=1, pre_dispatch=\"all\",","1341","        .. versionchanged:: 0.20","1342","            ``cv`` default value if None will change from 3-fold to 5-fold","1343","            in v0.22.","1344",""],"delete":["40","def cross_validate(estimator, X, y=None, groups=None, scoring=None, cv=None,","177","    >>> cv_results = cross_validate(lasso, X, y, return_train_score=False)","186","    >>> scores = cross_validate(lasso, X, y,","257","def cross_val_score(estimator, X, y=None, groups=None, scoring=None, cv=None,","341","    >>> print(cross_val_score(lasso, X, y))  # doctest: +ELLIPSIS","614","def cross_val_predict(estimator, X, y=None, groups=None, cv=None, n_jobs=1,","716","    >>> y_pred = cross_val_predict(lasso, X, y)","890","def permutation_test_score(estimator, X, y, groups=None, cv=None,","1027","                   train_sizes=np.linspace(0.1, 1.0, 5), cv=None, scoring=None,","1028","                   exploit_incremental_learning=False, n_jobs=1,","1268","                     cv=None, scoring=None, n_jobs=1, pre_dispatch=\"all\","]}],"sklearn\/linear_model\/tests\/test_least_angle.py":[{"add":["184","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","421","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","438","@pytest.mark.filterwarnings('ignore::FutureWarning')","529","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":[]}],"sklearn\/model_selection\/tests\/test_validation.py":[{"add":["242","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","284","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","406","                                         return_train_score=val, cv=5)","513","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","534","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","572","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","599","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","793","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","843","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","890","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","905","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","920","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","967","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","986","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1340","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1346","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1355","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1383","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1425","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22","1454","@pytest.mark.filterwarnings('ignore: You should specify a value')  # 0.22"],"delete":["404","                                         return_train_score=val)"]}],"sklearn\/linear_model\/least_angle.py":[{"add":["1015","        .. versionchanged:: 0.20","1016","            ``cv`` default value if None will change from 3-fold to 5-fold","1017","            in v0.22.","1018","","1077","                 normalize=True, precompute='auto', cv='warn',","1228","        .. versionchanged:: 0.20","1229","            ``cv`` default value if None will change from 3-fold to 5-fold","1230","            in v0.22.","1231","","1307","                 normalize=True, precompute='auto', cv='warn',"],"delete":["1073","                 normalize=True, precompute='auto', cv=None,","1299","                 normalize=True, precompute='auto', cv=None,"]}]}},"87d96a2c2af9e02f3ff34221e7b98904e4216c60":{"changes":{"sklearn\/preprocessing\/tests\/test_label.py":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/preprocessing\/label.py":"MODIFY"},"diff":{"sklearn\/preprocessing\/tests\/test_label.py":[{"add":["210","    # Fail on inverse_transform(\"\")","211","    msg = \"bad input shape ()\"","212","    assert_raise_message(ValueError, msg, le.inverse_transform, \"\")","213","","214","","215","def test_label_encoder_empty_array():","216","    le = LabelEncoder()","217","    le.fit(np.array([\"1\", \"2\", \"1\", \"2\", \"2\"]))","218","    # test empty transform","219","    transformed = le.transform([])","220","    assert_array_equal(np.array([]), transformed)","221","    # test empty inverse transform","222","    inverse_transformed = le.inverse_transform([])","223","    assert_array_equal(np.array([]), inverse_transformed)","224",""],"delete":[]}],"doc\/whats_new\/v0.20.rst":[{"add":["307","Preprocessing","308","","309","- Fixed bugs in :class:`preprocessing.LabelEncoder` which would sometimes throw","310","  errors when ``transform`` or ``inverse_transform`` was called with empty arrays.","311","  :issue:`10458` by :user:`Mayur Kulkarni <maykulkarni>`.","312",""],"delete":[]}],"sklearn\/preprocessing\/label.py":[{"add":["128","        # transform of empty array is empty array","129","        if _num_samples(y) == 0:","130","            return np.array([])","152","        y = column_or_1d(y, warn=True)","153","        # inverse transform of empty array is empty array","154","        if _num_samples(y) == 0:","155","            return np.array([])"],"delete":[]}]}},"6eb218e301430a97e167ad8da018062f317c4d7e":{"changes":{"sklearn\/feature_extraction\/tests\/test_image.py":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/feature_extraction\/image.py":"MODIFY"},"diff":{"sklearn\/feature_extraction\/tests\/test_image.py":[{"add":["4","from __future__ import division","173","def test_extract_patch_same_size_image():","174","    face = downsampled_face","175","    # Request patches of the same size as image","176","    # Should return just the single patch a.k.a. the image","177","    patches = extract_patches_2d(face, face.shape, max_patches=2)","178","    assert_equal(patches.shape[0], 1)","179","","180","","181","def test_extract_patches_less_than_max_patches():","182","    face = downsampled_face","183","    i_h, i_w = face.shape","184","    p_h, p_w = 3 * i_h \/\/ 4, 3 * i_w \/\/ 4","185","    # this is 3185","186","    expected_n_patches = (i_h - p_h + 1) * (i_w - p_w + 1)","187","","188","    patches = extract_patches_2d(face, (p_h, p_w), max_patches=4000)","189","    assert_equal(patches.shape, (expected_n_patches, p_h, p_w))","190","","191",""],"delete":[]}],"doc\/whats_new\/v0.20.rst":[{"add":["205","Feature Extraction","206","","207","- Fixed a bug in :func:`feature_extraction.image.extract_patches_2d` which would","208","  throw an exception if ``max_patches`` was greater than or equal to the number","209","  of all possible patches rather than simply returning the number of possible","210","  patches. :issue:`10100` by :user:`Varun Agrawal <varunagrawal>`","211","","212","\t"],"delete":[]}],"sklearn\/feature_extraction\/image.py":[{"add":["231","        elif (isinstance(max_patches, (numbers.Integral))","232","              and max_patches >= all_patches):","233","            return all_patches"],"delete":[]}]}},"96a2c10da1d5d793a57d8c1734f7a06c5ec88347":{"changes":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":"MODIFY",".gitignore":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY","sklearn\/linear_model\/coordinate_descent.py":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_coordinate_descent.py":[{"add":["5","import pytest","672","@pytest.mark.parametrize(\"check_input\", [True, False])","673","def test_enet_copy_X_True(check_input):","674","    X, y, _, _ = build_dataset()","675","    X = X.copy(order='F')","676","","677","    original_X = X.copy()","678","    enet = ElasticNet(copy_X=True)","679","    enet.fit(X, y, check_input=check_input)","680","","681","    assert_array_equal(original_X, X)","682","","683","","684","def test_enet_copy_X_False_check_input_False():","685","    X, y, _, _ = build_dataset()","686","    X = X.copy(order='F')","687","","688","    original_X = X.copy()","689","    enet = ElasticNet(copy_X=False)","690","    enet.fit(X, y, check_input=False)","691","","692","    # No copying, X is overwritten","693","    assert_true(np.any(np.not_equal(original_X, X)))","694","","695",""],"delete":[]}],".gitignore":[{"add":["67",".pytest_cache\/","68","_configtest.o.d"],"delete":[]}],"doc\/whats_new\/v0.20.rst":[{"add":["237","- Fixed a bug in :class:`linear_model.ElasticNet` which caused the input to be","238","  overridden when using parameter ``copy_X=True`` and ``check_input=False``.","239","  :issue:`10581` by :user:`Yacine Mazari <ymazari>`.","240",""],"delete":[]}],"sklearn\/linear_model\/coordinate_descent.py":[{"add":["702","        # Remember if X is copied","703","        X_copied = False","707","            X_copied = self.copy_X and self.fit_intercept","710","                             copy=X_copied, multi_output=True, y_numeric=True)","714","        # Ensure copying happens only once, don't do it again if done above","715","        should_copy = self.copy_X and not X_copied","718","                     self.fit_intercept, copy=should_copy)"],"delete":["707","                             copy=self.copy_X and self.fit_intercept,","708","                             multi_output=True, y_numeric=True)","714","                     self.fit_intercept, copy=False)"]}]}},"9a301b45789b0c09336b48b4e1d6091d3c33d5c0":{"changes":{"doc\/developers\/tips.rst":"MODIFY"},"diff":{"doc\/developers\/tips.rst":[{"add":["81","When a unit test fails, the following tricks can make debugging easier:"],"delete":["81","When a unit tests fail, the following tricks can make debugging easier:"]}]}},"53622e856c2747c7b559d3d29410cd37ca0addd2":{"changes":{"examples\/ensemble\/plot_isolation_forest.py":"MODIFY","sklearn\/ensemble\/iforest.py":"MODIFY","doc\/whats_new\/v0.20.rst":"MODIFY","examples\/plot_anomaly_comparison.py":"MODIFY","sklearn\/utils\/estimator_checks.py":"MODIFY","sklearn\/ensemble\/tests\/test_iforest.py":"MODIFY","benchmarks\/bench_isolation_forest.py":"MODIFY"},"diff":{"examples\/ensemble\/plot_isolation_forest.py":[{"add":["42","clf = IsolationForest(behaviour='new', max_samples=100,","43","                      random_state=rng, contamination='auto')"],"delete":["42","clf = IsolationForest(max_samples=100, random_state=rng, contamination='auto')"]}],"sklearn\/ensemble\/iforest.py":[{"add":["91","    behaviour : str, default='old'","92","        Behaviour of the ``decision_function`` which can be either 'old' or","93","        'new'. Passing ``behaviour='new'`` makes the ``decision_function``","94","        change to match other anomaly detection algorithm API which will be","95","        the default behaviour in the future. As explained in details in the","96","        ``offset_`` attribute documentation, the ``decision_function`` becomes","97","        dependent on the contamination parameter, in such a way that 0 becomes","98","        its natural threshold to detect outliers.","99","","100","        .. versionadded:: 0.20","101","           ``behaviour`` is added in 0.20 for back-compatibility purpose.","102","","103","        .. deprecated:: 0.20","104","           ``behaviour='old'`` is deprecated in 0.20 and will not be possible","105","           in 0.22.","106","","107","        .. deprecated:: 0.22","108","           ``behaviour`` parameter will be deprecated in 0.22 and removed in","109","           0.24.","110","","136","        Assuming behaviour == 'new', offset_ is defined as follows.","143","        Assuming the behaviour parameter is set to 'old', we always have","144","        offset_ = -0.5, making the decision function independent from the","145","        contamination parameter.","164","                 behaviour='old',","181","","182","        self.behaviour = behaviour","214","        if self.behaviour == 'old':","215","            warnings.warn('behaviour=\"old\" is deprecated and will be removed '","216","                          'in version 0.22. Please use behaviour=\"new\", which '","217","                          'makes the decision_function change to match '","218","                          'other anomaly detection algorithm API.',","219","                          FutureWarning)","220","","262","        if self.behaviour == 'old':","263","            # in this case, decision_function = 0.5 + self.score_samples(X):","264","            if self._contamination == \"auto\":","265","                raise ValueError(\"contamination parameter cannot be set to \"","266","                                 \"'auto' when behaviour == 'old'.\")","267","","268","            self.offset_ = -0.5","269","            self._threshold_ = sp.stats.scoreatpercentile(","270","                self.decision_function(X), 100. * self._contamination)","271","","272","            return self","273","","274","        # else, self.behaviour == 'new':","279","            return self","280","","281","        # else, define offset_ wrt contamination parameter, so that the","282","        # threshold_ attribute is implicitly 0 and is not needed anymore:","283","        self.offset_ = sp.stats.scoreatpercentile(","284","            self.score_samples(X), 100. * self._contamination)","307","        threshold = self.threshold_ if self.behaviour == 'old' else 0","308","        is_inlier[self.decision_function(X) < threshold] = -1","409","        if self.behaviour != 'old':","410","            raise AttributeError(\"threshold_ attribute does not exist when \"","411","                                 \"behaviour != 'old'\")","414","        return self._threshold_"],"delete":["232","            # need to save (depreciated) threshold_ in this case:","233","            self._threshold_ = sp.stats.scoreatpercentile(","234","                self.score_samples(X), 100. * 0.1)","235","        else:","236","            self.offset_ = sp.stats.scoreatpercentile(","237","                self.score_samples(X), 100. * self._contamination)","260","        is_inlier[self.decision_function(X) < 0] = -1","363","        if self.contamination == 'auto':","364","            return self._threshold_","365","        return self.offset_"]}],"doc\/whats_new\/v0.20.rst":[{"add":["915"," - A ``behaviour`` parameter has been introduced in :class:`ensemble.IsolationForest`","916","  to ensure backward compatibility.","917","  In the old behaviour, the ``decision_function`` is independent of the ``contamination``","918","  parameter. A threshold attribute depending on the ``contamination`` parameter is thus","919","  used.","920","  In the new behaviour the ``decision_function`` is dependent on the ``contamination``","921","  parameter, in such a way that 0 becomes its natural threshold to detect outliers.","922","  Setting behaviour to \"old\" is deprecated and will not be possible in version 0.22.","923","  Beside, the behaviour parameter will be removed in 0.24.","924","  :issue:`11553` by `Nicolas Goix`_.","925",""],"delete":[]}],"examples\/plot_anomaly_comparison.py":[{"add":["82","    (\"Isolation Forest\", IsolationForest(behaviour='new',","83","                                         contamination=outliers_fraction,"],"delete":["82","    (\"Isolation Forest\", IsolationForest(contamination=outliers_fraction,"]}],"sklearn\/utils\/estimator_checks.py":[{"add":["370","    if estimator.__class__.__name__ == \"IsolationForest\":","371","        # XXX to be removed in 0.22.","372","        # this is used because the old IsolationForest does not","373","        # respect the outlier detection API and thus and does not","374","        # pass the outlier detection common tests.","375","        estimator.set_params(behaviour='new')","376",""],"delete":[]}],"sklearn\/ensemble\/tests\/test_iforest.py":[{"add":["17","from sklearn.utils.testing import assert_raises_regex","50","@pytest.mark.filterwarnings('ignore:threshold_ attribute')","67","@pytest.mark.filterwarnings('ignore:threshold_ attribute')","68","@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')","97","@pytest.mark.filterwarnings('ignore:threshold_ attribute')","98","@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')","136","    # test threshold_ attribute error when behaviour is not old:","137","    msg = \"threshold_ attribute does not exist when behaviour != 'old'\"","138","    assert_raises_regex(AttributeError, msg, getattr,","139","                        IsolationForest(behaviour='new'), 'threshold_')","140","","143","@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')","153","@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')","170","@pytest.mark.filterwarnings('ignore:threshold_ attribute')","171","@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')","197","@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')","222","@pytest.mark.filterwarnings('ignore:threshold_ attribute')","229","        clf = IsolationForest(behaviour='new', random_state=rng,","230","                              contamination=contamination)","240","@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')","249","@pytest.mark.filterwarnings('ignore:threshold_ attribute')","250","@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')","276","@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')","289","@pytest.mark.filterwarnings('ignore:default contamination')","290","@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')","300","    assert_warns_message(FutureWarning,","301","                         'behaviour=\"old\" is deprecated and will be removed '","302","                         'in version 0.22',","303","                         clf.fit, X)","304","","305","    clf = IsolationForest().fit(X)","310","","311","","312","@pytest.mark.filterwarnings('ignore:default contamination')","313","@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')","314","def test_behaviour_param():","315","    X_train = [[1, 1], [1, 2], [2, 1]]","316","    clf1 = IsolationForest(behaviour='old').fit(X_train)","317","    clf2 = IsolationForest(behaviour='new', contamination='auto').fit(X_train)","318","    assert_array_equal(clf1.decision_function([[2., 2.]]),","319","                       clf2.decision_function([[2., 2.]]))"],"delete":["212","        clf = IsolationForest(random_state=rng, contamination=contamination)","276","    clf = IsolationForest(contamination='auto').fit(X)"]}],"benchmarks\/bench_isolation_forest.py":[{"add":["121","    model = IsolationForest(behaviour='new', n_jobs=-1,","122","                            random_state=random_state)"],"delete":["121","    model = IsolationForest(n_jobs=-1, random_state=random_state)"]}]}},"816e2eb5233d7926d4fe7c1892abfe329d0a8bdc":{"changes":{"\/dev\/null":"DELETE","doc\/conftest.py":"ADD"},"diff":{"\/dev\/null":[{"add":[],"delete":[]}],"doc\/conftest.py":[{"add":[],"delete":[]}]}},"5cf3fb70a1a476be79d262ce8bff4cee73b72401":{"changes":{"sklearn\/manifold\/locally_linear.py":"MODIFY"},"diff":{"sklearn\/manifold\/locally_linear.py":[{"add":["591","    embedding_ : array-like, shape [n_samples, n_components]","595","        Reconstruction error associated with `embedding_`"],"delete":["591","    embedding_vectors_ : array-like, shape [n_components, n_samples]","595","        Reconstruction error associated with `embedding_vectors_`"]}]}},"26421be2dfe9d9e633a69abda4caed3ff2b669d1":{"changes":{"Makefile":"MODIFY"},"diff":{"Makefile":[{"add":["36","\t$(PYTEST) sklearn --showlocals -v --cov=sklearn --cov-report=html:coverage"],"delete":["36","\t$(PYTEST) sklearn --show-locals -v --with-cov sklearn"]}]}}}
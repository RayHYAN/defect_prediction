{"d163d5ad9433d11b36fb3ce580d97c9462087a40":{"changes":{"sklearn\/semi_supervised\/tests\/test_label_propagation.py":"MODIFY","sklearn\/semi_supervised\/_label_propagation.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY"},"diff":{"sklearn\/semi_supervised\/tests\/test_label_propagation.py":[{"add":["5","from scipy.sparse import issparse","10","from sklearn.model_selection import train_test_split","11","from sklearn.neighbors import NearestNeighbors","157","","158","","159","def test_predict_sparse_callable_kernel():","160","    # This is a non-regression test for #15866","161","","162","    # Custom sparse kernel (top-K RBF)","163","    def topk_rbf(X, Y=None, n_neighbors=10, gamma=1e-5):","164","        nn = NearestNeighbors(n_neighbors=10, metric='euclidean', n_jobs=-1)","165","        nn.fit(X)","166","        W = -1 * nn.kneighbors_graph(Y, mode='distance').power(2) * gamma","167","        np.exp(W.data, out=W.data)","168","        assert issparse(W)","169","        return W.T","170","","171","    n_classes = 4","172","    n_samples = 500","173","    n_test = 10","174","    X, y = make_classification(n_classes=n_classes,","175","                               n_samples=n_samples,","176","                               n_features=20,","177","                               n_informative=20,","178","                               n_redundant=0,","179","                               n_repeated=0,","180","                               random_state=0)","181","","182","    X_train, X_test, y_train, y_test = train_test_split(X, y,","183","                                                        test_size=n_test,","184","                                                        random_state=0)","185","","186","    model = label_propagation.LabelSpreading(kernel=topk_rbf)","187","    model.fit(X_train, y_train)","188","    assert model.score(X_test, y_test) >= 0.9","189","","190","    model = label_propagation.LabelPropagation(kernel=topk_rbf)","191","    model.fit(X_train, y_train)","192","    assert model.score(X_test, y_test) >= 0.9"],"delete":[]}],"sklearn\/semi_supervised\/_label_propagation.py":[{"add":["197","            probabilities = safe_sparse_dot(","198","                    weight_matrices, self.label_distributions_)"],"delete":["197","            probabilities = np.dot(weight_matrices, self.label_distributions_)"]}],"doc\/whats_new\/v0.22.rst":[{"add":["55","  ","56",":mod:`sklearn.semi_supervised`","57","..............................","58","","59","- |Fix| :class:`semi_supervised.LabelPropagation` and","60","  :class:`semi_supervised.LabelSpreading` now allow callable kernel function to","61","  return sparse weight matrix.","62","  :pr:`15868` by :user:`Niklas Smedemark-Margulies <nik-sm>`."],"delete":[]}]}},"bcd399f4cbe6ad13a5dd1e82c128cebb8fcf9eb4":{"changes":{"sklearn\/model_selection\/_validation.py":"MODIFY","sklearn\/linear_model\/tests\/test_logistic.py":"MODIFY","sklearn\/feature_selection\/rfe.py":"MODIFY","sklearn\/model_selection\/tests\/test_validation.py":"MODIFY","doc\/modules\/cross_validation.rst":"MODIFY","sklearn\/feature_selection\/mutual_info_.py":"MODIFY"},"diff":{"sklearn\/model_selection\/_validation.py":[{"add":["179","    >>> from sklearn.metrics import make_scorer"],"delete":["179","    >>> from sklearn.metrics.scorer import make_scorer"]}],"sklearn\/linear_model\/tests\/test_logistic.py":[{"add":["11","from sklearn.metrics import get_scorer"],"delete":["11","from sklearn.metrics.scorer import get_scorer"]}],"sklearn\/feature_selection\/rfe.py":[{"add":["21","from ..metrics import check_scoring"],"delete":["21","from ..metrics.scorer import check_scoring"]}],"sklearn\/model_selection\/tests\/test_validation.py":[{"add":["54","from sklearn.metrics import check_scoring"],"delete":["54","from sklearn.metrics.scorer import check_scoring"]}],"doc\/modules\/cross_validation.rst":[{"add":["243","    >>> from sklearn.metrics import make_scorer"],"delete":["243","    >>> from sklearn.metrics.scorer import make_scorer"]}],"sklearn\/feature_selection\/mutual_info_.py":[{"add":["7","from ..metrics.cluster import mutual_info_score"],"delete":["7","from ..metrics.cluster.supervised import mutual_info_score"]}]}},"97958c174f8b95f7e86d6a0280847be61bfc8e04":{"changes":{"sklearn\/ensemble\/_hist_gradient_boosting\/gradient_boosting.py":"MODIFY","sklearn\/ensemble\/_hist_gradient_boosting\/tests\/test_warm_start.py":"MODIFY"},"diff":{"sklearn\/ensemble\/_hist_gradient_boosting\/gradient_boosting.py":[{"add":["272","            if self.do_early_stopping_ and self._use_validation_data:","273","                raw_predictions_val = self._raw_predict(X_binned_val)"],"delete":[]}],"sklearn\/ensemble\/_hist_gradient_boosting\/tests\/test_warm_start.py":[{"add":["95","@pytest.mark.parametrize('scoring', (None, 'loss'))","96","def test_warm_start_early_stopping(GradientBoosting, X, y, scoring):","103","        random_state=42, warm_start=True, tol=1e-3, scoring=scoring,"],"delete":["95","def test_warm_start_early_stopping(GradientBoosting, X, y):","102","        random_state=42, warm_start=True, tol=1e-3"]}]}},"0396c886066c9a0dc2a49dc8ac97037b4e73d947":{"changes":{"doc\/whats_new\/v0.23.rst":"MODIFY","sklearn\/metrics\/tests\/test_regression.py":"MODIFY","sklearn\/metrics\/_regression.py":"MODIFY"},"diff":{"doc\/whats_new\/v0.23.rst":[{"add":["155",":mod:`sklearn.metrics`","156","......................","157","","158","- |Fix| Fixed a bug in :func:`metrics.mean_squared_error` to not ignore","159","  argument `squared` when argument `multioutput='raw_values'`. ","160","  :pr:`16323` by :user:`Rushabh Vasani <rushabh-v>`","161",""],"delete":[]}],"sklearn\/metrics\/tests\/test_regression.py":[{"add":["58","def test_mean_squared_error_multioutput_raw_value_squared():","59","    # non-regression test for","60","    # https:\/\/github.com\/scikit-learn\/scikit-learn\/pull\/16323","61","    mse1 = mean_squared_error(","62","        [[1]], [[10]], multioutput=\"raw_values\", squared=True","63","    )","64","    mse2 = mean_squared_error(","65","        [[1]], [[10]], multioutput=\"raw_values\", squared=False","66","    )","67","    assert np.sqrt(mse1) == pytest.approx(mse2)","68","","69",""],"delete":[]}],"sklearn\/metrics\/_regression.py":[{"add":["257","            return output_errors if squared else np.sqrt(output_errors)"],"delete":["257","            return output_errors"]}]}},"d6d624db5d6fea6f1c29952f7de63d1d1d6ae345":{"changes":{"sklearn\/decomposition\/_dict_learning.py":"MODIFY","sklearn\/decomposition\/_factor_analysis.py":"MODIFY","sklearn\/decomposition\/tests\/test_nmf.py":"MODIFY","sklearn\/decomposition\/_lda.py":"MODIFY","sklearn\/decomposition\/_kernel_pca.py":"MODIFY","sklearn\/decomposition\/_pca.py":"MODIFY","sklearn\/decomposition\/_sparse_pca.py":"MODIFY","sklearn\/decomposition\/_fastica.py":"MODIFY","sklearn\/decomposition\/_truncated_svd.py":"MODIFY","sklearn\/decomposition\/_incremental_pca.py":"MODIFY","sklearn\/decomposition\/_nmf.py":"MODIFY"},"diff":{"sklearn\/decomposition\/_dict_learning.py":[{"add":["19","from ..utils.validation import check_is_fitted, _deprecate_positional_args","1015","    @_deprecate_positional_args","1016","    def __init__(self, dictionary, *, transform_algorithm='omp',","1186","    @_deprecate_positional_args","1187","    def __init__(self, n_components=None, *, alpha=1, max_iter=1000, tol=1e-8,","1392","    @_deprecate_positional_args","1393","    def __init__(self, n_components=None, *, alpha=1, n_iter=1000,"],"delete":["19","from ..utils.validation import check_is_fitted","1015","    def __init__(self, dictionary, transform_algorithm='omp',","1185","    def __init__(self, n_components=None, alpha=1, max_iter=1000, tol=1e-8,","1390","    def __init__(self, n_components=None, alpha=1, n_iter=1000,"]}],"sklearn\/decomposition\/_factor_analysis.py":[{"add":["30","from ..utils.validation import check_is_fitted, _deprecate_positional_args","140","    @_deprecate_positional_args","141","    def __init__(self, n_components=None, *, tol=1e-2, copy=True,","142","                 max_iter=1000,"],"delete":["30","from ..utils.validation import check_is_fitted","140","    def __init__(self, n_components=None, tol=1e-2, copy=True, max_iter=1000,"]}],"sklearn\/decomposition\/tests\/test_nmf.py":[{"add":["65","        assert_raise_message(ValueError, msg, NMF(3, init=init).fit, A)"],"delete":["65","        assert_raise_message(ValueError, msg, NMF(3, init).fit, A)"]}],"sklearn\/decomposition\/_lda.py":[{"add":["22","from ..utils.validation import _deprecate_positional_args","283","    @_deprecate_positional_args","284","    def __init__(self, n_components=10, *, doc_topic_prior=None,"],"delete":["282","","283","    def __init__(self, n_components=10, doc_topic_prior=None,"]}],"sklearn\/decomposition\/_kernel_pca.py":[{"add":["16","from ..utils.validation import _deprecate_positional_args","141","    @_deprecate_positional_args","142","    def __init__(self, n_components=None, *, kernel=\"linear\","],"delete":["140","","141","    def __init__(self, n_components=None, kernel=\"linear\","]}],"sklearn\/decomposition\/_pca.py":[{"add":["27","from ..utils.validation import _deprecate_positional_args","327","    @_deprecate_positional_args"],"delete":["326",""]}],"sklearn\/decomposition\/_sparse_pca.py":[{"add":["10","from ..utils.validation import _deprecate_positional_args","134","    @_deprecate_positional_args","135","    def __init__(self, n_components=None, *, alpha=1, ridge_alpha=0.01,","344","    @_deprecate_positional_args","345","    def __init__(self, n_components=None, *, alpha=1, ridge_alpha=0.01,"],"delete":["133","    def __init__(self, n_components=None, alpha=1, ridge_alpha=0.01,","342","    def __init__(self, n_components=None, alpha=1, ridge_alpha=0.01,"]}],"sklearn\/decomposition\/_fastica.py":[{"add":["22","from ..utils.validation import _deprecate_positional_args","393","    @_deprecate_positional_args","394","    def __init__(self, n_components=None, *, algorithm='parallel', whiten=True,"],"delete":["392","    def __init__(self, n_components=None, algorithm='parallel', whiten=True,"]}],"sklearn\/decomposition\/_truncated_svd.py":[{"add":["16","from ..utils.validation import _deprecate_positional_args","17","","120","    @_deprecate_positional_args","121","    def __init__(self, n_components=2, *, algorithm=\"randomized\", n_iter=5,"],"delete":["118","    def __init__(self, n_components=2, algorithm=\"randomized\", n_iter=5,"]}],"sklearn\/decomposition\/_incremental_pca.py":[{"add":["12","from ..utils.validation import _deprecate_positional_args","166","    @_deprecate_positional_args","167","    def __init__(self, n_components=None, *, whiten=False, copy=True,"],"delete":["165","","166","    def __init__(self, n_components=None, whiten=False, copy=True,"]}],"sklearn\/decomposition\/_nmf.py":[{"add":["21","from ..utils.validation import _deprecate_positional_args","1235","    @_deprecate_positional_args","1236","    def __init__(self, n_components=None, *, init=None, solver='cd',"],"delete":["1234","","1235","    def __init__(self, n_components=None, init=None, solver='cd',"]}]}},"7366a5a4cc2a94eca2911a90c3abfe026cd53f64":{"changes":{"sklearn\/metrics\/_classification.py":"MODIFY","sklearn\/metrics\/tests\/test_classification.py":"MODIFY","doc\/whats_new\/v0.23.rst":"MODIFY","sklearn\/metrics\/_plot\/tests\/test_plot_confusion_matrix.py":"MODIFY"},"diff":{"sklearn\/metrics\/_classification.py":[{"add":["278","        n_labels = labels.size","279","        if n_labels == 0:","280","            raise ValueError(\"'labels' should contains at least one label.\")","281","        elif y_true.size == 0:","282","            return np.zeros((n_labels, n_labels), dtype=np.int)","283","        elif np.all([l not in y_true for l in labels]):"],"delete":["278","        if np.all([l not in y_true for l in labels]):"]}],"sklearn\/metrics\/tests\/test_classification.py":[{"add":["910","","911","@pytest.mark.parametrize(","912","    \"labels, err_msg\",","913","    [([], \"'labels' should contains at least one label.\"),","914","     ([3, 4], \"At least one label specified must be in y_true\")],","915","    ids=[\"empty list\", \"unknown labels\"]","916",")","917","def test_confusion_matrix_error(labels, err_msg):","918","    y_true, y_pred, _ = make_prediction(binary=False)","919","    with pytest.raises(ValueError, match=err_msg):","920","        confusion_matrix(y_true, y_pred, labels=labels)","921","","922","","923","@pytest.mark.parametrize(","924","    'labels', (None, [0, 1], [0, 1, 2]),","925","    ids=['None', 'binary', 'multiclass']","926",")","927","def test_confusion_matrix_on_zero_length_input(labels):","928","    expected_n_classes = len(labels) if labels else 0","929","    expected = np.zeros((expected_n_classes, expected_n_classes), dtype=np.int)","930","    cm = confusion_matrix([], [], labels=labels)","931","    assert_array_equal(cm, expected)"],"delete":["910","    # check for exception when none of the specified labels are in y_true","911","    with pytest.raises(ValueError):","912","        confusion_matrix(y_true, y_pred,","913","                         labels=[extra_label, extra_label + 1])"]}],"doc\/whats_new\/v0.23.rst":[{"add":["254","- |Fix| Fixed a bug in :func:`metrics.confusion_matrix` that would raise","255","  an error when `y_true` and `y_pred` were length zero and `labels` was","256","  not `None`. In addition, we raise an error when an empty list is given to","257","  the `labels` parameter.","258","  :pr:`16442` by `Kyle Parsons <parsons-kyle-89>`.","259",""],"delete":[]}],"sklearn\/metrics\/_plot\/tests\/test_plot_confusion_matrix.py":[{"add":[],"delete":["228","","229",""]}]}},"6464e15f61d2fdb904f8595f1971e4b71ddec3fb":{"changes":{"sklearn\/gaussian_process\/kernels.py":"MODIFY"},"diff":{"sklearn\/gaussian_process\/kernels.py":[{"add":["1098","    constant_value_bounds : pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)","1099","        The lower and upper bound on `constant_value`.","1100","        If set to \"fixed\", `constant_value` cannot be changed during","1101","        hyperparameter tuning.","1217","    noise_level_bounds : pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)","1218","        The lower and upper bound on 'noise_level'.","1219","        If set to \"fixed\", 'noise_level' cannot be changed during","1220","        hyperparameter tuning.","1346","    length_scale_bounds : pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)","1347","        The lower and upper bound on 'length_scale'.","1348","        If set to \"fixed\", 'length_scale' cannot be changed during","1349","        hyperparameter tuning.","1504","    length_scale_bounds : pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)","1505","        The lower and upper bound on 'length_scale'.","1506","        If set to \"fixed\", 'length_scale' cannot be changed during","1507","        hyperparameter tuning.","1689","    length_scale_bounds : pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)","1690","        The lower and upper bound on 'length_scale'.","1691","        If set to \"fixed\", 'length_scale' cannot be changed during","1692","        hyperparameter tuning.","1694","    alpha_bounds : pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)","1695","        The lower and upper bound on 'alpha'.","1696","        If set to \"fixed\", 'alpha' cannot be changed during","1697","        hyperparameter tuning.","1832","    length_scale : float > 0, default=1.0","1833","        The length scale of the kernel.","1835","    periodicity : float > 0, default=1.0","1836","        The periodicity of the kernel.","1838","    length_scale_bounds : pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)","1839","        The lower and upper bound on 'length_scale'.","1840","        If set to \"fixed\", 'length_scale' cannot be changed during","1841","        hyperparameter tuning.","1842","","1843","    periodicity_bounds : pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)","1844","        The lower and upper bound on 'periodicity'.","1845","        If set to \"fixed\", 'periodicity' cannot be changed during","1846","        hyperparameter tuning.","1980","    sigma_0_bounds : pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)","1981","        The lower and upper bound on 'sigma_0'.","1982","        If set to \"fixed\", 'sigma_0' cannot be changed during","1983","        hyperparameter tuning.","2121","    gamma_bounds : pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)","2122","        The lower and upper bound on 'gamma'.","2123","        If set to \"fixed\", 'gamma' cannot be changed during","2124","        hyperparameter tuning."],"delete":["1098","    constant_value_bounds : pair of floats >= 0, default=(1e-5, 1e5)","1099","        The lower and upper bound on constant_value","1100","","1216","    noise_level_bounds : pair of floats >= 0, default=(1e-5, 1e5)","1217","        The lower and upper bound on noise_level","1218","","1344","    length_scale_bounds : pair of floats >= 0, default=(1e-5, 1e5)","1345","        The lower and upper bound on length_scale","1500","    length_scale_bounds : pair of floats >= 0, default=(1e-5, 1e5)","1501","        The lower and upper bound on length_scale","1683","    length_scale_bounds : pair of floats >= 0, default=(1e-5, 1e5)","1684","        The lower and upper bound on length_scale","1686","    alpha_bounds : pair of floats >= 0, default=(1e-5, 1e5)","1687","        The lower and upper bound on alpha","1821","    length_scale : float, default=1.0","1822","        The length scale of the kernel. It should be strictly positive.","1824","    periodicity : float, default=1.0","1825","        The periodicity of the kernel. It should be strictly positive.","1827","    length_scale_bounds : pair of floats >= 0, default=(1e-5, 1e5)","1828","        The lower and upper bound on length scale.","1830","    periodicity_bounds : pair of floats >= 0, default=(1e-5, 1e5)","1831","        The lower and upper bound on periodicity.","1965","    sigma_0_bounds : pair of floats >= 0, default=(1e-5, 1e5)","1966","        The lower and upper bound on l.","2104","    gamma_bounds : pair of floats, default=(1e-5, 1e5)","2105","        The lower and upper bound on gamma. They should be positive."]}]}},"ffc7a473fd978e5b2f6f7a2ea65f4a66001f6f2a":{"changes":{"sklearn\/dummy.py":"MODIFY"},"diff":{"sklearn\/dummy.py":[{"add":["15","from .utils.validation import check_is_fitted, _check_sample_weight","147","        if sample_weight is not None:","148","            sample_weight = _check_sample_weight(sample_weight, X)","149","","480","","482","            sample_weight = _check_sample_weight(sample_weight, X)"],"delete":["15","from .utils.validation import check_is_fitted","478","            sample_weight = np.asarray(sample_weight)"]}]}},"beb7afcef408833a31d46d74ddc029b1780f3d30":{"changes":{"sklearn\/cluster\/_dbscan.py":"MODIFY"},"diff":{"sklearn\/cluster\/_dbscan.py":[{"add":["16","from ..utils import check_array","17","from ..utils.validation import _check_sample_weight","315","            sample_weight = _check_sample_weight(sample_weight, X)"],"delete":["16","from ..utils import check_array, check_consistent_length","314","            sample_weight = np.asarray(sample_weight)","315","            check_consistent_length(X, sample_weight)"]}]}},"0c0b6dad69eed6bf42e98ef5c865718ec49bb932":{"changes":{"sklearn\/preprocessing\/_data.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY","sklearn\/preprocessing\/tests\/test_data.py":"MODIFY"},"diff":{"sklearn\/preprocessing\/_data.py":[{"add":["2264","        # Due to floating-point precision error in `np.nanpercentile`,","2265","        # make sure that quantiles are monotonically increasing.","2266","        # Upstream issue in numpy:","2267","        # https:\/\/github.com\/numpy\/numpy\/issues\/14685","2268","        self.quantiles_ = np.maximum.accumulate(self.quantiles_)","2312","        # due to floating-point precision error in `np.nanpercentile`,","2313","        # make sure the quantiles are monotonically increasing","2314","        # Upstream issue in numpy:","2315","        # https:\/\/github.com\/numpy\/numpy\/issues\/14685","2316","        self.quantiles_ = np.maximum.accumulate(self.quantiles_)"],"delete":[]}],"doc\/whats_new\/v0.22.rst":[{"add":["819","- |Fix| :class:`preprocessing.QuantileTransformer` now guarantees the ","820","  `quantiles_` attribute to be completely sorted in non-decreasing manner.","821","  :pr:`15751` by :user:`Tirth Patel <tirthasheshpatel>`.","822",""],"delete":[]}],"sklearn\/preprocessing\/tests\/test_data.py":[{"add":["27","from sklearn.utils._testing import _convert_container","1535","@pytest.mark.parametrize(\"array_type\", ['array', 'sparse'])","1536","def test_quantile_transformer_sorted_quantiles(array_type):","1537","    # Non-regression test for:","1538","    # https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/15733","1539","    # Taken from upstream bug report:","1540","    # https:\/\/github.com\/numpy\/numpy\/issues\/14685","1541","    X = np.array([0, 1, 1, 2, 2, 3, 3, 4, 5, 5, 1, 1, 9, 9, 9, 8, 8, 7] * 10)","1542","    X = 0.1 * X.reshape(-1, 1)","1543","    X = _convert_container(X, array_type)","1544","","1545","    n_quantiles = 100","1546","    qt = QuantileTransformer(n_quantiles=n_quantiles).fit(X)","1547","","1548","    # Check that the estimated quantile threasholds are monotically","1549","    # increasing:","1550","    quantiles = qt.quantiles_[:, 0]","1551","    assert len(quantiles) == 100","1552","    assert all(np.diff(quantiles) >= 0)","1553","","1554",""],"delete":[]}]}},"94f877b55efb55b4cccf8fe03f8d299abca3eb7a":{"changes":{"sklearn\/metrics\/_plot\/confusion_matrix.py":"MODIFY","doc\/whats_new\/v0.23.rst":"MODIFY","sklearn\/metrics\/_plot\/tests\/test_plot_confusion_matrix.py":"MODIFY"},"diff":{"sklearn\/metrics\/_plot\/confusion_matrix.py":[{"add":["63","            the format specification is 'd' or '.2g' whichever is shorter.","92","","95","","96","                if values_format is None:","97","                    text_cm = format(cm[i, j], '.2g')","98","                    if cm.dtype.kind != 'f':","99","                        text_d = format(cm[i, j], 'd')","100","                        if len(text_d) < len(text_cm):","101","                            text_cm = text_d","102","                else:","103","                    text_cm = format(cm[i, j], values_format)","104","","105","                self.text_[i, j] = ax.text(","106","                    j, i, text_cm,","107","                    ha=\"center\", va=\"center\",","108","                    color=color)","174","        the format specification is 'd' or '.2g' whichever is shorter."],"delete":["63","            the format specification is '.2g'.","85","","90","            if values_format is None:","91","                values_format = '.2g'","97","                self.text_[i, j] = ax.text(j, i,","98","                                           format(cm[i, j], values_format),","99","                                           ha=\"center\", va=\"center\",","100","                                           color=color)","166","        the format specification is '.2g'."]}],"doc\/whats_new\/v0.23.rst":[{"add":["264","- |API| Changed the formatting of values in","265","  :meth:`metrics.ConfusionMatrixDisplay.plot` and","266","  :func:`metrics.plot_confusion_matrix` to pick the shorter format (either '2g'","267","  or 'd'). :pr:`16159` by :user:`Rick Mackenbach <Rick-Mackenbach>` and ","268","  `Thomas Fan`_.","269",""],"delete":[]}],"sklearn\/metrics\/_plot\/tests\/test_plot_confusion_matrix.py":[{"add":["23","","265","","266","","267","def test_confusion_matrix_standard_format(pyplot):","268","    cm = np.array([[10000000, 0], [123456, 12345678]])","269","    plotted_text = ConfusionMatrixDisplay(cm, [False, True]).plot().text_","270","    # Values should be shown as whole numbers 'd',","271","    # except the first number which should be shown as 1e+07 (longer length)","272","    # and the last number will be showns as 1.2e+07 (longer length)","273","    test = [t.get_text() for t in plotted_text.ravel()]","274","    assert test == ['1e+07', '0', '123456', '1.2e+07']","275","","276","    cm = np.array([[0.1, 10], [100, 0.525]])","277","    plotted_text = ConfusionMatrixDisplay(cm, [False, True]).plot().text_","278","    # Values should now formatted as '.2g', since there's a float in","279","    # Values are have two dec places max, (e.g 100 becomes 1e+02)","280","    test = [t.get_text() for t in plotted_text.ravel()]","281","    assert test == ['0.1', '10', '1e+02', '0.53']"],"delete":[]}]}},"c809b8d1d083041c260d92ba8a68398801047a80":{"changes":{"sklearn\/cluster\/_affinity_propagation.py":"MODIFY","sklearn\/cluster\/tests\/test_affinity_propagation.py":"MODIFY"},"diff":{"sklearn\/cluster\/_affinity_propagation.py":[{"add":["196","                never_converged = False","201","        never_converged = True","208","    if K > 0 and not never_converged:","412","        X = check_array(X)"],"delete":["206","    if K > 0:"]}],"sklearn\/cluster\/tests\/test_affinity_propagation.py":[{"add":["154","def test_affinity_propagation_non_convergence_regressiontest():","155","    X = np.array([[1, 0, 0, 0, 0, 0],","156","                  [0, 1, 1, 1, 0, 0],","157","                  [0, 0, 1, 0, 0, 1]])","158","    af = AffinityPropagation(affinity='euclidean', max_iter=2).fit(X)","159","    assert_array_equal(np.array([-1, -1, -1]), af.labels_)","160","","161",""],"delete":[]}]}},"e05b9e146006236aa41349105e8a01ac9535fba7":{"changes":{".github\/ISSUE_TEMPLATE\/bug_report.md":"MODIFY"},"diff":{".github\/ISSUE_TEMPLATE\/bug_report.md":[{"add":["9","<!--","12","-->"],"delete":[]}]}},"c311efd501538ceccec0d3def70f601331e090ca":{"changes":{"sklearn\/utils\/tests\/test_utils.py":"MODIFY","sklearn\/utils\/tests\/test_testing.py":"MODIFY","sklearn\/inspection\/tests\/test_plot_partial_dependence.py":"MODIFY","sklearn\/inspection\/_partial_dependence.py":"MODIFY","sklearn\/utils\/_testing.py":"MODIFY"},"diff":{"sklearn\/utils\/tests\/test_utils.py":[{"add":["11","                                    assert_array_equal,","12","                                    assert_allclose_dense_sparse,","13","                                    assert_raises_regex,","14","                                    assert_warns_message,","15","                                    assert_no_warnings,","16","                                    _convert_container)"],"delete":["11","                                   assert_array_equal,","12","                                   assert_allclose_dense_sparse,","13","                                   assert_raises_regex,","14","                                   assert_warns_message, assert_no_warnings)","238","def _convert_container(container, constructor_name, columns_name=None):","239","    if constructor_name == 'list':","240","        return list(container)","241","    elif constructor_name == 'tuple':","242","        return tuple(container)","243","    elif constructor_name == 'array':","244","        return np.asarray(container)","245","    elif constructor_name == 'sparse':","246","        return sp.csr_matrix(container)","247","    elif constructor_name == 'dataframe':","248","        pd = pytest.importorskip('pandas')","249","        return pd.DataFrame(container, columns=columns_name)","250","    elif constructor_name == 'series':","251","        pd = pytest.importorskip('pandas')","252","        return pd.Series(container)","253","    elif constructor_name == 'slice':","254","        return slice(container[0], container[1])","255","","256",""]}],"sklearn\/utils\/tests\/test_testing.py":[{"add":["34","    _delete_folder,","35","    _convert_container)","677","","678","","679","@pytest.mark.parametrize(","680","    \"constructor_name, container_type\",","681","    [('list', list),","682","     ('tuple', tuple),","683","     ('array', np.ndarray),","684","     ('sparse', sparse.csr_matrix),","685","     ('dataframe', pytest.importorskip('pandas').DataFrame),","686","     ('series', pytest.importorskip('pandas').Series),","687","     ('index', pytest.importorskip('pandas').Index),","688","     ('slice', slice)]","689",")","690","def test_convert_container(constructor_name, container_type):","691","    container = [0, 1]","692","    assert isinstance(_convert_container(container, constructor_name),","693","                      container_type)"],"delete":["34","    _delete_folder)"]}],"sklearn\/inspection\/tests\/test_plot_partial_dependence.py":[{"add":["12","from sklearn.utils._testing import _convert_container","13","","90","    \"input_type, feature_names_type\",","91","    [('dataframe', None),","92","     ('dataframe', 'list'), ('list', 'list'), ('array', 'list'),","93","     ('dataframe', 'array'), ('list', 'array'), ('array', 'array'),","94","     ('dataframe', 'series'), ('list', 'series'), ('array', 'series'),","95","     ('dataframe', 'index'), ('list', 'index'), ('array', 'index')]","98","                                              input_type, feature_names_type):","106","","107","    if feature_names_type is None:","108","        feature_names = None","109","    else:","110","        feature_names = _convert_container(boston.feature_names,","111","                                           feature_names_type)"],"delete":["88","    \"input_type, use_feature_names\",","89","    [('dataframe', False), ('dataframe', True),","90","     ('list', True), ('array', True)]","93","                                              input_type, use_feature_names):","101","    feature_names = boston.feature_names if use_feature_names else None"]}],"sklearn\/inspection\/_partial_dependence.py":[{"add":["625","    elif hasattr(feature_names, \"tolist\"):","626","        # convert numpy array or pandas index to a list"],"delete":["625","    elif isinstance(feature_names, np.ndarray):"]}],"sklearn\/utils\/_testing.py":[{"add":["914","","915","","916","def _convert_container(container, constructor_name, columns_name=None):","917","    if constructor_name == 'list':","918","        return list(container)","919","    elif constructor_name == 'tuple':","920","        return tuple(container)","921","    elif constructor_name == 'array':","922","        return np.asarray(container)","923","    elif constructor_name == 'sparse':","924","        return sp.sparse.csr_matrix(container)","925","    elif constructor_name == 'dataframe':","926","        pd = pytest.importorskip('pandas')","927","        return pd.DataFrame(container, columns=columns_name)","928","    elif constructor_name == 'series':","929","        pd = pytest.importorskip('pandas')","930","        return pd.Series(container)","931","    elif constructor_name == 'index':","932","        pd = pytest.importorskip('pandas')","933","        return pd.Index(container)","934","    elif constructor_name == 'slice':","935","        return slice(container[0], container[1])"],"delete":[]}]}},"078e3ef296f29b6a601b075ebd43c2792e8c620f":{"changes":{"build_tools\/azure\/install.cmd":"MODIFY"},"diff":{"build_tools\/azure\/install.cmd":[{"add":["27","    pip install coverage==4.5.3 codecov pytest-cov"],"delete":["27","    pip install coverage codecov pytest-cov"]}]}},"3e4ad0567de5401ec42cc49af68cd07b83f0d716":{"changes":{"doc\/templates\/index.html":"MODIFY"},"diff":{"doc\/templates\/index.html":[{"add":["10","        <a class=\"btn sk-landing-btn mb-1\" href=\"whats_new\/v{{ version }}.html\" role=\"button\">What's New in {{ version }}<\/a>"],"delete":["10","        <a class=\"btn sk-landing-btn mb-1\" href=\"whats_new.html\" role=\"button\">Whats New in {{ version }}<\/a>"]}]}},"77aec1fb8dbacbcdd1b863cdaca27571e301fa29":{"changes":{"sklearn\/feature_extraction\/_dict_vectorizer.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY"},"diff":{"sklearn\/feature_extraction\/_dict_vectorizer.py":[{"add":["156","        indptr = [0]"],"delete":["156","        indptr = array(\"i\", [0])","184","        indptr = np.frombuffer(indptr, dtype=np.intc)"]}],"doc\/whats_new\/v0.22.rst":[{"add":["310","- |Fix| Fixed a bug that caused :class:`feature_extraction.DictVectorizer` to raise","311","  an `OverflowError` during the `transform` operation when producing a `scipy.sparse`","312","  matrix on large input data. :pr:`15463` by :user:`Norvan Sahiner <norvan>`.","313",""],"delete":[]}]}},"b9692a6becca64daeac28c6156e847f2989ce45e":{"changes":{"sklearn\/decomposition\/_kernel_pca.py":"MODIFY","doc\/whats_new\/v0.23.rst":"MODIFY"},"diff":{"sklearn\/decomposition\/_kernel_pca.py":[{"add":["218","                                   np.zeros_like(self.alphas_).T)"],"delete":["218","                                   np.empty_like(self.alphas_).T)"]}],"doc\/whats_new\/v0.23.rst":[{"add":["148","- |Fix| Fixed bug that was causing :class:`decomposition.KernelPCA` to sometimes","149","  raise `invalid value encountered in multiply` during `fit`.","150","  :pr:`16718` by :user:`Gui Miotto <gui-miotto>`.","151",""],"delete":[]}]}},"baa4f0780801a71a92a18b33008207f12fedba0b":{"changes":{"sklearn\/ensemble\/tests\/test_bagging.py":"MODIFY","sklearn\/tree\/_classes.py":"MODIFY","sklearn\/ensemble\/_bagging.py":"MODIFY","doc\/whats_new\/v0.23.rst":"MODIFY"},"diff":{"sklearn\/ensemble\/tests\/test_bagging.py":[{"add":["880","","881","","882","def test_bagging_get_estimators_indices():","883","    # Check that Bagging estimator can generate sample indices properly","884","    # Non-regression test for:","885","    # https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/16436","886","","887","    rng = np.random.RandomState(0)","888","    X = rng.randn(13, 4)","889","    y = np.arange(13)","890","","891","    class MyEstimator(DecisionTreeRegressor):","892","        \"\"\"An estimator which stores y indices information at fit.\"\"\"","893","        def fit(self, X, y):","894","            self._sample_indices = y","895","","896","    clf = BaggingRegressor(base_estimator=MyEstimator(),","897","                           n_estimators=1, random_state=0)","898","    clf.fit(X, y)","899","","900","    assert_array_equal(clf.estimators_[0]._sample_indices,","901","                       clf.estimators_samples_[0])"],"delete":[]}],"sklearn\/tree\/_classes.py":[{"add":["1670","    0.7447..."],"delete":["1670","    0.7788..."]}],"sklearn\/ensemble\/_bagging.py":[{"add":["84","        random_state = seeds[i]","408","                seed, self.bootstrap_features, self.bootstrap,"],"delete":["84","        random_state = np.random.RandomState(seeds[i])","407","            random_state = np.random.RandomState(seed)","409","                random_state, self.bootstrap_features, self.bootstrap,"]}],"doc\/whats_new\/v0.23.rst":[{"add":["25","- :class:`ensemble.BaggingClassifier`, :class:`ensemble.BaggingRegressor`,","26","  and :class:`ensemble.IsolationForest`. |Fix|","143","- |Fix| Fixed a bug in :class:`ensemble.BaggingClassifier`,","144","  :class:`ensemble.BaggingRegressor` and :class:`ensemble.IsolationForest`","145","  where the attribute `estimators_samples_` did not generate the proper indices","146","  used during `fit`.","147","  :pr:`16437` by :user:`Jin-Hwan CHO <chofchof>`.","148",""],"delete":["25","- list models here"]}]}},"5a4340834d23c4bdcd813ccda24a690ae174c168":{"changes":{"sklearn\/__init__.py":"MODIFY","sklearn\/tests\/test_docstring_parameters.py":"MODIFY","sklearn\/utils\/fixes.py":"MODIFY","sklearn\/experimental\/enable_iterative_imputer.py":"MODIFY","sklearn\/covariance\/_graph_lasso.py":"MODIFY","sklearn\/svm\/_classes.py":"MODIFY","doc\/developers\/contributing.rst":"MODIFY","sklearn\/manifold\/_t_sne.py":"MODIFY","sklearn\/externals\/_arff.py":"MODIFY","sklearn\/svm\/_base.py":"MODIFY","sklearn\/impute\/__init__.py":"MODIFY","sklearn\/svm\/tests\/test_svm.py":"MODIFY","sklearn\/manifold\/_isomap.py":"MODIFY","sklearn\/linear_model\/_least_angle.py":"MODIFY","sklearn\/linear_model\/_coordinate_descent.py":"MODIFY","azure-pipelines.yml":"MODIFY","sklearn\/_build_utils\/deprecated_modules.py":"MODIFY","sklearn\/manifold\/tests\/test_t_sne.py":"MODIFY","sklearn\/ensemble\/tests\/test_forest.py":"MODIFY","sklearn\/ensemble\/__init__.py":"MODIFY","sklearn\/linear_model\/_stochastic_gradient.py":"MODIFY","sklearn\/model_selection\/_split.py":"MODIFY","sklearn\/utils\/metaestimators.py":"MODIFY","doc\/developers\/maintainer.rst":"MODIFY","sklearn\/utils\/_pprint.py":"MODIFY","sklearn\/tests\/test_random_projection.py":"MODIFY","sklearn\/experimental\/enable_hist_gradient_boosting.py":"MODIFY","sklearn\/ensemble\/_base.py":"MODIFY","sklearn\/dummy.py":"MODIFY"},"diff":{"sklearn\/__init__.py":[{"add":["62","    # mypy error: Cannot determine type of '__SKLEARN_SETUP__'","63","    __SKLEARN_SETUP__  # type: ignore"],"delete":["62","    __SKLEARN_SETUP__"]}],"sklearn\/tests\/test_docstring_parameters.py":[{"add":["34","        pckg[1] for pckg in walk_packages(","35","            prefix='sklearn.',","36","            # mypy error: Module has no attribute \"__path__\"","37","            path=sklearn.__path__)  # type: ignore  # mypy issue #1422"],"delete":["34","        pckg[1] for pckg in walk_packages(prefix='sklearn.',","35","                                          path=sklearn.__path__)"]}],"sklearn\/utils\/fixes.py":[{"add":["41","    # mypy error: Name 'lobpcg' already defined (possibly by an import)","42","    from ..externals._lobpcg import lobpcg  # type: ignore  # noqa","49","    # mypy error: Name 'pinvh' already defined (possibly by an import)","50","    from scipy.linalg import pinvh  # type: ignore  # noqa"],"delete":["41","    from ..externals._lobpcg import lobpcg  # noqa","48","    from scipy.linalg import pinvh # noqa"]}],"sklearn\/experimental\/enable_iterative_imputer.py":[{"add":["17","# use settattr to avoid mypy errors when monkeypatching","18","setattr(impute, 'IterativeImputer', IterativeImputer)"],"delete":["17","impute.IterativeImputer = IterativeImputer"]}],"sklearn\/covariance\/_graph_lasso.py":[{"add":["22","# mypy error: Module 'sklearn.linear_model' has no attribute '_cd_fast'","23","from ..linear_model import _cd_fast as cd_fast  # type: ignore"],"delete":["22","from ..linear_model import _cd_fast as cd_fast"]}],"sklearn\/svm\/_classes.py":[{"add":["972","    # mypy error: Decorated property not supported","973","    @deprecated(  # type: ignore","980","    # mypy error: Decorated property not supported","981","    @deprecated(  # type: ignore","1308","    # mypy error: Decorated property not supported","1309","    @deprecated(  # type: ignore","1316","    # mypy error: Decorated property not supported","1317","    @deprecated(  # type: ignore"],"delete":["972","    @deprecated(","979","    @deprecated(","1306","    @deprecated(","1313","    @deprecated("]}],"doc\/developers\/contributing.rst":[{"add":["217","       $ pip install cython pytest pytest-cov flake8 mypy","370","","416","* A moderate use of type annotations is encouraged but is not mandatory. See","417","  [mypy quickstart](https:\/\/mypy.readthedocs.io\/en\/latest\/getting_started.html)","418","  for an introduction, as well as [pandas contributing documentation](","419","  https:\/\/pandas.pydata.org\/pandas-docs\/stable\/development\/contributing.html#type-hints)","420","  for style guidelines. Whether you add type annotation or not::","421","","422","    mypy --ignore-missing-import sklearn","423","","424","  must not produce new errors in your pull request. Using `# type: ignore` annotation can be a workaround for a few cases that are not supported by mypy, in particular,","425","   - when importing C or Cython modules","426","   - on properties with decorators","427",""],"delete":["217","       $ pip install cython pytest pytest-cov flake8"]}],"sklearn\/manifold\/_t_sne.py":[{"add":["24","# mypy error: Module 'sklearn.manifold' has no attribute '_barnes_hut_tsne'","25","from . import _barnes_hut_tsne  # type: ignore"],"delete":["24","from . import _barnes_hut_tsne"]}],"sklearn\/externals\/_arff.py":[{"add":["150","from typing import Optional","151","","322","    message : Optional[str] = None"],"delete":["320","    message = None"]}],"sklearn\/svm\/_base.py":[{"add":["5","# mypy error: error: Module 'sklearn.svm' has no attribute '_libsvm'","6","# (and same for other imports)","7","from . import _libsvm as libsvm  # type: ignore","8","from .import _liblinear as liblinear  # type: ignore","9","from . import _libsvm_sparse as libsvm_sparse  # type: ignore"],"delete":["5","from . import _libsvm as libsvm","6","from .import _liblinear as liblinear","7","from . import _libsvm_sparse as libsvm_sparse"]}],"sklearn\/impute\/__init__.py":[{"add":["1","import typing","6","if typing.TYPE_CHECKING:","7","    # Avoid errors in type checkers (e.g. mypy) for experimental estimators.","8","    # TODO: remove this check once the estimator is no longer experimental.","9","    from ._iterative import IterativeImputer  # noqa","10",""],"delete":[]}],"sklearn\/svm\/tests\/test_svm.py":[{"add":["30","# mypy error: Module 'sklearn.svm' has no attribute '_libsvm'","31","from sklearn.svm import _libsvm  # type: ignore"],"delete":["30","from sklearn.svm import _libsvm"]}],"sklearn\/manifold\/_isomap.py":[{"add":["169","    # mypy error: Decorated property not supported","170","    @deprecated(  # type: ignore","171","        \"Attribute `training_data_` was deprecated in version 0.22 and\"","172","        \" will be removed in 0.24.\"","173","    )"],"delete":["169","    @deprecated(\"Attribute `training_data_` was deprecated in version 0.22 and\"","170","                \" will be removed in 0.24.\")"]}],"sklearn\/linear_model\/_least_angle.py":[{"add":["21","# mypy error: Module 'sklearn.utils' has no attribute 'arrayfuncs'","22","from ..utils import arrayfuncs, as_float_array  # type: ignore"],"delete":["21","from ..utils import arrayfuncs, as_float_array"]}],"sklearn\/linear_model\/_coordinate_descent.py":[{"add":["27","# mypy error: Module 'sklearn.linear_model' has no attribute '_cd_fast'","28","from . import _cd_fast as cd_fast  # type: ignore"],"delete":["27","from . import _cd_fast as cd_fast"]}],"azure-pipelines.yml":[{"add":["19","    - bash: |","20","        conda create --name flake8_env --yes python=3.8","21","        conda activate flake8_env","22","        pip install flake8 mypy==0.770","30","          conda activate flake8_env","35","        if [[ $BUILD_SOURCEVERSIONMESSAGE =~ \\[lint\\ skip\\] ]]; then","36","          # skip linting","37","          echo \"Skipping linting\"","38","          exit 0","39","        else","40","          conda activate flake8_env","41","          mypy sklearn\/ --ignore-missing-imports","42","        fi","43","      displayName: Run mypy","44","    - bash: |"],"delete":["19","    - bash: conda create --name flake8_env --yes flake8","27","          source activate flake8_env"]}],"sklearn\/_build_utils\/deprecated_modules.py":[{"add":["273","# mypy error: Module X has no attribute y (typically for C extensions)","274","from . import {new_module_name}  # type: ignore"],"delete":["273","from . import {new_module_name}"]}],"sklearn\/manifold\/tests\/test_t_sne.py":[{"add":["23","# mypy error: Module 'sklearn.manifold' has no attribute '_barnes_hut_tsne'","24","from sklearn.manifold import _barnes_hut_tsne  # type: ignore"],"delete":["23","from sklearn.manifold import _barnes_hut_tsne"]}],"sklearn\/ensemble\/tests\/test_forest.py":[{"add":["17","from typing import Dict, Any","103","FOREST_ESTIMATORS: Dict[str, Any] = dict()","108","FOREST_CLASSIFIERS_REGRESSORS: Dict[str, Any] = FOREST_CLASSIFIERS.copy()","1262","# mypy error: Variable \"DEFAULT_JOBLIB_BACKEND\" is not valid type","1263","class MyBackend(DEFAULT_JOBLIB_BACKEND):  # type: ignore"],"delete":["102","FOREST_ESTIMATORS = dict()","107","FOREST_CLASSIFIERS_REGRESSORS = FOREST_CLASSIFIERS.copy()","1261","class MyBackend(DEFAULT_JOBLIB_BACKEND):"]}],"sklearn\/ensemble\/__init__.py":[{"add":["4","import typing","24","if typing.TYPE_CHECKING:","25","    # Avoid errors in type checkers (e.g. mypy) for experimental estimators.","26","    # TODO: remove this check once the estimator is no longer experimental.","27","    from ._hist_gradient_boosting.gradient_boosting import (  # noqa","28","        HistGradientBoostingRegressor, HistGradientBoostingClassifier","29","    )"],"delete":[]}],"sklearn\/linear_model\/_stochastic_gradient.py":[{"add":["289","    # mypy error: Decorated property not supported","290","    @deprecated(\"Attribute standard_coef_ was deprecated \"  # type: ignore","296","    # mypy error: Decorated property not supported","297","    @deprecated(  # type: ignore","298","        \"Attribute standard_intercept_ was deprecated \"","299","        \"in version 0.23 and will be removed in 0.25.\"","300","    )","305","    # mypy error: Decorated property not supported","306","    @deprecated(\"Attribute average_coef_ was deprecated \"  # type: ignore","312","    # mypy error: Decorated property not supported","313","    @deprecated(\"Attribute average_intercept_ was deprecated \"  # type: ignore"],"delete":["289","    @deprecated(\"Attribute standard_coef_ was deprecated \"","295","    @deprecated(\"Attribute standard_intercept_ was deprecated \"","296","                \"in version 0.23 and will be removed in 0.25.\")","301","    @deprecated(\"Attribute average_coef_ was deprecated \"","307","    @deprecated(\"Attribute average_intercept_ was deprecated \""]}],"sklearn\/model_selection\/_split.py":[{"add":["2146","# Use setattr to avoid mypy errors when monkeypatching.","2147","setattr(train_test_split, '__test__', False)"],"delete":["2146","train_test_split.__test__ = False"]}],"sklearn\/utils\/metaestimators.py":[{"add":["4","from typing import List, Any","20","    steps: List[Any]","21",""],"delete":[]}],"doc\/developers\/maintainer.rst":[{"add":["291","To avoid type checker (e.g. mypy) errors a direct import of experimenal","292","estimators should be done in the parent module, protected by the","293","``if typing.TYPE_CHECKING`` check. See `sklearn\/ensemble\/__init__.py","294","<https:\/\/github.com\/scikit-learn\/scikit-learn\/blob\/master\/sklearn\/ensemble\/__init__.py>`_,","295","or `sklearn\/impute\/__init__.py","296","<https:\/\/github.com\/scikit-learn\/scikit-learn\/blob\/master\/sklearn\/impute\/__init__.py>`_","297","for an example.","298",""],"delete":[]}],"sklearn\/utils\/_pprint.py":[{"add":["326","    # mypy error: \"Type[PrettyPrinter]\" has no attribute \"_dispatch\"","327","    _dispatch = pprint.PrettyPrinter._dispatch.copy()  # type: ignore"],"delete":["326","    _dispatch = pprint.PrettyPrinter._dispatch.copy()"]}],"sklearn\/tests\/test_random_projection.py":[{"add":["2","from typing import List, Any","26","all_sparse_random_matrix: List[Any] = [_sparse_random_matrix]","27","all_dense_random_matrix: List[Any] = [_gaussian_random_matrix]","30","all_SparseRandomProjection: List[Any] = [SparseRandomProjection]","31","all_DenseRandomProjection: List[Any] = [GaussianRandomProjection]"],"delete":["25","all_sparse_random_matrix = [_sparse_random_matrix]","26","all_dense_random_matrix = [_gaussian_random_matrix]","29","all_SparseRandomProjection = [SparseRandomProjection]","30","all_DenseRandomProjection = [GaussianRandomProjection]"]}],"sklearn\/experimental\/enable_hist_gradient_boosting.py":[{"add":["28","# use settattr to avoid mypy errors when monkeypatching","29","setattr(ensemble, \"HistGradientBoostingClassifier\",","30","        HistGradientBoostingClassifier)","31","setattr(ensemble, \"HistGradientBoostingRegressor\",","32","        HistGradientBoostingRegressor)","33",""],"delete":["28","ensemble.HistGradientBoostingClassifier = HistGradientBoostingClassifier","29","ensemble.HistGradientBoostingRegressor = HistGradientBoostingRegressor"]}],"sklearn\/ensemble\/_base.py":[{"add":["8","from typing import List","109","    _required_parameters: List[str] = []"],"delete":["108","    _required_parameters = []"]}],"sklearn\/dummy.py":[{"add":["397","    # mypy error: Decorated property not supported","398","    @deprecated(  # type: ignore","625","    # mypy error: Decorated property not supported","626","    @deprecated(  # type: ignore"],"delete":["397","    @deprecated(","624","    @deprecated("]}]}},"1ba06518c5c4c7c1865110a8f34c4da64d8e478f":{"changes":{"sklearn\/datasets\/_openml.py":"MODIFY","sklearn\/datasets\/_svmlight_format_io.py":"MODIFY","sklearn\/datasets\/_rcv1.py":"MODIFY","sklearn\/datasets\/_base.py":"MODIFY","sklearn\/datasets\/_california_housing.py":"MODIFY","sklearn\/datasets\/_species_distributions.py":"MODIFY","sklearn\/datasets\/_covtype.py":"MODIFY","sklearn\/datasets\/_lfw.py":"MODIFY","sklearn\/linear_model\/tests\/test_omp.py":"MODIFY","sklearn\/datasets\/_samples_generator.py":"MODIFY","sklearn\/datasets\/_olivetti_faces.py":"MODIFY","sklearn\/datasets\/_kddcup99.py":"MODIFY","sklearn\/datasets\/_twenty_newsgroups.py":"MODIFY","sklearn\/datasets\/tests\/test_base.py":"MODIFY"},"diff":{"sklearn\/datasets\/_openml.py":[{"add":["25","from ..utils.validation import _deprecate_positional_args","611","@_deprecate_positional_args","612","def fetch_openml(name=None, *, version='active', data_id=None, data_home=None,"],"delete":["610","def fetch_openml(name=None, version='active', data_id=None, data_home=None,"]}],"sklearn\/datasets\/_svmlight_format_io.py":[{"add":["27","from ..utils.validation import _deprecate_positional_args","40","@_deprecate_positional_args","41","def load_svmlight_file(f, *, n_features=None, dtype=np.float64,","155","    return tuple(load_svmlight_files([f], n_features=n_features,","156","                                     dtype=dtype,","157","                                     multilabel=multilabel,","158","                                     zero_based=zero_based,","159","                                     query_id=query_id,","160","                                     offset=offset,","161","                                     length=length))","205","@_deprecate_positional_args","206","def load_svmlight_files(files, *, n_features=None, dtype=np.float64,","390","@_deprecate_positional_args","391","def dump_svmlight_file(X, y, f, *, zero_based=True, comment=None,","392","                       query_id=None,"],"delete":["39","def load_svmlight_file(f, n_features=None, dtype=np.float64,","153","    return tuple(load_svmlight_files([f], n_features, dtype, multilabel,","154","                                     zero_based, query_id, offset, length))","198","def load_svmlight_files(files, n_features=None, dtype=np.float64,","382","def dump_svmlight_file(X, y, f,  zero_based=True, comment=None, query_id=None,"]}],"sklearn\/datasets\/_rcv1.py":[{"add":["27","from ..utils.validation import _deprecate_positional_args","78","@_deprecate_positional_args","79","def fetch_rcv1(*, data_home=None, subset='all', download_if_missing=True,"],"delete":["77","def fetch_rcv1(data_home=None, subset='all', download_if_missing=True,"]}],"sklearn\/datasets\/_base.py":[{"add":["19","from ..utils.validation import _deprecate_positional_args","83","@_deprecate_positional_args","84","def load_files(container_path, *, description=None, categories=None,","271","@_deprecate_positional_args","272","def load_wine(*, return_X_y=False, as_frame=False):","386","@_deprecate_positional_args","387","def load_iris(*, return_X_y=False, as_frame=False):","501","@_deprecate_positional_args","502","def load_breast_cancer(*, return_X_y=False, as_frame=False):","626","@_deprecate_positional_args","627","def load_digits(*, n_class=10, return_X_y=False, as_frame=False):","750","@_deprecate_positional_args","751","def load_diabetes(*, return_X_y=False, as_frame=False):","843","@_deprecate_positional_args","844","def load_linnerud(*, return_X_y=False, as_frame=False):","947","@_deprecate_positional_args","948","def load_boston(*, return_X_y=False):"],"delete":["82","def load_files(container_path, description=None, categories=None,","269","def load_wine(return_X_y=False, as_frame=False):","383","def load_iris(return_X_y=False, as_frame=False):","497","def load_breast_cancer(return_X_y=False, as_frame=False):","621","def load_digits(n_class=10, return_X_y=False, as_frame=False):","744","def load_diabetes(return_X_y=False, as_frame=False):","836","def load_linnerud(return_X_y=False, as_frame=False):","939","def load_boston(return_X_y=False):"]}],"sklearn\/datasets\/_california_housing.py":[{"add":["38","from ..utils.validation import _deprecate_positional_args","39","","52","@_deprecate_positional_args","53","def fetch_california_housing(*, data_home=None, download_if_missing=True,"],"delete":["50","def fetch_california_housing(data_home=None, download_if_missing=True,"]}],"sklearn\/datasets\/_species_distributions.py":[{"add":["52","from ..utils.validation import _deprecate_positional_args","140","@_deprecate_positional_args","141","def fetch_species_distributions(*, data_home=None,"],"delete":["139","def fetch_species_distributions(data_home=None,"]}],"sklearn\/datasets\/_covtype.py":[{"add":["30","from ..utils.validation import _deprecate_positional_args","31","","44","@_deprecate_positional_args","45","def fetch_covtype(*, data_home=None, download_if_missing=True,"],"delete":["42","def fetch_covtype(data_home=None, download_if_missing=True,"]}],"sklearn\/datasets\/_lfw.py":[{"add":["22","from ..utils.validation import _deprecate_positional_args","218","@_deprecate_positional_args","219","def fetch_lfw_people(*, data_home=None, funneled=True, resize=0.5,","389","@_deprecate_positional_args","390","def fetch_lfw_pairs(*, subset='train', data_home=None, funneled=True,","391","                    resize=0.5,"],"delete":["217","def fetch_lfw_people(data_home=None, funneled=True, resize=0.5,","387","def fetch_lfw_pairs(subset='train', data_home=None, funneled=True, resize=0.5,"]}],"sklearn\/linear_model\/tests\/test_omp.py":[{"add":["20","y, X, gamma = make_sparse_coded_signal(n_samples=n_targets,","21","                                       n_components=n_features,","22","                                       n_features=n_samples,","23","                                       n_nonzero_coefs=n_nonzero_coefs,","24","                                       random_state=0)"],"delete":["20","y, X, gamma = make_sparse_coded_signal(n_targets, n_features, n_samples,","21","                                       n_nonzero_coefs, random_state=0)"]}],"sklearn\/datasets\/_samples_generator.py":[{"add":["20","from ..utils.validation import _deprecate_positional_args","36","@_deprecate_positional_args","37","def make_classification(n_samples=100, n_features=20, *, n_informative=2,","265","@_deprecate_positional_args","266","def make_multilabel_classification(n_samples=100, n_features=20, *,","267","                                   n_classes=5,","428","@_deprecate_positional_args","429","def make_hastie_10_2(n_samples=12000, *, random_state=None):","477","@_deprecate_positional_args","478","def make_regression(n_samples=100, n_features=100, *, n_informative=10,","600","@_deprecate_positional_args","601","def make_circles(n_samples=100, *, shuffle=True, noise=None, random_state=None,","677","@_deprecate_positional_args","678","def make_moons(n_samples=100, *, shuffle=True, noise=None, random_state=None):","741","@_deprecate_positional_args","742","def make_blobs(n_samples=100, n_features=2, *, centers=None, cluster_std=1.0,","900","@_deprecate_positional_args","901","def make_friedman1(n_samples=100, n_features=10, *, noise=0.0,","902","                   random_state=None):","964","@_deprecate_positional_args","965","def make_friedman2(n_samples=100, *, noise=0.0, random_state=None):","1030","@_deprecate_positional_args","1031","def make_friedman3(n_samples=100, *, noise=0.0, random_state=None):","1095","@_deprecate_positional_args","1096","def make_low_rank_matrix(n_samples=100, n_features=100, *, effective_rank=10,","1165","@_deprecate_positional_args","1166","def make_sparse_coded_signal(n_samples, *, n_components, n_features,","1228","@_deprecate_positional_args","1229","def make_sparse_uncorrelated(n_samples=100, n_features=10, *,","1230","                             random_state=None):","1281","@_deprecate_positional_args","1282","def make_spd_matrix(n_dim, *, random_state=None):","1315","@_deprecate_positional_args","1316","def make_sparse_spd_matrix(dim=1, *, alpha=0.95, norm_diag=False,","1390","@_deprecate_positional_args","1391","def make_swiss_roll(n_samples=100, *, noise=0.0, random_state=None):","1443","@_deprecate_positional_args","1444","def make_s_curve(n_samples=100, *, noise=0.0, random_state=None):","1486","@_deprecate_positional_args","1487","def make_gaussian_quantiles(*, mean=None, cov=1., n_samples=100,","1582","@_deprecate_positional_args","1583","def make_biclusters(shape, n_clusters, *, noise=0.0, minval=10,","1674","@_deprecate_positional_args","1675","def make_checkerboard(shape, n_clusters, *, noise=0.0, minval=10,"],"delete":["35","def make_classification(n_samples=100, n_features=20, n_informative=2,","263","def make_multilabel_classification(n_samples=100, n_features=20, n_classes=5,","424","def make_hastie_10_2(n_samples=12000, random_state=None):","472","def make_regression(n_samples=100, n_features=100, n_informative=10,","594","def make_circles(n_samples=100, shuffle=True, noise=None, random_state=None,","670","def make_moons(n_samples=100, shuffle=True, noise=None, random_state=None):","733","def make_blobs(n_samples=100, n_features=2, centers=None, cluster_std=1.0,","891","def make_friedman1(n_samples=100, n_features=10, noise=0.0, random_state=None):","953","def make_friedman2(n_samples=100, noise=0.0, random_state=None):","1018","def make_friedman3(n_samples=100, noise=0.0, random_state=None):","1082","def make_low_rank_matrix(n_samples=100, n_features=100, effective_rank=10,","1151","def make_sparse_coded_signal(n_samples, n_components, n_features,","1213","def make_sparse_uncorrelated(n_samples=100, n_features=10, random_state=None):","1264","def make_spd_matrix(n_dim, random_state=None):","1297","def make_sparse_spd_matrix(dim=1, alpha=0.95, norm_diag=False,","1371","def make_swiss_roll(n_samples=100, noise=0.0, random_state=None):","1423","def make_s_curve(n_samples=100, noise=0.0, random_state=None):","1465","def make_gaussian_quantiles(mean=None, cov=1., n_samples=100,","1560","def make_biclusters(shape, n_clusters, noise=0.0, minval=10,","1651","def make_checkerboard(shape, n_clusters, noise=0.0, minval=10,"]}],"sklearn\/datasets\/_olivetti_faces.py":[{"add":["27","from ..utils.validation import _deprecate_positional_args","38","@_deprecate_positional_args","39","def fetch_olivetti_faces(*, data_home=None, shuffle=False, random_state=0,"],"delete":["37","def fetch_olivetti_faces(data_home=None, shuffle=False, random_state=0,"]}],"sklearn\/datasets\/_kddcup99.py":[{"add":["25","from ..utils.validation import _deprecate_positional_args","26","","47","@_deprecate_positional_args","48","def fetch_kddcup99(*, subset=None, data_home=None, shuffle=False,"],"delete":["45","def fetch_kddcup99(subset=None, data_home=None, shuffle=False,"]}],"sklearn\/datasets\/_twenty_newsgroups.py":[{"add":["47","from ..utils.validation import _deprecate_positional_args","149","@_deprecate_positional_args","150","def fetch_20newsgroups(*, data_home=None, subset='train', categories=None,","326","@_deprecate_positional_args","327","def fetch_20newsgroups_vectorized(*, subset=\"train\", remove=(), data_home=None,"],"delete":["148","def fetch_20newsgroups(data_home=None, subset='train', categories=None,","324","def fetch_20newsgroups_vectorized(subset=\"train\", remove=(), data_home=None,"]}],"sklearn\/datasets\/tests\/test_base.py":[{"add":["154","    digits = load_digits(n_class=9)"],"delete":["154","    digits = load_digits(9)"]}]}},"1382831f4158f358701a00c6ad216d7814c5716f":{"changes":{"doc\/developers\/maintainer.rst":"MODIFY"},"diff":{"doc\/developers\/maintainer.rst":[{"add":["3","","4","Releasing","5","---------","6","","7","This section is about preparing a major release, incrementing the minor","8","version, or a bug fix release incrementing the patch version. Our convention is","9","that we release one or more release candidates (0.RRrcN) before releasing the","10","final distributions. We follow the `PEP101","11","<https:\/\/www.python.org\/dev\/peps\/pep-0101\/>`_ to indicate release candidates,","12","post, and minor releases.","13","","15","................","21","   and commit. This is only needed if the authors have changed since the last","22","   release. This step is sometimes done independent of the release. This","23","   updates the maintainer list and is not the contributor list for the release.","32","     sections. It's not perfect, and requires manual checking of the changes.","33","     If the whats new list is well curated, it may not be necessary.","38","4. Make sure the deprecations, FIXME and TODOs tagged for the release have","39","   been taken care of.","41","**Permissions**","43","The release manager requires a set of permissions on top of the usual","44","permissions given to maintainers, which includes:","46","- *maintainer* role on ``scikit-learn`` projects on ``pypi.org`` and","47","  ``test.pypi.org``, separately.","48","- become a member of the *scikit-learn* team on conda-forge by editing the ","49","  ``recipe\/meta.yaml`` file on ","50","  ``https:\/\/github.com\/conda-forge\/scikit-learn-feedstock``","51","- *maintainer* on ``https:\/\/github.com\/MacPython\/scikit-learn-wheels``","52","","53","","54",".. _preparing_a_release_pr:","55","","56","Preparing a release PR","57","......................","58","","59","Releasing the first RC of e.g. version `0.99` involves creating the release","60","branch `0.99.X` directly on the main repo, where `X` really is the letter X,","61","**not a placeholder**. This is considered the *feature freeze*. The","62","development for the major and minor releases of 0.99 should","63","**also** happen under `0.99.X`. Each release (rc, major, or minor) is a tag","64","under that branch.","65","","66","In terms of including changes, the first RC ideally counts as a *feature","67","freeze*. Each coming release candidate and the final release afterwards will","68","include minor documentation changes and bug fixes. Any major enhancement or","69","feature should be excluded.","70","","71","The minor releases should include bug fixes and some relevant documentation","72","changes only. Any PR resulting in a behavior change which is not a bug fix","73","should be excluded.","74","","75","First, create a branch, **on your own fork** (to release e.g. `0.999.3`)::","76","","77","    $ # assuming master and upstream\/master are the same","80","Then, create a PR **to the** `scikit-learn\/0.999.X` **branch** (not to","81","master!) with all the desired changes::","82","","83","\t$ git rebase -i upstream\/0.999.2","84","","85","It's nice to have a copy of the ``git rebase -i`` log in the PR to help others","86","understand what's included.","89","................","91","0. Create the release branch on the main repo, if it does not exist. This is","92","   done only once, as the major and minor releases happen on the same branch::","93","","94","     $ git checkout -b 0.99.X","95","","96","   Again, `X` is literal here, and `99` is replaced by the release number.","97","   The branches are called ``0.19.X``, ``0.20.X``, etc.","98","","99","1. Update docs. Note that this is for the final release, not necessarily for","100","   the RC releases. These changes should be made in master and cherry-picked","101","   into the release branch, only before the final release.","108","   - Update the release date in ``whats_new.rst``","110","   - Edit the doc\/templates\/index.html to change the 'News' entry of the front","111","     page.","114","   `sklearn\/__init__.py`, the ``__version__`` variable by removing ``dev*``","115","   only when ready to release. On master, increment the version in the same","116","   place (when branching for release). This means while we're in the release","117","   candidate period, the latest stable is two versions behind the master","118","   branch, instead of one.","120","3. At this point all relevant PRs should have been merged into the `0.99.X`","121","   branch. Create the source tarball:","131","   - You can also test a binary dist build using::","132","","133","       $ python setup.py bdist_wheel","134","","135","   - You can test if PyPi is going to accept the package using::","136","","137","       $ twine check dist\/*","138","","139","   You can run ``twine check`` after step 5 (fetching artifacts) as well.","140","","145","4. Proceed with caution. Ideally, tags should be created when you're almost","146","   certain that the release is ready, since adding a tag to the main repo can","147","   trigger certain automated processes. You can test upload the ``sdist`` to","148","   ``test.pypi.org``, and test the next step by setting ``BUILD_COMMIT`` to the","149","   branch name (``0.99.X`` for instance) in a PR to the wheel building repo.","150","   Once all works, you can proceed with tagging. Create the tag and push it (if","151","   it's an RC, it can be ``0.xxrc1`` for instance)::","152","","153","    $ git tag -a 0.99  # in the 0.99.X branch","154","","155","    $ git push git@github.com:scikit-learn\/scikit-learn.git 0.99","156","","166","       $ rm -r dist # only if there's anything other than the sdist tar.gz there","171","   along with the source tarball (\"scikit-learn-RRR.tar.gz\").","176","   Before uploading to pypi, you can test upload to test.pypi.org::","177","","178","       $ twine upload --verbose --repository-url https:\/\/test.pypi.org\/legacy\/ dist\/*","179","","195","       $ sed -i \"s\/latestStable = '.*\/latestStable = '0.999';\/\" versionwarning.js","196","       $ git add stable\/ versionwarning.js","197","       $ git commit -m \"Update stable to point to 0.999\"","204","    * [ ] update dependencies and release tag at","205","      https:\/\/github.com\/MacPython\/scikit-learn-wheels","208","    * [ ] confirm bot detected at","209","      https:\/\/github.com\/conda-forge\/scikit-learn-feedstock and wait for merge","211","    * [ ] fix the binder release version in ``.binder\/requirement.txt`` (see","212","      #15847)","213","    * [ ] announce on mailing list and on twitter"],"delete":["4","----------------","10","   and commit.","19","     sections.","24","Preparing a bug-fix-release","25","...........................","27","Since any commits to a released branch (e.g. 0.999.X) will automatically update","28","the web site documentation, it is best to develop a bug-fix release with a pull","29","request in which 0.999.X is the base. It also allows you to keep track of any","30","tasks towards release with a TO DO list.","32","Most development of the bug fix release, and its documentation, should","33","happen in master to avoid asynchrony. To select commits from master for use in","34","the bug fix (version 0.999.3), you can use::","37","    $ git rebase -i 0.999.X","39","Then pick the commits for release and resolve any issues, and create a pull","40","request with 0.999.X as base. Add a commit updating ``sklearn.__version__``.","41","Additional commits can be cherry-picked into the ``release-0.999.3`` branch","42","while preparing the release.","45","----------------","47","1. Update docs:","54","   - Update the release date in whats_new.rst","56","   - Edit the doc\/index.rst to change the 'News' entry of the front page.","57","","58","   - Note that these changes should be made in master and cherry-picked into","59","     the release branch.","62","   sklearn\/__init__.py, the ``__version__`` variable by removing ``dev*`` only","63","   when ready to release.","64","   On master, increment the version in the same place (when branching for","65","   release).","67","3. Create the tag and push it::","68","","69","    $ git tag -a 0.999","70","","71","    $ git push git@github.com:scikit-learn\/scikit-learn.git --tags","72","","73","4. Create the source tarball:","96","       $ rm -r dist","101","   along with the source tarball (\"scikit-learn-XXX.tar.gz\").","121","       $ sed -i \"s\/latestStable = '.*\/latestStable = '0.999';\" versionwarning.js","122","       $ git commit -m \"Update stable to point to 0.999\" stable","129","    * [ ] update dependencies and release tag at https:\/\/github.com\/MacPython\/scikit-learn-wheels","132","    * [ ] confirm bot detected at https:\/\/github.com\/conda-forge\/scikit-learn-feedstock and wait for merge","134","    * [ ] announce on mailing list","135","    * [ ] (regenerate Dash docs: https:\/\/github.com\/Kapeli\/Dash-User-Contributions\/tree\/master\/docsets\/Scikit)"]}]}},"45bc7d98b883d3c6163344996362125497a1476b":{"changes":{"examples\/inspection\/plot_linear_model_coefficient_interpretation.py":"MODIFY"},"diff":{"examples\/inspection\/plot_linear_model_coefficient_interpretation.py":[{"add":["65","# Wages are described as floating-point number in dollars per hour."],"delete":["65","# Wages are described as floating-point number in :math:`k$`"]}]}},"32e9911c9987bc810cf4b326de5995e2c50aefc4":{"changes":{"doc\/modules\/classes.rst":"MODIFY","sklearn\/semi_supervised\/_label_propagation.py":"MODIFY"},"diff":{"doc\/modules\/classes.rst":[{"add":[],"delete":["1482","Low-level methods","1483","-----------------","1484","","1485",".. autosummary::","1486","   :toctree: generated","1487","   :template: function.rst","1488","","1489","   svm.libsvm.cross_validation","1490","   svm.libsvm.decision_function","1491","   svm.libsvm.fit","1492","   svm.libsvm.predict","1493","   svm.libsvm.predict_proba","1494","","1495",""]}],"sklearn\/semi_supervised\/_label_propagation.py":[{"add":["66","from ..neighbors import NearestNeighbors"],"delete":["66","from ..neighbors.unsupervised import NearestNeighbors"]}]}},"46001e7cfb163b73a83d5adf73fb454e8a3c64b6":{"changes":{"azure-pipelines.yml":"MODIFY","sklearn\/model_selection\/_validation.py":"MODIFY","sklearn\/model_selection\/tests\/test_search.py":"MODIFY","sklearn\/utils\/validation.py":"MODIFY","doc\/whats_new\/v0.22.rst":"MODIFY","build_tools\/azure\/install.sh":"MODIFY","sklearn\/utils\/tests\/test_validation.py":"MODIFY","sklearn\/model_selection\/_search.py":"MODIFY"},"diff":{"azure-pipelines.yml":[{"add":["73","      # It runs tests requiring lightgbm, pandas and PyAMG."],"delete":["73","      # It runs tests requiring pandas and PyAMG.","76","        # FIXME: pinned until SciPy wheels are available for Python 3.8"]}],"sklearn\/model_selection\/_validation.py":[{"add":["25","from ..utils.validation import _check_fit_params","492","    fit_params = _check_fit_params(X, fit_params, train)","832","    fit_params = _check_fit_params(X, fit_params, train)"],"delete":["491","    fit_params = {k: _index_param_value(X, v, train)","492","                  for k, v in fit_params.items()}","832","    fit_params = {k: _index_param_value(X, v, train)","833","                  for k, v in fit_params.items()}","943","def _index_param_value(X, v, indices):","944","    \"\"\"Private helper function for parameter value indexing.\"\"\"","945","    if not _is_arraylike(v) or _num_samples(v) != _num_samples(X):","946","        # pass through: skip indexing","947","        return v","948","    if sp.issparse(v):","949","        v = v.tocsr()","950","    return _safe_indexing(v, indices)","951","","952",""]}],"sklearn\/model_selection\/tests\/test_search.py":[{"add":["29","from sklearn.base import BaseEstimator, ClassifierMixin","38","from sklearn.model_selection import train_test_split","221","@pytest.mark.parametrize(\"SearchCV\", [GridSearchCV, RandomizedSearchCV])","222","def test_SearchCV_with_fit_params(SearchCV):","226","    searcher = SearchCV(","227","        clf, {'foo_param': [1, 2, 3]}, cv=2, error_score=\"raise\"","228","    )","232","    err_msg = r\"Expected fit parameter\\(s\\) \\['eggs'\\] not seen.\"","233","    with pytest.raises(AssertionError, match=err_msg):","234","        searcher.fit(X, y, spam=np.ones(10))","235","","236","    err_msg = \"Fit parameter spam has length 1; expected\"","237","    with pytest.raises(AssertionError, match=err_msg):","238","        searcher.fit(X, y, spam=np.ones(1), eggs=np.zeros(10))","1841","","1842","","1843","@pytest.mark.parametrize(","1844","    \"SearchCV, param_search\",","1845","    [(GridSearchCV, {'a': [0.1, 0.01]}),","1846","     (RandomizedSearchCV, {'a': uniform(1, 3)})]","1847",")","1848","def test_scalar_fit_param(SearchCV, param_search):","1849","    # unofficially sanctioned tolerance for scalar values in fit_params","1850","    # non-regression test for:","1851","    # https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/15805","1852","    class TestEstimator(BaseEstimator, ClassifierMixin):","1853","        def __init__(self, a=None):","1854","            self.a = a","1855","","1856","        def fit(self, X, y, r=None):","1857","            self.r_ = r","1858","","1859","        def predict(self, X):","1860","            return np.zeros(shape=(len(X)))","1861","","1862","    model = SearchCV(TestEstimator(), param_search)","1863","    X, y = make_classification(random_state=42)","1864","    model.fit(X, y, r=42)","1865","    assert model.best_estimator_.r_ == 42","1866","","1867","","1868","@pytest.mark.parametrize(","1869","    \"SearchCV, param_search\",","1870","    [(GridSearchCV, {'alpha': [0.1, 0.01]}),","1871","     (RandomizedSearchCV, {'alpha': uniform(0.01, 0.1)})]","1872",")","1873","def test_scalar_fit_param_compat(SearchCV, param_search):","1874","    # check support for scalar values in fit_params, for instance in LightGBM","1875","    # that do not exactly respect the scikit-learn API contract but that we do","1876","    # not want to break without an explicit deprecation cycle and API","1877","    # recommendations for implementing early stopping with a user provided","1878","    # validation set. non-regression test for:","1879","    # https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/15805","1880","    X_train, X_valid, y_train, y_valid = train_test_split(","1881","        *make_classification(random_state=42), random_state=42","1882","    )","1883","","1884","    class _FitParamClassifier(SGDClassifier):","1885","","1886","        def fit(self, X, y, sample_weight=None, tuple_of_arrays=None,","1887","                scalar_param=None, callable_param=None):","1888","            super().fit(X, y, sample_weight=sample_weight)","1889","            assert scalar_param > 0","1890","            assert callable(callable_param)","1891","","1892","            # The tuple of arrays should be preserved as tuple.","1893","            assert isinstance(tuple_of_arrays, tuple)","1894","            assert tuple_of_arrays[0].ndim == 2","1895","            assert tuple_of_arrays[1].ndim == 1","1896","            return self","1897","","1898","    def _fit_param_callable():","1899","        pass","1900","","1901","    model = SearchCV(","1902","        _FitParamClassifier(), param_search","1903","    )","1904","","1905","    # NOTE: `fit_params` should be data dependent (e.g. `sample_weight`) which","1906","    # is not the case for the following parameters. But this abuse is common in","1907","    # popular third-party libraries and we should tolerate this behavior for","1908","    # now and be careful not to break support for those without following","1909","    # proper deprecation cycle.","1910","    fit_params = {","1911","        'tuple_of_arrays': (X_valid, y_valid),","1912","        'callable_param': _fit_param_callable,","1913","        'scalar_param': 42,","1914","    }","1915","    model.fit(X_train, y_train, **fit_params)"],"delete":["29","from sklearn.base import BaseEstimator","220","def check_hyperparameter_searcher_with_fit_params(klass, **klass_kwargs):","224","    searcher = klass(clf, {'foo_param': [1, 2, 3]}, cv=2, **klass_kwargs)","228","    assert_raise_message(AssertionError,","229","                         \"Expected fit parameter(s) ['eggs'] not seen.\",","230","                         searcher.fit, X, y, spam=np.ones(10))","231","    assert_raise_message(","232","        ValueError,","233","        \"Found input variables with inconsistent numbers of samples: [\",","234","        searcher.fit, X, y, spam=np.ones(1),","235","        eggs=np.zeros(10))","239","def test_grid_search_with_fit_params():","240","    check_hyperparameter_searcher_with_fit_params(GridSearchCV,","241","                                                  error_score='raise')","242","","243","","244","def test_random_search_with_fit_params():","245","    check_hyperparameter_searcher_with_fit_params(RandomizedSearchCV, n_iter=1,","246","                                                  error_score='raise')","247","","248",""]}],"sklearn\/utils\/validation.py":[{"add":["214","def _make_indexable(iterable):","215","    \"\"\"Ensure iterable supports indexing or convert to an indexable variant.","216","","217","    Convert sparse matrices to csr and other non-indexable iterable to arrays.","218","    Let `None` and indexable objects (e.g. pandas dataframes) pass unchanged.","219","","220","    Parameters","221","    ----------","222","    iterable : {list, dataframe, array, sparse} or None","223","        Object to be converted to an indexable iterable.","224","    \"\"\"","225","    if sp.issparse(iterable):","226","        return iterable.tocsr()","227","    elif hasattr(iterable, \"__getitem__\") or hasattr(iterable, \"iloc\"):","228","        return iterable","229","    elif iterable is None:","230","        return iterable","231","    return np.array(iterable)","232","","233","","246","    result = [_make_indexable(X) for X in iterables]","1290","","1291","","1292","def _check_fit_params(X, fit_params, indices=None):","1293","    \"\"\"Check and validate the parameters passed during `fit`.","1294","","1295","    Parameters","1296","    ----------","1297","    X : array-like of shape (n_samples, n_features)","1298","        Data array.","1299","","1300","    fit_params : dict","1301","        Dictionary containing the parameters passed at fit.","1302","","1303","    indices : array-like of shape (n_samples,), default=None","1304","        Indices to be selected if the parameter has the same size as `X`.","1305","","1306","    Returns","1307","    -------","1308","    fit_params_validated : dict","1309","        Validated parameters. We ensure that the values support indexing.","1310","    \"\"\"","1311","    from . import _safe_indexing","1312","    fit_params_validated = {}","1313","    for param_key, param_value in fit_params.items():","1314","        if (not _is_arraylike(param_value) or","1315","                _num_samples(param_value) != _num_samples(X)):","1316","            # Non-indexable pass-through (for now for backward-compatibility).","1317","            # https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/15805","1318","            fit_params_validated[param_key] = param_value","1319","        else:","1320","            # Any other fit_params should support indexing","1321","            # (e.g. for cross-validation).","1322","            fit_params_validated[param_key] = _make_indexable(param_value)","1323","            fit_params_validated[param_key] = _safe_indexing(","1324","                fit_params_validated[param_key], indices","1325","            )","1326","","1327","    return fit_params_validated"],"delete":["226","    result = []","227","    for X in iterables:","228","        if sp.issparse(X):","229","            result.append(X.tocsr())","230","        elif hasattr(X, \"__getitem__\") or hasattr(X, \"iloc\"):","231","            result.append(X)","232","        elif X is None:","233","            result.append(X)","234","        else:","235","            result.append(np.array(X))"]}],"doc\/whats_new\/v0.22.rst":[{"add":["68",":mod:`sklearn.model_selection`","69","..............................","70","","71","- |Fix| :class:`model_selection.GridSearchCV` and","72","  :class:`model_selection.RandomizedSearchCV` accept scalar values provided in","73","  `fit_params`. Change in 0.22 was breaking backward compatibility.","74","  :pr:`15863` by :user:`Adrin Jalali <adrinjalali>` and","75","  :user:`Guillaume Lemaitre <glemaitre>`.","76",""],"delete":[]}],"build_tools\/azure\/install.sh":[{"add":["94","    # do not install dependencies for lightgbm since it requires scikit-learn","95","    python -m pip install lightgbm --no-deps"],"delete":[]}],"sklearn\/utils\/tests\/test_validation.py":[{"add":["34","from sklearn.utils import _safe_indexing","49","from sklearn.utils.validation import _check_fit_params","1102","","1103","","1104","@pytest.mark.parametrize(\"indices\", [None, [1, 3]])","1105","def test_check_fit_params(indices):","1106","    X = np.random.randn(4, 2)","1107","    fit_params = {","1108","        'list': [1, 2, 3, 4],","1109","        'array': np.array([1, 2, 3, 4]),","1110","        'sparse-col': sp.csc_matrix([1, 2, 3, 4]).T,","1111","        'sparse-row': sp.csc_matrix([1, 2, 3, 4]),","1112","        'scalar-int': 1,","1113","        'scalar-str': 'xxx',","1114","        'None': None,","1115","    }","1116","    result = _check_fit_params(X, fit_params, indices)","1117","    indices_ = indices if indices is not None else list(range(X.shape[0]))","1118","","1119","    for key in ['sparse-row', 'scalar-int', 'scalar-str', 'None']:","1120","        assert result[key] is fit_params[key]","1121","","1122","    assert result['list'] == _safe_indexing(fit_params['list'], indices_)","1123","    assert_array_equal(","1124","        result['array'], _safe_indexing(fit_params['array'], indices_)","1125","    )","1126","    assert_allclose_dense_sparse(","1127","        result['sparse-col'],","1128","        _safe_indexing(fit_params['sparse-col'], indices_)","1129","    )"],"delete":[]}],"sklearn\/model_selection\/_search.py":[{"add":["35","from ..utils.validation import indexable, check_is_fitted, _check_fit_params","650","        fit_params = _check_fit_params(X, fit_params)"],"delete":["35","from ..utils.validation import indexable, check_is_fitted","650","        # make sure fit_params are sliceable","651","        fit_params_values = indexable(*fit_params.values())","652","        fit_params = dict(zip(fit_params.keys(), fit_params_values))"]}]}}}
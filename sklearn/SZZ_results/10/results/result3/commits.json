{"f95e5b1a0d2139a94393954675d4a84920653176":{"changes":{"sklearn\/tree\/_utils.pyx":"MODIFY","sklearn\/tree\/_criterion.pyx":"MODIFY","sklearn\/tree\/_criterion.pxd":"MODIFY","sklearn\/tree\/_utils.pxd":"MODIFY"},"diff":{"sklearn\/tree\/_utils.pyx":[{"add":["208","    cdef void heapify_up(self, PriorityHeapRecord* heap, SIZE_t pos) nogil:","209","        \"\"\"Restore heap invariant parent.improvement > child.improvement from","210","           ``pos`` upwards. \"\"\"","211","        if pos == 0:","212","            return","213","","214","        cdef SIZE_t parent_pos = (pos - 1) \/ 2","215","","216","        if heap[parent_pos].improvement < heap[pos].improvement:","217","            heap[parent_pos], heap[pos] = heap[pos], heap[parent_pos]","218","            self.heapify_up(heap, parent_pos)","219","","220","    cdef void heapify_down(self, PriorityHeapRecord* heap, SIZE_t pos,","221","                           SIZE_t heap_length) nogil:","222","        \"\"\"Restore heap invariant parent.improvement > children.improvement from","223","           ``pos`` downwards. \"\"\"","224","        cdef SIZE_t left_pos = 2 * (pos + 1) - 1","225","        cdef SIZE_t right_pos = 2 * (pos + 1)","226","        cdef SIZE_t largest = pos","227","","228","        if (left_pos < heap_length and","229","                heap[left_pos].improvement > heap[largest].improvement):","230","            largest = left_pos","231","","232","        if (right_pos < heap_length and","233","                heap[right_pos].improvement > heap[largest].improvement):","234","            largest = right_pos","235","","236","        if largest != pos:","237","            heap[pos], heap[largest] = heap[largest], heap[pos]","238","            self.heapify_down(heap, largest, heap_length)","239","","276","        self.heapify_up(heap, heap_ptr)","298","            self.heapify_down(heap, 0, heap_ptr - 1)"],"delete":["175","cdef void heapify_up(PriorityHeapRecord* heap, SIZE_t pos) nogil:","176","    \"\"\"Restore heap invariant parent.improvement > child.improvement from","177","       ``pos`` upwards. \"\"\"","178","    if pos == 0:","179","        return","180","","181","    cdef SIZE_t parent_pos = (pos - 1) \/ 2","182","","183","    if heap[parent_pos].improvement < heap[pos].improvement:","184","        heap[parent_pos], heap[pos] = heap[pos], heap[parent_pos]","185","        heapify_up(heap, parent_pos)","186","","187","","188","cdef void heapify_down(PriorityHeapRecord* heap, SIZE_t pos,","189","                       SIZE_t heap_length) nogil:","190","    \"\"\"Restore heap invariant parent.improvement > children.improvement from","191","       ``pos`` downwards. \"\"\"","192","    cdef SIZE_t left_pos = 2 * (pos + 1) - 1","193","    cdef SIZE_t right_pos = 2 * (pos + 1)","194","    cdef SIZE_t largest = pos","195","","196","    if (left_pos < heap_length and","197","            heap[left_pos].improvement > heap[largest].improvement):","198","        largest = left_pos","199","","200","    if (right_pos < heap_length and","201","            heap[right_pos].improvement > heap[largest].improvement):","202","        largest = right_pos","203","","204","    if largest != pos:","205","        heap[pos], heap[largest] = heap[largest], heap[pos]","206","        heapify_down(heap, largest, heap_length)","207","","208","","278","        heapify_up(heap, heap_ptr)","300","            heapify_down(heap, 0, heap_ptr - 1)"]}],"sklearn\/tree\/_criterion.pyx":[{"add":["268","        if (self.sum_total == NULL or","855","        self.weighted_n_right = (self.weighted_n_node_samples -","966","            impurity_right[0] -= (sum_right[k] \/ self.weighted_n_right) ** 2.0","1269","    Uses the formula (35) in Friedman's original Gradient Boosting paper:","1322","        return (diff * diff \/ (self.weighted_n_left * self.weighted_n_right *"],"delete":["268","        if (self.sum_total == NULL or ","855","        self.weighted_n_right = (self.weighted_n_node_samples - ","966","            impurity_right[0] -= (sum_right[k] \/ self.weighted_n_right) ** 2.0 ","1269","    Uses the formula (35) in Friedmans original Gradient Boosting paper:","1322","        return (diff * diff \/ (self.weighted_n_left * self.weighted_n_right * "]}],"sklearn\/tree\/_criterion.pxd":[{"add":["47","                                    # where k is output index."],"delete":["47","                                    # where k is output index. "]}],"sklearn\/tree\/_utils.pxd":[{"add":["108","    cdef void heapify_up(self, PriorityHeapRecord* heap, SIZE_t pos) nogil","109","    cdef void heapify_down(self, PriorityHeapRecord* heap, SIZE_t pos, SIZE_t heap_length) nogil"],"delete":[]}]}},"fa6fafcfdbd3cea4583fd63f45f7b80e76de74e7":{"changes":{"sklearn\/datasets\/tests\/test_20news.py":"MODIFY"},"diff":{"sklearn\/datasets\/tests\/test_20news.py":[{"add":["59","    try:","60","        datasets.fetch_20newsgroups(subset='all',","61","                                    download_if_missing=False)","62","    except IOError:","63","        raise SkipTest(\"Download 20 newsgroups to run this test\")","65","    # test subset = train","68","    assert_equal(bunch.data.shape, (11314, 130107))","72","    # test subset = test","75","    assert_equal(bunch.data.shape, (7532, 130107))","79","    # test subset = all","80","    bunch = datasets.fetch_20newsgroups_vectorized(subset='all')","82","    assert_equal(bunch.data.shape, (11314 + 7532, 130107))"],"delete":["59","    # This test is slow.","60","    raise SkipTest(\"Test too slow.\")","64","    assert_equal(bunch.data.shape, (11314, 107428))","70","    assert_equal(bunch.data.shape, (7532, 107428))","74","    bunch = datasets.fetch_20newsgroups_vectorized(subset=\"all\")","76","    assert_equal(bunch.data.shape, (11314 + 7532, 107428))"]}]}},"979591643397d78fcf27c51e2fbe6493d527a42f":{"changes":{"sklearn\/linear_model\/least_angle.py":"MODIFY"},"diff":{"sklearn\/linear_model\/least_angle.py":[{"add":["65","        ..). Only coefficients up to the smallest alpha value (``alphas_[alphas_ >"],"delete":["65","        ..). Only coeffiencts up to the smallest alpha value (``alphas_[alphas_ >"]}]}},"b32897f1c32ad184cc84634567d87eab83c1e1eb":{"changes":{"sklearn\/linear_model\/tests\/test_ridge.py":"MODIFY","sklearn\/linear_model\/ridge.py":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_ridge.py":[{"add":["299","    fit_intercept = filter_ == DENSE_FILTER","300","    if fit_intercept:","301","        X_diabetes_ = X_diabetes - X_diabetes.mean(0)","302","    else:","303","        X_diabetes_ = X_diabetes","304","    ridge_gcv = _RidgeGCV(fit_intercept=fit_intercept)","305","    ridge = Ridge(alpha=1.0, fit_intercept=fit_intercept)","306","","307","    # because fit_intercept is applied","310","    decomp = ridge_gcv._pre_compute(X_diabetes_, y_diabetes, fit_intercept)","319","        X_new = X_diabetes_[sel]","322","        value = ridge.predict([X_diabetes_[i]])[0]","333","    decomp = ridge_gcv._pre_compute_svd(X_diabetes_, y_diabetes, fit_intercept)"],"delete":["299","    ridge_gcv = _RidgeGCV(fit_intercept=False)","300","    ridge = Ridge(alpha=1.0, fit_intercept=False)","303","    decomp = ridge_gcv._pre_compute(X_diabetes, y_diabetes)","312","        X_new = X_diabetes[sel]","315","        value = ridge.predict([X_diabetes[i]])[0]","326","    decomp = ridge_gcv._pre_compute_svd(X_diabetes, y_diabetes)"]}],"sklearn\/linear_model\/ridge.py":[{"add":["852","    def _pre_compute(self, X, y, centered_kernel=True):","855","        # the following emulates an additional constant regressor","856","        # corresponding to fit_intercept=True","857","        # but this is done only when the features have been centered","858","        if centered_kernel:","859","            K += np.ones_like(K)","883","        w = 1. \/ (v + alpha)","884","        constant_column = np.var(Q, 0) < 1.e-12","885","        # detect constant columns","886","        w[constant_column] = 0  # cancel the regularization for the intercept","887","        w[v == 0] = 0","903","    def _pre_compute_svd(self, X, y, centered_kernel=True):","906","        if centered_kernel:","907","            X = np.hstack((X, np.ones((X.shape[0], 1))))","908","        # to emulate fit_intercept=True situation, add a column on ones","909","        # Note that by centering, the other columns are orthogonal to that one","919","        constant_column = np.var(U, 0) < 1.e-12","920","        # detect columns colinear to ones","922","        w[constant_column] = - (alpha ** -1)","923","        # cancel the regularization for the intercept","991","        if sample_weight is not None:","992","            X, y = _rescale_data(X, y, sample_weight)","993","","994","        centered_kernel = not sparse.issparse(X) and self.fit_intercept","995","","996","        v, Q, QT_y = _pre_compute(X, y, centered_kernel)","1006","                out, c = _errors(alpha, y, v, Q, QT_y)","1008","                out, c = _values(alpha, y, v, Q, QT_y)","1092","                              parameters, fit_params=fit_params, cv=self.cv,","1093","                              scoring=self.scoring)"],"delete":["852","    def _pre_compute(self, X, y):","878","        w = 1.0 \/ (v + alpha)","894","    def _pre_compute_svd(self, X, y):","942","","975","        v, Q, QT_y = _pre_compute(X, y)","984","            weighted_alpha = (sample_weight * alpha","985","                              if sample_weight is not None","986","                              else alpha)","988","                out, c = _errors(weighted_alpha, y, v, Q, QT_y)","990","                out, c = _values(weighted_alpha, y, v, Q, QT_y)","1074","                              parameters, fit_params=fit_params, cv=self.cv)"]}]}},"1a5be6df1b66f3fe3831c7440438c919ad424626":{"changes":{"sklearn\/isotonic.py":"MODIFY","sklearn\/tests\/test_isotonic.py":"MODIFY"},"diff":{"sklearn\/isotonic.py":[{"add":["431","        if hasattr(self, '_necessary_X_') and hasattr(self, '_necessary_y_'):","432","            self._build_f(self._necessary_X_, self._necessary_y_)"],"delete":["431","        self._build_f(self._necessary_X_, self._necessary_y_)"]}],"sklearn\/tests\/test_isotonic.py":[{"add":["3","import copy","398","","399","","400","def test_isotonic_copy_before_fit():","401","    # https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/6628","402","    ir = IsotonicRegression()","403","    copy.copy(ir)"],"delete":[]}]}},"a08555a2384884c03d5deb509192a052c06caa85":{"changes":{"doc\/modules\/classes.rst":"MODIFY","sklearn\/model_selection\/tests\/test_search.py":"MODIFY","doc\/modules\/cross_validation.rst":"MODIFY","examples\/model_selection\/plot_multi_metric_evaluation.py":"ADD","sklearn\/metrics\/scorer.py":"MODIFY","sklearn\/metrics\/tests\/test_score_objects.py":"MODIFY","sklearn\/model_selection\/__init__.py":"MODIFY","sklearn\/model_selection\/_validation.py":"MODIFY","doc\/modules\/grid_search.rst":"MODIFY","sklearn\/model_selection\/tests\/test_validation.py":"MODIFY","doc\/whats_new.rst":"MODIFY","doc\/modules\/model_evaluation.rst":"MODIFY","sklearn\/model_selection\/_search.py":"MODIFY"},"diff":{"doc\/modules\/classes.rst":[{"add":["225","   model_selection.cross_validate"],"delete":[]}],"sklearn\/model_selection\/tests\/test_search.py":[{"add":["9","import re","31","from sklearn.base import clone","37","from sklearn.model_selection import fit_grid_point","58","from sklearn.metrics import recall_score","59","from sklearn.metrics import accuracy_score","376","    for scoring in [None, ['accuracy', 'precision']]:","377","        grid_search = GridSearchCV(clf, {'foo_param': [1, 2, 3]}, refit=False)","378","        grid_search.fit(X, y)","379","        assert_true(not hasattr(grid_search, \"best_estimator_\") and","380","                    hasattr(grid_search, \"best_index_\") and","381","                    hasattr(grid_search, \"best_params_\"))","383","        # Make sure the functions predict\/transform etc raise meaningful","384","        # error messages","385","        for fn_name in ('predict', 'predict_proba', 'predict_log_proba',","386","                        'transform', 'inverse_transform'):","387","            assert_raise_message(NotFittedError,","388","                                 ('refit=False. %s is available only after '","389","                                  'refitting on the best parameters'","390","                                  % fn_name), getattr(grid_search, fn_name), X)","391","","392","    # Test that an invalid refit param raises appropriate error messages","393","    for refit in [\"\", 5, True, 'recall', 'accuracy']:","394","        assert_raise_message(ValueError, \"For multi-metric scoring, the \"","395","                             \"parameter refit must be set to a scorer key\",","396","                             GridSearchCV(clf, {}, refit=refit,","397","                                          scoring={'acc': 'accuracy',","398","                                                   'prec': 'precision'}).fit,","399","                             X, y)","639","","640","        def check_df(x):","641","            return isinstance(x, InputFeatureType)","642","","643","        def check_series(x):","644","            return isinstance(x, TargetType)","645","","659","    # Multi-metric evaluation unsupervised","660","    scoring = ['adjusted_rand_score', 'fowlkes_mallows_score']","661","    for refit in ['adjusted_rand_score', 'fowlkes_mallows_score']:","662","        grid_search = GridSearchCV(km, param_grid=dict(n_clusters=[2, 3, 4]),","663","                                   scoring=scoring, refit=refit)","664","        grid_search.fit(X, y)","665","        # Both ARI and FMS can find the right number :)","666","        assert_equal(grid_search.best_params_[\"n_clusters\"], 3)","667","","668","    # Single metric evaluation unsupervised","720","def check_cv_results_array_types(search, param_keys, score_keys):","722","    cv_results = search.cv_results_","730","","731","    scorer_keys = search.scorer_.keys() if search.multimetric_ else ['score']","732","","733","    for key in scorer_keys:","734","        assert_true(cv_results['rank_test_%s' % key].dtype == np.int32)","746","    # TODO Remove test in 0.20","747","    if search.multimetric_:","748","        assert_raise_message(AttributeError, \"not available for multi-metric\",","749","                             getattr, search, 'grid_scores_')","750","    else:","751","        cv_results = search.cv_results_","752","        res_scores = np.vstack(list([cv_results[\"split%d_test_score\" % i]","753","                                     for i in range(search.n_splits_)])).T","754","        res_means = cv_results[\"mean_test_score\"]","755","        res_params = cv_results[\"params\"]","756","        n_cand = len(res_params)","757","        grid_scores = assert_warns(DeprecationWarning, getattr,","758","                                   search, 'grid_scores_')","759","        assert_equal(len(grid_scores), n_cand)","760","        # Check consistency of the structure of grid_scores","761","        for i in range(n_cand):","762","            assert_equal(grid_scores[i].parameters, res_params[i])","763","            assert_array_equal(grid_scores[i].cv_validation_scores,","764","                               res_scores[i, :])","765","            assert_array_equal(grid_scores[i].mean_validation_score,","766","                               res_means[i])","790","    for iid in (False, True):","791","        search = GridSearchCV(SVC(), cv=n_splits, iid=iid, param_grid=params)","792","        search.fit(X, y)","803","        check_cv_results_array_types(search, param_keys, score_keys)","806","        cv_results = search.cv_results_","807","        n_candidates = len(search.cv_results_['params'])","822","    X, y = make_classification(n_samples=50, n_features=4, random_state=42)","827","    params = dict(C=expon(scale=10), gamma=expon(scale=0.1))","840","    for iid in (False, True):","841","        search = RandomizedSearchCV(SVC(), n_iter=n_search_iter, cv=n_splits,","842","                                    iid=iid, param_distributions=params)","843","        search.fit(X, y)","847","        check_cv_results_array_types(search, param_keys, score_keys)","949","def test_grid_search_cv_results_multimetric():","950","    X, y = make_classification(n_samples=50, n_features=4, random_state=42)","951","","952","    n_splits = 3","953","    params = [dict(kernel=['rbf', ], C=[1, 10], gamma=[0.1, 1]),","954","              dict(kernel=['poly', ], degree=[1, 2])]","955","","956","    for iid in (False, True):","957","        grid_searches = []","958","        for scoring in ({'accuracy': make_scorer(accuracy_score),","959","                         'recall': make_scorer(recall_score)},","960","                        'accuracy', 'recall'):","961","            grid_search = GridSearchCV(SVC(), cv=n_splits, iid=iid,","962","                                       param_grid=params, scoring=scoring,","963","                                       refit=False)","964","            grid_search.fit(X, y)","965","            assert_equal(grid_search.iid, iid)","966","            grid_searches.append(grid_search)","967","","968","        compare_cv_results_multimetric_with_single(*grid_searches, iid=iid)","969","","970","","971","def test_random_search_cv_results_multimetric():","972","    X, y = make_classification(n_samples=50, n_features=4, random_state=42)","973","","974","    n_splits = 3","975","    n_search_iter = 30","976","    scoring = ('accuracy', 'recall')","977","","978","    # Scipy 0.12's stats dists do not accept seed, hence we use param grid","979","    params = dict(C=np.logspace(-10, 1), gamma=np.logspace(-5, 0, base=0.1))","980","    for iid in (True, False):","981","        for refit in (True, False):","982","            random_searches = []","983","            for scoring in (('accuracy', 'recall'), 'accuracy', 'recall'):","984","                # If True, for multi-metric pass refit='accuracy'","985","                if refit:","986","                    refit = 'accuracy' if isinstance(scoring, tuple) else refit","987","                clf = SVC(probability=True, random_state=42)","988","                random_search = RandomizedSearchCV(clf, n_iter=n_search_iter,","989","                                                   cv=n_splits, iid=iid,","990","                                                   param_distributions=params,","991","                                                   scoring=scoring,","992","                                                   refit=refit, random_state=0)","993","                random_search.fit(X, y)","994","                random_searches.append(random_search)","995","","996","            compare_cv_results_multimetric_with_single(*random_searches,","997","                                                       iid=iid)","998","            if refit:","999","                compare_refit_methods_when_refit_with_acc(","1000","                    random_searches[0], random_searches[1], refit)","1001","","1002","","1003","def compare_cv_results_multimetric_with_single(","1004","        search_multi, search_acc, search_rec, iid):","1005","    \"\"\"Compare multi-metric cv_results with the ensemble of multiple","1006","    single metric cv_results from single metric grid\/random search\"\"\"","1007","","1008","    assert_equal(search_multi.iid, iid)","1009","    assert_true(search_multi.multimetric_)","1010","    assert_array_equal(sorted(search_multi.scorer_),","1011","                       ('accuracy', 'recall'))","1012","","1013","    cv_results_multi = search_multi.cv_results_","1014","    cv_results_acc_rec = {re.sub('_score$', '_accuracy', k): v","1015","                          for k, v in search_acc.cv_results_.items()}","1016","    cv_results_acc_rec.update({re.sub('_score$', '_recall', k): v","1017","                               for k, v in search_rec.cv_results_.items()})","1018","","1019","    # Check if score and timing are reasonable, also checks if the keys","1020","    # are present","1021","    assert_true(all((np.all(cv_results_multi[k] <= 1) for k in (","1022","                    'mean_score_time', 'std_score_time', 'mean_fit_time',","1023","                    'std_fit_time'))))","1024","","1025","    # Compare the keys, other than time keys, among multi-metric and","1026","    # single metric grid search results. np.testing.assert_equal performs a","1027","    # deep nested comparison of the two cv_results dicts","1028","    np.testing.assert_equal({k: v for k, v in cv_results_multi.items()","1029","                             if not k.endswith('_time')},","1030","                            {k: v for k, v in cv_results_acc_rec.items()","1031","                             if not k.endswith('_time')})","1032","","1033","","1034","def compare_refit_methods_when_refit_with_acc(search_multi, search_acc, refit):","1035","    \"\"\"Compare refit multi-metric search methods with single metric methods\"\"\"","1036","    if refit:","1037","        assert_equal(search_multi.refit, 'accuracy')","1038","    else:","1039","        assert_false(search_multi.refit)","1040","    assert_equal(search_acc.refit, refit)","1041","","1042","    X, y = make_blobs(n_samples=100, n_features=4, random_state=42)","1043","    for method in ('predict', 'predict_proba', 'predict_log_proba'):","1044","        assert_almost_equal(getattr(search_multi, method)(X),","1045","                            getattr(search_acc, method)(X))","1046","    assert_almost_equal(search_multi.score(X, y), search_acc.score(X, y))","1047","    for key in ('best_index_', 'best_score_', 'best_params_'):","1048","        assert_equal(getattr(search_multi, key), getattr(search_acc, key))","1049","","1050","","1157","def test_fit_grid_point():","1158","    X, y = make_classification(random_state=0)","1159","    cv = StratifiedKFold(random_state=0)","1160","    svc = LinearSVC(random_state=0)","1161","    scorer = make_scorer(accuracy_score)","1162","","1163","    for params in ({'C': 0.1}, {'C': 0.01}, {'C': 0.001}):","1164","        for train, test in cv.split(X, y):","1165","            this_scores, this_params, n_test_samples = fit_grid_point(","1166","                X, y, clone(svc), params, train, test,","1167","                scorer, verbose=False)","1168","","1169","            est = clone(svc).set_params(**params)","1170","            est.fit(X[train], y[train])","1171","            expected_score = scorer(est, X[test], y[test])","1172","","1173","            # Test the return values of fit_grid_point","1174","            assert_almost_equal(this_scores, expected_score)","1175","            assert_equal(params, this_params)","1176","            assert_equal(n_test_samples, test.size)","1177","","1178","    # Should raise an error upon multimetric scorer","1179","    assert_raise_message(ValueError, \"scoring value should either be a \"","1180","                         \"callable, string or None.\", fit_grid_point, X, y,","1181","                         svc, params, train, test, {'score': scorer},","1182","                         verbose=True)","1183","","1184","","1429","    np.testing.assert_equal({k: v for k, v in gs.cv_results_.items()","1430","                             if not k.endswith('_time')},","1431","                            {k: v for k, v in gs2.cv_results_.items()","1432","                             if not k.endswith('_time')})"],"delete":["29","from sklearn.externals.six.moves import zip","372","    grid_search = GridSearchCV(clf, {'foo_param': [1, 2, 3]}, refit=False)","373","    grid_search.fit(X, y)","374","    assert_true(not hasattr(grid_search, \"best_estimator_\") and","375","                hasattr(grid_search, \"best_index_\") and","376","                hasattr(grid_search, \"best_params_\"))","378","    # Make sure the predict\/transform etc fns raise meaningfull error msg","379","    for fn_name in ('predict', 'predict_proba', 'predict_log_proba',","380","                    'transform', 'inverse_transform'):","381","        assert_raise_message(NotFittedError,","382","                             ('refit=False. %s is available only after '","383","                              'refitting on the best parameters' % fn_name),","384","                             getattr(grid_search, fn_name), X)","624","        check_df = lambda x: isinstance(x, InputFeatureType)","625","        check_series = lambda x: isinstance(x, TargetType)","638","    grid_search = GridSearchCV(km, param_grid=dict(n_clusters=[2, 3, 4]),","639","                               scoring='adjusted_rand_score')","640","    grid_search.fit(X, y)","641","    # ARI can find the right number :)","642","    assert_equal(grid_search.best_params_[\"n_clusters\"], 3)","647","    # So can FMS ;)","696","def check_cv_results_array_types(cv_results, param_keys, score_keys):","705","    assert_true(cv_results['rank_test_score'].dtype == np.int32)","717","    # TODO Remove in 0.20","718","    cv_results = search.cv_results_","719","    res_scores = np.vstack(list([cv_results[\"split%d_test_score\" % i]","720","                                 for i in range(search.n_splits_)])).T","721","    res_means = cv_results[\"mean_test_score\"]","722","    res_params = cv_results[\"params\"]","723","    n_cand = len(res_params)","724","    grid_scores = assert_warns(DeprecationWarning, getattr,","725","                               search, 'grid_scores_')","726","    assert_equal(len(grid_scores), n_cand)","727","    # Check consistency of the structure of grid_scores","728","    for i in range(n_cand):","729","        assert_equal(grid_scores[i].parameters, res_params[i])","730","        assert_array_equal(grid_scores[i].cv_validation_scores,","731","                           res_scores[i, :])","732","        assert_array_equal(grid_scores[i].mean_validation_score, res_means[i])","743","    grid_search = GridSearchCV(SVC(), cv=n_splits, iid=False,","744","                               param_grid=params)","745","    grid_search.fit(X, y)","746","    grid_search_iid = GridSearchCV(SVC(), cv=n_splits, iid=True,","747","                                   param_grid=params)","748","    grid_search_iid.fit(X, y)","762","    for search, iid in zip((grid_search, grid_search_iid), (False, True)):","773","        check_cv_results_array_types(cv_results, param_keys, score_keys)","776","        cv_results = grid_search.cv_results_","777","        n_candidates = len(grid_search.cv_results_['params'])","792","    # Make a dataset with a lot of noise to get various kind of prediction","793","    # errors across CV folds and parameter settings","794","    X, y = make_classification(n_samples=200, n_features=100, n_informative=3,","795","                               random_state=0)","797","    # scipy.stats dists now supports `seed` but we still support scipy 0.12","798","    # which doesn't support the seed. Hence the assertions in the test for","799","    # random_search alone should not depend on randomization.","802","    params = dict(C=expon(scale=10), gamma=expon(scale=0.1))","803","    random_search = RandomizedSearchCV(SVC(), n_iter=n_search_iter,","804","                                       cv=n_splits, iid=False,","805","                                       param_distributions=params)","806","    random_search.fit(X, y)","807","    random_search_iid = RandomizedSearchCV(SVC(), n_iter=n_search_iter,","808","                                           cv=n_splits, iid=True,","809","                                           param_distributions=params)","810","    random_search_iid.fit(X, y)","824","    for search, iid in zip((random_search, random_search_iid), (False, True)):","828","        check_cv_results_array_types(cv_results, param_keys, score_keys)","1274","    def _pop_time_keys(cv_results):","1275","        for key in ('mean_fit_time', 'std_fit_time',","1276","                    'mean_score_time', 'std_score_time'):","1277","            cv_results.pop(key)","1278","        return cv_results","1279","","1286","    np.testing.assert_equal(_pop_time_keys(gs.cv_results_),","1287","                            _pop_time_keys(gs2.cv_results_))"]}],"doc\/modules\/cross_validation.rst":[{"add":["174","","175",".. _multimetric_cross_validation:","176","","177","The cross_validate function and multiple metric evaluation","178","----------------------------------------------------------","179","","180","The ``cross_validate`` function differs from ``cross_val_score`` in two ways -","181","","182","- It allows specifying multiple metrics for evaluation.","183","","184","- It returns a dict containing training scores, fit-times and score-times in","185","  addition to the test score.","186","","187","For single metric evaluation, where the scoring parameter is a string,","188","callable or None, the keys will be - ``['test_score', 'fit_time', 'score_time']``","189","","190","And for multiple metric evaluation, the return value is a dict with the","191","following keys -","192","``['test_<scorer1_name>', 'test_<scorer2_name>', 'test_<scorer...>', 'fit_time', 'score_time']``","193","","194","``return_train_score`` is set to ``True`` by default. It adds train score keys","195","for all the scorers. If train scores are not needed, this should be set to","196","``False`` explicitly.","197","","198","The multiple metrics can be specified either as a list, tuple or set of","199","predefined scorer names::","200","","201","    >>> from sklearn.model_selection import cross_validate","202","    >>> from sklearn.metrics import recall_score","203","    >>> scoring = ['precision_macro', 'recall_macro']","204","    >>> clf = svm.SVC(kernel='linear', C=1, random_state=0)","205","    >>> scores = cross_validate(clf, iris.data, iris.target, scoring=scoring,","206","    ...                         cv=5, return_train_score=False)","207","    >>> sorted(scores.keys())","208","    ['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']","209","    >>> scores['test_recall_macro']                       # doctest: +ELLIPSIS","210","    array([ 0.96...,  1.  ...,  0.96...,  0.96...,  1.        ])","211","","212","Or as a dict mapping scorer name to a predefined or custom scoring function::","213","","214","    >>> from sklearn.metrics.scorer import make_scorer","215","    >>> scoring = {'prec_macro': 'precision_macro',","216","    ...            'rec_micro': make_scorer(recall_score, average='macro')}","217","    >>> scores = cross_validate(clf, iris.data, iris.target, scoring=scoring,","218","    ...                         cv=5, return_train_score=True)","219","    >>> sorted(scores.keys())                 # doctest: +NORMALIZE_WHITESPACE","220","    ['fit_time', 'score_time', 'test_prec_macro', 'test_rec_micro',","221","     'train_prec_macro', 'train_rec_micro']","222","    >>> scores['train_rec_micro']                         # doctest: +ELLIPSIS","223","    array([ 0.97...,  0.97...,  0.99...,  0.98...,  0.98...])","224","","225","Here is an example of ``cross_validate`` using a single metric::","226","","227","    >>> scores = cross_validate(clf, iris.data, iris.target,","228","    ...                         scoring='precision_macro')","229","    >>> sorted(scores.keys())","230","    ['fit_time', 'score_time', 'test_score', 'train_score']","231","","232","","247","  0.973..."],"delete":["188","  0.966..."]}],"examples\/model_selection\/plot_multi_metric_evaluation.py":[{"add":[],"delete":[]}],"sklearn\/metrics\/scorer.py":[{"add":["211","    valid = True","218","            valid = False  # Don't raise here to make the error message elegant","219","        if not valid:","263","    elif callable(scoring):","276","    elif scoring is None:","277","        if hasattr(estimator, 'score'):","278","            return _passthrough_scorer","279","        elif allow_none:","280","            return None","281","        else:","282","            raise TypeError(","283","                \"If no scoring is specified, the estimator passed should \"","284","                \"have a 'score' method. The estimator %r does not.\"","285","                % estimator)","287","        raise ValueError(\"scoring value should either be a callable, string or\"","288","                         \" None. %r was passed\" % scoring)","289","","290","","291","def _check_multimetric_scoring(estimator, scoring=None):","292","    \"\"\"Check the scoring parameter in cases when multiple metrics are allowed","293","","294","    Parameters","295","    ----------","296","    estimator : sklearn estimator instance","297","        The estimator for which the scoring will be applied.","298","","299","    scoring : string, callable, list\/tuple, dict or None, default: None","300","        A single string (see :ref:`scoring_parameter`) or a callable","301","        (see :ref:`scoring`) to evaluate the predictions on the test set.","302","","303","        For evaluating multiple metrics, either give a list of (unique) strings","304","        or a dict with names as keys and callables as values.","305","","306","        NOTE that when using custom scorers, each scorer should return a single","307","        value. Metric functions returning a list\/array of values can be wrapped","308","        into multiple scorers that return one value each.","309","","310","        See :ref:`multivalued_scorer_wrapping` for an example.","311","","312","        If None the estimator's default scorer (if available) is used.","313","        The return value in that case will be ``{'score': <default_scorer>}``.","314","        If the estimator's default scorer is not available, a ``TypeError``","315","        is raised.","316","","317","    Returns","318","    -------","319","    scorers_dict : dict","320","        A dict mapping each scorer name to its validated scorer.","321","","322","    is_multimetric : bool","323","        True if scorer is a list\/tuple or dict of callables","324","        False if scorer is None\/str\/callable","325","    \"\"\"","326","    if callable(scoring) or scoring is None or isinstance(scoring,","327","                                                          six.string_types):","328","        scorers = {\"score\": check_scoring(estimator, scoring=scoring)}","329","        return scorers, False","330","    else:","331","        err_msg_generic = (\"scoring should either be a single string or \"","332","                           \"callable for single metric evaluation or a \"","333","                           \"list\/tuple of strings or a dict of scorer name \"","334","                           \"mapped to the callable for multiple metric \"","335","                           \"evaluation. Got %s of type %s\"","336","                           % (repr(scoring), type(scoring)))","337","","338","        if isinstance(scoring, (list, tuple, set)):","339","            err_msg = (\"The list\/tuple elements must be unique \"","340","                       \"strings of predefined scorers. \")","341","            invalid = False","342","            try:","343","                keys = set(scoring)","344","            except TypeError:","345","                invalid = True","346","            if invalid:","347","                raise ValueError(err_msg)","348","","349","            if len(keys) != len(scoring):","350","                raise ValueError(err_msg + \"Duplicate elements were found in\"","351","                                 \" the given list. %r\" % repr(scoring))","352","            elif len(keys) > 0:","353","                if not all(isinstance(k, six.string_types) for k in keys):","354","                    if any(callable(k) for k in keys):","355","                        raise ValueError(err_msg +","356","                                         \"One or more of the elements were \"","357","                                         \"callables. Use a dict of score name \"","358","                                         \"mapped to the scorer callable. \"","359","                                         \"Got %r\" % repr(scoring))","360","                    else:","361","                        raise ValueError(err_msg +","362","                                         \"Non-string types were found in \"","363","                                         \"the given list. Got %r\"","364","                                         % repr(scoring))","365","                scorers = {scorer: check_scoring(estimator, scoring=scorer)","366","                           for scorer in scoring}","367","            else:","368","                raise ValueError(err_msg +","369","                                 \"Empty list was given. %r\" % repr(scoring))","370","","371","        elif isinstance(scoring, dict):","372","            keys = set(scoring)","373","            if not all(isinstance(k, six.string_types) for k in keys):","374","                raise ValueError(\"Non-string types were found in the keys of \"","375","                                 \"the given dict. scoring=%r\" % repr(scoring))","376","            if len(keys) == 0:","377","                raise ValueError(\"An empty dict was passed. %r\"","378","                                 % repr(scoring))","379","            scorers = {key: check_scoring(estimator, scoring=scorer)","380","                       for key, scorer in scoring.items()}","381","        else:","382","            raise ValueError(err_msg_generic)","383","        return scorers, True"],"delete":["255","    has_scoring = scoring is not None","261","    elif has_scoring:","274","    elif hasattr(estimator, 'score'):","275","        return _passthrough_scorer","276","    elif allow_none:","277","        return None","279","        raise TypeError(","280","            \"If no scoring is specified, the estimator passed should \"","281","            \"have a 'score' method. The estimator %r does not.\" % estimator)"]}],"sklearn\/metrics\/tests\/test_score_objects.py":[{"add":["10","from sklearn.utils.testing import assert_equal","14","from sklearn.utils.testing import assert_false","25","from sklearn.metrics import accuracy_score","26","from sklearn.metrics.scorer import _check_multimetric_scoring","110","    \"\"\"Dummy estimator to test scoring validators\"\"\"","115","    \"\"\"Dummy estimator to test scoring validators\"\"\"","121","    \"\"\"Dummy estimator to test scoring validators\"\"\"","130","    \"\"\"Dummy estimator to test scoring validators\"\"\"","151","def check_scoring_validator_for_single_metric_usecases(scoring_validator):","152","    # Test all branches of single metric usecases","156","    assert_raises_regexp(TypeError, pattern, scoring_validator, estimator)","160","    scorer = scoring_validator(estimator)","168","    assert_raises_regexp(TypeError, pattern, scoring_validator, estimator)","170","    scorer = scoring_validator(estimator, \"accuracy\")","174","    scorer = scoring_validator(estimator, \"accuracy\")","177","    # Test the allow_none parameter for check_scoring alone","178","    if scoring_validator is check_scoring:","179","        estimator = EstimatorWithFit()","180","        scorer = scoring_validator(estimator, allow_none=True)","181","        assert_true(scorer is None)","182","","183","","184","def check_multimetric_scoring_single_metric_wrapper(*args, **kwargs):","185","    # This wraps the _check_multimetric_scoring to take in single metric","186","    # scoring parameter so we can run the tests that we will run for","187","    # check_scoring, for check_multimetric_scoring too for single-metric","188","    # usecases","189","    scorers, is_multi = _check_multimetric_scoring(*args, **kwargs)","190","    # For all single metric use cases, it should register as not multimetric","191","    assert_false(is_multi)","192","    if args[0] is not None:","193","        assert_true(scorers is not None)","194","        names, scorers = zip(*scorers.items())","195","        assert_equal(len(scorers), 1)","196","        assert_equal(names[0], 'score')","197","        scorers = scorers[0]","198","    return scorers","199","","200","","201","def test_check_scoring_and_check_multimetric_scoring():","202","    check_scoring_validator_for_single_metric_usecases(check_scoring)","203","    # To make sure the check_scoring is correctly applied to the constituent","204","    # scorers","205","    check_scoring_validator_for_single_metric_usecases(","206","        check_multimetric_scoring_single_metric_wrapper)","207","","208","    # For multiple metric use cases","209","    # Make sure it works for the valid cases","210","    for scoring in (('accuracy',), ['precision'],","211","                    {'acc': 'accuracy', 'precision': 'precision'},","212","                    ('accuracy', 'precision'), ['precision', 'accuracy'],","213","                    {'accuracy': make_scorer(accuracy_score),","214","                     'precision': make_scorer(precision_score)}):","215","        estimator = LinearSVC(random_state=0)","216","        estimator.fit([[1], [2], [3]], [1, 1, 0])","217","","218","        scorers, is_multi = _check_multimetric_scoring(estimator, scoring)","219","        assert_true(is_multi)","220","        assert_true(isinstance(scorers, dict))","221","        assert_equal(sorted(scorers.keys()), sorted(list(scoring)))","222","        assert_true(all([isinstance(scorer, _PredictScorer)","223","                         for scorer in list(scorers.values())]))","224","","225","        if 'acc' in scoring:","226","            assert_almost_equal(scorers['acc'](","227","                estimator, [[1], [2], [3]], [1, 0, 0]), 2. \/ 3.)","228","        if 'accuracy' in scoring:","229","            assert_almost_equal(scorers['accuracy'](","230","                estimator, [[1], [2], [3]], [1, 0, 0]), 2. \/ 3.)","231","        if 'precision' in scoring:","232","            assert_almost_equal(scorers['precision'](","233","                estimator, [[1], [2], [3]], [1, 0, 0]), 0.5)","234","","235","    estimator = EstimatorWithFitAndPredict()","236","    estimator.fit([[1]], [1])","237","","238","    # Make sure it raises errors when scoring parameter is not valid.","239","    # More weird corner cases are tested at test_validation.py","240","    error_message_regexp = \".*must be unique strings.*\"","241","    for scoring in ((make_scorer(precision_score),  # Tuple of callables","242","                     make_scorer(accuracy_score)), [5],","243","                    (make_scorer(precision_score),), (), ('f1', 'f1')):","244","        assert_raises_regexp(ValueError, error_message_regexp,","245","                             _check_multimetric_scoring, estimator,","246","                             scoring=scoring)"],"delete":["106","    \"\"\"Dummy estimator to test check_scoring\"\"\"","111","    \"\"\"Dummy estimator to test check_scoring\"\"\"","117","    \"\"\"Dummy estimator to test check_scoring\"\"\"","126","    \"\"\"Dummy estimator to test check_scoring\"\"\"","147","def test_check_scoring():","148","    # Test all branches of check_scoring","152","    assert_raises_regexp(TypeError, pattern, check_scoring, estimator)","156","    scorer = check_scoring(estimator)","164","    assert_raises_regexp(TypeError, pattern, check_scoring, estimator)","166","    scorer = check_scoring(estimator, \"accuracy\")","170","    scorer = check_scoring(estimator, \"accuracy\")","173","    estimator = EstimatorWithFit()","174","    scorer = check_scoring(estimator, allow_none=True)","175","    assert_true(scorer is None)"]}],"sklearn\/model_selection\/__init__.py":[{"add":["20","from ._validation import cross_validate","53","           'cross_validate',"],"delete":[]}],"sklearn\/model_selection\/_validation.py":[{"add":["5","# Author: Alexandre Gramfort <alexandre.gramfort@inria.fr>","6","#         Gael Varoquaux <gael.varoquaux@normalesup.org>","8","#         Raghav RV <rvraghav93@gmail.com>","26","from ..externals.six.moves import zip","27","from ..metrics.scorer import check_scoring, _check_multimetric_scoring","32","","33","__all__ = ['cross_validate', 'cross_val_score', 'cross_val_predict',","34","           'permutation_test_score', 'learning_curve', 'validation_curve']","35","","36","","37","def cross_validate(estimator, X, y=None, groups=None, scoring=None, cv=None,","38","                   n_jobs=1, verbose=0, fit_params=None,","39","                   pre_dispatch='2*n_jobs', return_train_score=True):","40","    \"\"\"Evaluate metric(s) by cross-validation and also record fit\/score times.","41","","42","    Read more in the :ref:`User Guide <multimetric_cross_validation>`.","43","","44","    Parameters","45","    ----------","46","    estimator : estimator object implementing 'fit'","47","        The object to use to fit the data.","48","","49","    X : array-like","50","        The data to fit. Can be for example a list, or an array.","51","","52","    y : array-like, optional, default: None","53","        The target variable to try to predict in the case of","54","        supervised learning.","55","","56","    groups : array-like, with shape (n_samples,), optional","57","        Group labels for the samples used while splitting the dataset into","58","        train\/test set.","59","","60","    scoring : string, callable, list\/tuple, dict or None, default: None","61","        A single string (see :ref:`scoring_parameter`) or a callable","62","        (see :ref:`scoring`) to evaluate the predictions on the test set.","63","","64","        For evaluating multiple metrics, either give a list of (unique) strings","65","        or a dict with names as keys and callables as values.","66","","67","        NOTE that when using custom scorers, each scorer should return a single","68","        value. Metric functions returning a list\/array of values can be wrapped","69","        into multiple scorers that return one value each.","70","","71","        See :ref:`multivalued_scorer_wrapping` for an example.","72","","73","        If None, the estimator's default scorer (if available) is used.","74","","75","    cv : int, cross-validation generator or an iterable, optional","76","        Determines the cross-validation splitting strategy.","77","        Possible inputs for cv are:","78","          - None, to use the default 3-fold cross validation,","79","          - integer, to specify the number of folds in a `(Stratified)KFold`,","80","          - An object to be used as a cross-validation generator.","81","          - An iterable yielding train, test splits.","82","","83","        For integer\/None inputs, if the estimator is a classifier and ``y`` is","84","        either binary or multiclass, :class:`StratifiedKFold` is used. In all","85","        other cases, :class:`KFold` is used.","86","","87","        Refer :ref:`User Guide <cross_validation>` for the various","88","        cross-validation strategies that can be used here.","89","","90","    n_jobs : integer, optional","91","        The number of CPUs to use to do the computation. -1 means","92","        'all CPUs'.","93","","94","    verbose : integer, optional","95","        The verbosity level.","96","","97","    fit_params : dict, optional","98","        Parameters to pass to the fit method of the estimator.","99","","100","    pre_dispatch : int, or string, optional","101","        Controls the number of jobs that get dispatched during parallel","102","        execution. Reducing this number can be useful to avoid an","103","        explosion of memory consumption when more jobs get dispatched","104","        than CPUs can process. This parameter can be:","105","","106","            - None, in which case all the jobs are immediately","107","              created and spawned. Use this for lightweight and","108","              fast-running jobs, to avoid delays due to on-demand","109","              spawning of the jobs","110","","111","            - An int, giving the exact number of total jobs that are","112","              spawned","113","","114","            - A string, giving an expression as a function of n_jobs,","115","              as in '2*n_jobs'","116","","117","    return_train_score : boolean, default True","118","        Whether to include train scores in the return dict if ``scoring`` is","119","        of multimetric type.","120","","121","    Returns","122","    -------","123","    scores : dict of float arrays of shape=(n_splits,)","124","        Array of scores of the estimator for each run of the cross validation.","125","","126","        A dict of arrays containing the score\/time arrays for each scorer is","127","        returned. The possible keys for this ``dict`` are:","128","","129","            ``test_score``","130","                The score array for test scores on each cv split.","131","            ``train_score``","132","                The score array for train scores on each cv split.","133","                This is available only if ``return_train_score`` parameter","134","                is ``True``.","135","            ``fit_time``","136","                The time for fitting the estimator on the train","137","                set for each cv split.","138","            ``score_time``","139","                The time for scoring the estimator on the test set for each","140","                cv split. (Note time for scoring on the train set is not","141","                included even if ``return_train_score`` is set to ``True``","142","","143","    Examples","144","    --------","145","    >>> from sklearn import datasets, linear_model","146","    >>> from sklearn.model_selection import cross_val_score","147","    >>> from sklearn.metrics.scorer import make_scorer","148","    >>> from sklearn.metrics import confusion_matrix","149","    >>> from sklearn.svm import LinearSVC","150","    >>> diabetes = datasets.load_diabetes()","151","    >>> X = diabetes.data[:150]","152","    >>> y = diabetes.target[:150]","153","    >>> lasso = linear_model.Lasso()","154","","155","    # single metric evaluation using cross_validate","156","    >>> cv_results = cross_validate(lasso, X, y, return_train_score=False)","157","    >>> sorted(cv_results.keys())                         # doctest: +ELLIPSIS","158","    ['fit_time', 'score_time', 'test_score']","159","    >>> cv_results['test_score']    # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE","160","    array([ 0.33...,  0.08...,  0.03...])","161","","162","    # Multiple metric evaluation using cross_validate","163","    # (Please refer the ``scoring`` parameter doc for more information)","164","    >>> scores = cross_validate(lasso, X, y,","165","    ...                         scoring=('r2', 'neg_mean_squared_error'))","166","    >>> print(scores['test_neg_mean_squared_error'])      # doctest: +ELLIPSIS","167","    [-3635.5... -3573.3... -6114.7...]","168","    >>> print(scores['train_r2'])                         # doctest: +ELLIPSIS","169","    [ 0.28...  0.39...  0.22...]","170","","171","    See Also","172","    ---------","173","    :func:`sklearn.metrics.cross_val_score`:","174","        Run cross-validation for single metric evaluation.","175","","176","    :func:`sklearn.metrics.make_scorer`:","177","        Make a scorer from a performance metric or loss function.","178","","179","    \"\"\"","180","    X, y, groups = indexable(X, y, groups)","181","","182","    cv = check_cv(cv, y, classifier=is_classifier(estimator))","183","    scorers, _ = _check_multimetric_scoring(estimator, scoring=scoring)","184","","185","    # We clone the estimator to make sure that all the folds are","186","    # independent, and that it is pickle-able.","187","    parallel = Parallel(n_jobs=n_jobs, verbose=verbose,","188","                        pre_dispatch=pre_dispatch)","189","    scores = parallel(","190","        delayed(_fit_and_score)(","191","            clone(estimator), X, y, scorers, train, test, verbose, None,","192","            fit_params, return_train_score=return_train_score,","193","            return_times=True)","194","        for train, test in cv.split(X, y, groups))","195","","196","    if return_train_score:","197","        train_scores, test_scores, fit_times, score_times = zip(*scores)","198","        train_scores = _aggregate_score_dicts(train_scores)","199","    else:","200","        test_scores, fit_times, score_times = zip(*scores)","201","    test_scores = _aggregate_score_dicts(test_scores)","202","","203","    ret = dict()","204","    ret['fit_time'] = np.array(fit_times)","205","    ret['score_time'] = np.array(score_times)","206","","207","    for name in scorers:","208","        ret['test_%s' % name] = np.array(test_scores[name])","209","        if return_train_score:","210","            ret['train_%s' % name] = np.array(train_scores[name])","211","","212","    return ret","228","        The data to fit. Can be for example a list, or an array.","304","    :func:`sklearn.model_selection.cross_validate`:","305","        To run cross-validation on multiple metrics and also to return","306","        train scores, fit times and score times.","307","","312","    # To ensure multimetric format is not supported","314","","315","    cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,","316","                                scoring={'score': scorer}, cv=cv,","317","                                return_train_score=False,","318","                                n_jobs=n_jobs, verbose=verbose,","319","                                fit_params=fit_params,","320","                                pre_dispatch=pre_dispatch)","321","    return cv_results['test_score']","342","    scorer : A single callable or dict mapping scorer name to the callable","343","        If it is a single callable, the return value for ``train_scores`` and","344","        ``test_scores`` is a single float.","345","","346","        For a dict, it should be one mapping the scorer name to the scorer","347","        callable object \/ function.","348","","349","        The callable object \/ fn should have signature","379","    return_n_test_samples : boolean, optional, default: False","380","        Whether to return the ``n_test_samples``","381","","382","    return_times : boolean, optional, default: False","383","        Whether to return the fit\/score times.","384","","387","    train_scores : dict of scorer name -> float, optional","388","        Score on training set (for all the scorers),","389","        returned only if `return_train_score` is `True`.","391","    test_scores : dict of scorer name -> float, optional","392","        Score on testing set (for all the scorers).","419","    test_scores = {}","420","    train_scores = {}","429","    is_multimetric = not callable(scorer)","430","    n_scorers = len(scorer.keys()) if is_multimetric else 1","431","","445","            if is_multimetric:","446","                test_scores = dict(zip(scorer.keys(),","447","                                   [error_score, ] * n_scorers))","448","                if return_train_score:","449","                    train_scores = dict(zip(scorer.keys(),","450","                                        [error_score, ] * n_scorers))","451","            else:","452","                test_scores = error_score","453","                if return_train_score:","454","                    train_scores = error_score","465","        # _score will return dict if is_multimetric is True","466","        test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)","469","            train_scores = _score(estimator, X_train, y_train, scorer,","470","                                  is_multimetric)","473","        if is_multimetric:","474","            for scorer_name, score in test_scores.items():","475","                msg += \", %s=%s\" % (scorer_name, score)","476","        else:","477","            msg += \", score=%s\" % test_scores","483","    ret = [train_scores, test_scores] if return_train_score else [test_scores]","494","def _score(estimator, X_test, y_test, scorer, is_multimetric=False):","495","    \"\"\"Compute the score(s) of an estimator on a given test set.","496","","497","    Will return a single float if is_multimetric is False and a dict of floats,","498","    if is_multimetric is True","499","    \"\"\"","500","    if is_multimetric:","501","        return _multimetric_score(estimator, X_test, y_test, scorer)","503","        if y_test is None:","504","            score = scorer(estimator, X_test)","505","        else:","506","            score = scorer(estimator, X_test, y_test)","507","","508","        if hasattr(score, 'item'):","509","            try:","510","                # e.g. unwrap memmapped scalars","511","                score = score.item()","512","            except ValueError:","513","                # non-scalar?","514","                pass","515","","516","        if not isinstance(score, numbers.Number):","517","            raise ValueError(\"scoring must return a number, got %s (%s) \"","518","                             \"instead. (scorer=%r)\"","519","                             % (str(score), type(score), scorer))","523","def _multimetric_score(estimator, X_test, y_test, scorers):","524","    \"\"\"Return a dict of score for multimetric scoring\"\"\"","525","    scores = {}","526","","527","    for name, scorer in scorers.items():","528","        if y_test is None:","529","            score = scorer(estimator, X_test)","530","        else:","531","            score = scorer(estimator, X_test, y_test)","532","","533","        if hasattr(score, 'item'):","534","            try:","535","                # e.g. unwrap memmapped scalars","536","                score = score.item()","537","            except ValueError:","538","                # non-scalar?","539","                pass","540","        scores[name] = score","541","","542","        if not isinstance(score, numbers.Number):","543","            raise ValueError(\"scoring must return a number, got %s (%s) \"","544","                             \"instead. (scorer=%s)\"","545","                             % (str(score), type(score), name))","546","    return scores","547","","548","","805","        A single string (see :ref:`_scoring_parameter`) or a callable","806","        (see :ref:`_scoring`) to evaluate the predictions on the test set.","807","","808","        If None the estimator's default scorer, if available, is used.","1254","","1255","","1256","def _aggregate_score_dicts(scores):","1257","    \"\"\"Aggregate the list of dict to dict of np ndarray","1258","","1259","    The aggregated output of _fit_and_score will be a list of dict","1260","    of form [{'prec': 0.1, 'acc':1.0}, {'prec': 0.1, 'acc':1.0}, ...]","1261","    Convert it to a dict of array {'prec': np.array([0.1 ...]), ...}","1262","","1263","    Parameters","1264","    ----------","1265","","1266","    scores : list of dict","1267","        List of dicts of the scores for all scorers. This is a flat list,","1268","        assumed originally to be of row major order.","1269","","1270","    Example","1271","    -------","1272","","1273","    >>> scores = [{'a': 1, 'b':10}, {'a': 2, 'b':2}, {'a': 3, 'b':3},","1274","    ...           {'a': 10, 'b': 10}]                         # doctest: +SKIP","1275","    >>> _aggregate_score_dicts(scores)                        # doctest: +SKIP","1276","    {'a': array([1, 2, 3, 10]),","1277","     'b': array([10, 2, 3, 10])}","1278","    \"\"\"","1279","    out = {}","1280","    for key in scores[0]:","1281","        out[key] = np.asarray([score[key] for score in scores])","1282","    return out"],"delete":["5","# Author: Alexandre Gramfort <alexandre.gramfort@inria.fr>,","6","#         Gael Varoquaux <gael.varoquaux@normalesup.org>,","10","","26","from ..metrics.scorer import check_scoring","31","__all__ = ['cross_val_score', 'cross_val_predict', 'permutation_test_score',","32","           'learning_curve', 'validation_curve']","48","        The data to fit. Can be, for example a list, or an array at least 2d.","128","    X, y, groups = indexable(X, y, groups)","129","","130","    cv = check_cv(cv, y, classifier=is_classifier(estimator))","132","    # We clone the estimator to make sure that all the folds are","133","    # independent, and that it is pickle-able.","134","    parallel = Parallel(n_jobs=n_jobs, verbose=verbose,","135","                        pre_dispatch=pre_dispatch)","136","    scores = parallel(delayed(_fit_and_score)(clone(estimator), X, y, scorer,","137","                                              train, test, verbose, None,","138","                                              fit_params)","139","                      for train, test in cv.split(X, y, groups))","140","    return np.array(scores)[:, 0]","161","    scorer : callable","162","        A scorer callable object \/ function with signature","194","    train_score : float, optional","195","        Score on training set, returned only if `return_train_score` is `True`.","197","    test_score : float","198","        Score on test set.","246","            test_score = error_score","247","            if return_train_score:","248","                train_score = error_score","259","        test_score = _score(estimator, X_test, y_test, scorer)","262","            train_score = _score(estimator, X_train, y_train, scorer)","265","        msg += \", score=%f\" % test_score","271","    ret = [train_score, test_score] if return_train_score else [test_score]","282","def _score(estimator, X_test, y_test, scorer):","283","    \"\"\"Compute the score of an estimator on a given test set.\"\"\"","284","    if y_test is None:","285","        score = scorer(estimator, X_test)","287","        score = scorer(estimator, X_test, y_test)","288","    if hasattr(score, 'item'):","289","        try:","290","            # e.g. unwrap memmapped scalars","291","            score = score.item()","292","        except ValueError:","293","            # non-scalar?","294","            pass","295","    if not isinstance(score, numbers.Number):","296","        raise ValueError(\"scoring must return a number, got %s (%s) instead.\"","297","                         % (str(score), type(score)))","557","        A string (see model evaluation documentation) or","558","        a scorer callable object \/ function with signature","559","        ``scorer(estimator, X, y)``.","999",""]}],"doc\/modules\/grid_search.rst":[{"add":["86","    - See :ref:`sphx_glr_auto_examples_model_selection_plot_multi_metric_evaluation`","87","      for an example of :class:`GridSearchCV` being used to evaluate multiple","88","      metrics simultaneously.","89","","167",".. _multimetric_grid_search:","168","","169","Specifying multiple metrics for evaluation","170","------------------------------------------","171","","172","``GridSearchCV`` and ``RandomizedSearchCV`` allow specifying multiple metrics","173","for the ``scoring`` parameter.","174","","175","Multimetric scoring can either be specified as a list of strings of predefined","176","scores names or a dict mapping the scorer name to the scorer function and\/or","177","the predefined scorer name(s). See :ref:`multimetric_scoring` for more details.","178","","179","When specifying multiple metrics, the ``refit`` parameter must be set to the","180","metric (string) for which the ``best_params_`` will be found and used to build","181","the ``best_estimator_`` on the whole dataset. If the search should not be","182","refit, set ``refit=False``. Leaving refit to the default value ``None`` will","183","result in an error when using multiple metrics.","184","","185","See :ref:`sphx_glr_auto_examples_model_selection_plot_multi_metric_evaluation`","186","for an example usage.","187",""],"delete":[]}],"sklearn\/model_selection\/tests\/test_validation.py":[{"add":["18","from sklearn.utils.testing import assert_raises_regex","28","from sklearn.model_selection import cross_validate","46","from sklearn.metrics import accuracy_score","47","from sklearn.metrics import confusion_matrix","48","from sklearn.metrics import precision_recall_fscore_support","50","from sklearn.metrics import r2_score","51","from sklearn.metrics.scorer import check_scoring","65","from sklearn.base import clone","272","def test_cross_validate_invalid_scoring_param():","273","    X, y = make_classification(random_state=0)","274","    estimator = MockClassifier()","275","","276","    # Test the errors","277","    error_message_regexp = \".*must be unique strings.*\"","278","","279","    # List\/tuple of callables should raise a message advising users to use","280","    # dict of names to callables mapping","281","    assert_raises_regex(ValueError, error_message_regexp,","282","                        cross_validate, estimator, X, y,","283","                        scoring=(make_scorer(precision_score),","284","                                 make_scorer(accuracy_score)))","285","    assert_raises_regex(ValueError, error_message_regexp,","286","                        cross_validate, estimator, X, y,","287","                        scoring=(make_scorer(precision_score),))","288","","289","    # So should empty lists\/tuples","290","    assert_raises_regex(ValueError, error_message_regexp + \"Empty list.*\",","291","                        cross_validate, estimator, X, y, scoring=())","292","","293","    # So should duplicated entries","294","    assert_raises_regex(ValueError, error_message_regexp + \"Duplicate.*\",","295","                        cross_validate, estimator, X, y,","296","                        scoring=('f1_micro', 'f1_micro'))","297","","298","    # Nested Lists should raise a generic error message","299","    assert_raises_regex(ValueError, error_message_regexp,","300","                        cross_validate, estimator, X, y,","301","                        scoring=[[make_scorer(precision_score)]])","302","","303","    error_message_regexp = (\".*should either be.*string or callable.*for \"","304","                            \"single.*.*dict.*for multi.*\")","305","","306","    # Empty dict should raise invalid scoring error","307","    assert_raises_regex(ValueError, \"An empty dict\",","308","                        cross_validate, estimator, X, y, scoring=(dict()))","309","","310","    # And so should any other invalid entry","311","    assert_raises_regex(ValueError, error_message_regexp,","312","                        cross_validate, estimator, X, y, scoring=5)","313","","314","    multiclass_scorer = make_scorer(precision_recall_fscore_support)","315","","316","    # Multiclass Scorers that return multiple values are not supported yet","317","    assert_raises_regex(ValueError,","318","                        \"Can't handle mix of binary and continuous\",","319","                        cross_validate, estimator, X, y,","320","                        scoring=multiclass_scorer)","321","    assert_raises_regex(ValueError,","322","                        \"Can't handle mix of binary and continuous\",","323","                        cross_validate, estimator, X, y,","324","                        scoring={\"foo\": multiclass_scorer})","325","","326","    multivalued_scorer = make_scorer(confusion_matrix)","327","","328","    # Multiclass Scorers that return multiple values are not supported yet","329","    assert_raises_regex(ValueError, \"scoring must return a number, got\",","330","                        cross_validate, SVC(), X, y,","331","                        scoring=multivalued_scorer)","332","    assert_raises_regex(ValueError, \"scoring must return a number, got\",","333","                        cross_validate, SVC(), X, y,","334","                        scoring={\"foo\": multivalued_scorer})","335","","336","    assert_raises_regex(ValueError, \"'mse' is not a valid scoring value.\",","337","                        cross_validate, SVC(), X, y, scoring=\"mse\")","338","","339","","340","def test_cross_validate():","341","    # Compute train and test mse\/r2 scores","342","    cv = KFold(n_splits=5)","343","","344","    # Regression","345","    X_reg, y_reg = make_regression(n_samples=30, random_state=0)","346","    reg = Ridge(random_state=0)","347","","348","    # Classification","349","    X_clf, y_clf = make_classification(n_samples=30, random_state=0)","350","    clf = SVC(kernel=\"linear\", random_state=0)","351","","352","    for X, y, est in ((X_reg, y_reg, reg), (X_clf, y_clf, clf)):","353","        # It's okay to evaluate regression metrics on classification too","354","        mse_scorer = check_scoring(est, 'neg_mean_squared_error')","355","        r2_scorer = check_scoring(est, 'r2')","356","        train_mse_scores = []","357","        test_mse_scores = []","358","        train_r2_scores = []","359","        test_r2_scores = []","360","        for train, test in cv.split(X, y):","361","            est = clone(reg).fit(X[train], y[train])","362","            train_mse_scores.append(mse_scorer(est, X[train], y[train]))","363","            train_r2_scores.append(r2_scorer(est, X[train], y[train]))","364","            test_mse_scores.append(mse_scorer(est, X[test], y[test]))","365","            test_r2_scores.append(r2_scorer(est, X[test], y[test]))","366","","367","        train_mse_scores = np.array(train_mse_scores)","368","        test_mse_scores = np.array(test_mse_scores)","369","        train_r2_scores = np.array(train_r2_scores)","370","        test_r2_scores = np.array(test_r2_scores)","371","","372","        scores = (train_mse_scores, test_mse_scores, train_r2_scores,","373","                  test_r2_scores)","374","","375","        yield check_cross_validate_single_metric, est, X, y, scores","376","        yield check_cross_validate_multi_metric, est, X, y, scores","377","","378","","379","def check_cross_validate_single_metric(clf, X, y, scores):","380","    (train_mse_scores, test_mse_scores, train_r2_scores,","381","     test_r2_scores) = scores","382","    # Test single metric evaluation when scoring is string or singleton list","383","    for (return_train_score, dict_len) in ((True, 4), (False, 3)):","384","        # Single metric passed as a string","385","        if return_train_score:","386","            # It must be True by default","387","            mse_scores_dict = cross_validate(clf, X, y, cv=5,","388","                                             scoring='neg_mean_squared_error')","389","            assert_array_almost_equal(mse_scores_dict['train_score'],","390","                                      train_mse_scores)","391","        else:","392","            mse_scores_dict = cross_validate(clf, X, y, cv=5,","393","                                             scoring='neg_mean_squared_error',","394","                                             return_train_score=False)","395","        assert_true(isinstance(mse_scores_dict, dict))","396","        assert_equal(len(mse_scores_dict), dict_len)","397","        assert_array_almost_equal(mse_scores_dict['test_score'],","398","                                  test_mse_scores)","399","","400","        # Single metric passed as a list","401","        if return_train_score:","402","            # It must be True by default","403","            r2_scores_dict = cross_validate(clf, X, y, cv=5, scoring=['r2'])","404","            assert_array_almost_equal(r2_scores_dict['train_r2'],","405","                                      train_r2_scores)","406","        else:","407","            r2_scores_dict = cross_validate(clf, X, y, cv=5, scoring=['r2'],","408","                                            return_train_score=False)","409","        assert_true(isinstance(r2_scores_dict, dict))","410","        assert_equal(len(r2_scores_dict), dict_len)","411","        assert_array_almost_equal(r2_scores_dict['test_r2'], test_r2_scores)","412","","413","","414","def check_cross_validate_multi_metric(clf, X, y, scores):","415","    # Test multimetric evaluation when scoring is a list \/ dict","416","    (train_mse_scores, test_mse_scores, train_r2_scores,","417","     test_r2_scores) = scores","418","    all_scoring = (('r2', 'neg_mean_squared_error'),","419","                   {'r2': make_scorer(r2_score),","420","                    'neg_mean_squared_error': 'neg_mean_squared_error'})","421","","422","    keys_sans_train = set(('test_r2', 'test_neg_mean_squared_error',","423","                           'fit_time', 'score_time'))","424","    keys_with_train = keys_sans_train.union(","425","        set(('train_r2', 'train_neg_mean_squared_error')))","426","","427","    for return_train_score in (True, False):","428","        for scoring in all_scoring:","429","            if return_train_score:","430","                # return_train_score must be True by default","431","                cv_results = cross_validate(clf, X, y, cv=5, scoring=scoring)","432","                assert_array_almost_equal(cv_results['train_r2'],","433","                                          train_r2_scores)","434","                assert_array_almost_equal(","435","                    cv_results['train_neg_mean_squared_error'],","436","                    train_mse_scores)","437","            else:","438","                cv_results = cross_validate(clf, X, y, cv=5, scoring=scoring,","439","                                            return_train_score=False)","440","            assert_true(isinstance(cv_results, dict))","441","            assert_equal(set(cv_results.keys()),","442","                         keys_with_train if return_train_score","443","                         else keys_sans_train)","444","            assert_array_almost_equal(cv_results['test_r2'], test_r2_scores)","445","            assert_array_almost_equal(","446","                cv_results['test_neg_mean_squared_error'], test_mse_scores)","447","","448","            # Make sure all the arrays are of np.ndarray type","449","            assert type(cv_results['test_r2']) == np.ndarray","450","            assert (type(cv_results['test_neg_mean_squared_error']) ==","451","                    np.ndarray)","452","            assert type(cv_results['fit_time'] == np.ndarray)","453","            assert type(cv_results['score_time'] == np.ndarray)","454","","455","            # Ensure all the times are within sane limits","456","            assert np.all(cv_results['fit_time'] >= 0)","457","            assert np.all(cv_results['fit_time'] < 10)","458","            assert np.all(cv_results['score_time'] >= 0)","459","            assert np.all(cv_results['score_time'] < 10)","460","","461","","586","        score = cross_val_score(clf, X, y, scoring=scoring, cv=3)","588","    # Test that score function is called only 3 times (for cv=3)"],"delete":["388","        score = cross_val_score(clf, X, y, scoring=scoring)"]}],"doc\/whats_new.rst":[{"add":["33","   - :class:`model_selection.GridSearchCV` and","34","     :class:`model_selection.RandomizedSearchCV` now support simultaneous","35","     evaluation of multiple metrics. Refer to the","36","     :ref:`multimetric_grid_search` section of the user guide for more","37","     information. :issue:`7388` by `Raghav RV`_","38","","39","   - Added the :func:`model_selection.cross_validate` which allows evaluation","40","     of multiple metrics. This function returns a dict with more useful","41","     information from cross-validation such as the train scores, fit times and","42","     score times.","43","     Refer to :ref:`multimetric_cross_validation` section of the userguide","44","     for more information. :issue:`7388` by `Raghav RV`_","45","     "],"delete":[]}],"doc\/modules\/model_evaluation.rst":[{"add":["212",".. _multimetric_scoring:","213","","214","Using mutiple metric evaluation","215","-------------------------------","216","","217","Scikit-learn also permits evaluation of multiple metrics in ``GridSearchCV``,","218","``RandomizedSearchCV`` and ``cross_validate``.","219","","220","There are two ways to specify multiple scoring metrics for the ``scoring``","221","parameter:","222","","223","- As an iterable of string metrics::","224","      >>> scoring = ['accuracy', 'precision']","225","","226","- As a ``dict`` mapping the scorer name to the scoring function::","227","      >>> from sklearn.metrics import accuracy_score","228","      >>> from sklearn.metrics import make_scorer","229","      >>> scoring = {'accuracy': make_scorer(accuracy_score),","230","      ...            'prec': 'precision'}","231","","232","Note that the dict values can either be scorer functions or one of the","233","predefined metric strings.","234","","235","Currently only those scorer functions that return a single score can be passed","236","inside the dict. Scorer functions that return multiple values are not","237","permitted and will require a wrapper to return a single metric::","238","","239","    >>> from sklearn.model_selection import cross_validate","240","    >>> from sklearn.metrics import confusion_matrix","241","    >>> # A sample toy binary classification dataset","242","    >>> X, y = datasets.make_classification(n_classes=2, random_state=0)","243","    >>> svm = LinearSVC(random_state=0)","244","    >>> tp = lambda y_true, y_pred: confusion_matrix(y_true, y_pred)[0, 0]","245","    >>> tn = lambda y_true, y_pred: confusion_matrix(y_true, y_pred)[0, 0]","246","    >>> fp = lambda y_true, y_pred: confusion_matrix(y_true, y_pred)[1, 0]","247","    >>> fn = lambda y_true, y_pred: confusion_matrix(y_true, y_pred)[0, 1]","248","    >>> scoring = {'tp' : make_scorer(tp), 'tn' : make_scorer(tn),","249","    ...            'fp' : make_scorer(fp), 'fn' : make_scorer(fn)}","250","    >>> cv_results = cross_validate(svm.fit(X, y), X, y, scoring=scoring)","251","    >>> # Getting the test set false positive scores","252","    >>> print(cv_results['test_tp'])          # doctest: +NORMALIZE_WHITESPACE","253","    [12 13 15]","254","    >>> # Getting the test set false negative scores","255","    >>> print(cv_results['test_fn'])          # doctest: +NORMALIZE_WHITESPACE","256","    [5 4 1]"],"delete":[]}],"sklearn\/model_selection\/_search.py":[{"add":["11","#         Raghav RV <rvraghav93@gmail.com>","28","from ._validation import _aggregate_score_dicts","38","from ..metrics.scorer import _check_multimetric_scoring","300","    scorer : callable or None","301","        The scorer callable object \/ function must have its signature as","304","        If ``None`` the estimator's default scorer is used.","305","","321","         Score of this parameter setting on given training \/ test split.","329","    # NOTE we are not using the return value as the scorer by itself should be","330","    # validated before. We use check_scoring only to reject multimetric scorer","331","    check_scoring(estimator, scorer)","332","    scores, n_samples_test = _fit_and_score(estimator, X, y,","333","                                            scorer, train,","334","                                            test, verbose, parameters,","335","                                            fit_params=fit_params,","336","                                            return_n_test_samples=True,","337","                                            error_score=error_score)","338","    return scores, parameters, n_samples_test","430","        self._check_is_fitted('score')","435","        score = self.scorer_[self.refit] if self.multimetric_ else self.scorer_","436","        return score(self.best_estimator_, X, y)","440","            raise NotFittedError('This %s instance was initialized '","441","                                 'with refit=False. %s is '","442","                                 'available only after refitting on the best '","443","                                 'parameters. You can refit an estimator '","444","                                 'manually using the ``best_parameters_`` '","445","                                 'attribute'","446","                                 % (type(self).__name__, method_name))","591","","592","        scorers, self.multimetric_ = _check_multimetric_scoring(","593","            self.estimator, scoring=self.scoring)","594","","595","        if self.multimetric_:","596","            if self.refit is not False and (","597","                    not isinstance(self.refit, six.string_types) or","598","                    # This will work for both dict \/ list (tuple)","599","                    self.refit not in scorers):","600","                raise ValueError(\"For multi-metric scoring, the parameter \"","601","                                 \"refit must be set to a scorer key \"","602","                                 \"to refit an estimator with the best \"","603","                                 \"parameter setting on the whole data and \"","604","                                 \"make the best_* attributes \"","605","                                 \"available for that metric. If this is not \"","606","                                 \"needed, refit should be set to False \"","607","                                 \"explicitly. %r was passed.\" % self.refit)","608","            else:","609","                refit_metric = self.refit","610","        else:","611","            refit_metric = 'score'","629","        )(delayed(_fit_and_score)(clone(base_estimator), X, y, scorers, train,","630","                                  test, self.verbose, parameters,","641","            (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,","644","            (test_score_dicts, test_sample_counts, fit_time,","645","             score_time) = zip(*out)","646","","647","        # test_score_dicts and train_score dicts are lists of dictionaries and","648","        # we make them into dict of lists","649","        test_scores = _aggregate_score_dicts(test_score_dicts)","650","        if self.return_train_score:","651","            train_scores = _aggregate_score_dicts(train_score_dicts)","658","            # We want `array` to have `n_candidates` rows and `n_splits` cols.","663","                    # Uses closure to alter the results","699","        # NOTE test_sample counts (weights) remain the same for all candidates","700","        test_sample_counts = np.array(test_sample_counts[:n_splits],","701","                                      dtype=np.int)","702","        for scorer_name in scorers.keys():","703","            # Computed the (weighted) mean and std for test scores alone","704","            _store('test_%s' % scorer_name, test_scores[scorer_name],","705","                   splits=True, rank=True,","706","                   weights=test_sample_counts if self.iid else None)","707","            if self.return_train_score:","708","                _store('train_%s' % scorer_name, train_scores[scorer_name],","709","                       splits=True)","710","","711","        # For multi-metric evaluation, store the best_index_, best_params_ and","712","        # best_score_ iff refit is one of the scorer names","713","        # In single metric evaluation, refit_metric is \"score\"","714","        if self.refit or not self.multimetric_:","715","            self.best_index_ = results[\"rank_test_%s\" % refit_metric].argmin()","716","            self.best_params_ = candidate_params[self.best_index_]","717","            self.best_score_ = results[\"mean_test_%s\" % refit_metric][","718","                self.best_index_]","721","            self.best_estimator_ = clone(base_estimator).set_params(","722","                **self.best_params_)","724","                self.best_estimator_.fit(X, y, **fit_params)","726","                self.best_estimator_.fit(X, **fit_params)","727","","728","        # Store the only scorer not as a dict for single metric evaluation","729","        self.scorer_ = scorers if self.multimetric_ else scorers['score']","730","","731","        self.cv_results_ = results","732","        self.n_splits_ = n_splits","733","","738","        check_is_fitted(self, 'cv_results_')","739","        if self.multimetric_:","740","            raise AttributeError(\"grid_scores_ attribute is not available for\"","741","                                 \" multi-metric evaluation.\")","792","    scoring : string, callable, list\/tuple, dict or None, default: None","793","        A single string (see :ref:`scoring_parameter`) or a callable","794","        (see :ref:`scoring`) to evaluate the predictions on the test set.","795","","796","        For evaluating multiple metrics, either give a list of (unique) strings","797","        or a dict with names as keys and callables as values.","798","","799","        NOTE that when using custom scorers, each scorer should return a single","800","        value. Metric functions returning a list\/array of values can be wrapped","801","        into multiple scorers that return one value each.","802","","803","        See :ref:`multivalued_scorer_wrapping` for an example.","804","","805","        If None, the estimator's default scorer (if available) is used.","855","    refit : boolean, or string, default=True","856","        Refit an estimator using the best found parameters on the whole","857","        dataset.","858","","859","        For multiple metric evaluation, this needs to be a string denoting the","860","        scorer is used to find the best parameters for refitting the estimator","861","        at the end.","862","","863","        The refitted estimator is made available at the ``best_estimator_``","864","        attribute and permits using ``predict`` directly on this","865","        ``GridSearchCV`` instance.","866","","867","        Also for multiple metric evaluation, the attributes ``best_index_``,","868","        ``best_score_`` and ``best_parameters_`` will only be available if","869","        ``refit`` is set and all of them will be determined w.r.t this specific","870","        scorer.","871","","872","        See ``scoring`` parameter to know more about multiple metric","873","        evaluation.","926","        |param_kernel|param_gamma|param_degree|split0_test_score|...|..rank...|","962","        NOTE","963","","964","        The key ``'params'`` is used to store a list of parameter","965","        settings dicts for all the parameter candidates.","970","        For multi-metric evaluation, the scores for all the scorers are","971","        available in the ``cv_results_`` dict at the keys ending with that","972","        scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown","973","        above. ('split0_test_precision', 'mean_train_precision' etc.)","974","","975","    best_estimator_ : estimator or dict","978","        on the left out data. Not available if ``refit=False``.","979","","980","        See ``refit`` parameter for more information on allowed values.","983","        Mean cross-validated score of the best_estimator","984","","985","        For multi-metric evaluation, this is present only if ``refit`` is","986","        specified.","991","        For multi-metric evaluation, this is present only if ``refit`` is","992","        specified.","993","","1002","        For multi-metric evaluation, this is present only if ``refit`` is","1003","        specified.","1004","","1005","    scorer_ : function or a dict","1009","        For multi-metric evaluation, this attribute holds the validated","1010","        ``scoring`` dict which maps the scorer key to the scorer callable.","1011","","1102","    scoring : string, callable, list\/tuple, dict or None, default: None","1103","        A single string (see :ref:`scoring_parameter`) or a callable","1104","        (see :ref:`scoring`) to evaluate the predictions on the test set.","1105","","1106","        For evaluating multiple metrics, either give a list of (unique) strings","1107","        or a dict with names as keys and callables as values.","1108","","1109","        NOTE that when using custom scorers, each scorer should return a single","1110","        value. Metric functions returning a list\/array of values can be wrapped","1111","        into multiple scorers that return one value each.","1112","","1113","        See :ref:`multivalued_scorer_wrapping` for an example.","1114","","1115","        If None, the estimator's default scorer (if available) is used.","1165","    refit : boolean, or string default=True","1166","        Refit an estimator using the best found parameters on the whole","1167","        dataset.","1168","","1169","        For multiple metric evaluation, this needs to be a string denoting the","1170","        scorer that would be used to find the best parameters for refitting","1171","        the estimator at the end.","1172","","1173","        The refitted estimator is made available at the ``best_estimator_``","1174","        attribute and permits using ``predict`` directly on this","1175","        ``RandomizedSearchCV`` instance.","1176","","1177","        Also for multiple metric evaluation, the attributes ``best_index_``,","1178","        ``best_score_`` and ``best_parameters_`` will only be available if","1179","        ``refit`` is set and all of them will be determined w.r.t this specific","1180","        scorer.","1181","","1182","        See ``scoring`` parameter to know more about multiple metric","1183","        evaluation.","1243","            'params'             : [{'kernel' : 'rbf', 'gamma' : 0.1}, ...],","1246","        NOTE","1247","","1248","        The key ``'params'`` is used to store a list of parameter","1249","        settings dicts for all the parameter candidates.","1254","        For multi-metric evaluation, the scores for all the scorers are","1255","        available in the ``cv_results_`` dict at the keys ending with that","1256","        scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown","1257","        above. ('split0_test_precision', 'mean_train_precision' etc.)","1258","","1259","    best_estimator_ : estimator or dict","1262","        on the left out data. Not available if ``refit=False``.","1263","","1264","        For multi-metric evaluation, this attribute is present only if","1265","        ``refit`` is specified.","1266","","1267","        See ``refit`` parameter for more information on allowed values.","1270","        Mean cross-validated score of the best_estimator.","1271","","1272","        For multi-metric evaluation, this is not available if ``refit`` is","1273","        ``False``. See ``refit`` parameter for more information.","1278","        For multi-metric evaluation, this is not available if ``refit`` is","1279","        ``False``. See ``refit`` parameter for more information.","1280","","1289","        For multi-metric evaluation, this is not available if ``refit`` is","1290","        ``False``. See ``refit`` parameter for more information.","1291","","1292","    scorer_ : function or a dict","1296","        For multi-metric evaluation, this attribute holds the validated","1297","        ``scoring`` dict which maps the scorer key to the scorer callable.","1298",""],"delete":["297","    scorer : callable or None.","298","        If provided must be a scorer callable object \/ function with signature","316","        Score of this parameter setting on given training \/ test split.","324","    score, n_samples_test, _ = _fit_and_score(estimator, X, y, scorer, train,","325","                                              test, verbose, parameters,","326","                                              fit_params=fit_params,","327","                                              return_n_test_samples=True,","328","                                              error_score=error_score)","329","    return score, parameters, n_samples_test","425","        return self.scorer_(self.best_estimator_, X, y)","429","            raise NotFittedError(('This GridSearchCV instance was initialized '","430","                                  'with refit=False. %s is '","431","                                  'available only after refitting on the best '","432","                                  'parameters. ') % method_name)","577","        self.scorer_ = check_scoring(self.estimator, scoring=self.scoring)","595","        )(delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,","596","                                  train, test, self.verbose, parameters,","607","            (train_scores, test_scores, test_sample_counts, fit_time,","610","            (test_scores, test_sample_counts, fit_time, score_time) = zip(*out)","636","        # Computed the (weighted) mean and std for test scores alone","637","        # NOTE test_sample counts (weights) remain the same for all candidates","638","        test_sample_counts = np.array(test_sample_counts[:n_splits],","639","                                      dtype=np.int)","640","","641","        _store('test_score', test_scores, splits=True, rank=True,","642","               weights=test_sample_counts if self.iid else None)","643","        if self.return_train_score:","644","            _store('train_score', train_scores, splits=True)","647","","648","        best_index = np.flatnonzero(results[\"rank_test_score\"] == 1)[0]","649","        best_parameters = candidate_params[best_index]","650","","666","","670","        self.cv_results_ = results","671","        self.best_index_ = best_index","672","        self.n_splits_ = n_splits","675","            # fit the best estimator using the entire dataset","676","            # clone first to work around broken estimators","677","            best_estimator = clone(base_estimator).set_params(","678","                **best_parameters)","680","                best_estimator.fit(X, y, **fit_params)","682","                best_estimator.fit(X, **fit_params)","683","            self.best_estimator_ = best_estimator","687","    def best_params_(self):","688","        check_is_fitted(self, 'cv_results_')","689","        return self.cv_results_['params'][self.best_index_]","690","","691","    @property","692","    def best_score_(self):","693","        check_is_fitted(self, 'cv_results_')","694","        return self.cv_results_['mean_test_score'][self.best_index_]","695","","696","    @property","704","        check_is_fitted(self, 'cv_results_')","749","    scoring : string, callable or None, default=None","750","        A string (see model evaluation documentation) or","751","        a scorer callable object \/ function with signature","752","        ``scorer(estimator, X, y)``.","753","        If ``None``, the ``score`` method of the estimator is used.","803","    refit : boolean, default=True","804","        Refit the best estimator with the entire dataset.","805","        If \"False\", it is impossible to make predictions using","806","        this GridSearchCV instance after fitting.","859","        |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_....|","895","        NOTE that the key ``'params'`` is used to store a list of parameter","896","        settings dict for all the parameter candidates.","901","    best_estimator_ : estimator","904","        on the left out data. Not available if refit=False.","907","        Score of best_estimator on the left out data.","920","    scorer_ : function","1014","    scoring : string, callable or None, default=None","1015","        A string (see model evaluation documentation) or","1016","        a scorer callable object \/ function with signature","1017","        ``scorer(estimator, X, y)``.","1018","        If ``None``, the ``score`` method of the estimator is used.","1068","    refit : boolean, default=True","1069","        Refit the best estimator with the entire dataset.","1070","        If \"False\", it is impossible to make predictions using","1071","        this RandomizedSearchCV instance after fitting.","1131","            'params' : [{'kernel' : 'rbf', 'gamma' : 0.1}, ...],","1134","        NOTE that the key ``'params'`` is used to store a list of parameter","1135","        settings dict for all the parameter candidates.","1140","    best_estimator_ : estimator","1143","        on the left out data. Not available if refit=False.","1146","        Score of best_estimator on the left out data.","1159","    scorer_ : function"]}]}},"74a9756fa784d1f22873ad23c8b4948c6e290108":{"changes":{"sklearn\/utils\/fixes.py":"MODIFY","sklearn\/utils\/tests\/test_fixes.py":"MODIFY","doc\/whats_new.rst":"MODIFY","sklearn\/feature_selection\/from_model.py":"MODIFY","sklearn\/feature_selection\/tests\/test_from_model.py":"MODIFY"},"diff":{"sklearn\/utils\/fixes.py":[{"add":["421","","422","if 'axis' not in signature(np.linalg.norm).parameters:","423","","424","    def norm(X, ord=None, axis=None):","425","        \"\"\"","426","        Handles the axis parameter for the norm function","427","        in old versions of numpy (useless for numpy >= 1.8).","428","        \"\"\"","429","","430","        if axis is None or X.ndim == 1:","431","            result = np.linalg.norm(X, ord=ord)","432","            return result","433","","434","        if axis not in (0, 1):","435","            raise NotImplementedError(\"\"\"","436","            The fix that adds axis parameter to the old numpy","437","            norm only works for 1D or 2D arrays.","438","            \"\"\")","439","","440","        if axis == 0:","441","            X = X.T","442","","443","        result = np.zeros(X.shape[0])","444","        for i in range(len(result)):","445","            result[i] = np.linalg.norm(X[i], ord=ord)","446","","447","        return result","448","","449","else:","450","    norm = np.linalg.norm"],"delete":[]}],"sklearn\/utils\/tests\/test_fixes.py":[{"add":["7","import math","19","from sklearn.utils.fixes import norm","70","","71","","72","def test_norm():","73","    X = np.array([[-2, 4, 5],","74","                  [1, 3, -4],","75","                  [0, 0, 8],","76","                  [0, 0, 0]]).astype(float)","77","","78","    # Test various axis and order","79","    assert_equal(math.sqrt(135), norm(X))","80","    assert_array_equal(","81","        np.array([math.sqrt(5), math.sqrt(25), math.sqrt(105)]),","82","        norm(X, axis=0)","83","    )","84","    assert_array_equal(np.array([3, 7, 17]), norm(X, axis=0, ord=1))","85","    assert_array_equal(np.array([2, 4, 8]), norm(X, axis=0, ord=np.inf))","86","    assert_array_equal(np.array([0, 0, 0]), norm(X, axis=0, ord=-np.inf))","87","    assert_array_equal(np.array([11, 8, 8, 0]), norm(X, axis=1, ord=1))","88","","89","    # Test shapes","90","    assert_equal((), norm(X).shape)","91","    assert_equal((3,), norm(X, axis=0).shape)","92","    assert_equal((4,), norm(X, axis=1).shape)"],"delete":[]}],"doc\/whats_new.rst":[{"add":["54","   - Added ``norm_order`` parameter to :class:`feature_selection.SelectFromModel`","55","     to enable selection of the norm order when ``coef_`` is more than 1D","56",""],"delete":[]}],"sklearn\/feature_selection\/from_model.py":[{"add":["12","from ..utils.fixes import norm","15","def _get_feature_importances(estimator, norm_order=1):","24","            importances = norm(estimator.coef_, axis=0, ord=norm_order)","175","    norm_order : non-zero int, inf, -inf, default 1","176","        Order of the norm used to filter the vectors of coefficients below","177","        ``threshold`` in the case where the ``coef_`` attribute of the","178","        estimator is of dimension 2.","179","","190","","191","    def __init__(self, estimator, threshold=None, prefit=False, norm_order=1):","195","        self.norm_order = norm_order","207","        scores = _get_feature_importances(estimator, self.norm_order)"],"delete":["14","def _get_feature_importances(estimator):","23","            importances = np.sum(np.abs(estimator.coef_), axis=0)","184","    def __init__(self, estimator, threshold=None, prefit=False):","199","        scores = _get_feature_importances(estimator)"]}],"sklearn\/feature_selection\/tests\/test_from_model.py":[{"add":["19","from sklearn.utils.fixes import norm","105","@skip_if_32bit","106","def test_feature_importances_2d_coef():","107","    X, y = datasets.make_classification(","108","        n_samples=1000, n_features=10, n_informative=3, n_redundant=0,","109","        n_repeated=0, shuffle=False, random_state=0, n_classes=4)","110","","111","    est = LogisticRegression()","112","    for threshold, func in zip([\"mean\", \"median\"], [np.mean, np.median]):","113","        for order in [1, 2, np.inf]:","114","            # Fit SelectFromModel a multi-class problem","115","            transformer = SelectFromModel(estimator=LogisticRegression(),","116","                                          threshold=threshold,","117","                                          norm_order=order)","118","            transformer.fit(X, y)","119","            assert_true(hasattr(transformer.estimator_, 'coef_'))","120","            X_new = transformer.transform(X)","121","            assert_less(X_new.shape[1], X.shape[1])","122","","123","            # Manually check that the norm is correctly performed","124","            est.fit(X, y)","125","            importances = norm(est.coef_, axis=0, ord=order)","126","            feature_mask = importances > func(importances)","127","            assert_array_equal(X_new, X[:, feature_mask])","128","","129",""],"delete":[]}]}},"913967b6ee83420285c8472604aad91621f04e7f":{"changes":{"sklearn\/svm\/libsvm_sparse.pyx":"MODIFY"},"diff":{"sklearn\/svm\/libsvm_sparse.pyx":[{"add":["400","        raise MemoryError(\"We've run out of memory\")"],"delete":["400","        raise MemoryError(\"We've run out of of memory\")"]}]}},"c31ad7ada3d46f8b8119685b91d1562f8e710b09":{"changes":{"sklearn\/gaussian_process\/kernels.py":"MODIFY","sklearn\/gaussian_process\/tests\/test_kernels.py":"MODIFY"},"diff":{"sklearn\/gaussian_process\/kernels.py":[{"add":["35","def _check_length_scale(X, length_scale):","36","    length_scale = np.squeeze(length_scale).astype(float)","37","    if np.ndim(length_scale) > 1:","38","        raise ValueError(\"length_scale cannot be of dimension greater than 1\")","39","    if np.ndim(length_scale) == 1 and X.shape[1] != length_scale.shape[0]:","40","        raise ValueError(\"Anisotropic kernel must have the same number of \"","41","                         \"dimensions as data (%d!=%d)\"","42","                         % (length_scale.shape[0], X.shape[1]))","43","    return length_scale","44","","45","","105","    # This is mainly a testing utility to check that two hyperparameters","106","    # are equal.","107","    def __eq__(self, other):","108","        return (self.name == other.name and","109","                self.value_type == other.value_type and","110","                np.all(self.bounds == other.bounds) and","111","                self.n_elements == other.n_elements and","112","                self.fixed == other.fixed)","113","","209","        for attr in dir(self):","211","                r.append(getattr(self, attr))","229","        params = self.get_params()","232","                theta.append(params[hyperparameter.name])","247","        params = self.get_params()","254","                params[hyperparameter.name] = np.exp(","255","                    theta[i:i + hyperparameter.n_elements])","258","                params[hyperparameter.name] = np.exp(theta[i])","265","        self.set_params(**params)","935","    @property","936","    def hyperparameter_constant_value(self):","937","        return Hyperparameter(","938","            \"constant_value\", \"numeric\", self.constant_value_bounds)","1026","    @property","1027","    def hyperparameter_noise_level(self):","1028","        return Hyperparameter(","1029","            \"noise_level\", \"numeric\", self.noise_level_bounds)","1124","        self.length_scale = length_scale","1127","    @property","1128","    def anisotropic(self):","1129","        return np.iterable(self.length_scale) and len(self.length_scale) > 1","1130","","1131","    @property","1132","    def hyperparameter_length_scale(self):","1133","        if self.anisotropic:","1134","            return Hyperparameter(\"length_scale\", \"numeric\",","1135","                                  self.length_scale_bounds,","1136","                                  len(self.length_scale))","1137","        return Hyperparameter(","1138","            \"length_scale\", \"numeric\", self.length_scale_bounds)","1167","        length_scale = _check_length_scale(X, self.length_scale)","1169","            dists = pdist(X \/ length_scale, metric='sqeuclidean')","1178","            dists = cdist(X \/ length_scale, Y \/ length_scale,","1186","            elif not self.anisotropic or length_scale.shape[0] == 1:","1193","                    \/ (length_scale ** 2)","1277","        length_scale = _check_length_scale(X, self.length_scale)","1279","            dists = pdist(X \/ length_scale, metric='euclidean')","1284","            dists = cdist(X \/ length_scale, Y \/ length_scale,","1317","                    \/ (length_scale ** 2)","1387","    @property","1388","    def hyperparameter_length_scale(self):","1389","        return Hyperparameter(","1390","            \"length_scale\", \"numeric\", self.length_scale_bounds)","1391","","1392","    @property","1393","    def hyperparameter_alpha(self):","1394","        return Hyperparameter(\"alpha\", \"numeric\", self.alpha_bounds)","1496","    @property","1497","    def hyperparameter_length_scale(self):","1498","        return Hyperparameter(","1499","            \"length_scale\", \"numeric\", self.length_scale_bounds)","1500","","1501","    @property","1502","    def hyperparameter_periodicity(self):","1503","        return Hyperparameter(","1504","            \"periodicity\", \"numeric\", self.periodicity_bounds)","1602","    @property","1603","    def hyperparameter_sigma_0(self):","1604","        return Hyperparameter(\"sigma_0\", \"numeric\", self.sigma_0_bounds)","1732","        self.pairwise_kernels_kwargs = pairwise_kernels_kwargs","1733","","1734","    @property","1735","    def hyperparameter_gamma(self):","1736","        return Hyperparameter(\"gamma\", \"numeric\", self.gamma_bounds)","1764","        pairwise_kernels_kwargs = self.pairwise_kernels_kwargs","1765","        if self.pairwise_kernels_kwargs is None:","1766","            pairwise_kernels_kwargs = {}","1767","","1771","                             **pairwise_kernels_kwargs)","1780","                        filter_params=True, **pairwise_kernels_kwargs)"],"delete":["189","        for attr, value in sorted(self.__dict__.items()):","191","                r.append(value)","211","                theta.append(getattr(self, hyperparameter.name))","232","                setattr(self, hyperparameter.name,","233","                        np.exp(theta[i:i + hyperparameter.n_elements]))","236","                setattr(self, hyperparameter.name, np.exp(theta[i]))","912","        self.hyperparameter_constant_value = \\","913","            Hyperparameter(\"constant_value\", \"numeric\", constant_value_bounds)","1001","        self.hyperparameter_noise_level = \\","1002","            Hyperparameter(\"noise_level\", \"numeric\", noise_level_bounds)","1097","        if np.iterable(length_scale):","1098","            if len(length_scale) > 1:","1099","                self.anisotropic = True","1100","                self.length_scale = np.asarray(length_scale, dtype=np.float)","1101","            else:","1102","                self.anisotropic = False","1103","                self.length_scale = float(length_scale[0])","1104","        else:","1105","            self.anisotropic = False","1106","            self.length_scale = float(length_scale)","1109","        if self.anisotropic:  # anisotropic length_scale","1110","            self.hyperparameter_length_scale = \\","1111","                Hyperparameter(\"length_scale\", \"numeric\", length_scale_bounds,","1112","                               len(length_scale))","1113","        else:","1114","            self.hyperparameter_length_scale = \\","1115","                Hyperparameter(\"length_scale\", \"numeric\", length_scale_bounds)","1144","        if self.anisotropic and X.shape[1] != self.length_scale.shape[0]:","1145","            raise Exception(\"Anisotropic kernel must have the same number of \"","1146","                            \"dimensions as data (%d!=%d)\"","1147","                            % (self.length_scale.shape[0], X.shape[1]))","1148","","1150","            dists = pdist(X \/ self.length_scale, metric='sqeuclidean')","1159","            dists = cdist(X \/ self.length_scale, Y \/ self.length_scale,","1167","            elif not self.anisotropic or self.length_scale.shape[0] == 1:","1174","                    \/ (self.length_scale ** 2)","1177","            else:","1178","                raise Exception(\"Anisotropic kernels require that the number \"","1179","                                \"of length scales and features match.\")","1261","        if self.anisotropic and X.shape[1] != self.length_scale.shape[0]:","1262","            raise Exception(\"Anisotropic kernel must have the same number of \"","1263","                            \"dimensions as data (%d!=%d)\"","1264","                            % (self.length_scale.shape[0], X.shape[1]))","1265","","1267","            dists = pdist(X \/ self.length_scale, metric='euclidean')","1272","            dists = cdist(X \/ self.length_scale, Y \/ self.length_scale,","1305","                    \/ (self.length_scale ** 2)","1375","        self.hyperparameter_length_scale = \\","1376","            Hyperparameter(\"length_scale\", \"numeric\", length_scale_bounds)","1377","        self.hyperparameter_alpha = \\","1378","            Hyperparameter(\"alpha\", \"numeric\", alpha_bounds)","1480","        self.hyperparameter_length_scale = \\","1481","            Hyperparameter(\"length_scale\", \"numeric\", length_scale_bounds)","1482","        self.hyperparameter_periodicity = \\","1483","            Hyperparameter(\"periodicity\", \"numeric\", periodicity_bounds)","1581","        self.hyperparameter_sigma_0 = \\","1582","            Hyperparameter(\"sigma_0\", \"numeric\", sigma_0_bounds)","1709","","1710","        self.hyperparameter_gamma = \\","1711","            Hyperparameter(\"gamma\", \"numeric\", gamma_bounds)","1712","","1714","        if pairwise_kernels_kwargs is not None:","1715","            self.pairwise_kernels_kwargs = pairwise_kernels_kwargs","1716","        else:","1717","            self.pairwise_kernels_kwargs = {}","1748","                             **self.pairwise_kernels_kwargs)","1757","                        filter_params=True, **self.pairwise_kernels_kwargs)"]}],"sklearn\/gaussian_process\/tests\/test_kernels.py":[{"add":["185","def check_hyperparameters_equal(kernel1, kernel2):","186","    \"\"\"Check that hyperparameters of two kernels are equal\"\"\"","187","    for attr in set(dir(kernel1) + dir(kernel2)):","188","        if attr.startswith(\"hyperparameter_\"):","189","            attr_value1 = getattr(kernel1, attr)","190","            attr_value2 = getattr(kernel2, attr)","191","            assert_equal(attr_value1, attr_value2)","192","","193","","196","    bounds = (1e-5, 1e5)","200","        # XXX: Should this be fixed?","201","        # This differs from the sklearn's estimators equality check.","204","","205","        # Check that all constructor parameters are equal.","206","        assert_equal(kernel.get_params(), kernel_cloned.get_params())","207","","208","        # Check that all hyperparameters are equal.","209","        yield check_hyperparameters_equal, kernel, kernel_cloned","210","","211","        # This test is to verify that using set_params does not","212","        # break clone on kernels.","213","        # This used to break because in kernels such as the RBF, non-trivial","214","        # logic that modified the length scale used to be in the constructor","215","        # See https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/6961","216","        # for more details.","217","        params = kernel.get_params()","218","        # RationalQuadratic kernel is isotropic.","219","        isotropic_kernels = (ExpSineSquared, RationalQuadratic)","220","        if 'length_scale' in params and not isinstance(kernel, isotropic_kernels):","221","            length_scale = params['length_scale']","222","            if np.iterable(length_scale):","223","                params['length_scale'] = length_scale[0]","224","                params['length_scale_bounds'] = bounds","226","                params['length_scale'] = [length_scale] * 2","227","                params['length_scale_bounds'] = bounds * 2","228","            kernel_cloned.set_params(**params)","229","            kernel_cloned_clone = clone(kernel_cloned)","230","            assert_equal(kernel_cloned_clone.get_params(),","231","                         kernel_cloned.get_params())","232","            assert_not_equal(id(kernel_cloned_clone), id(kernel_cloned))","233","            yield check_hyperparameters_equal, kernel_cloned, kernel_cloned_clone"],"delete":["192","        for attr in kernel.__dict__.keys():","193","            attr_value = getattr(kernel, attr)","194","            attr_value_cloned = getattr(kernel_cloned, attr)","195","            if attr.startswith(\"hyperparameter_\"):","196","                assert_equal(attr_value.name, attr_value_cloned.name)","197","                assert_equal(attr_value.value_type,","198","                             attr_value_cloned.value_type)","199","                assert_array_equal(attr_value.bounds,","200","                                   attr_value_cloned.bounds)","201","                assert_equal(attr_value.n_elements,","202","                             attr_value_cloned.n_elements)","203","            elif np.iterable(attr_value):","204","                for i in range(len(attr_value)):","205","                    if np.iterable(attr_value[i]):","206","                        assert_array_equal(attr_value[i],","207","                                           attr_value_cloned[i])","208","                    else:","209","                        assert_equal(attr_value[i], attr_value_cloned[i])","211","                assert_equal(attr_value, attr_value_cloned)","212","            if not isinstance(attr_value, Hashable):","213","                # modifiable attributes must not be identical","214","                assert_not_equal(id(attr_value), id(attr_value_cloned))"]}]}},"bd99858a92858e1fde0d4eb678b0d35591ebca01":{"changes":{"sklearn\/model_selection\/_validation.py":"MODIFY","sklearn\/cross_validation.py":"MODIFY"},"diff":{"sklearn\/model_selection\/_validation.py":[{"add":["138","    Examples","139","    --------","140","    >>> from sklearn import datasets, linear_model","141","    >>> from sklearn.cross_validation import cross_val_score","142","    >>> diabetes = datasets.load_diabetes()","143","    >>> X = diabetes.data[:150]","144","    >>> y = diabetes.target[:150]","145","    >>> lasso = linear_model.Lasso()","146","    >>> print(cross_val_score(lasso, X, y))  # doctest: +ELLIPSIS","147","    [ 0.33150734  0.08022311  0.03531764]","148","","377","","378","    Examples","379","    --------","380","    >>> from sklearn import datasets, linear_model","381","    >>> from sklearn.cross_validation import cross_val_predict","382","    >>> diabetes = datasets.load_diabetes()","383","    >>> X = diabetes.data[:150]","384","    >>> y = diabetes.target[:150]","385","    >>> lasso = linear_model.Lasso()","386","    >>> y_pred = cross_val_predict(lasso, X, y)"],"delete":[]}],"sklearn\/cross_validation.py":[{"add":["1265","","1266","    Examples","1267","    --------","1268","    >>> from sklearn import datasets, linear_model","1269","    >>> from sklearn.cross_validation import cross_val_predict","1270","    >>> diabetes = datasets.load_diabetes()","1271","    >>> X = diabetes.data[:150]","1272","    >>> y = diabetes.target[:150]","1273","    >>> lasso = linear_model.Lasso()","1274","    >>> y_pred = cross_val_predict(lasso, X, y)","1451","    Examples","1452","    --------","1453","    >>> from sklearn import datasets, linear_model","1454","    >>> from sklearn.cross_validation import cross_val_score","1455","    >>> diabetes = datasets.load_diabetes()","1456","    >>> X = diabetes.data[:150]","1457","    >>> y = diabetes.target[:150]","1458","    >>> lasso = linear_model.Lasso()","1459","    >>> print(cross_val_score(lasso, X, y))  # doctest:  +ELLIPSIS","1460","    [ 0.33150734  0.08022311  0.03531764]","1461",""],"delete":[]}]}},"c98adf7d580d87c0241568fa178c2afd08afc847":{"changes":{"sklearn\/datasets\/base.py":"MODIFY","doc\/whats_new.rst":"MODIFY","sklearn\/datasets\/tests\/test_base.py":"MODIFY"},"diff":{"sklearn\/datasets\/base.py":[{"add":["320","def load_breast_cancer(return_X_y=False):","334","    Parameters","335","    ----------","336","    return_X_y : boolean, default=False","337","        If True, returns ``(data, target)`` instead of a Bunch object.","338","        See below for more information about the `data` and `target` object.","339","","340","    .. versionadded:: 0.18","341","","351","    (data, target) : tuple if ``return_X_y`` is True","352","","353","    .. versionadded:: 0.18","354","","404","    if return_X_y:","405","        return data, target","406",""],"delete":["320","def load_breast_cancer():"]}],"doc\/whats_new.rst":[{"add":["233","     :func:`load_iris` dataset, ","234","     (`#7049 <https:\/\/github.com\/scikit-learn\/scikit-learn\/pull\/7049>`_)","235","     :func:`load_breast_cancer` dataset","236","     (`#7152 <https:\/\/github.com\/scikit-learn\/scikit-learn\/pull\/7152>`_) by"],"delete":["233","     :func:`load_iris` dataset.","234","     (`#7049 <https:\/\/github.com\/scikit-learn\/scikit-learn\/pull\/7049>`_) by"]}],"sklearn\/datasets\/tests\/test_base.py":[{"add":["198","    # test return_X_y option","199","    X_y_tuple = load_breast_cancer(return_X_y=True)","200","    bunch = load_breast_cancer()","201","    assert_true(isinstance(X_y_tuple, tuple))","202","    assert_array_equal(X_y_tuple[0], bunch.data)","203","    assert_array_equal(X_y_tuple[1], bunch.target)","204",""],"delete":[]}]}},"70d7fecaab23095cf3793977d3c15d1a21a7a868":{"changes":{"sklearn\/model_selection\/tests\/test_validation.py":"MODIFY"},"diff":{"sklearn\/model_selection\/tests\/test_validation.py":[{"add":["7","from time import sleep","65","try:","66","    WindowsError","67","except NameError:","68","    WindowsError = None","69","","70","","790","    scores = np.memmap(tf.name, dtype=np.float64)","791","    score = np.memmap(tf.name, shape=(), mode='r', dtype=np.float64)","798","        # Best effort to release the mmap file handles before deleting the","799","        # backing file under Windows","800","        scores, score = None, None","801","        for _ in range(3):","802","            try:","803","                os.unlink(tf.name)","804","                break","805","            except WindowsError:","806","                sleep(1.)"],"delete":["783","    scores = np.memmap(tf.name, dtype=float)","784","    score = np.memmap(tf.name, shape=(), mode='w+', dtype=float)","791","        os.unlink(tf.name)"]}]}},"376aa50e70d7b45e115e01654bc0a91b5cb9b60d":{"changes":{"sklearn\/tree\/_tree.pxd":"MODIFY","sklearn\/tree\/tree.py":"MODIFY","sklearn\/ensemble\/gradient_boosting.py":"MODIFY","doc\/whats_new.rst":"MODIFY","sklearn\/tree\/_tree.pyx":"MODIFY","sklearn\/ensemble\/forest.py":"MODIFY","sklearn\/tree\/tests\/test_tree.py":"MODIFY"},"diff":{"sklearn\/tree\/_tree.pxd":[{"add":["6","#          Nelson Liu <nelson@nelsonliu.me>","98","    cdef double min_impurity_split  # Impurity threshold for early stopping"],"delete":[]}],"sklearn\/tree\/tree.py":[{"add":["12","#          Nelson Liu <nelson@nelsonliu.me>","92","                 min_impurity_split,","104","        self.min_impurity_split = min_impurity_split","309","        if self.min_impurity_split < 0.:","310","            raise ValueError(\"min_impurity_split must be greater than or equal \"","311","                             \"to 0\")","312","","368","                                            max_depth, self.min_impurity_split)","374","                                           max_leaf_nodes, self.min_impurity_split)","617","    min_impurity_split : float, optional (default=1e-7)","618","        Threshold for early stopping in tree growth. A node will split","619","        if its impurity is above the threshold, otherwise it is a leaf.","620","","698","                 min_impurity_split=1e-7,","712","            min_impurity_split=min_impurity_split,","863","    min_impurity_split : float, optional (default=1e-7)","864","        Threshold for early stopping in tree growth. If the impurity","865","        of a node is below the threshold, the node is a leaf.","866","","936","                 min_impurity_split=1e-7,","948","            min_impurity_split=min_impurity_split,","986","                 min_impurity_split=1e-7,","998","            min_impurity_split=min_impurity_split,","1035","                 min_impurity_split=1e-7,","1046","            min_impurity_split=min_impurity_split,"],"delete":["361","                                            max_depth)","367","                                           max_leaf_nodes)"]}],"sklearn\/ensemble\/gradient_boosting.py":[{"add":["724","                 max_depth, min_impurity_split, init, subsample, max_features,","738","        self.min_impurity_split = min_impurity_split","1361","    min_impurity_split : float, optional (default=1e-7)","1362","        Threshold for early stopping in tree growth. A node will split","1363","        if its impurity is above the threshold, otherwise it is a leaf.","1364","","1444","                 max_depth=3, min_impurity_split=1e-7, init=None,","1445","                 random_state=None, max_features=None, verbose=0,","1457","            max_leaf_nodes=max_leaf_nodes,","1458","            min_impurity_split=min_impurity_split,","1459","            warm_start=warm_start,","1720","    min_impurity_split : float, optional (default=1e-7)","1721","        Threshold for early stopping in tree growth. A node will split","1722","        if its impurity is above the threshold, otherwise it is a leaf.","1723","","1804","                 max_depth=3, min_impurity_split=1e-7, init=None, random_state=None,","1814","            max_features=max_features, min_impurity_split=min_impurity_split,"],"delete":["724","                 max_depth, init, subsample, max_features,","1439","                 max_depth=3, init=None, random_state=None,","1440","                 max_features=None, verbose=0,","1452","            max_leaf_nodes=max_leaf_nodes, warm_start=warm_start,","1793","                 max_depth=3, init=None, random_state=None,","1803","            max_features=max_features,"]}],"doc\/whats_new.rst":[{"add":["127","     - Added weighted impurity-based early stopping criterion for decision tree","128","       growth. (`#6954","129","       <https:\/\/github.com\/scikit-learn\/scikit-learn\/pull\/6954>`_) by `Nelson","130","       Liu`_","131",""],"delete":[]}],"sklearn\/tree\/_tree.pyx":[{"add":["14","#          Nelson Liu <nelson@nelsonliu.me>","133","                  SIZE_t max_depth, double min_impurity_split):","139","        self.min_impurity_split = min_impurity_split","169","        cdef double min_impurity_split = self.min_impurity_split","227","                is_leaf = (is_leaf or","228","                           (impurity <= min_impurity_split))","294","                  SIZE_t max_depth, SIZE_t max_leaf_nodes,","295","                  double min_impurity_split):","302","        self.min_impurity_split = min_impurity_split","428","        cdef double min_impurity_split = self.min_impurity_split","444","                   (impurity <= min_impurity_split))"],"delete":["65","cdef DTYPE_t MIN_IMPURITY_SPLIT = 1e-7","133","                  SIZE_t max_depth):","225","                is_leaf = is_leaf or (impurity <= MIN_IMPURITY_SPLIT)","291","                  SIZE_t max_depth, SIZE_t max_leaf_nodes):","438","                   (impurity <= MIN_IMPURITY_SPLIT))"]}],"sklearn\/ensemble\/forest.py":[{"add":["807","    min_impurity_split : float, optional (default=1e-7)","808","        Threshold for early stopping in tree growth. A node will split","809","        if its impurity is above the threshold, otherwise it is a leaf.","810","","905","                 min_impurity_split=1e-7,","918","                              \"max_features\", \"max_leaf_nodes\", \"min_impurity_split\",","935","        self.min_impurity_split = min_impurity_split","1009","    min_impurity_split : float, optional (default=1e-7)","1010","        Threshold for early stopping in tree growth. A node will split","1011","        if its impurity is above the threshold, otherwise it is a leaf.","1012","","1076","                 min_impurity_split=1e-7,","1088","                              \"max_features\", \"max_leaf_nodes\", \"min_impurity_split\",","1104","        self.min_impurity_split = min_impurity_split","1174","    min_impurity_split : float, optional (default=1e-7)","1175","        Threshold for early stopping in tree growth. A node will split","1176","        if its impurity is above the threshold, otherwise it is a leaf.","1177","","1273","                 min_impurity_split=1e-7,","1286","                              \"max_features\", \"max_leaf_nodes\", \"min_impurity_split\",","1303","        self.min_impurity_split = min_impurity_split","1375","    min_impurity_split : float, optional (default=1e-7)","1376","        Threshold for early stopping in tree growth. A node will split","1377","        if its impurity is above the threshold, otherwise it is a leaf.","1378","","1443","                 min_impurity_split=1e-7,","1455","                              \"max_features\", \"max_leaf_nodes\", \"min_impurity_split\",","1471","        self.min_impurity_split = min_impurity_split","1526","    min_impurity_split : float, optional (default=1e-7)","1527","        Threshold for early stopping in tree growth. A node will split","1528","        if its impurity is above the threshold, otherwise it is a leaf.","1529","","1574","                 min_impurity_split=1e-7,","1585","                              \"max_features\", \"max_leaf_nodes\", \"min_impurity_split\",","1601","        self.min_impurity_split = min_impurity_split"],"delete":["913","                              \"max_features\", \"max_leaf_nodes\",","1077","                              \"max_features\", \"max_leaf_nodes\",","1269","                              \"max_features\", \"max_leaf_nodes\",","1432","                              \"max_features\", \"max_leaf_nodes\",","1556","                              \"max_features\", \"max_leaf_nodes\","]}],"sklearn\/tree\/tests\/test_tree.py":[{"add":["526","        assert_raises(ValueError, TreeEstimator(min_impurity_split=-1.0).fit, X, y)","684","def test_min_impurity_split():","685","    # test if min_impurity_split creates leaves with impurity","686","    # [0, min_impurity_split) when min_samples_leaf = 1 and","687","    # min_samples_split = 2.","688","    X = np.asfortranarray(iris.data.astype(tree._tree.DTYPE))","689","    y = iris.target","690","","691","    # test both DepthFirstTreeBuilder and BestFirstTreeBuilder","692","    # by setting max_leaf_nodes","693","    for max_leaf_nodes, name in product((None, 1000), ALL_TREES.keys()):","694","        TreeEstimator = ALL_TREES[name]","695","        min_impurity_split = .5","696","","697","        # verify leaf nodes without min_impurity_split less than","698","        # impurity 1e-7","699","        est = TreeEstimator(max_leaf_nodes=max_leaf_nodes,","700","                            random_state=0)","701","        assert_less_equal(est.min_impurity_split, 1e-7,","702","                     \"Failed, min_impurity_split = {0} > 1e-7\".format(","703","                         est.min_impurity_split))","704","        est.fit(X, y)","705","        for node in range(est.tree_.node_count):","706","            if (est.tree_.children_left[node] == TREE_LEAF or","707","                est.tree_.children_right[node] == TREE_LEAF):","708","                assert_equal(est.tree_.impurity[node], 0.,","709","                             \"Failed with {0} \"","710","                             \"min_impurity_split={1}\".format(","711","                                 est.tree_.impurity[node],","712","                                 est.min_impurity_split))","713","","714","        # verify leaf nodes have impurity [0,min_impurity_split] when using min_impurity_split","715","        est = TreeEstimator(max_leaf_nodes=max_leaf_nodes,","716","                            min_impurity_split=min_impurity_split,","717","                            random_state=0)","718","        est.fit(X, y)","719","        for node in range(est.tree_.node_count):","720","            if (est.tree_.children_left[node] == TREE_LEAF or","721","                est.tree_.children_right[node] == TREE_LEAF):","722","                assert_greater_equal(est.tree_.impurity[node], 0,","723","                                     \"Failed with {0}, \"","724","                                     \"min_impurity_split={1}\".format(","725","                                         est.tree_.impurity[node],","726","                                         est.min_impurity_split))","727","                assert_less_equal(est.tree_.impurity[node], min_impurity_split,","728","                                  \"Failed with {0}, \"","729","                                  \"min_impurity_split={1}\".format(","730","                                      est.tree_.impurity[node],","731","                                      est.min_impurity_split))","732","","733",""],"delete":[]}]}},"1a8ddbede3ec810cb29c222fcd4332e82523e9f3":{"changes":{"sklearn\/mixture\/tests\/test_dpgmm.py":"MODIFY","sklearn\/mixture\/dpgmm.py":"MODIFY","sklearn\/mixture\/tests\/test_gmm.py":"MODIFY"},"diff":{"sklearn\/mixture\/tests\/test_dpgmm.py":[{"add":["9","from sklearn.utils.testing import assert_warns_message, ignore_warnings","12","from sklearn.mixture.dpgmm import digamma, gammaln","13","from sklearn.mixture.dpgmm import wishart_log_det, wishart_logz","14","","19","@ignore_warnings(category=DeprecationWarning)","37","@ignore_warnings(category=DeprecationWarning)","67","@ignore_warnings(category=DeprecationWarning)","83","@ignore_warnings(category=DeprecationWarning)","99","@ignore_warnings(category=DeprecationWarning)","100","def test_digamma():","101","    assert_warns_message(DeprecationWarning, \"The function digamma is\"","102","                         \" deprecated in 0.18 and will be removed in 0.20. \"","103","                         \"Use scipy.special.digamma instead.\", digamma, 3)","104","","105","","106","@ignore_warnings(category=DeprecationWarning)","107","def test_gammaln():","108","    assert_warns_message(DeprecationWarning, \"The function gammaln\"","109","                         \" is deprecated in 0.18 and will be removed\"","110","                         \" in 0.20. Use scipy.special.gammaln instead.\",","111","                         gammaln, 3)","112","","113","","114","@ignore_warnings(category=DeprecationWarning)","118","    result = assert_warns_message(DeprecationWarning, \"The function \"","119","                                  \"log_normalize is deprecated in 0.18 and\"","120","                                  \" will be removed in 0.20.\",","121","                                  log_normalize, a)","122","    assert np.allclose(v, result, rtol=0.01)","123","","124","","125","@ignore_warnings(category=DeprecationWarning)","126","def test_wishart_log_det():","127","    a = np.array([0.1, 0.8, 0.01, 0.09])","128","    b = np.array([0.2, 0.7, 0.05, 0.1])","129","    assert_warns_message(DeprecationWarning, \"The function \"","130","                         \"wishart_log_det is deprecated in 0.18 and\"","131","                         \" will be removed in 0.20.\",","132","                         wishart_log_det, a, b, 2, 4)","133","","134","","135","@ignore_warnings(category=DeprecationWarning)","136","def test_wishart_logz():","137","    assert_warns_message(DeprecationWarning, \"The function \"","138","                         \"wishart_logz is deprecated in 0.18 and \"","139","                         \"will be removed in 0.20.\", wishart_logz,","140","                         3, np.identity(3), 1, 3)","141","","142","","143","@ignore_warnings(category=DeprecationWarning)","144","def test_DPGMM_deprecation():","145","    assert_warns_message(DeprecationWarning, \"The DPGMM class is\"","146","                         \" not working correctly and it's better \"","147","                         \"to not use it. DPGMM is deprecated in 0.18 \"","148","                         \"and will be removed in 0.20.\", DPGMM)","184","@ignore_warnings(category=DeprecationWarning)","185","def test_VBGMM_deprecation():","186","    assert_warns_message(DeprecationWarning, \"The VBGMM class is\"","187","                         \" not working correctly and it's better\"","188","                         \" to not use it. VBGMM is deprecated in 0.18\"","189","                         \" and will be removed in 0.20.\", VBGMM)","190","","191",""],"delete":["94","    assert np.allclose(v, log_normalize(a), rtol=0.01)"]}],"sklearn\/mixture\/dpgmm.py":[{"add":["18","from ..utils import check_random_state, check_array, deprecated","25","@deprecated(\"The function digamma is deprecated in 0.18 and \"","26","            \"will be removed in 0.20. Use scipy.special.digamma instead.\")","31","@deprecated(\"The function gammaln is deprecated in 0.18 and \"","32","            \"will be removed in 0.20. Use scipy.special.gammaln instead.\")","37","@deprecated(\"The function log_normalize is deprecated in 0.18 and \"","38","            \"will be removed in 0.20.\")","51","@deprecated(\"The function wishart_log_det is deprecated in 0.18 and \"","52","            \"will be removed in 0.20.\")","63","@deprecated(\"The function wishart_logz is deprecated in 0.18 and \"","64","            \"will be removed in 0.20.\")","118","@deprecated(\"The DPGMM class is not working correctly and it's better \"","119","            \"to not use it. DPGMM is deprecated in 0.18 and \"","120","            \"will be removed in 0.20.\")","621","@deprecated(\"The VBGMM class is not working correctly and it's better\"","622","            \" to not use it. VBGMM is deprecated in 0.18 and \"","623","            \"will be removed in 0.20.\")"],"delete":["18","from ..utils import check_random_state, check_array"]}],"sklearn\/mixture\/tests\/test_gmm.py":[{"add":["206","        with ignore_warnings(category=DeprecationWarning):","207","            ll, responsibilities = g.score_samples(X)","228","        with ignore_warnings(category=DeprecationWarning):","229","            samples = g.sample(n)","237","        with ignore_warnings(category=DeprecationWarning):","238","            g.weights_ = self.weights","239","            g.means_ = self.means","240","            g.covars_ = 20 * self.covars[self.covariance_type]","243","        with ignore_warnings(category=DeprecationWarning):","244","            X = g.sample(n_samples=100)","245","            g = self.model(n_components=self.n_components,","246","                           covariance_type=self.covariance_type,","247","                           random_state=rng, min_covar=1e-1,","248","                           n_iter=1, init_params=params)","249","            g.fit(X)","255","        with ignore_warnings(category=DeprecationWarning):","256","            for _ in range(5):","257","                g.params = params","258","                g.init_params = ''","259","                g.fit(X)","260","                trainll.append(self.score(g, X))","261","            g.n_iter = 10","263","            g.params = params","264","            g.fit(X)  # finish fitting","271","        with ignore_warnings(category=DeprecationWarning):","272","            delta_min = np.diff(trainll).min()","291","        with ignore_warnings(category=DeprecationWarning):","292","            g.fit(X)","293","            trainll = g.score(X)","308","        with ignore_warnings(category=DeprecationWarning):","309","            g.fit(X)","310","            trainll = g.score(X)","311","            if isinstance(g, mixture.DPGMM):","312","                self.assertTrue(np.sum(np.abs(trainll \/ 100)) < 5)","313","            else:","314","                self.assertTrue(np.sum(np.abs(trainll \/ 100)) < 2)","319","        with ignore_warnings(category=DeprecationWarning):","320","            return g.score(X).sum()","355","    with ignore_warnings(category=DeprecationWarning):","356","        train1 = g.fit(X).score(X).sum()","357","        g.n_init = 5","358","        train2 = g.fit(X).score(X).sum()","369","        with ignore_warnings(category=DeprecationWarning):","370","            g = mixture.GMM(n_components=n_components, covariance_type=cv_type,","371","                            random_state=rng, min_covar=1e-7, n_iter=1)","372","            g.fit(X)","373","            assert_true(g._n_parameters() == n_params[cv_type])","385","    with ignore_warnings(category=DeprecationWarning):","386","        g_full.fit(X)","387","        g_full_bic = g_full.bic(X)","388","        for cv_type in ['tied', 'diag', 'spherical']:","389","            g = mixture.GMM(n_components=n_components, covariance_type=cv_type,","390","                            random_state=rng, min_covar=1e-7, n_iter=1)","391","            g.fit(X)","392","            assert_array_almost_equal(g.bic(X), g_full_bic)"],"delete":["206","        ll, responsibilities = g.score_samples(X)","227","        samples = g.sample(n)","235","        g.weights_ = self.weights","236","        g.means_ = self.means","237","        g.covars_ = 20 * self.covars[self.covariance_type]","240","        X = g.sample(n_samples=100)","241","        g = self.model(n_components=self.n_components,","242","                       covariance_type=self.covariance_type,","243","                       random_state=rng, min_covar=1e-1,","244","                       n_iter=1, init_params=params)","245","        g.fit(X)","251","        for _ in range(5):","252","            g.params = params","254","            g.fit(X)","255","            trainll.append(self.score(g, X))","256","        g.n_iter = 10","257","        g.init_params = ''","258","        g.params = params","259","        g.fit(X)  # finish fitting","266","        delta_min = np.diff(trainll).min()","285","        g.fit(X)","286","        trainll = g.score(X)","301","        g.fit(X)","302","        trainll = g.score(X)","303","        if isinstance(g, mixture.DPGMM):","304","            self.assertTrue(np.sum(np.abs(trainll \/ 100)) < 5)","305","        else:","306","            self.assertTrue(np.sum(np.abs(trainll \/ 100)) < 2)","311","        return g.score(X).sum()","346","    train1 = g.fit(X).score(X).sum()","347","    g.n_init = 5","348","    train2 = g.fit(X).score(X).sum()","359","        g = mixture.GMM(n_components=n_components, covariance_type=cv_type,","360","                        random_state=rng, min_covar=1e-7, n_iter=1)","361","        g.fit(X)","362","        assert_true(g._n_parameters() == n_params[cv_type])","374","    g_full.fit(X)","375","    g_full_bic = g_full.bic(X)","376","    for cv_type in ['tied', 'diag', 'spherical']:","377","        g = mixture.GMM(n_components=n_components, covariance_type=cv_type,","378","                        random_state=rng, min_covar=1e-7, n_iter=1)","379","        g.fit(X)","380","        assert_array_almost_equal(g.bic(X), g_full_bic)"]}]}},"1cf192b2e59e71bdcc788f051895e4f9fb45a8ee":{"changes":{"sklearn\/discriminant_analysis.py":"MODIFY"},"diff":{"sklearn\/discriminant_analysis.py":[{"add":["146","       Deprecated :class:`lda.LDA` have been moved to :class:`LinearDiscriminantAnalysis`.","558","       Deprecated :class:`qda.QDA` have been moved to :class:`QuadraticDiscriminantAnalysis`.","559","","560","    Read more in the :ref:`User Guide <lda_qda>`."],"delete":["146","       Deprecated :class:`lda.LDA` have been moved to *LinearDiscriminantAnalysis*.","558","       Deprecated :class:`qda.QDA` have been moved to *QuadraticDiscriminantAnalysis*."]}]}},"1bcd6c3c5530e721860cae5fc410551b8ca744b0":{"changes":{"sklearn\/multioutput.py":"MODIFY"},"diff":{"sklearn\/multioutput.py":[{"add":["62","","65","        self : object","66","            Returns self."],"delete":["64","        self"]}]}},"58b35d8b9feb55422ed1b0f210f985860213d858":{"changes":{"doc\/modules\/manifold.rst":"MODIFY","doc\/modules\/gaussian_process.rst":"MODIFY","doc\/tutorial\/statistical_inference\/model_selection.rst":"MODIFY","sklearn\/covariance\/tests\/test_graph_lasso.py":"MODIFY","sklearn\/utils\/estimator_checks.py":"MODIFY","sklearn\/gaussian_process\/gpr.py":"MODIFY","doc\/developers\/contributing.rst":"MODIFY","doc\/datasets\/rcv1_fixture.py":"MODIFY","sklearn\/datasets\/mldata.py":"MODIFY","sklearn\/tests\/test_base.py":"MODIFY","sklearn\/feature_extraction\/image.py":"MODIFY","examples\/hetero_feature_union.py":"MODIFY","doc\/tutorial\/text_analytics\/working_with_text_data_fixture.py":"MODIFY","sklearn\/metrics\/tests\/test_pairwise.py":"MODIFY"},"diff":{"doc\/modules\/manifold.rst":[{"add":["61","Component Analysis (PCA), Independent Component Analysis, Linear","62","Discriminant Analysis, and others.  These algorithms define specific","64","These methods can be powerful, but often miss important non-linear","93","The manifold learning implementations available in scikit-learn are","123","   for this are *Dijkstra's Algorithm*, which is approximately","129","3. **Partial eigenvalue decomposition.**  The embedding is encoded in the","193","","223","","234","   weight matrix from multiple weights.  In practice, the added cost of","249","","273","","310","The graph generated can be considered as a discrete approximation of the","311","low dimensional manifold in the high dimensional space. Minimization of a","312","cost function based on the graph ensures that points close to each other on","313","the manifold are mapped close to each other in the low dimensional space,","328","   :math:`L = D^{-\\frac{1}{2}} (D - A) D^{-\\frac{1}{2}}`.","330","3. **Partial Eigenvalue Decomposition**. Eigenvalue decomposition is","344","     and Data Representation\"","356","tangent space, and performs a global optimization to align these local","423","","458","","501","and select the embedding with the lowest KL divergence.","554","but less accurate results.","562","is the number of output dimensions and :math:`N` is the number of samples. The","563","Barnes-Hut method improves on the exact method where t-SNE complexity is"],"delete":["61","Component Analysis (PCA), Independent Component Analysis, Linear ","62","Discriminant Analysis, and others.  These algorithms define specific ","64","These methods can be powerful, but often miss important non-linear ","93","The manifold learning implementations available in sklearn are","123","   for this are *Dijkstra's Algorithm*, which is approximately ","129","3. **Partial eigenvalue decomposition.**  The embedding is encoded in the ","193","   ","223","   ","234","   weight matrix from multiple weights.  In practice, the added cost of ","249","     ","273","   ","310","The graph generated can be considered as a discrete approximation of the ","311","low dimensional manifold in the high dimensional space. Minimization of a ","312","cost function based on the graph ensures that points close to each other on ","313","the manifold are mapped close to each other in the low dimensional space, ","328","   :math:`L = D^{-\\frac{1}{2}} (D - A) D^{-\\frac{1}{2}}`.  ","330","3. **Partial Eigenvalue Decomposition**. Eigenvalue decomposition is ","344","     and Data Representation\" ","356","tangent space, and performs a global optimization to align these local ","423"," ","458","  ","501","and select the embedding with the lowest KL divergence. ","554","but less accurate results. ","562","is the number of output dimensions and :math:`N` is the number of samples. The ","563","Barnes-Hut method improves on the exact method where t-SNE complexity is "]}],"doc\/modules\/gaussian_process.rst":[{"add":["68","the API of standard scikit-learn estimators, GaussianProcessRegressor:","166","This example is based on Section 5.4.3 of [RW2006]_.","604","      <http:\/\/www.gaussianprocess.org\/gpml\/chapters\/>`_","605","      **Gaussian Processes for Machine Learning**,","606","      Carl Eduard Rasmussen and Christopher K.I. Williams, MIT Press 2006.","607","      Link to an official complete PDF version of the book","608","      `here <http:\/\/www.gaussianprocess.org\/gpml\/chapters\/RW.pdf>`_ .","618","In this section, the implementation of Gaussian processes used in scikit-learn","619","until release 0.16.1 is described. Note that this implementation is deprecated","620","and will be removed in version 0.18."],"delete":["68","the API of standard sklearn estimators, GaussianProcessRegressor:","166","This example is based on Section 5.4.3 of [RW2006]_. ","604","      <http:\/\/www.gaussianprocess.org\/gpml\/chapters\/>`_ ","605","      **Gaussian Processes for Machine Learning**, ","606","      Carl Eduard Rasmussen and Christopher K.I. Williams, MIT Press 2006. ","607","      Link to an official complete PDF version of the book ","608","      `here <http:\/\/www.gaussianprocess.org\/gpml\/chapters\/RW.pdf>`_ . ","618","In this section, the implementation of Gaussian processes used in sklearn until","619","release 0.16.1 is described. Note that this implementation is deprecated and","620","will be removed in version 0.18."]}],"doc\/tutorial\/statistical_inference\/model_selection.rst":[{"add":["209","scikit-learn provides an object that, given data, computes the score","259","algorithm-by-algorithm basis. This is why, for certain estimators,","260","scikit-learn exposes :ref:`cross_validation` estimators that set their","261","parameter automatically by cross-validation::"],"delete":["209","The sklearn provides an object that, given data, computes the score","259","algorithm-by-algorithm basis. This is why for certain estimators the","260","sklearn exposes :ref:`cross_validation` estimators that set their parameter","261","automatically by cross-validation::"]}],"sklearn\/covariance\/tests\/test_graph_lasso.py":[{"add":["63","    # The iris datasets in R and scikit-learn do not match in a few places,","64","    # these values are for the scikit-learn version."],"delete":["63","    # The iris datasets in R and sklearn do not match in a few places, these","64","    # values are for the sklearn version"]}],"sklearn\/utils\/estimator_checks.py":[{"add":["222","    \"\"\"Check if estimator adheres to scikit-learn conventions."],"delete":["222","    \"\"\"Check if estimator adheres to sklearn conventions."]}],"sklearn\/gaussian_process\/gpr.py":[{"add":["25","    In addition to standard scikit-learn estimator API,","26","    GaussianProcessRegressor:"],"delete":["25","    In addition to standard sklearn estimator API, GaussianProcessRegressor:"]}],"doc\/developers\/contributing.rst":[{"add":["873","whether it is just for you or for contributing it to scikit-learn, there are","874","several internals of scikit-learn that you should be aware of in addition to","875","the scikit-learn API outlined above. You can check whether your estimator","931","All scikit-learn estimators have ``get_params`` and ``set_params`` functions."],"delete":["873","whether it is just for you or for contributing it to sklearn, there are several","874","internals of scikit-learn that you should be aware of in addition to the","875","sklearn API outlined above. You can check whether your estimator","931","All sklearn estimator have ``get_params`` and ``set_params`` functions."]}],"doc\/datasets\/rcv1_fixture.py":[{"add":["3","stateless hence will not cache the dataset as regular scikit-learn users would do."],"delete":["3","stateless hence will not cache the dataset as regular sklearn users would do."]}],"sklearn\/datasets\/mldata.py":[{"add":["105","    to respects the scikit-learn axes convention:","207","    # set axes to scikit-learn conventions"],"delete":["105","    to respects the sklearn axes convention:","207","    # set axes to sklearn conventions"]}],"sklearn\/tests\/test_base.py":[{"add":["75","    \"\"\"scikit-learn estimators shouldn't have vargs.\"\"\""],"delete":["75","    \"\"\"Sklearn estimators shouldn't have vargs.\"\"\""]}],"sklearn\/feature_extraction\/image.py":[{"add":["154","    For scikit-learn versions 0.14.1 and prior, return_as=np.ndarray was","155","    handled by returning a dense np.matrix instance.  Going forward, np.ndarray","190","    For scikit-learn versions 0.14.1 and prior, return_as=np.ndarray was","191","    handled by returning a dense np.matrix instance.  Going forward, np.ndarray"],"delete":["154","    For sklearn versions 0.14.1 and prior, return_as=np.ndarray was handled","155","    by returning a dense np.matrix instance.  Going forward, np.ndarray","190","    For sklearn versions 0.14.1 and prior, return_as=np.ndarray was handled","191","    by returning a dense np.matrix instance.  Going forward, np.ndarray"]}],"examples\/hetero_feature_union.py":[{"add":["53","    Please note that this is the opposite convention to scikit-learn feature"],"delete":["53","    Please note that this is the opposite convention to sklearn feature"]}],"doc\/tutorial\/text_analytics\/working_with_text_data_fixture.py":[{"add":["3","stateless hence will not cache the dataset as regular scikit-learn users would."],"delete":["3","stateless hence will not cache the dataset as regular sklearn users would do."]}],"sklearn\/metrics\/tests\/test_pairwise.py":[{"add":["63","    # \"cityblock\" uses scikit-learn metric, cityblock (function) is","64","    # scipy.spatial.","81","    # The string \"cosine\" uses sklearn.metric,","82","    # while the function cosine is scipy.spatial","334","    # Non-euclidean scikit-learn metric"],"delete":["63","    # \"cityblock\" uses sklearn metric, cityblock (function) is scipy.spatial.","80","    # \"cosine\" uses sklearn metric, cosine (function) is scipy.spatial","332","    # Non-euclidean sklearn metric"]}]}},"da118d0cb406c5a968cdeef6416c7b681022329c":{"changes":{"sklearn\/tree\/tree.py":"MODIFY","sklearn\/ensemble\/gradient_boosting.py":"MODIFY","doc\/whats_new.rst":"MODIFY","sklearn\/ensemble\/forest.py":"MODIFY","sklearn\/tree\/tests\/test_tree.py":"MODIFY"},"diff":{"sklearn\/tree\/tree.py":[{"add":["303","        if sample_weight is None:","304","            min_weight_leaf = (self.min_weight_fraction_leaf *","305","                               n_samples)","306","        else:","595","        The minimum weighted fraction of the sum total of weights (of all","596","        the input samples) required to be at a leaf node. Samples have","597","        equal weight when sample_weight is not provided.","866","        The minimum weighted fraction of the sum total of weights (of all","867","        the input samples) required to be at a leaf node. Samples have","868","        equal weight when sample_weight is not provided."],"delete":["303","        if self.min_weight_fraction_leaf != 0. and sample_weight is not None:","306","        else:","307","            min_weight_leaf = 0.","594","        The minimum weighted fraction of the input samples required to be at a","595","        leaf node.","864","        The minimum weighted fraction of the input samples required to be at a","865","        leaf node."]}],"sklearn\/ensemble\/gradient_boosting.py":[{"add":["1332","        The minimum weighted fraction of the sum total of weights (of all","1333","        the input samples) required to be at a leaf node. Samples have","1334","        equal weight when sample_weight is not provided.","1701","        The minimum weighted fraction of the sum total of weights (of all","1702","        the input samples) required to be at a leaf node. Samples have","1703","        equal weight when sample_weight is not provided."],"delete":["1332","        The minimum weighted fraction of the input samples required to be at a","1333","        leaf node.","1700","        The minimum weighted fraction of the input samples required to be at a","1701","        leaf node."]}],"doc\/whats_new.rst":[{"add":["26","   - The ``min_weight_fraction_leaf`` parameter of tree-based classifiers and","27","     regressors now assumes uniform sample weights by default if the","28","     ``sample_weight`` argument is not passed to the ``fit`` function.","29","     Previously, the parameter was silently ignored. (`#7301","30","     <https:\/\/github.com\/scikit-learn\/scikit-learn\/pull\/7301>`_) by `Nelson","31","     Liu`_.","32",""],"delete":[]}],"sklearn\/ensemble\/forest.py":[{"add":["809","        The minimum weighted fraction of the sum total of weights (of all","810","        the input samples) required to be at a leaf node. Samples have","811","        equal weight when sample_weight is not provided.","1021","        The minimum weighted fraction of the sum total of weights (of all","1022","        the input samples) required to be at a leaf node. Samples have","1023","        equal weight when sample_weight is not provided.","1193","        The minimum weighted fraction of the sum total of weights (of all","1194","        the input samples) required to be at a leaf node. Samples have","1195","        equal weight when sample_weight is not provided.","1404","        The minimum weighted fraction of the sum total of weights (of all","1405","        the input samples) required to be at a leaf node. Samples have","1406","        equal weight when sample_weight is not provided.","1562","        The minimum weighted fraction of the sum total of weights (of all","1563","        the input samples) required to be at a leaf node. Samples have","1564","        equal weight when sample_weight is not provided."],"delete":["809","        The minimum weighted fraction of the input samples required to be at a","810","        leaf node.","1020","        The minimum weighted fraction of the input samples required to be at a","1021","        leaf node.","1191","        The minimum weighted fraction of the input samples required to be at a","1192","        leaf node.","1401","        The minimum weighted fraction of the input samples required to be at a","1402","        leaf node.","1558","        The minimum weighted fraction of the input samples required to be at a","1559","        leaf node."]}],"sklearn\/tree\/tests\/test_tree.py":[{"add":["672","    # test case with no weights passed in","673","    total_weight = X.shape[0]","674","","675","    for max_leaf_nodes, frac in product((None, 1000), np.linspace(0, 0.5, 6)):","676","        est = TreeEstimator(min_weight_fraction_leaf=frac,","677","                            max_leaf_nodes=max_leaf_nodes,","678","                            random_state=0)","679","        est.fit(X, y)","680","","681","        if sparse:","682","            out = est.tree_.apply(X.tocsr())","683","        else:","684","            out = est.tree_.apply(X)","685","","686","        node_weights = np.bincount(out)","687","        # drop inner nodes","688","        leaf_weights = node_weights[node_weights != 0]","689","        assert_greater_equal(","690","            np.min(leaf_weights),","691","            total_weight * est.min_weight_fraction_leaf,","692","            \"Failed with {0} \"","693","            \"min_weight_fraction_leaf={1}\".format(","694","                name, est.min_weight_fraction_leaf))","695","","707","def check_min_weight_fraction_leaf_with_min_samples_leaf(name, datasets,","708","                                                         sparse=False):","709","    \"\"\"Test the interaction between min_weight_fraction_leaf and min_samples_leaf","710","    when sample_weights is not provided in fit.\"\"\"","711","    if sparse:","712","        X = DATASETS[datasets][\"X_sparse\"].astype(np.float32)","713","    else:","714","        X = DATASETS[datasets][\"X\"].astype(np.float32)","715","    y = DATASETS[datasets][\"y\"]","716","","717","    total_weight = X.shape[0]","718","    TreeEstimator = ALL_TREES[name]","719","    for max_leaf_nodes, frac in product((None, 1000), np.linspace(0, 0.5, 3)):","720","        # test integer min_samples_leaf","721","        est = TreeEstimator(min_weight_fraction_leaf=frac,","722","                            max_leaf_nodes=max_leaf_nodes,","723","                            min_samples_leaf=5,","724","                            random_state=0)","725","        est.fit(X, y)","726","","727","        if sparse:","728","            out = est.tree_.apply(X.tocsr())","729","        else:","730","            out = est.tree_.apply(X)","731","","732","        node_weights = np.bincount(out)","733","        # drop inner nodes","734","        leaf_weights = node_weights[node_weights != 0]","735","        assert_greater_equal(","736","            np.min(leaf_weights),","737","            max((total_weight *","738","                 est.min_weight_fraction_leaf), 5),","739","            \"Failed with {0} \"","740","            \"min_weight_fraction_leaf={1}, \"","741","            \"min_samples_leaf={2}\".format(name,","742","                                          est.min_weight_fraction_leaf,","743","                                          est.min_samples_leaf))","744","    for max_leaf_nodes, frac in product((None, 1000), np.linspace(0, 0.5, 3)):","745","        # test float min_samples_leaf","746","        est = TreeEstimator(min_weight_fraction_leaf=frac,","747","                            max_leaf_nodes=max_leaf_nodes,","748","                            min_samples_leaf=.1,","749","                            random_state=0)","750","        est.fit(X, y)","751","","752","        if sparse:","753","            out = est.tree_.apply(X.tocsr())","754","        else:","755","            out = est.tree_.apply(X)","756","","757","        node_weights = np.bincount(out)","758","        # drop inner nodes","759","        leaf_weights = node_weights[node_weights != 0]","760","        assert_greater_equal(","761","            np.min(leaf_weights),","762","            max((total_weight * est.min_weight_fraction_leaf),","763","                (total_weight * est.min_samples_leaf)),","764","            \"Failed with {0} \"","765","            \"min_weight_fraction_leaf={1}, \"","766","            \"min_samples_leaf={2}\".format(name,","767","                                          est.min_weight_fraction_leaf,","768","                                          est.min_samples_leaf))","769","","770","","771","def test_min_weight_fraction_leaf_with_min_samples_leaf():","772","    # Check on dense input","773","    for name in ALL_TREES:","774","        yield (check_min_weight_fraction_leaf_with_min_samples_leaf,","775","               name, \"iris\")","776","","777","    # Check on sparse input","778","    for name in SPARSE_TREES:","779","        yield (check_min_weight_fraction_leaf_with_min_samples_leaf,","780","               name, \"multilabel\", True)","781","","782",""],"delete":[]}]}},"9b2aac9e5c8749243c73f2377519d2f2c407b095":{"changes":{"sklearn\/linear_model\/tests\/test_theil_sen.py":"MODIFY","doc\/datasets\/labeled_faces_fixture.py":"MODIFY","sklearn\/preprocessing\/tests\/test_function_transformer.py":"MODIFY","sklearn\/utils\/tests\/test_bench.py":"MODIFY","sklearn\/utils\/tests\/test_murmurhash.py":"MODIFY","sklearn\/utils\/tests\/test_testing.py":"MODIFY","sklearn\/svm\/tests\/test_bounds.py":"MODIFY","sklearn\/tests\/test_discriminant_analysis.py":"MODIFY","sklearn\/utils\/tests\/test_fixes.py":"MODIFY","sklearn\/utils\/testing.py":"MODIFY","sklearn\/utils\/tests\/test_fast_dict.py":"MODIFY","sklearn\/neighbors\/tests\/test_dist_metrics.py":"MODIFY","sklearn\/feature_selection\/tests\/test_rfe.py":"MODIFY","sklearn\/cross_decomposition\/tests\/test_pls.py":"MODIFY","sklearn\/feature_extraction\/tests\/test_text.py":"MODIFY","sklearn\/feature_selection\/tests\/test_from_model.py":"MODIFY","doc\/datasets\/twenty_newsgroups_fixture.py":"MODIFY","sklearn\/utils\/tests\/test_metaestimators.py":"MODIFY","sklearn\/feature_extraction\/tests\/test_feature_hasher.py":"MODIFY","sklearn\/tree\/tests\/test_export.py":"MODIFY","sklearn\/datasets\/mldata.py":"MODIFY","sklearn\/mixture\/tests\/test_gmm.py":"MODIFY","sklearn\/gaussian_process\/tests\/test_gaussian_process.py":"MODIFY","sklearn\/metrics\/cluster\/tests\/test_supervised.py":"MODIFY","sklearn\/utils\/sparsetools\/tests\/test_traversal.py":"MODIFY","sklearn\/svm\/tests\/test_svm.py":"MODIFY","sklearn\/svm\/tests\/test_sparse.py":"MODIFY","sklearn\/manifold\/tests\/test_mds.py":"MODIFY","sklearn\/decomposition\/tests\/test_fastica.py":"MODIFY","sklearn\/semi_supervised\/tests\/test_label_propagation.py":"MODIFY","sklearn\/ensemble\/tests\/test_gradient_boosting_loss_functions.py":"MODIFY","sklearn\/utils\/tests\/test_seq_dataset.py":"MODIFY","sklearn\/ensemble\/tests\/test_base.py":"MODIFY","sklearn\/feature_selection\/tests\/test_base.py":"MODIFY","sklearn\/feature_extraction\/tests\/test_image.py":"MODIFY","sklearn\/linear_model\/tests\/test_least_angle.py":"MODIFY","sklearn\/manifold\/tests\/test_locally_linear.py":"MODIFY","sklearn\/manifold\/tests\/test_spectral_embedding.py":"MODIFY","sklearn\/utils\/tests\/test_validation.py":"MODIFY","sklearn\/datasets\/tests\/test_base.py":"MODIFY"},"diff":{"sklearn\/linear_model\/tests\/test_theil_sen.py":[{"add":["21","from sklearn.utils.testing import (","22","        assert_almost_equal, assert_greater, assert_less, raises,","23",")"],"delete":["17","from nose.tools import raises, assert_almost_equal","22","from sklearn.utils.testing import assert_greater, assert_less"]}],"doc\/datasets\/labeled_faces_fixture.py":[{"add":["8","from sklearn.utils.testing import SkipTest"],"delete":["7","from nose import SkipTest"]}],"sklearn\/preprocessing\/tests\/test_function_transformer.py":[{"add":["4","from sklearn.utils.testing import assert_equal, assert_array_equal","23","    assert_array_equal(","50","    assert_array_equal(","80","    assert_array_equal(","92","    assert_array_equal(F.transform(X),","93","                       np.around(X, decimals=3))","104","    assert_array_equal(F.transform(X), np.around(X, decimals=1))","115","    assert_array_equal(F.transform(X), np.around(X, decimals=1))","123","        func=np.sqrt,","124","        inverse_func=np.around, inv_kw_args=dict(decimals=3),","125","    )","126","    assert_array_equal(","127","        F.inverse_transform(F.transform(X)),","128","        np.around(np.sqrt(X), decimals=3),","129","    )"],"delete":["0","from nose.tools import assert_equal","23","    testing.assert_array_equal(","50","    testing.assert_array_equal(","80","    testing.assert_array_equal(","92","    testing.assert_array_equal(F.transform(X),","93","                                  np.around(X, decimals=3))","104","    testing.assert_array_equal(F.transform(X),","105","                                  np.around(X, decimals=1))","116","    testing.assert_array_equal(F.transform(X),","117","                               np.around(X, decimals=1))","125","            func=np.sqrt,","126","            inverse_func=np.around, inv_kw_args=dict(decimals=3))","127","    testing.assert_array_equal(","128","            F.inverse_transform(F.transform(X)),","129","            np.around(np.sqrt(X), decimals=3))"]}],"sklearn\/utils\/tests\/test_bench.py":[{"add":["4","from sklearn.utils.testing import assert_equal"],"delete":["4","from nose.tools import assert_equal"]}],"sklearn\/utils\/tests\/test_murmurhash.py":[{"add":["9","from sklearn.utils.testing import assert_equal, assert_true"],"delete":["9","from nose.tools import assert_equal, assert_true"]}],"sklearn\/utils\/tests\/test_testing.py":[{"add":["5","    assert_raises,"],"delete":["4","from nose.tools import assert_raises","5",""]}],"sklearn\/svm\/tests\/test_bounds.py":[{"add":["9","from sklearn.utils.testing import assert_true, raises","10","from sklearn.utils.testing import assert_raise_message","11","","67","@raises(ValueError)","74","@raises(ValueError)"],"delete":["0","import nose","1","from nose.tools import assert_equal, assert_true","2","from sklearn.utils.testing import clean_warning_registry","3","from sklearn.utils.testing import assert_raise_message","68","@nose.tools.raises(ValueError)","75","@nose.tools.raises(ValueError)"]}],"sklearn\/tests\/test_discriminant_analysis.py":[{"add":["13","from sklearn.utils.testing import SkipTest"],"delete":["2","from nose import SkipTest"]}],"sklearn\/utils\/tests\/test_fixes.py":[{"add":["11","from sklearn.utils.testing import assert_equal, assert_false, assert_true"],"delete":["7","from nose.tools import assert_equal","8","from nose.tools import assert_false","9","from nose.tools import assert_true","12",""]}],"sklearn\/utils\/testing.py":[{"add":["38","import unittest","70","           \"assert_approx_equal\", \"SkipTest\"]","71","","72","","73","_dummy = unittest.TestCase('__init__')","74","assert_equal = _dummy.assertEqual","75","assert_not_equal = _dummy.assertNotEqual","76","assert_true = _dummy.assertTrue","77","assert_false = _dummy.assertFalse","78","assert_raises = _dummy.assertRaises","79","","80","try:","81","    SkipTest = unittest.case.SkipTest","82","except AttributeError:","83","    # Python <= 2.6, we stil need nose here","84","    from nose import SkipTest","88","    assert_dict_equal = _dummy.assertDictEqual","89","    assert_in = _dummy.assertIn","90","    assert_not_in = _dummy.assertNotIn","91","except AttributeError:","92","    # Python <= 2.6","93","","94","    assert_dict_equal = assert_equal","103","    assert_raises_regex = _dummy.assertRaisesRegex","104","except AttributeError:","105","    # for Python 2.6","387","    assert_less = _dummy.assertLess","388","    assert_greater = _dummy.assertGreater","389","except AttributeError:"],"delete":["49","# Conveniently import all assertions in one place.","50","from nose.tools import assert_equal","51","from nose.tools import assert_not_equal","52","from nose.tools import assert_true","53","from nose.tools import assert_false","54","from nose.tools import assert_raises","56","try:","57","    from nose.tools import assert_dict_equal","58","except ImportError:","59","    # Not in old versions of nose, but is only for formatting anyway","60","    assert_dict_equal = assert_equal","61","from nose import SkipTest","81","           \"assert_approx_equal\"]","85","    from nose.tools import assert_in, assert_not_in","86","except ImportError:","87","    # Nose < 1.0.0","96","    from nose.tools import assert_raises_regex","97","except ImportError:","98","    # for Python 2","380","    from nose.tools import assert_less","381","except ImportError:","383","","384","try:","385","    from nose.tools import assert_greater","386","except ImportError:"]}],"sklearn\/utils\/tests\/test_fast_dict.py":[{"add":["5","from sklearn.utils.testing import assert_equal","8",""],"delete":["3","from nose.tools import assert_equal"]}],"sklearn\/neighbors\/tests\/test_dist_metrics.py":[{"add":["9","from sklearn.utils.testing import SkipTest"],"delete":["9","from nose import SkipTest"]}],"sklearn\/feature_selection\/tests\/test_rfe.py":[{"add":["16","from sklearn.utils.testing import assert_greater, assert_equal, assert_true"],"delete":["5","from nose.tools import assert_equal, assert_true","17","from sklearn.utils.testing import assert_greater"]}],"sklearn\/cross_decomposition\/tests\/test_pls.py":[{"add":["1","from sklearn.utils.testing import (assert_equal, assert_array_almost_equal,"],"delete":["1","from sklearn.utils.testing import (assert_array_almost_equal,","6","from nose.tools import assert_equal"]}],"sklearn\/feature_extraction\/tests\/test_text.py":[{"add":["27","from sklearn.utils.testing import (assert_equal, assert_false, assert_true,","28","                                   assert_not_equal, assert_almost_equal,","29","                                   assert_in, assert_less, assert_greater,","31","                                   clean_warning_registry, SkipTest)"],"delete":["23","from nose import SkipTest","24","from nose.tools import assert_equal","25","from nose.tools import assert_false","26","from nose.tools import assert_not_equal","27","from nose.tools import assert_true","28","from nose.tools import assert_almost_equal","33","from sklearn.utils.testing import (assert_in, assert_less, assert_greater,","35","                                   clean_warning_registry)"]}],"sklearn\/feature_selection\/tests\/test_from_model.py":[{"add":["3","from sklearn.utils.testing import assert_true","9","from sklearn.utils.testing import assert_raises"],"delete":["3","from nose.tools import assert_raises, assert_true","4",""]}],"doc\/datasets\/twenty_newsgroups_fixture.py":[{"add":["7","","9","from sklearn.utils.testing import SkipTest"],"delete":["7","from nose import SkipTest"]}],"sklearn\/utils\/tests\/test_metaestimators.py":[{"add":["0","from sklearn.utils.testing import assert_true, assert_false"],"delete":["0","from nose.tools import assert_true, assert_false"]}],"sklearn\/feature_extraction\/tests\/test_feature_hasher.py":[{"add":["3","from numpy.testing import assert_array_equal","6","from sklearn.utils.testing import assert_raises, assert_true, assert_equal","72","    assert_array_equal(x1, x2)"],"delete":["5","","6","from nose.tools import assert_raises, assert_true","7","from numpy.testing import assert_array_equal, assert_equal","73","    assert_equal(x1, x2)"]}],"sklearn\/tree\/tests\/test_export.py":[{"add":["10","from sklearn.utils.testing import assert_in, assert_equal, assert_raises"],"delete":["6","from numpy.testing import assert_equal","7","from nose.tools import assert_raises","8","","13","from sklearn.utils.testing import assert_in"]}],"sklearn\/datasets\/mldata.py":[{"add":["217","# The following is used by test runners to setup the docstring tests fixture"],"delete":["217","# The following is used by nosetests to setup the docstring tests fixture"]}],"sklearn\/mixture\/tests\/test_gmm.py":[{"add":["16","from sklearn.utils.testing import (assert_true, assert_greater,","17","                                   assert_raise_message, assert_warns_message,","18","                                   ignore_warnings)"],"delete":["10","from nose.tools import assert_true","17","from sklearn.utils.testing import (assert_greater, assert_raise_message,","18","                                   assert_warns_message, ignore_warnings)"]}],"sklearn\/gaussian_process\/tests\/test_gaussian_process.py":[{"add":["13","from sklearn.utils.testing import assert_greater, assert_true, raises"],"delete":["7","from nose.tools import raises","8","from nose.tools import assert_true","9","","16","from sklearn.utils.testing import assert_greater"]}],"sklearn\/metrics\/cluster\/tests\/test_supervised.py":[{"add":["14","","15","from sklearn.utils.testing import (","16","        assert_equal, assert_almost_equal, assert_raise_message,","17",")","18","from numpy.testing import assert_array_almost_equal","19",""],"delete":["1","from nose.tools import assert_almost_equal","2","from nose.tools import assert_equal","3","from numpy.testing import assert_array_almost_equal","17","from sklearn.utils.testing import assert_raise_message"]}],"sklearn\/utils\/sparsetools\/tests\/test_traversal.py":[{"add":["4","from sklearn.utils.testing import SkipTest","5",""],"delete":["2","from nose import SkipTest","3",""]}],"sklearn\/svm\/tests\/test_svm.py":[{"add":["17","from sklearn.utils.testing import assert_equal, assert_true, assert_false","21","from sklearn.utils.testing import ignore_warnings, assert_raises"],"delete":["11","from nose.tools import assert_raises, assert_true, assert_equal, assert_false","21","from sklearn.utils.testing import ignore_warnings"]}],"sklearn\/svm\/tests\/test_sparse.py":[{"add":["10","from sklearn.utils.testing import (assert_raises, assert_true, assert_false,","11","                                   assert_warns, assert_raise_message,"],"delete":["0","from nose.tools import assert_raises, assert_true, assert_false","1","","12","from sklearn.utils.testing import (assert_warns, assert_raise_message,"]}],"sklearn\/manifold\/tests\/test_mds.py":[{"add":["4","from sklearn.utils.testing import assert_raises"],"delete":["3","from nose.tools import assert_raises"]}],"sklearn\/decomposition\/tests\/test_fastica.py":[{"add":["15","from sklearn.utils.testing import assert_raises"],"delete":["9","from nose.tools import assert_raises","10",""]}],"sklearn\/semi_supervised\/tests\/test_label_propagation.py":[{"add":["4","from sklearn.utils.testing import assert_equal","29","        assert_equal(clf.transduction_[2], 1)"],"delete":["2","import nose","29","        nose.tools.assert_equal(clf.transduction_[2], 1)"]}],"sklearn\/ensemble\/tests\/test_gradient_boosting_loss_functions.py":[{"add":["10","from sklearn.utils.testing import assert_raises"],"delete":["9","from nose.tools import assert_raises","10",""]}],"sklearn\/utils\/tests\/test_seq_dataset.py":[{"add":["5","from numpy.testing import assert_array_equal","11","from sklearn.utils.testing import assert_equal"],"delete":["10","from numpy.testing import assert_array_equal","11","from nose.tools import assert_equal"]}],"sklearn\/ensemble\/tests\/test_base.py":[{"add":["12","from sklearn.utils.testing import assert_true","13",""],"delete":["9","from nose.tools import assert_true"]}],"sklearn\/feature_selection\/tests\/test_base.py":[{"add":["8","from sklearn.utils.testing import assert_raises, assert_equal"],"delete":["3","from nose.tools import assert_raises, assert_equal"]}],"sklearn\/feature_extraction\/tests\/test_image.py":[{"add":["14","from sklearn.utils.testing import SkipTest, assert_equal, assert_true"],"delete":["8","from nose.tools import assert_equal, assert_true","15","from sklearn.utils.testing import SkipTest"]}],"sklearn\/linear_model\/tests\/test_least_angle.py":[{"add":["4","from sklearn.utils.testing import assert_equal"],"delete":["0","from nose.tools import assert_equal","1",""]}],"sklearn\/manifold\/tests\/test_locally_linear.py":[{"add":["11","from sklearn.utils.testing import assert_raises","12","from sklearn.utils.testing import assert_true"],"delete":["1","from nose.tools import assert_true","131","    from nose.tools import assert_raises"]}],"sklearn\/manifold\/tests\/test_spectral_embedding.py":[{"add":["18","from sklearn.utils.testing import assert_true, assert_equal, assert_raises","19","from sklearn.utils.testing import SkipTest"],"delete":["0","from nose.tools import assert_true","1","from nose.tools import assert_equal","2","","11","from nose.tools import assert_raises","12","from nose.plugins.skip import SkipTest","13",""]}],"sklearn\/utils\/tests\/test_validation.py":[{"add":["11","from sklearn.utils.testing import assert_true, assert_false, assert_equal","12","from sklearn.utils.testing import assert_raises, assert_raises_regexp"],"delete":["10","from nose.tools import assert_raises, assert_true, assert_false, assert_equal","12","from sklearn.utils.testing import assert_raises_regexp"]}],"sklearn\/datasets\/tests\/test_base.py":[{"add":["28","from sklearn.utils.testing import with_setup","86","@with_setup(setup_load_files, teardown_load_files)","95","@with_setup(setup_load_files, teardown_load_files)","106","@with_setup(setup_load_files, teardown_load_files)"],"delete":["4","import nose","86","@nose.tools.with_setup(setup_load_files, teardown_load_files)","95","@nose.tools.with_setup(setup_load_files, teardown_load_files)","106","@nose.tools.with_setup(setup_load_files, teardown_load_files)"]}]}},"3b95d5fc2a4415e2dc0370ec45ee5942f50cad03":{"changes":{"sklearn\/cluster\/tests\/test_k_means.py":"MODIFY"},"diff":{"sklearn\/cluster\/tests\/test_k_means.py":[{"add":["802","                # ensure the extracted row is a 2d array","803","                X_test_0 = X_test[0] if is_sparse else X_test[0].reshape(1, -1)","805","                assert_equal(estimator.predict(X_test_0), estimator.labels_[0])"],"delete":["803","                assert_equal(estimator.predict(X_test[0]), estimator.labels_[0])"]}]}},"3cc7fead338bded628184ecef25516745a2067e3":{"changes":{"sklearn\/svm\/classes.py":"MODIFY","sklearn\/svm\/tests\/test_svm.py":"MODIFY"},"diff":{"sklearn\/svm\/classes.py":[{"add":["8","from ..utils import check_X_y, column_or_1d","331","    def fit(self, X, y, sample_weight=None):","376","            epsilon=self.epsilon, sample_weight=sample_weight)","768","    sample_weight : array-like, shape = [n_samples]","769","            Individual weights for each sample","770",""],"delete":["8","from ..utils import check_X_y","331","    def fit(self, X, y):","376","            epsilon=self.epsilon)"]}],"sklearn\/svm\/tests\/test_svm.py":[{"add":["10","from numpy.testing import assert_allclose","198","    assert_allclose(np.linalg.norm(lsvr.coef_),","199","                    np.linalg.norm(svr.coef_), 1, 0.0001)","200","    assert_almost_equal(score1, score2, 2)","201","","202","","203","def test_linearsvr_fit_sampleweight():","204","    # check correct result when sample_weight is 1","205","    # check that SVR(kernel='linear') and LinearSVC() give","206","    # comparable results","207","    diabetes = datasets.load_diabetes()","208","    n_samples = len(diabetes.target)","209","    unit_weight = np.ones(n_samples)","210","    lsvr = svm.LinearSVR(C=1e3).fit(diabetes.data, diabetes.target,","211","                                    sample_weight=unit_weight)","212","    score1 = lsvr.score(diabetes.data, diabetes.target)","213","","214","    lsvr_no_weight = svm.LinearSVR(C=1e3).fit(diabetes.data, diabetes.target)","215","    score2 = lsvr_no_weight.score(diabetes.data, diabetes.target)","216","","217","    assert_allclose(np.linalg.norm(lsvr.coef_),","218","                    np.linalg.norm(lsvr_no_weight.coef_), 1, 0.0001)","219","    assert_almost_equal(score1, score2, 2)","220","","221","    # check that fit(X)  = fit([X1, X2, X3],sample_weight = [n1, n2, n3]) where","222","    # X = X1 repeated n1 times, X2 repeated n2 times and so forth","223","    random_state = check_random_state(0)","224","    random_weight = random_state.randint(0, 10, n_samples)","225","    lsvr_unflat = svm.LinearSVR(C=1e3).fit(diabetes.data, diabetes.target,","226","                                           sample_weight=random_weight)","227","    score3 = lsvr_unflat.score(diabetes.data, diabetes.target,","228","                               sample_weight=random_weight)","229","","230","    X_flat = np.repeat(diabetes.data, random_weight, axis=0)","231","    y_flat = np.repeat(diabetes.target, random_weight, axis=0)","232","    lsvr_flat = svm.LinearSVR(C=1e3).fit(X_flat, y_flat)","233","    score4 = lsvr_flat.score(X_flat, y_flat)","234","","235","    assert_almost_equal(score3, score4, 2)","319","                            == clf.predict(iris.data)) > 0.9)","544","                    (loss, penalty, dual) == ('hinge', 'l2', False) or","545","                    (penalty, dual) == ('l1', True) or","546","                    loss == 'foo' or penalty == 'bar'):","604","                                      \" and loss='squared_hinge' is not supported\"),","807","    X = \"foo!\"  # input validation not required when SVM not fitted"],"delete":["8","","13","","27","","200","    assert np.linalg.norm(lsvr.coef_ - svr.coef_) \/ np.linalg.norm(svr.coef_) < .1","201","    assert np.abs(score1 - score2) < 0.1","279","","286","                    == clf.predict(iris.data)) > 0.9)","511","                (loss, penalty, dual) == ('hinge', 'l2', False) or","512","                (penalty, dual) == ('l1', True) or","513","                loss == 'foo' or penalty == 'bar'):","571","                         \" and loss='squared_hinge' is not supported\"),","636","","775","    X = \"foo!\"      # input validation not required when SVM not fitted"]}]}},"f893565773c7783dadb217ff984c8c37801d8509":{"changes":{"doc\/whats_new.rst":"MODIFY","sklearn\/preprocessing\/tests\/test_data.py":"MODIFY","sklearn\/preprocessing\/data.py":"MODIFY"},"diff":{"doc\/whats_new.rst":[{"add":["244","   - :class:`RobustScaler` now accepts ``quantile_range`` parameter.","245","     (`#5929 <https:\/\/github.com\/scikit-learn\/scikit-learn\/pull\/5929>`_)","246","     By `Konstantin Podshumok`_.","247","","4333","","4334",".. _Konstantin Podshumok: https:\/\/github.com\/podshumok"],"delete":[]}],"sklearn\/preprocessing\/tests\/test_data.py":[{"add":["842","def test_robust_scaler_iris_quantiles():","843","    X = iris.data","844","    scaler = RobustScaler(quantile_range=(10, 90))","845","    X_trans = scaler.fit_transform(X)","846","    assert_array_almost_equal(np.median(X_trans, axis=0), 0)","847","    X_trans_inv = scaler.inverse_transform(X_trans)","848","    assert_array_almost_equal(X, X_trans_inv)","849","    q = np.percentile(X_trans, q=(10, 90), axis=0)","850","    q_range = q[1] - q[0]","851","    assert_array_almost_equal(q_range, 1)","852","","853","","854","def test_robust_scaler_invalid_range():","855","    for range_ in [","856","        (-1, 90),","857","        (-2, -3),","858","        (10, 101),","859","        (100.5, 101),","860","        (90, 50),","861","    ]:","862","        scaler = RobustScaler(quantile_range=range_)","863","","864","        assert_raises_regex(ValueError, 'Invalid quantile range: \\(',","865","                            scaler.fit, iris.data)","866","","867",""],"delete":[]}],"sklearn\/preprocessing\/data.py":[{"add":["0","","401","       *minmax_scale* function interface","402","       to :class:`sklearn.preprocessing.MinMaxScaler`.","527","    @deprecated(\"Attribute ``std_`` will be removed in 0.19. \"","528","                \"Use ``scale_`` instead\")","902","    the quantile range (defaults to IQR: Interquartile Range).","903","    The IQR is the range between the 1st quartile (25th quantile)","904","    and the 3rd quartile (75th quantile).","934","    quantile_range : tuple (q_min, q_max), 0.0 < q_min < q_max < 100.0","935","        Default: (25.0, 75.0) = (1st quantile, 3rd quantile) = IQR","936","        Quantile range used to calculate scale_","937","","938","        .. versionadded:: 0.18","939","","972","    def __init__(self, with_centering=True, with_scaling=True,","973","                 quantile_range=(25.0, 75.0), copy=True):","976","        self.quantile_range = quantile_range","1012","","1013","            if not 0 <= self.quantile_range[0] <= self.quantile_range[1] <= 100:","1014","                raise ValueError(\"Invalid quantile range: %s\" %","1015","                                 str(self.quantile_range))","1016","","1017","            q = np.percentile(X, self.quantile_range, axis=0)","1075","def robust_scale(X, axis=0, with_centering=True, with_scaling=True,","1076","                 quantile_range=(25.0, 75.0), copy=True):","1101","    quantile_range : tuple (q_min, q_max), 0.0 < q_min < q_max < 100.0","1102","        Default: (25.0, 75.0) = (1st quantile, 3rd quantile) = IQR","1103","        Quantile range used to calculate scale_","1104","","1105","        .. versionadded:: 0.18","1106","","1131","                     quantile_range=quantile_range, copy=copy)","1750","                  ``X[:, i]``. Each feature value should be","1751","                  in ``range(n_values[i])``"],"delete":["400","       *minmax_scale* function interface to :class:`sklearn.preprocessing.MinMaxScaler`.","525","    @deprecated(\"Attribute ``std_`` will be removed in 0.19. Use ``scale_`` instead\")","899","    the Interquartile Range (IQR). The IQR is the range between the 1st","900","    quartile (25th quantile) and the 3rd quartile (75th quantile).","962","    def __init__(self, with_centering=True, with_scaling=True, copy=True):","1000","            q = np.percentile(X, (25, 75), axis=0)","1058","def robust_scale(X, axis=0, with_centering=True, with_scaling=True, copy=True):","1107","                     copy=copy)","1726","                  ``X[:, i]``. Each feature value should be in ``range(n_values[i])``"]}]}},"8994d0ef61f66228fadb142bba2a809178b81b39":{"changes":{"sklearn\/datasets\/base.py":"MODIFY","doc\/whats_new.rst":"MODIFY","sklearn\/datasets\/tests\/test_base.py":"MODIFY"},"diff":{"sklearn\/datasets\/base.py":[{"add":["266","        .. versionadded:: 0.18","279","        .. versionadded:: 0.18","340","        .. versionadded:: 0.18","353","        .. versionadded:: 0.18","413","def load_digits(n_class=10, return_X_y=False):","433","    return_X_y : boolean, default=False.","434","        If True, returns ``(data, target)`` instead of a Bunch object.","435","        See below for more information about the `data` and `target` object.","436","","437","        .. versionadded:: 0.18","438","","448","    (data, target) : tuple if ``return_X_y`` is True","449","","450","        .. versionadded:: 0.18","451","","470","    target = data[:, -1].astype(np.int)","480","    if return_X_y:","481","        return flat_data, target","482","","484","                 target=target,","490","def load_diabetes(return_X_y=False):","502","    Parameters","503","    ----------","504","    return_X_y : boolean, default=False.","505","        If True, returns ``(data, target)`` instead of a Bunch object.","506","        See below for more information about the `data` and `target` object.","507","","508","        .. versionadded:: 0.18","509","","516","","517","    (data, target) : tuple if ``return_X_y`` is True","518","","519","        .. versionadded:: 0.18    ","524","    ","525","    if return_X_y:","526","        return data, target","527","","531","def load_linnerud(return_X_y=False):","539","    Parameters","540","    ----------","541","    return_X_y : boolean, default=False.","542","        If True, returns ``(data, target)`` instead of a Bunch object.","543","        See below for more information about the `data` and `target` object.","544","","545","        .. versionadded:: 0.18","546","","554","    ","555","    (data, target) : tuple if ``return_X_y`` is True","556","","557","        .. versionadded:: 0.18","572","    if return_X_y:","573","        return data_exercise, data_physiological","574","","581","def load_boston(return_X_y=False):","591","    Parameters","592","    ----------","593","    return_X_y : boolean, default=False.","594","        If True, returns ``(data, target)`` instead of a Bunch object.","595","        See below for more information about the `data` and `target` object.","596","","597","        .. versionadded:: 0.18","598","","606","    (data, target) : tuple if ``return_X_y`` is True","607","","608","        .. versionadded:: 0.18    ","609","","638","    if return_X_y:","639","        return data, target","640",""],"delete":["266","    .. versionadded:: 0.18","279","    .. versionadded:: 0.18","340","    .. versionadded:: 0.18","353","    .. versionadded:: 0.18","413","def load_digits(n_class=10):","460","    target = data[:, -1]","471","                 target=target.astype(np.int),","477","def load_diabetes():","502","def load_linnerud():","537","def load_boston():"]}],"doc\/whats_new.rst":[{"add":["232","   - Added parameter ``return_X_y`` and return type ``(data, target) : tuple`` option to","233","     :func:`load_iris` dataset ","234","     `#7049 <https:\/\/github.com\/scikit-learn\/scikit-learn\/pull\/7049>`_, ","236","     `#7152 <https:\/\/github.com\/scikit-learn\/scikit-learn\/pull\/7152>`_,","237","     :func:`load_digits` dataset,","238","     :func:`load_diabetes` dataset,","239","     :func:`load_linnerud` dataset,","240","     :func:`load_boston` dataset","241","     `#7154 <https:\/\/github.com\/scikit-learn\/scikit-learn\/pull\/7154>`_ by"],"delete":["232","   - Added new return type ``(data, target)`` : tuple option to","233","     :func:`load_iris` dataset, ","234","     (`#7049 <https:\/\/github.com\/scikit-learn\/scikit-learn\/pull\/7049>`_)","236","     (`#7152 <https:\/\/github.com\/scikit-learn\/scikit-learn\/pull\/7152>`_) by"]}],"sklearn\/datasets\/tests\/test_base.py":[{"add":["130","    # test return_X_y option","131","    X_y_tuple = load_digits(return_X_y=True)","132","    bunch = load_digits()","133","    assert_true(isinstance(X_y_tuple, tuple))","134","    assert_array_equal(X_y_tuple[0], bunch.data)","135","    assert_array_equal(X_y_tuple[1], bunch.target)","136","","174","    # test return_X_y option","175","    X_y_tuple = load_diabetes(return_X_y=True)","176","    bunch = load_diabetes()","177","    assert_true(isinstance(X_y_tuple, tuple))","178","    assert_array_equal(X_y_tuple[0], bunch.data)","179","    assert_array_equal(X_y_tuple[1], bunch.target)","180","","189","    # test return_X_y option","190","    X_y_tuple = load_linnerud(return_X_y=True)","191","    bunch = load_linnerud()","192","    assert_true(isinstance(X_y_tuple, tuple))","193","    assert_array_equal(X_y_tuple[0], bunch.data)","194","    assert_array_equal(X_y_tuple[1], bunch.target)","233","    # test return_X_y option","234","    X_y_tuple = load_boston(return_X_y=True)","235","    bunch = load_boston()","236","    assert_true(isinstance(X_y_tuple, tuple))","237","    assert_array_equal(X_y_tuple[0], bunch.data)","238","    assert_array_equal(X_y_tuple[1], bunch.target)"],"delete":[]}]}},"379f54be688f8ef5c15ad3682a7a8d7dcc471260":{"changes":{"sklearn\/mixture\/gmm.py":"MODIFY","sklearn\/mixture\/tests\/test_gmm.py":"MODIFY"},"diff":{"sklearn\/mixture\/gmm.py":[{"add":["86","    covar : array_like","101","    X : array","102","        Randomly generated sample. The shape depends on `n_samples`:","103","        (n_features,) if `1`","104","        (n_features, n_samples) otherwise","106","    _sample_gaussian(mean, covar, covariance_type='diag', n_samples=1,","107","                     random_state=None)","108","","109","","110","def _sample_gaussian(mean, covar, covariance_type='diag', n_samples=1,","111","                     random_state=None):","433","                X[comp_in_X] = _sample_gaussian("],"delete":["86","    covar : array_like, optional","101","    X : array, shape (n_features, n_samples)","102","        Randomly generated sample","425","                X[comp_in_X] = sample_gaussian("]}],"sklearn\/mixture\/tests\/test_gmm.py":[{"add":["35","    samples = mixture.gmm._sample_gaussian(","43","    samples = mixture.gmm._sample_gaussian(","53","    samples = mixture.gmm._sample_gaussian(","60","    x = mixture.gmm._sample_gaussian(","61","        [0, 0], [[4, 3], [1, .1]], covariance_type='full', random_state=42)"],"delete":["35","    samples = mixture.sample_gaussian(","43","    samples = mixture.sample_gaussian(","53","    samples = mixture.sample_gaussian(","60","    from sklearn.mixture import sample_gaussian","61","    x = sample_gaussian([0, 0], [[4, 3], [1, .1]],","62","                        covariance_type='full', random_state=42)"]}]}},"c7465f2c0ed10baaa11388cdd9d8698f0f889fc5":{"changes":{"sklearn\/linear_model\/ridge.py":"MODIFY"},"diff":{"sklearn\/linear_model\/ridge.py":[{"add":["212","        Regularization strength; must be a positive float. Regularization","213","        improves the conditioning of the problem and reduces the variance of","214","        the estimates. Larger values specify stronger regularization.","215","        Alpha corresponds to ``C^-1`` in other linear models such as ","216","        LogisticRegression or LinearSVC. If an array is passed, penalties are","217","        assumed to be specific to the targets. Hence they must correspond in","218","        number.","507","        Regularization strength; must be a positive float. Regularization","508","        improves the conditioning of the problem and reduces the variance of","509","        the estimates. Larger values specify stronger regularization.","510","        Alpha corresponds to ``C^-1`` in other linear models such as ","511","        LogisticRegression or LinearSVC. If an array is passed, penalties are","512","        assumed to be specific to the targets. Hence they must correspond in","513","        number.","652","        Regularization strength; must be a positive float. Regularization","653","        improves the conditioning of the problem and reduces the variance of","654","        the estimates. Larger values specify stronger regularization.","655","        Alpha corresponds to ``C^-1`` in other linear models such as ","656","        LogisticRegression or LinearSVC.","1097","        Regularization strength; must be a positive float. Regularization","1098","        improves the conditioning of the problem and reduces the variance of","1099","        the estimates. Larger values specify stronger regularization.","1100","        Alpha corresponds to ``C^-1`` in other linear models such as ","1101","        LogisticRegression or LinearSVC. ","1199","        Regularization strength; must be a positive float. Regularization","1200","        improves the conditioning of the problem and reduces the variance of","1201","        the estimates. Larger values specify stronger regularization.","1202","        Alpha corresponds to ``C^-1`` in other linear models such as ","1203","        LogisticRegression or LinearSVC. "],"delete":["212","        The l_2 penalty to be used. If an array is passed, penalties are","213","        assumed to be specific to targets","502","        Small positive values of alpha improve the conditioning of the problem","503","        and reduce the variance of the estimates.  Alpha corresponds to","504","        ``C^-1`` in other linear models such as LogisticRegression or","505","        LinearSVC. If an array is passed, penalties are assumed to be specific","506","        to the targets. Hence they must correspond in number.","645","        Small positive values of alpha improve the conditioning of the problem","646","        and reduce the variance of the estimates.  Alpha corresponds to","647","        ``C^-1`` in other linear models such as LogisticRegression or","648","        LinearSVC.","1089","        Small positive values of alpha improve the conditioning of the","1090","        problem and reduce the variance of the estimates.","1091","        Alpha corresponds to ``C^-1`` in other linear models such as","1092","        LogisticRegression or LinearSVC.","1190","        Small positive values of alpha improve the conditioning of the","1191","        problem and reduce the variance of the estimates.","1192","        Alpha corresponds to ``C^-1`` in other linear models such as","1193","        LogisticRegression or LinearSVC."]}]}}}